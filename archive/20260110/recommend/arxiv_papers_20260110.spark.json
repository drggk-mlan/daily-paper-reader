{
  "mode": "spark",
  "generated_at": "2026-01-10T20:10:40.752586+00:00",
  "deep_dive": [
    {
      "id": "2601.03661v1",
      "title": "AMIR-GRPO: Inducing Implicit Preference Signals into GRPO",
      "abstract": "Reinforcement learning has become the primary paradigm for aligning large language models (LLMs) on complex reasoning tasks, with group relative policy optimization (GRPO) widely used in large-scale post-training. However, GRPO faces structural limitations in reasoning-heavy settings: sequence-level advantage normalization introduces systematic length bias, penalties for low-quality trajectories are diluted, and the scalar objective discards rich pairwise preference information embedded in within-group reward rankings. As a result, valuable supervision from costly rollouts remains underutilized.   We propose AMIR-GRPO, which augments GRPO with an implicit DPO-style contrastive regularizer constructed directly from intra-group reward rankings, requiring no additional annotations. This mechanism amplifies suppression of low-reward trajectories, attenuates response-level length bias, and transforms each rollout group into a denser set of supervision constraints. Across multiple mathematical reasoning benchmarks, AMIR-GRPO consistently outperforms strong GRPO baselines, yields clearer separation between correct and incorrect reasoning chains, and delivers broader coverage gains beyond the subset of instances solved by standard GRPO.",
      "authors": [
        "Amir Hossein Yari",
        "Fajri Koto"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 07:22:58+00:00",
      "link": "https://arxiv.org/pdf/2601.03661v1",
      "tags": [
        "keyword:RL"
      ],
      "llm_score": 10.0,
      "llm_evidence": "Improves GRPO reinforcement learning for aligning large language models",
      "llm_tags": [
        "RL",
        "大厂llm"
      ]
    },
    {
      "id": "2601.05203v1",
      "title": "Symbolically regressing dark matter halo profiles using weak lensing",
      "abstract": "The structure of dark matter haloes is often described by radial density profiles motivated by cosmological simulations. These are typically assumed to have a fixed functional form (e.g. NFW), with some free parameters that can be constrained with observations. However, relying on simulations has the disadvantage that the resulting profiles depend on the dark matter model and the baryonic physics implementation, which are highly uncertain. Instead, we present a method to constrain halo density profiles directly from observations. This is done using a symbolic regression algorithm called Exhaustive Symbolic Regression (ESR). ESR searches for the optimal analytic expression to fit data, combining both accuracy and simplicity. We apply ESR to a sample of 149 galaxy clusters from the HSC-XXL survey to identify which functional forms perform best across the entire sample of clusters. We identify density profiles that statistically outperform NFW under a minimum-description-length criterion. Within the radial range probed by the weak-lensing data ($R \\sim 0.3 - 3$ h$^{-1}$ Mpc), the highest-ranked ESR profiles exhibit shallow inner behaviour and a maximum in the density profile. As a practical application, we show how the best-fitting ESR models can be used to obtain enclosed mass estimates. We find masses that are, on average, higher than those derived using NFW, highlighting a source of potential bias when assuming the wrong density profile. These results have important knock-on effects for analyses that utilise clusters, for example cosmological constraints on $σ_8$ and $Ω_m$ from cluster abundance and clustering. Beyond the HSC dataset, the method is readily applicable to any data constraining the dark matter distribution in galaxies and galaxy clusters, such as other weak lensing surveys, galactic rotation curves, or complementary probes.",
      "authors": [
        "Alicia Martín",
        "Tariq Yasin",
        "Deaglan J. Bartlett",
        "Harry Desmond",
        "Pedro G. Ferreira"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO",
        "astro-ph.GA"
      ],
      "published": "2026-01-08 18:26:43+00:00",
      "link": "https://arxiv.org/pdf/2601.05203v1",
      "tags": [
        "keyword:符号回归（示例）"
      ],
      "llm_score": 10.0,
      "llm_evidence": "Application of symbolic regression algorithm ESR to fit analytic expressions to data",
      "llm_tags": [
        "符号回归（示例）",
        "sr-bench"
      ]
    },
    {
      "id": "2601.03540v1",
      "title": "DeepSynth-Eval: Objectively Evaluating Information Consolidation in Deep Survey Writing",
      "abstract": "The evolution of Large Language Models (LLMs) towards autonomous agents has catalyzed progress in Deep Research. While retrieval capabilities are well-benchmarked, the post-retrieval synthesis stage--where agents must digest massive amounts of context and consolidate fragmented evidence into coherent, long-form reports--remains under-evaluated due to the subjectivity of open-ended writing. To bridge this gap, we introduce DeepSynth-Eval, a benchmark designed to objectively evaluate information consolidation capabilities. We leverage high-quality survey papers as gold standards, reverse-engineering research requests and constructing \"Oracle Contexts\" from their bibliographies to isolate synthesis from retrieval noise. We propose a fine-grained evaluation protocol using General Checklists (for factual coverage) and Constraint Checklists (for structural organization), transforming subjective judgment into verifiable metrics. Experiments across 96 tasks reveal that synthesizing information from hundreds of references remains a significant challenge. Our results demonstrate that agentic plan-and-write workflows significantly outperform single-turn generation, effectively reducing hallucinations and improving adherence to complex structural constraints.",
      "authors": [
        "Hongzhi Zhang",
        "Yuanze Hu",
        "Tinghai Zhang",
        "Jia Fu",
        "Tao Wang",
        "Junwei Jing",
        "Zhaoxin Fan",
        "Qi Wang",
        "Ruiming Tang",
        "Han Li",
        "Guorui Zhou",
        "Kun Gai"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 03:07:52+00:00",
      "link": "https://arxiv.org/pdf/2601.03540v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ],
      "llm_score": 9.0,
      "llm_evidence": "Benchmark for evaluating LLM information consolidation and synthesis capabilities",
      "llm_tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.03550v1",
      "title": "ReEfBench: Quantifying the Reasoning Efficiency of LLMs",
      "abstract": "Test-time scaling has enabled Large Language Models (LLMs) to tackle complex reasoning, yet the limitations of current Chain-of-Thought (CoT) evaluation obscures whether performance gains stem from genuine reasoning or mere verbosity. To address this, (1) we propose a novel neuro-symbolic framework for the non-intrusive, comprehensive process-centric evaluation of reasoning. (2) Through this lens, we identify four distinct behavioral prototypes and diagnose the failure modes. (3) We examine the impact of inference mode, training strategy, and model scale. Our analysis reveals that extended token generation is not a prerequisite for deep reasoning. Furthermore, we reveal critical constraints: mixing long and short CoT data in training risks in premature saturation and collapse, while distillation into smaller models captures behavioral length but fails to replicate logical efficacy due to intrinsic capacity limits.",
      "authors": [
        "Zhizhang Fu",
        "Yuancheng Gu",
        "Chenkai Hu",
        "Hanmeng Liu",
        "Yue Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 03:33:07+00:00",
      "link": "https://arxiv.org/pdf/2601.03550v1",
      "tags": [
        "keyword:符号回归（示例）"
      ],
      "llm_score": 9.0,
      "llm_evidence": "Neuro-symbolic framework for evaluating LLM reasoning efficiency",
      "llm_tags": [
        "符号回归（示例）",
        "大厂llm"
      ]
    },
    {
      "id": "2601.04352v1",
      "title": "Comparative Analysis of Custom CNN Architectures versus Pre-trained Models and Transfer Learning: A Study on Five Bangladesh Datasets",
      "abstract": "This study presents a comprehensive comparative analysis of custom-built Convolutional Neural Networks (CNNs) against popular pre-trained architectures (ResNet-18 and VGG-16) using both feature extraction and transfer learning approaches. We evaluated these models across five diverse image classification datasets from Bangladesh: Footpath Vision, Auto Rickshaw Detection, Mango Image Classification, Paddy Variety Recognition, and Road Damage Detection. Our experimental results demonstrate that transfer learning with fine-tuning consistently outperforms both custom CNNs built from scratch and feature extraction methods, achieving accuracy improvements ranging from 3% to 76% across different datasets. Notably, ResNet-18 with fine-tuning achieved perfect 100% accuracy on the Road Damage BD dataset. While custom CNNs offer advantages in model size (3.4M parameters vs. 11-134M for pre-trained models) and training efficiency on simpler tasks, pre-trained models with transfer learning provide superior performance, particularly on complex classification tasks with limited training data. This research provides practical insights for practitioners in selecting appropriate deep learning approaches based on dataset characteristics, computational resources, and performance requirements.",
      "authors": [
        "Ibrahim Tanvir",
        "Alif Ruslan",
        "Sartaj Solaiman"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-07 19:36:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04352v1",
      "tags": [
        "keyword:resnet"
      ],
      "llm_score": 8.0,
      "llm_evidence": "Evaluates ResNet-18 performance across multiple image classification datasets",
      "llm_tags": [
        "resnet"
      ]
    },
    {
      "id": "2601.03525v1",
      "title": "VeRPO: Verifiable Dense Reward Policy Optimization for Code Generation",
      "abstract": "Effective reward design is a central challenge in Reinforcement Learning (RL) for code generation. Mainstream pass/fail outcome rewards enforce functional correctness via executing unit tests, but the resulting sparsity limits potential performance gains. While recent work has explored external Reward Models (RM) to generate richer, continuous rewards, the learned RMs suffer from reward misalignment and prohibitive computational cost. In this paper, we introduce \\textbf{VeRPO} (\\textbf{V}erifiable D\\textbf{e}nse \\textbf{R}eward \\textbf{P}olicy \\textbf{O}ptimization), a novel RL framework for code generation that synthesizes \\textit{robust and dense rewards fully grounded in verifiable execution feedback}. The core idea of VeRPO is constructing dense rewards from weighted partial success: by dynamically estimating the difficulty weight of each unit test based on the execution statistics during training, a dense reward is derived from the sum of weights of the passed unit tests. To solidify the consistency between partial success and end-to-end functional correctness, VeRPO further integrates the dense signal with global execution outcomes, establishing a robust and dense reward paradigm relying solely on verifiable execution feedback. Extensive experiments across diverse benchmarks and settings demonstrate that VeRPO consistently outperforms outcome-driven and RM-based baselines, achieving up to +8.83\\% gain in pass@1 with negligible time cost (< 0.02\\%) and zero GPU memory overhead.",
      "authors": [
        "Longwen Wang",
        "Xuan'er Wu",
        "Xiaohui Hu",
        "Yirui Liu",
        "Yuankai Fan",
        "Kaidong Yu",
        "Qizhen Weng",
        "Wei Xi",
        "Xuelong Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 02:29:49+00:00",
      "link": "https://arxiv.org/pdf/2601.03525v1",
      "tags": [
        "keyword:RL"
      ],
      "llm_score": 9.0,
      "llm_evidence": "Reinforcement learning framework for code generation with dense rewards",
      "llm_tags": [
        "RL"
      ]
    },
    {
      "id": "2601.04540v1",
      "title": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation",
      "abstract": "Recent advancements in large language models (LLMs) have automated various software engineering tasks, with benchmarks emerging to evaluate their capabilities. However, for adaptation, a critical activity during code reuse, there is no benchmark to assess LLMs' performance, leaving their practical utility in this area unclear. To fill this gap, we propose AdaptEval, a benchmark designed to evaluate LLMs on code snippet adaptation. Unlike existing benchmarks, AdaptEval incorporates the following three distinctive features: First, Practical Context. Tasks in AdaptEval are derived from developers' practices, preserving rich contextual information from Stack Overflow and GitHub communities. Second, Multi-granularity Annotation. Each task is annotated with requirements at both task and adaptation levels, supporting the evaluation of LLMs across diverse adaptation scenarios. Third, Fine-grained Evaluation. AdaptEval includes a two-tier testing framework combining adaptation-level and function-level tests, which enables evaluating LLMs' performance across various individual adaptations. Based on AdaptEval, we conduct the first empirical study to evaluate six instruction-tuned LLMs and especially three reasoning LLMs on code snippet adaptation. Experimental results demonstrate that AdaptEval enables the assessment of LLMs' adaptation capabilities from various perspectives. It also provides critical insights into their current limitations, particularly their struggle to follow explicit instructions. We hope AdaptEval can facilitate further investigation and enhancement of LLMs' capabilities in code snippet adaptation, supporting their real-world applications.",
      "authors": [
        "Tanghaoran Zhang",
        "Xinjun Mao",
        "Shangwen Wang",
        "Yuxin Zhao",
        "Yao Lu",
        "Jin Zhang",
        "Zhang Zhang",
        "Kang Yang",
        "Yue Yu"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "published": "2026-01-08 03:13:20+00:00",
      "link": "https://arxiv.org/pdf/2601.04540v1",
      "tags": [
        "query:sr-bench"
      ],
      "llm_score": 9.0,
      "llm_evidence": "Standardized benchmark and evaluation framework for large language models",
      "llm_tags": [
        "sr-bench",
        "大厂llm"
      ]
    },
    {
      "id": "2601.03605v1",
      "title": "DiVA: Fine-grained Factuality Verification with Agentic-Discriminative Verifier",
      "abstract": "Despite the significant advancements of Large Language Models (LLMs), their factuality remains a critical challenge, fueling growing interest in factuality verification. Existing research on factuality verification primarily conducts binary judgments (e.g., correct or incorrect), which fails to distinguish varying degrees of error severity. This limits its utility for applications such as fine-grained evaluation and preference optimization. To bridge this gap, we propose the Agentic Discriminative Verifier (DiVA), a hybrid framework that synergizes the agentic search capabilities of generative models with the precise scoring aptitude of discriminative models. We also construct a new benchmark, FGVeriBench, as a robust testbed for fine-grained factuality verification. Experimental results on FGVeriBench demonstrate that our DiVA significantly outperforms existing methods on factuality verification for both general and multi-hop questions.",
      "authors": [
        "Hui Huang",
        "Muyun Yang",
        "Yuki Arase"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 05:35:01+00:00",
      "link": "https://arxiv.org/pdf/2601.03605v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ],
      "llm_score": 9.0,
      "llm_evidence": "Proposes a new benchmark (FGVeriBench) for fine-grained factuality evaluation of LLMs.",
      "llm_tags": [
        "大厂llm"
      ]
    },
    {
      "id": "2601.04051v1",
      "title": "Symbolic Regression for Shared Expressions: Introducing Partial Parameter Sharing",
      "abstract": "Symbolic Regression aims to find symbolic expressions that describe datasets. Due to better interpretability, it is a machine learning paradigm particularly powerful for scientific discovery. In recent years, several works have expanded the concept to allow the description of similar phenomena using a single expression with varying sets of parameters, thereby introducing categorical variables. Some previous works allow only \"non-shared\" (category-value-specific) parameters, and others also incorporate \"shared\" (category-value-agnostic) parameters. We expand upon those efforts by considering multiple categorical variables, and introducing intermediate levels of parameter sharing. With two categorical variables, an intermediate level of parameter sharing emerges, i.e., parameters which are shared across either category but change across the other. The new approach potentially decreases the number of parameters, while revealing additional information about the problem. Using a synthetic, fitting-only example, we test the limits of this setup in terms of data requirement reduction and transfer learning. As a real-world symbolic regression example, we demonstrate the benefits of the proposed approach on an astrophysics dataset used in a previous study, which considered only one categorical variable. We achieve a similar fit quality but require significantly fewer individual parameters, and extract additional information about the problem.",
      "authors": [
        "Viktor Martinek",
        "Roland Herzog"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 16:12:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04051v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ],
      "llm_score": 9.0,
      "llm_evidence": "Proposes new methods for symbolic regression using partial parameter sharing",
      "llm_tags": [
        "符号回归（示例）"
      ]
    },
    {
      "id": "2601.04397v1",
      "title": "Performance Analysis of Image Classification on Bangladeshi Datasets",
      "abstract": "Convolutional Neural Networks (CNNs) have demonstrated remarkable success in image classification tasks; however, the choice between designing a custom CNN from scratch and employing established pre-trained architectures remains an important practical consideration. In this work, we present a comparative analysis of a custom-designed CNN and several widely used deep learning architectures, including VGG-16, ResNet-50, and MobileNet, for an image classification task. The custom CNN is developed and trained from scratch, while the popular architectures are employed using transfer learning under identical experimental settings. All models are evaluated using standard performance metrics such as accuracy, precision, recall, and F1-score. Experimental results show that pre-trained CNN architectures consistently outperform the custom CNN in terms of classification accuracy and convergence speed, particularly when training data is limited. However, the custom CNN demonstrates competitive performance with significantly fewer parameters and reduced computational complexity. This study highlights the trade-offs between model complexity, performance, and computational efficiency, and provides practical insights into selecting appropriate CNN architectures for image classification problems.",
      "authors": [
        "Mohammed Sami Khan",
        "Fabiha Muniat",
        "Rowzatul Zannat"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 21:15:16+00:00",
      "link": "https://arxiv.org/pdf/2601.04397v1",
      "tags": [
        "keyword:resnet"
      ],
      "llm_score": 8.0,
      "llm_evidence": "Evaluates ResNet-50 performance in a comparative image classification study",
      "llm_tags": [
        "resnet"
      ]
    },
    {
      "id": "2601.03703v1",
      "title": "TreeAdv: Tree-Structured Advantage Redistribution for Group-Based RL",
      "abstract": "Reinforcement learning with group-based objectives, such as Group Relative Policy Optimization (GRPO), is a common framework for aligning large language models on complex reasoning tasks. However, standard GRPO treats each rollout trajectory as an independent flat sequence and assigns a single sequence-level advantage to all tokens, which leads to sample inefficiency and a length bias toward verbose, redundant chains of thought without improving logical depth. We introduce TreeAdv (Tree-Structured Advantage Redistribution for Group-Based RL), which makes the tree structure of group rollouts explicit for both exploration and advantage assignment. Specifically, TreeAdv builds a group of trees (a forest) based on an entropy-driven sampling method where each tree branches at high-uncertainty decisions while sharing low-uncertainty tokens across rollouts. Then, TreeAdv aggregates token-level advantages for internal tree segments by redistributing the advantages of complete rollouts (all leaf nodes), and TreeAdv can easily apply to group-based objectives such as GRPO or GSPO. Across 10 math reasoning benchmarks, TreeAdv consistently outperforms GRPO and GSPO, while using substantially fewer generated tokens under identical supervision, data, and decoding budgets.",
      "authors": [
        "Lang Cao",
        "Hui Ruan",
        "Yongqian Li",
        "Peng Chao",
        "Wu Ning",
        "Haonan Song",
        "Renhong Chen",
        "Yitong Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 08:42:14+00:00",
      "link": "https://arxiv.org/pdf/2601.03703v1",
      "tags": [
        "keyword:RL"
      ],
      "llm_score": 9.0,
      "llm_evidence": "Applies reinforcement learning techniques like GRPO to align large language models",
      "llm_tags": [
        "RL",
        "大厂llm"
      ]
    }
  ],
  "quick_skim": [
    {
      "id": "2601.03486v1",
      "title": "Adaptive Model-Based Reinforcement Learning for Orbit Feedback Control in NSLS-II Storage Ring",
      "abstract": "The National Synchrotron Light Source II (NSLS-II) uses highly stable electron beam to produce high-quality X-ray beams with high brightness and low-emittance synchrotron radiation. The traditional algorithm to stabilize the beam applies singular value decomposition (SVD) on the orbit response matrix to remove noise and extract actions. Supervised learning has been studied on NSLS-II storage ring stabilization and other accelerator facilities recently. Several problems, for example, machine status drifting, environment noise, and non-linear accelerator dynamics, remain unresolved in the SVD-based and supervised learning algorithms. To address these problems, we propose an adaptive training framework based on model-based reinforcement learning. This framework consists of two types of optimizations: trajectory optimization attempts to minimize the expected total reward in a differentiable environment, and online model optimization learns non-linear machine dynamics through the agent-environment interaction. Through online training, this framework tracks the internal status drifting in the electron beam ring. Simulation and real in-facility experiments on NSLS-II reveal that our method stabilizes the beam position and minimizes the alignment error, defined as the root mean square (RMS) error between adjusted beam positions and the reference position, down to ~1$μ$m.",
      "authors": [
        "Zeyu Dong",
        "Yuke Tian",
        "Yu Sun"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-01-07 00:49:57+00:00",
      "link": "https://arxiv.org/pdf/2601.03486v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ],
      "llm_score": 7.0,
      "llm_evidence": "Applies model-based reinforcement learning to stabilize electron beams in a storage ring facility.",
      "llm_tags": [
        "RL"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2601.03496v1",
      "title": "STELLA: Self-Reflective Terminology-Aware Framework for Building an Aerospace Information Retrieval Benchmark",
      "abstract": "Tasks in the aerospace industry heavily rely on searching and reusing large volumes of technical documents, yet there is no public information retrieval (IR) benchmark that reflects the terminology- and query-intent characteristics of this domain. To address this gap, this paper proposes the STELLA (Self-Reflective TErminoLogy-Aware Framework for BuiLding an Aerospace Information Retrieval Benchmark) framework. Using this framework, we introduce the STELLA benchmark, an aerospace-specific IR evaluation set constructed from NASA Technical Reports Server (NTRS) documents via a systematic pipeline that comprises document layout detection, passage chunking, terminology dictionary construction, synthetic query generation, and cross-lingual extension. The framework generates two types of queries: the Terminology Concordant Query (TCQ), which includes the terminology verbatim to evaluate lexical matching, and the Terminology Agnostic Query (TAQ), which utilizes the terminology's description to assess semantic matching. This enables a disentangled evaluation of the lexical and semantic matching capabilities of embedding models. In addition, we combine Chain-of-Density (CoD) and the Self-Reflection method with query generation to improve quality and implement a hybrid cross-lingual extension that reflects real user querying practices. Evaluation of seven embedding models on the STELLA benchmark shows that large decoder-based embedding models exhibit the strongest semantic understanding, while lexical matching methods such as BM25 remain highly competitive in domains where exact lexical matching technical term is crucial. The STELLA benchmark provides a reproducible foundation for reliable performance evaluation and improvement of embedding models in aerospace-domain IR tasks. The STELLA benchmark can be found in https://huggingface.co/datasets/telepix/STELLA.",
      "authors": [
        "Bongmin Kim"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL"
      ],
      "published": "2026-01-07 01:23:44+00:00",
      "link": "https://arxiv.org/pdf/2601.03496v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Framework for building specialized information retrieval benchmarks for technical reports",
      "llm_tags": [
        "sr-bench",
        "大厂llm"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.03515v1",
      "title": "Mem-Gallery: Benchmarking Multimodal Long-Term Conversational Memory for MLLM Agents",
      "abstract": "Long-term memory is a critical capability for multimodal large language model (MLLM) agents, particularly in conversational settings where information accumulates and evolves over time. However, existing benchmarks either evaluate multi-session memory in text-only conversations or assess multimodal understanding within localized contexts, failing to evaluate how multimodal memory is preserved, organized, and evolved across long-term conversational trajectories. Thus, we introduce Mem-Gallery, a new benchmark for evaluating multimodal long-term conversational memory in MLLM agents. Mem-Gallery features high-quality multi-session conversations grounded in both visual and textual information, with long interaction horizons and rich multimodal dependencies. Building on this dataset, we propose a systematic evaluation framework that assesses key memory capabilities along three functional dimensions: memory extraction and test-time adaptation, memory reasoning, and memory knowledge management. Extensive benchmarking across thirteen memory systems reveals several key findings, highlighting the necessity of explicit multimodal information retention and memory organization, the persistent limitations in memory reasoning and knowledge management, as well as the efficiency bottleneck of current models.",
      "authors": [
        "Yuanchen Bei",
        "Tianxin Wei",
        "Xuying Ning",
        "Yanjun Zhao",
        "Zhining Liu",
        "Xiao Lin",
        "Yada Zhu",
        "Hendrik Hamann",
        "Jingrui He",
        "Hanghang Tong"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 02:03:13+00:00",
      "link": "https://arxiv.org/pdf/2601.03515v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ],
      "llm_score": 7.0,
      "llm_evidence": "Benchmark for evaluating multimodal long-term memory in LLM agents",
      "llm_tags": [
        "大厂llm"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2601.03500v1",
      "title": "SDCD: Structure-Disrupted Contrastive Decoding for Mitigating Hallucinations in Large Vision-Language Models",
      "abstract": "Large Vision-Language Models (LVLMs) demonstrate significant progress in multimodal understanding and reasoning, yet object hallucination remains a critical challenge. While existing research focuses on mitigating language priors or high-level statistical biases, they often overlook the internal complexities of the visual encoding process. We identify that visual statistical bias, arising from the inherent Bag-of-Patches behavior of Vision Encoders under weak structural supervision, acts as a contributing factor of object hallucinations. Under this bias, models prioritize local texture features within individual patches over holistic geometric structures. This tendency may induce spurious visual confidence and result in hallucinations. To address this, we introduce a training-free algorithm called Structure-Disrupted Contrastive Decoding (SDCD), which performs contrastive calibration of the output distribution by introducing a shuffled structure-disrupted view. By penalizing tokens that maintain high confidence under this structure-less view, SDCD effectively suppresses the texture-driven bias. Experimental results demonstrate that SDCD significantly mitigates hallucinations across multiple benchmarks and enhances the overall multimodal capabilities of LVLMs.",
      "authors": [
        "Yuxuan Xia",
        "Siheng Wang",
        "Peng Li"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 01:27:58+00:00",
      "link": "https://arxiv.org/pdf/2601.03500v1",
      "tags": [
        "keyword:resnet"
      ],
      "llm_score": 6.0,
      "llm_evidence": "mitigating hallucinations in large vision-language models",
      "llm_tags": [
        "大厂llm"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.03676v1",
      "title": "Towards Compositional Generalization of LLMs via Skill Taxonomy Guided Data Synthesis",
      "abstract": "Large Language Models (LLMs) and agent-based systems often struggle with compositional generalization due to a data bottleneck in which complex skill combinations follow a long-tailed, power-law distribution, limiting both instruction-following performance and generalization in agent-centric tasks. To address this challenge, we propose STEPS, a Skill Taxonomy guided Entropy-based Post-training data Synthesis framework for generating compositionally challenging data. STEPS explicitly targets compositional generalization by uncovering latent relationships among skills and organizing them into an interpretable, hierarchical skill taxonomy using structural information theory. Building on this taxonomy, we formulate data synthesis as a constrained information maximization problem, selecting skill combinations that maximize marginal structural information within the hierarchy while preserving semantic coherence. Experiments on challenging instruction-following benchmarks show that STEPS outperforms existing data synthesis baselines, while also yielding improved compositional generalization in downstream agent-based evaluations.",
      "authors": [
        "Yifan Wei",
        "Li Du",
        "Xiaoyan Yu",
        "Yang Feng",
        "Angsheng Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 07:58:51+00:00",
      "link": "https://arxiv.org/pdf/2601.03676v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench",
        "query:大厂llm"
      ],
      "llm_score": 7.0,
      "llm_evidence": "Post-training data synthesis for improving LLM compositional generalization",
      "llm_tags": [
        "大厂llm"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2601.03509v1",
      "title": "Evolving Programmatic Skill Networks",
      "abstract": "We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional network that evolves through experience. PSN defines three core mechanisms instantiated via large language models: (1)REFLECT for structured fault localization over skill compositions, (2) progressive optimization with maturity-aware update gating that stabilizes reliable skills while maintaining plasticity for uncertain ones, and (3) canonical structural refactoring under rollback validation that maintains network compactness. We further show that PSN's learning dynamics exhibit structural parallels to neural network training. Experiments on MineDojo and Crafter demonstrate robust skill reuse, rapid adaptation, and strong generalization across open-ended task distributions.\\footnote{We plan to open-source the code.",
      "authors": [
        "Haochen Shi",
        "Xingdi Yuan",
        "Bang Liu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "published": "2026-01-07 01:43:25+00:00",
      "link": "https://arxiv.org/pdf/2601.03509v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Uses symbolic programs and LLMs to evolve compositional skill networks for embodied agents.",
      "llm_tags": [
        "符号回归（示例）",
        "RL"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.03686v1",
      "title": "Dual-Attention Heterogeneous GNN for Multi-robot Collaborative Area Search via Deep Reinforcement Learning",
      "abstract": "In multi-robot collaborative area search, a key challenge is to dynamically balance the two objectives of exploring unknown areas and covering specific targets to be rescued. Existing methods are often constrained by homogeneous graph representations, thus failing to model and balance these distinct tasks. To address this problem, we propose a Dual-Attention Heterogeneous Graph Neural Network (DA-HGNN) trained using deep reinforcement learning. Our method constructs a heterogeneous graph that incorporates three entity types: robot nodes, frontier nodes, and interesting nodes, as well as their historical states. The dual-attention mechanism comprises the relational-aware attention and type-aware attention operations. The relational-aware attention captures the complex spatio-temporal relationships among robots and candidate goals. Building on this relational-aware heterogeneous graph, the type-aware attention separately computes the relevance between robots and each goal type (frontiers vs. points of interest), thereby decoupling the exploration and coverage from the unified tasks. Extensive experiments conducted in interactive 3D scenarios within the iGibson simulator, leveraging the Gibson and MatterPort3D datasets, validate the superior scalability and generalization capability of the proposed approach.",
      "authors": [
        "Lina Zhu",
        "Jiyu Cheng",
        "Yuehu Liu",
        "Wei Zhang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-07 08:18:49+00:00",
      "link": "https://arxiv.org/pdf/2601.03686v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ],
      "llm_score": 7.0,
      "llm_evidence": "Applies Deep Reinforcement Learning to multi-robot collaborative search tasks",
      "llm_tags": [
        "RL"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2601.03511v1",
      "title": "IntroLM: Introspective Language Models via Prefilling-Time Self-Evaluation",
      "abstract": "A major challenge for the operation of large language models (LLMs) is how to predict whether a specific LLM will produce sufficiently high-quality output for a given query. Existing approaches rely on external classifiers, most commonly BERT based models, which suffer from limited context windows, constrained representational capacity, and additional computational overhead. We propose IntroLM, a method that enables causal language models to predict their own output quality during the prefilling phase without affecting generation using introspective tokens. By introducing token conditional LoRA that activates only for the introspective token, the model learns to predict the output quality for a given query while preserving the original backbone behavior and avoiding external evaluators. On question answering benchmarks, IntroLM applied to Qwen3 8B achieves a ROC AUC of 90 precent for success prediction, outperforming a DeBERTa classifier by 14 precent. When integrated into multi model routing systems, IntroLM achieves superior cost performance tradeoffs, reducing latency by up to 33 precent and large model usage by up to 50 precent at matched reliability.",
      "authors": [
        "Hossein Hosseini Kasnavieh",
        "Gholamreza Haffari",
        "Chris Leckie",
        "Adel N. Toosi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-07 01:48:17+00:00",
      "link": "https://arxiv.org/pdf/2601.03511v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Method for LLMs to predict output quality, relevant to LLM training and evaluation methodologies.",
      "llm_tags": [
        "大厂llm"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.03590v1",
      "title": "Can LLMs See Without Pixels? Benchmarking Spatial Intelligence from Textual Descriptions",
      "abstract": "Recent advancements in Spatial Intelligence (SI) have predominantly relied on Vision-Language Models (VLMs), yet a critical question remains: does spatial understanding originate from visual encoders or the fundamental reasoning backbone? Inspired by this question, we introduce SiT-Bench, a novel benchmark designed to evaluate the SI performance of Large Language Models (LLMs) without pixel-level input, comprises over 3,800 expert-annotated items across five primary categories and 17 subtasks, ranging from egocentric navigation and perspective transformation to fine-grained robotic manipulation. By converting single/multi-view scenes into high-fidelity, coordinate-aware textual descriptions, we challenge LLMs to perform symbolic textual reasoning rather than visual pattern matching. Evaluation results of state-of-the-art (SOTA) LLMs reveals that while models achieve proficiency in localized semantic tasks, a significant \"spatial gap\" remains in global consistency. Notably, we find that explicit spatial reasoning significantly boosts performance, suggesting that LLMs possess latent world-modeling potential. Our proposed dataset SiT-Bench serves as a foundational resource to foster the development of spatially-grounded LLM backbones for future VLMs and embodied agents. Our code and benchmark will be released at https://github.com/binisalegend/SiT-Bench .",
      "authors": [
        "Zhongbin Guo",
        "Zhen Yang",
        "Yushan Li",
        "Xinyue Zhang",
        "Wenyu Gao",
        "Jiacheng Wang",
        "Chengzhi Li",
        "Xiangrui Liu",
        "Ping Jian"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 05:13:52+00:00",
      "link": "https://arxiv.org/pdf/2601.03590v1",
      "tags": [
        "query:sr-bench"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Benchmark for LLM spatial intelligence using symbolic textual descriptions",
      "llm_tags": [
        "大厂llm"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.03597v1",
      "title": "From Chains to Graphs: Self-Structured Reasoning for General-Domain LLMs",
      "abstract": "Large Language Models (LLMs) show strong reasoning ability in open-domain question answering, yet their reasoning processes are typically linear and often logically inconsistent. In contrast, real-world reasoning requires integrating multiple premises and solving subproblems in parallel. Existing methods, such as Chain-of-Thought (CoT), express reasoning in a linear textual form, which may appear coherent but frequently leads to inconsistent conclusions. Recent approaches rely on externally provided graphs and do not explore how LLMs can construct and use their own graph-structured reasoning, particularly in open-domain QA. To fill this gap, we novelly explore graph-structured reasoning of LLMs in general-domain question answering. We propose Self-Graph Reasoning (SGR), a framework that enables LLMs to explicitly represent their reasoning process as a structured graph before producing the final answer. We further construct a graph-structured reasoning dataset that merges multiple candidate reasoning graphs into refined graph structures for model training. Experiments on five QA benchmarks across both general and specialized domains show that SGR consistently improves reasoning consistency and yields a 17.74% gain over the base model. The LLaMA-3.3-70B model fine-tuned with SGR performs comparably to GPT-4o and surpasses Claude-3.5-Haiku, demonstrating the effectiveness of graph-structured reasoning.",
      "authors": [
        "Yingjian Chen",
        "Haoran Liu",
        "Yinhong Liu",
        "Sherry T. Tong",
        "Aosong Feng",
        "Jinghui Lu",
        "Juntao Zhang",
        "Yusuke Iwasawa",
        "Yutaka Matsuo",
        "Irene Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 05:27:41+00:00",
      "link": "https://arxiv.org/pdf/2601.03597v1",
      "tags": [
        "query:大厂llm"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Reasoning methodologies and architectural improvements for general-domain LLMs",
      "llm_tags": [
        "大厂llm"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.03604v1",
      "title": "Interleaved Tool-Call Reasoning for Protein Function Understanding",
      "abstract": "Recent advances in large language models (LLMs) have highlighted the effectiveness of chain-of-thought reasoning in symbolic domains such as mathematics and programming. However, our study shows that directly transferring such text-based reasoning paradigms to protein function understanding is ineffective: reinforcement learning mainly amplifies superficial keyword patterns while failing to introduce new biological knowledge, resulting in limited generalization. We argue that protein function prediction is a knowledge-intensive scientific task that fundamentally relies on external biological priors and computational tools rather than purely internal reasoning. To address this gap, we propose PFUA, a tool-augmented protein reasoning agent that unifies problem decomposition, tool invocation, and grounded answer generation. Instead of relying on long unconstrained reasoning traces, PFUA integrates domain-specific tools to produce verifiable intermediate evidence. Experiments on four benchmarks demonstrate that PFUA consistently outperforms text-only reasoning models with an average performance improvement of 103%.",
      "authors": [
        "Chuanliu Fan",
        "Zicheng Ma",
        "Huanran Meng",
        "Aijia Zhang",
        "Wenjie Du",
        "Jun Zhang",
        "Yi Qin Gao",
        "Ziqiang Cao",
        "Guohong Fu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 05:34:38+00:00",
      "link": "https://arxiv.org/pdf/2601.03604v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Explores reinforcement learning and LLM reasoning in scientific domains",
      "llm_tags": [
        "RL",
        "大厂llm"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.03624v1",
      "title": "Architecting Agentic Communities using Design Patterns",
      "abstract": "The rapid evolution of Large Language Models (LLM) and subsequent Agentic AI technologies requires systematic architectural guidance for building sophisticated, production-grade systems. This paper presents an approach for architecting such systems using design patterns derived from enterprise distributed systems standards, formal methods, and industry practice. We classify these patterns into three tiers: LLM Agents (task-specific automation), Agentic AI (adaptive goal-seekers), and Agentic Communities (organizational frameworks where AI agents and human participants coordinate through formal roles, protocols, and governance structures). We focus on Agentic Communities - coordination frameworks encompassing LLM Agents, Agentic AI entities, and humans - most relevant for enterprise and industrial applications. Drawing on established coordination principles from distributed systems, we ground these patterns in a formal framework that specifies collaboration agreements where AI agents and humans fill roles within governed ecosystems. This approach provides both practical guidance and formal verification capabilities, enabling expression of organizational, legal, and ethical rules through accountability mechanisms that ensure operational and verifiable governance of inter-agent communication, negotiation, and intent modeling. We validate this framework through a clinical trial matching case study. Our goal is to provide actionable guidance to practitioners while maintaining the formal rigor essential for enterprise deployment in dynamic, multi-agent ecosystems.",
      "authors": [
        "Zoran Milosevic",
        "Fethi Rabhi"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 06:10:07+00:00",
      "link": "https://arxiv.org/pdf/2601.03624v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Discusses architectural guidance for LLM agents and agentic communities",
      "llm_tags": [
        "大厂llm"
      ],
      "quick_tier": "6"
    }
  ],
  "stats": {
    "mode": "spark",
    "tag_count": 5,
    "deep_candidates": 72,
    "deep_cap": 11,
    "deep_selected": 11,
    "quick_candidates": 70,
    "quick_target": 12,
    "quick_selected": 12
  }
}