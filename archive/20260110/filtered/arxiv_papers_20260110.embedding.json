{
  "top_k": 100,
  "generated_at": "2026-01-10T17:26:37.644892+00:00",
  "papers": [
    {
      "id": "2601.05251v1",
      "title": "Mesh4D: 4D Mesh Reconstruction and Tracking from Monocular Video",
      "abstract": "We propose Mesh4D, a feed-forward model for monocular 4D mesh reconstruction. Given a monocular video of a dynamic object, our model reconstructs the object's complete 3D shape and motion, represented as a deformation field. Our key contribution is a compact latent space that encodes the entire animation sequence in a single pass. This latent space is learned by an autoencoder that, during training, is guided by the skeletal structure of the training objects, providing strong priors on plausible deformations. Crucially, skeletal information is not required at inference time. The encoder employs spatio-temporal attention, yielding a more stable representation of the object's overall deformation. Building on this representation, we train a latent diffusion model that, conditioned on the input video and the mesh reconstructed from the first frame, predicts the full animation in one shot. We evaluate Mesh4D on reconstruction and novel view synthesis benchmarks, outperforming prior methods in recovering accurate 3D shape and deformation.",
      "authors": [
        "Zeren Jiang",
        "Chuanxia Zheng",
        "Iro Laina",
        "Diane Larlus",
        "Andrea Vedaldi"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:59:56+00:00",
      "link": "https://arxiv.org/pdf/2601.05251v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.05249v1",
      "title": "RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes",
      "abstract": "Nighttime color constancy remains a challenging problem in computational photography due to low-light noise and complex illumination conditions. We present RL-AWB, a novel framework combining statistical methods with deep reinforcement learning for nighttime white balance. Our method begins with a statistical algorithm tailored for nighttime scenes, integrating salient gray pixel detection with novel illumination estimation. Building on this foundation, we develop the first deep reinforcement learning approach for color constancy that leverages the statistical algorithm as its core, mimicking professional AWB tuning experts by dynamically optimizing parameters for each image. To facilitate cross-sensor evaluation, we introduce the first multi-sensor nighttime dataset. Experiment results demonstrate that our method achieves superior generalization capability across low-light and well-illuminated images. Project page: https://ntuneillee.github.io/research/rl-awb/",
      "authors": [
        "Yuan-Kang Lee",
        "Kuan-Lin Chen",
        "Chia-Che Chang",
        "Yu-Lun Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:59:55+00:00",
      "link": "https://arxiv.org/pdf/2601.05249v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.05248v1",
      "title": "LaST$_{0}$: Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model",
      "abstract": "Vision-Language-Action (VLA) models have recently demonstrated strong generalization capabilities in robotic manipulation. Some existing VLA approaches attempt to improve action accuracy by explicitly generating linguistic reasoning traces or future visual observations before action execution. However, explicit reasoning typically incurs non-negligible inference latency, which constrains the temporal resolution required for robotic manipulation. Moreover, such reasoning is confined to the linguistic space, imposing a representational bottleneck that struggles to faithfully capture ineffable physical attributes. To mitigate these limitations, we propose LaST$_0$, a framework that enables efficient reasoning before acting through a Latent Spatio-Temporal Chain-of-Thought (CoT), capturing fine-grained physical and robotic dynamics that are often difficult to verbalize. Specifically, we introduce a token-efficient latent CoT space that models future visual dynamics, 3D structural information, and robot proprioceptive states, and further extends these representations across time to enable temporally consistent implicit reasoning trajectories. Furthermore, LaST$_0$ adopts a dual-system architecture implemented via a Mixture-of-Transformers design, where a reasoning expert conducts low-frequency latent inference and an acting expert generates high-frequency actions conditioned on robotics-oriented latent representations. To facilitate coordination, LaST$_0$ is trained with heterogeneous operation frequencies, enabling adaptive switching between reasoning and action inference rates during deployment. Across ten simulated and six real-world manipulation tasks, LaST$_0$ improves mean success rates by 8% and 13% over prior VLA methods, respectively, while achieving substantially faster inference. Project website: https://sites.google.com/view/last0",
      "authors": [
        "Zhuoyang Liu",
        "Jiaming Liu",
        "Hao Chen",
        "Ziyu Guo",
        "Chengkai Hou",
        "Chenyang Gu",
        "Jiale Yu",
        "Xiangju Mi",
        "Renrui Zhang",
        "Zhengping Che",
        "Jian Tang",
        "Pheng-Ann Heng",
        "Shanghang Zhang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-08 18:59:53+00:00",
      "link": "https://arxiv.org/pdf/2601.05248v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.05246v1",
      "title": "Pixel-Perfect Visual Geometry Estimation",
      "abstract": "Recovering clean and accurate geometry from images is essential for robotics and augmented reality. However, existing geometry foundation models still suffer severely from flying pixels and the loss of fine details. In this paper, we present pixel-perfect visual geometry models that can predict high-quality, flying-pixel-free point clouds by leveraging generative modeling in the pixel space. We first introduce Pixel-Perfect Depth (PPD), a monocular depth foundation model built upon pixel-space diffusion transformers (DiT). To address the high computational complexity associated with pixel-space diffusion, we propose two key designs: 1) Semantics-Prompted DiT, which incorporates semantic representations from vision foundation models to prompt the diffusion process, preserving global semantics while enhancing fine-grained visual details; and 2) Cascade DiT architecture that progressively increases the number of image tokens, improving both efficiency and accuracy. To further extend PPD to video (PPVD), we introduce a new Semantics-Consistent DiT, which extracts temporally consistent semantics from a multi-view geometry foundation model. We then perform reference-guided token propagation within the DiT to maintain temporal coherence with minimal computational and memory overhead. Our models achieve the best performance among all generative monocular and video depth estimation models and produce significantly cleaner point clouds than all other models.",
      "authors": [
        "Gangwei Xu",
        "Haotong Lin",
        "Hongcheng Luo",
        "Haiyang Sun",
        "Bing Wang",
        "Guang Chen",
        "Sida Peng",
        "Hangjun Ye",
        "Xin Yang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:59:49+00:00",
      "link": "https://arxiv.org/pdf/2601.05246v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.05242v1",
      "title": "GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization",
      "abstract": "As language models become increasingly capable, users expect them to provide not only accurate responses but also behaviors aligned with diverse human preferences across a variety of scenarios. To achieve this, Reinforcement learning (RL) pipelines have begun incorporating multiple rewards, each capturing a distinct preference, to guide models toward these desired behaviors. However, recent work has defaulted to apply Group Relative Policy Optimization (GRPO) under multi-reward setting without examining its suitability. In this paper, we demonstrate that directly applying GRPO to normalize distinct rollout reward combinations causes them to collapse into identical advantage values, reducing the resolution of the training signal and resulting in suboptimal convergence and, in some cases, early training failure. We then introduce Group reward-Decoupled Normalization Policy Optimization (GDPO), a new policy optimization method to resolve these issues by decoupling the normalization of individual rewards, more faithfully preserving their relative differences and enabling more accurate multi-reward optimization, along with substantially improved training stability. We compare GDPO with GRPO across three tasks: tool calling, math reasoning, and coding reasoning, evaluating both correctness metrics (accuracy, bug ratio) and constraint adherence metrics (format, length). Across all settings, GDPO consistently outperforms GRPO, demonstrating its effectiveness and generalizability for multi-reward reinforcement learning optimization.",
      "authors": [
        "Shih-Yang Liu",
        "Xin Dong",
        "Ximing Lu",
        "Shizhe Diao",
        "Peter Belcak",
        "Mingjie Liu",
        "Min-Hung Chen",
        "Hongxu Yin",
        "Yu-Chiang Frank Wang",
        "Kwang-Ting Cheng",
        "Yejin Choi",
        "Jan Kautz",
        "Pavlo Molchanov"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 18:59:24+00:00",
      "link": "https://arxiv.org/pdf/2601.05242v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.05241v1",
      "title": "RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation",
      "abstract": "The diversity, quantity, and quality of manipulation data are critical for training effective robot policies. However, due to hardware and physical setup constraints, collecting large-scale real-world manipulation data remains difficult to scale across diverse environments. Recent work uses text-prompt conditioned image diffusion models to augment manipulation data by altering the backgrounds and tabletop objects in the visual observations. However, these approaches often overlook the practical need for multi-view and temporally coherent observations required by state-of-the-art policy models. Further, text prompts alone cannot reliably specify the scene setup. To provide the diffusion model with explicit visual guidance, we introduce visual identity prompting, which supplies exemplar images as conditioning inputs to guide the generation of the desired scene setup. To this end, we also build a scalable pipeline to curate a visual identity pool from large robotics datasets. Using our augmented manipulation data to train downstream vision-language-action and visuomotor policy models yields consistent performance gains in both simulation and real-robot settings.",
      "authors": [
        "Boyang Wang",
        "Haoran Zhang",
        "Shujie Zhang",
        "Jinkun Hao",
        "Mingda Jia",
        "Qi Lv",
        "Yucheng Mao",
        "Zhaoyang Lyu",
        "Jia Zeng",
        "Xudong Xu",
        "Jiangmiao Pang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "published": "2026-01-08 18:59:22+00:00",
      "link": "https://arxiv.org/pdf/2601.05241v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.05237v1",
      "title": "ObjectForesight: Predicting Future 3D Object Trajectories from Human Videos",
      "abstract": "Humans can effortlessly anticipate how objects might move or change through interaction--imagining a cup being lifted, a knife slicing, or a lid being closed. We aim to endow computational systems with a similar ability to predict plausible future object motions directly from passive visual observation. We introduce ObjectForesight, a 3D object-centric dynamics model that predicts future 6-DoF poses and trajectories of rigid objects from short egocentric video sequences. Unlike conventional world or dynamics models that operate in pixel or latent space, ObjectForesight represents the world explicitly in 3D at the object level, enabling geometrically grounded and temporally coherent predictions that capture object affordances and trajectories. To train such a model at scale, we leverage recent advances in segmentation, mesh reconstruction, and 3D pose estimation to curate a dataset of 2 million plus short clips with pseudo-ground-truth 3D object trajectories. Through extensive experiments, we show that ObjectForesight achieves significant gains in accuracy, geometric consistency, and generalization to unseen objects and scenes, establishing a scalable framework for learning physically grounded, object-centric dynamics models directly from observation. objectforesight.github.io",
      "authors": [
        "Rustin Soraki",
        "Homanga Bharadhwaj",
        "Ali Farhadi",
        "Roozbeh Mottaghi"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 18:58:08+00:00",
      "link": "https://arxiv.org/pdf/2601.05237v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.05230v1",
      "title": "Learning Latent Action World Models In The Wild",
      "abstract": "Agents capable of reasoning and planning in the real world require the ability of predicting the consequences of their actions. While world models possess this capability, they most often require action labels, that can be complex to obtain at scale. This motivates the learning of latent action models, that can learn an action space from videos alone. Our work addresses the problem of learning latent actions world models on in-the-wild videos, expanding the scope of existing works that focus on simple robotics simulations, video games, or manipulation data. While this allows us to capture richer actions, it also introduces challenges stemming from the video diversity, such as environmental noise, or the lack of a common embodiment across videos. To address some of the challenges, we discuss properties that actions should follow as well as relevant architectural choices and evaluations. We find that continuous, but constrained, latent actions are able to capture the complexity of actions from in-the-wild videos, something that the common vector quantization does not. We for example find that changes in the environment coming from agents, such as humans entering the room, can be transferred across videos. This highlights the capability of learning actions that are specific to in-the-wild videos. In the absence of a common embodiment across videos, we are mainly able to learn latent actions that become localized in space, relative to the camera. Nonetheless, we are able to train a controller that maps known actions to latent ones, allowing us to use latent actions as a universal interface and solve planning tasks with our world model with similar performance as action-conditioned baselines. Our analyses and experiments provide a step towards scaling latent action models to the real world.",
      "authors": [
        "Quentin Garrido",
        "Tushar Nagarajan",
        "Basile Terver",
        "Nicolas Ballas",
        "Yann LeCun",
        "Michael Rabbat"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-01-08 18:55:39+00:00",
      "link": "https://arxiv.org/pdf/2601.05230v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.05227v1",
      "title": "Stochastic Deep Learning: A Probabilistic Framework for Modeling Uncertainty in Structured Temporal Data",
      "abstract": "I propose a novel framework that integrates stochastic differential equations (SDEs) with deep generative models to improve uncertainty quantification in machine learning applications involving structured and temporal data. This approach, termed Stochastic Latent Differential Inference (SLDI), embeds an Itô SDE in the latent space of a variational autoencoder, allowing for flexible, continuous-time modeling of uncertainty while preserving a principled mathematical foundation. The drift and diffusion terms of the SDE are parameterized by neural networks, enabling data-driven inference and generalizing classical time series models to handle irregular sampling and complex dynamic structure.   A central theoretical contribution is the co-parameterization of the adjoint state with a dedicated neural network, forming a coupled forward-backward system that captures not only latent evolution but also gradient dynamics. I introduce a pathwise-regularized adjoint loss and analyze variance-reduced gradient flows through the lens of stochastic calculus, offering new tools for improving training stability in deep latent SDEs. My paper unifies and extends variational inference, continuous-time generative modeling, and control-theoretic optimization, providing a rigorous foundation for future developments in stochastic probabilistic machine learning.",
      "authors": [
        "James Rice"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.LG",
        "econ.EM",
        "math.ST"
      ],
      "published": "2026-01-08 18:53:59+00:00",
      "link": "https://arxiv.org/pdf/2601.05227v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.05219v1",
      "title": "CAOS: Conformal Aggregation of One-Shot Predictors",
      "abstract": "One-shot prediction enables rapid adaptation of pretrained foundation models to new tasks using only one labeled example, but lacks principled uncertainty quantification. While conformal prediction provides finite-sample coverage guarantees, standard split conformal methods are inefficient in the one-shot setting due to data splitting and reliance on a single predictor. We propose Conformal Aggregation of One-Shot Predictors (CAOS), a conformal framework that adaptively aggregates multiple one-shot predictors and uses a leave-one-out calibration scheme to fully exploit scarce labeled data. Despite violating classical exchangeability assumptions, we prove that CAOS achieves valid marginal coverage using a monotonicity-based argument. Experiments on one-shot facial landmarking and RAFT text classification tasks show that CAOS produces substantially smaller prediction sets than split conformal baselines while maintaining reliable coverage.",
      "authors": [
        "Maja Waldron"
      ],
      "primary_category": "stat.ML",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 18:44:21+00:00",
      "link": "https://arxiv.org/pdf/2601.05219v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.05205v1",
      "title": "EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI",
      "abstract": "Pervasive AI increasingly depends on on-device learning systems that deliver low-latency and energy-efficient computation under strict resource constraints. Liquid State Machines (LSMs) offer a promising approach for low-power temporal processing in pervasive and neuromorphic systems, but their deployment remains challenging due to high hyperparameter sensitivity and the computational cost of traditional optimization methods that ignore energy constraints. This work presents EARL, an energy-aware reinforcement learning framework that integrates Bayesian optimization with an adaptive reinforcement learning based selection policy to jointly optimize accuracy and energy consumption. EARL employs surrogate modeling for global exploration, reinforcement learning for dynamic candidate prioritization, and an early termination mechanism to eliminate redundant evaluations, substantially reducing computational overhead. Experiments on three benchmark datasets demonstrate that EARL achieves 6 to 15 percent higher accuracy, 60 to 80 percent lower energy consumption, and up to an order of magnitude reduction in optimization time compared to leading hyperparameter tuning frameworks. These results highlight the effectiveness of energy-aware adaptive search in improving the efficiency and scalability of LSMs for resource-constrained on-device AI applications.",
      "authors": [
        "Zain Iqbal",
        "Lorenzo Valerio"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.PF"
      ],
      "published": "2026-01-08 18:31:11+00:00",
      "link": "https://arxiv.org/pdf/2601.05205v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.05200v1",
      "title": "Multivector Reranking in the Era of Strong First-Stage Retrievers",
      "abstract": "Learned multivector representations power modern search systems with strong retrieval effectiveness, but their real-world use is limited by the high cost of exhaustive token-level retrieval. Therefore, most systems adopt a \\emph{gather-and-refine} strategy, where a lightweight gather phase selects candidates for full scoring. However, this approach requires expensive searches over large token-level indexes and often misses the documents that would rank highest under full similarity. In this paper, we reproduce several state-of-the-art multivector retrieval methods on two publicly available datasets, providing a clear picture of the current multivector retrieval field and observing the inefficiency of token-level gathering. Building on top of that, we show that replacing the token-level gather phase with a single-vector document retriever -- specifically, a learned sparse retriever (LSR) -- produces a smaller and more semantically coherent candidate set. This recasts the gather-and-refine pipeline into the well-established two-stage retrieval architecture. As retrieval latency decreases, query encoding with two neural encoders becomes the dominant computational bottleneck. To mitigate this, we integrate recent inference-free LSR methods, demonstrating that they preserve the retrieval effectiveness of the dual-encoder pipeline while substantially reducing query encoding time. Finally, we investigate multiple reranking configurations that balance efficiency, memory, and effectiveness, and we introduce two optimization techniques that prune low-quality candidates early. Empirical results show that these techniques improve retrieval efficiency by up to 1.8$\\times$ with no loss in quality. Overall, our two-stage approach achieves over $24\\times$ speedup over the state-of-the-art multivector retrieval systems, while maintaining comparable or superior retrieval quality.",
      "authors": [
        "Silvio Martinico",
        "Franco Maria Nardini",
        "Cosimo Rulli",
        "Rossano Venturini"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-08 18:22:18+00:00",
      "link": "https://arxiv.org/pdf/2601.05200v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05192v1",
      "title": "LELA: an LLM-based Entity Linking Approach with Zero-Shot Domain Adaptation",
      "abstract": "Entity linking (mapping ambiguous mentions in text to entities in a knowledge base) is a foundational step in tasks such as knowledge graph construction, question-answering, and information extraction. Our method, LELA, is a modular coarse-to-fine approach that leverages the capabilities of large language models (LLMs), and works with different target domains, knowledge bases and LLMs, without any fine-tuning phase. Our experiments across various entity linking settings show that LELA is highly competitive with fine-tuned approaches, and substantially outperforms the non-fine-tuned ones.",
      "authors": [
        "Samy Haffoudhi",
        "Fabian M. Suchanek",
        "Nils Holzenberger"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 18:15:34+00:00",
      "link": "https://arxiv.org/pdf/2601.05192v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05191v1",
      "title": "Cutting AI Research Costs: How Task-Aware Compression Makes Large Language Model Agents Affordable",
      "abstract": "When researchers deploy large language models for autonomous tasks like reviewing literature or generating hypotheses, the computational bills add up quickly. A single research session using a 70-billion parameter model can cost around $127 in cloud fees, putting these tools out of reach for many academic labs. We developed AgentCompress to tackle this problem head-on. The core idea came from a simple observation during our own work: writing a novel hypothesis clearly demands more from the model than reformatting a bibliography. Why should both tasks run at full precision? Our system uses a small neural network to gauge how hard each incoming task will be, based only on its opening words, then routes it to a suitably compressed model variant. The decision happens in under a millisecond. Testing across 500 research workflows in four scientific fields, we cut compute costs by 68.3% while keeping 96.2% of the original success rate. For labs watching their budgets, this could mean the difference between running experiments and sitting on the sidelines",
      "authors": [
        "Zuhair Ahmed Khan Taha",
        "Mohammed Mudassir Uddin",
        "Shahnawaz Alam"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-08 18:13:46+00:00",
      "link": "https://arxiv.org/pdf/2601.05191v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05187v1",
      "title": "SimuAgent: An LLM-Based Simulink Modeling Assistant Enhanced with Reinforcement Learning",
      "abstract": "Large language models (LLMs) have revolutionized text-based code automation, but their potential in graph-oriented engineering workflows remains under-explored. We introduce SimuAgent, an LLM-powered modeling and simulation agent tailored for Simulink. SimuAgent replaces verbose XML with a concise, dictionary-style Python representation, dramatically cutting token counts, improving interpretability, and enabling fast, in-process simulation. A lightweight plan-execute architecture, trained in two stages, equips the agent with both low-level tool skills and high-level design reasoning. To tackle sparse rewards in long-horizon tasks, we propose Reflection-GRPO (ReGRPO), which augments Group Relative Policy Optimization (GRPO) with self-reflection traces that supply rich intermediate feedback, accelerating convergence and boosting robustness. Experiments on SimuBench, our newly released benchmark comprising 5300 multi-domain modeling tasks, show that a Qwen2.5-7B model fine-tuned with SimuAgent converges faster and achieves higher modeling accuracy than standard RL baselines, and even surpasses GPT-4o when evaluated with few-shot prompting on the same benchmark. Ablations confirm that the two-stage curriculum and abstract-reconstruct data augmentation further enhance generalization. SimuAgent trains and runs entirely on-premise with modest hardware, delivering a privacy-preserving, cost-effective solution for industrial model-driven engineering. SimuAgent bridges the gap between LLMs and graphical modeling environments, offering a practical solution for AI-assisted engineering design in industrial settings.",
      "authors": [
        "Yanchang Liang",
        "Xiaowei Zhao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 18:10:35+00:00",
      "link": "https://arxiv.org/pdf/2601.05187v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05184v1",
      "title": "Observations and Remedies for Large Language Model Bias in Self-Consuming Performative Loop",
      "abstract": "The rapid advancement of large language models (LLMs) has led to growing interest in using synthetic data to train future models. However, this creates a self-consuming retraining loop, where models are trained on their own outputs and may cause performance drops and induce emerging biases. In real-world applications, previously deployed LLMs may influence the data they generate, leading to a dynamic system driven by user feedback. For example, if a model continues to underserve users from a group, less query data will be collected from this particular demographic of users. In this study, we introduce the concept of \\textbf{S}elf-\\textbf{C}onsuming \\textbf{P}erformative \\textbf{L}oop (\\textbf{SCPL}) and investigate the role of synthetic data in shaping bias during these dynamic iterative training processes under controlled performative feedback. This controlled setting is motivated by the inaccessibility of real-world user preference data from dynamic production systems, and enables us to isolate and analyze feedback-driven bias evolution in a principled manner. We focus on two types of loops, including the typical retraining setting and the incremental fine-tuning setting, which is largely underexplored. Through experiments on three real-world tasks, we find that the performative loop increases preference bias and decreases disparate bias. We design a reward-based rejection sampling strategy to mitigate the bias, moving towards more trustworthy self-improving systems.",
      "authors": [
        "Yaxuan Wang",
        "Zhongteng Cai",
        "Yujia Bao",
        "Xueru Zhang",
        "Yang Liu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 18:08:15+00:00",
      "link": "https://arxiv.org/pdf/2601.05184v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05174v1",
      "title": "FaST: Efficient and Effective Long-Horizon Forecasting for Large-Scale Spatial-Temporal Graphs via Mixture-of-Experts",
      "abstract": "Spatial-Temporal Graph (STG) forecasting on large-scale networks has garnered significant attention. However, existing models predominantly focus on short-horizon predictions and suffer from notorious computational costs and memory consumption when scaling to long-horizon predictions and large graphs. Targeting the above challenges, we present FaST, an effective and efficient framework based on heterogeneity-aware Mixture-of-Experts (MoEs) for long-horizon and large-scale STG forecasting, which unlocks one-week-ahead (672 steps at a 15-minute granularity) prediction with thousands of nodes. FaST is underpinned by two key innovations. First, an adaptive graph agent attention mechanism is proposed to alleviate the computational burden inherent in conventional graph convolution and self-attention modules when applied to large-scale graphs. Second, we propose a new parallel MoE module that replaces traditional feed-forward networks with Gated Linear Units (GLUs), enabling an efficient and scalable parallel structure. Extensive experiments on real-world datasets demonstrate that FaST not only delivers superior long-horizon predictive accuracy but also achieves remarkable computational efficiency compared to state-of-the-art baselines. Our source code is available at: https://github.com/yijizhao/FaST.",
      "authors": [
        "Yiji Zhao",
        "Zihao Zhong",
        "Ao Wang",
        "Haomin Wen",
        "Ming Jin",
        "Yuxuan Liang",
        "Huaiyu Wan",
        "Hao Wu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 18:00:58+00:00",
      "link": "https://arxiv.org/pdf/2601.05174v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.05170v1",
      "title": "Reverse-engineering NLI: A study of the meta-inferential properties of Natural Language Inference",
      "abstract": "Natural Language Inference (NLI) has been an important task for evaluating language models for Natural Language Understanding, but the logical properties of the task are poorly understood and often mischaracterized. Understanding the notion of inference captured by NLI is key to interpreting model performance on the task. In this paper we formulate three possible readings of the NLI label set and perform a comprehensive analysis of the meta-inferential properties they entail. Focusing on the SNLI dataset, we exploit (1) NLI items with shared premises and (2) items generated by LLMs to evaluate models trained on SNLI for meta-inferential consistency and derive insights into which reading of the logical relations is encoded by the dataset.",
      "authors": [
        "Rasmus Blanck",
        "Bill Noble",
        "Stergios Chatzikyriakidis"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 17:58:52+00:00",
      "link": "https://arxiv.org/pdf/2601.05170v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05163v1",
      "title": "DocDancer: Towards Agentic Document-Grounded Information Seeking",
      "abstract": "Document Question Answering (DocQA) focuses on answering questions grounded in given documents, yet existing DocQA agents lack effective tool utilization and largely rely on closed-source models. In this work, we introduce DocDancer, an end-to-end trained open-source Doc agent. We formulate DocQA as an information-seeking problem and propose a tool-driven agent framework that explicitly models document exploration and comprehension. To enable end-to-end training of such agents, we introduce an Exploration-then-Synthesis data synthesis pipeline that addresses the scarcity of high-quality training data for DocQA. Training on the synthesized data, the trained models on two long-context document understanding benchmarks, MMLongBench-Doc and DocBench, show their effectiveness. Further analysis provides valuable insights for the agentic tool design and synthetic data.",
      "authors": [
        "Qintong Zhang",
        "Xinjie Lv",
        "Jialong Wu",
        "Baixuan Li",
        "Zhengwei Tao",
        "Guochen Yan",
        "Huanyao Zhang",
        "Bin Wang",
        "Jiahao Xu",
        "Haitao Mi",
        "Wentao Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 17:54:32+00:00",
      "link": "https://arxiv.org/pdf/2601.05163v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05152v1",
      "title": "Safe Continual Reinforcement Learning Methods for Nonstationary Environments. Towards a Survey of the State of the Art",
      "abstract": "This work provides a state-of-the-art survey of continual safe online reinforcement learning (COSRL) methods. We discuss theoretical aspects, challenges, and open questions in building continual online safe reinforcement learning algorithms. We provide the taxonomy and the details of continual online safe reinforcement learning methods based on the type of safe learning mechanism that takes adaptation to nonstationarity into account. We categorize safety constraints formulation for online reinforcement learning algorithms, and finally, we discuss prospects for creating reliable, safe online learning algorithms.   Keywords: safe RL in nonstationary environments, safe continual reinforcement learning under nonstationarity, HM-MDP, NSMDP, POMDP, safe POMDP, constraints for continual learning, safe continual reinforcement learning review, safe continual reinforcement learning survey, safe continual reinforcement learning, safe online learning under distribution shift, safe continual online adaptation, safe reinforcement learning, safe exploration, safe adaptation, constrained Markov decision processes, safe reinforcement learning, partially observable Markov decision process, safe reinforcement learning and hidden Markov decision processes, Safe Online Reinforcement Learning, safe online reinforcement learning, safe online reinforcement learning, safe meta-learning, safe meta-reinforcement learning, safe context-based reinforcement learning, formulating safety constraints for continual learning",
      "authors": [
        "Timofey Tomashevskiy"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 17:42:56+00:00",
      "link": "https://arxiv.org/pdf/2601.05152v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.05138v1",
      "title": "VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control",
      "abstract": "Video world models aim to simulate dynamic, real-world environments, yet existing methods struggle to provide unified and precise control over camera and multi-object motion, as videos inherently operate dynamics in the projected 2D image plane. To bridge this gap, we introduce VerseCrafter, a 4D-aware video world model that enables explicit and coherent control over both camera and object dynamics within a unified 4D geometric world state. Our approach is centered on a novel 4D Geometric Control representation, which encodes the world state through a static background point cloud and per-object 3D Gaussian trajectories. This representation captures not only an object's path but also its probabilistic 3D occupancy over time, offering a flexible, category-agnostic alternative to rigid bounding boxes or parametric models. These 4D controls are rendered into conditioning signals for a pretrained video diffusion model, enabling the generation of high-fidelity, view-consistent videos that precisely adhere to the specified dynamics. Unfortunately, another major challenge lies in the scarcity of large-scale training data with explicit 4D annotations. We address this by developing an automatic data engine that extracts the required 4D controls from in-the-wild videos, allowing us to train our model on a massive and diverse dataset.",
      "authors": [
        "Sixiao Zheng",
        "Minghao Yin",
        "Wenbo Hu",
        "Xiaoyu Li",
        "Ying Shan",
        "Yanwei Fu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 17:28:52+00:00",
      "link": "https://arxiv.org/pdf/2601.05138v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.05127v1",
      "title": "LooseRoPE: Content-aware Attention Manipulation for Semantic Harmonization",
      "abstract": "Recent diffusion-based image editing methods commonly rely on text or high-level instructions to guide the generation process, offering intuitive but coarse control. In contrast, we focus on explicit, prompt-free editing, where the user directly specifies the modification by cropping and pasting an object or sub-object into a chosen location within an image. This operation affords precise spatial and visual control, yet it introduces a fundamental challenge: preserving the identity of the pasted object while harmonizing it with its new context. We observe that attention maps in diffusion-based editing models inherently govern whether image regions are preserved or adapted for coherence. Building on this insight, we introduce LooseRoPE, a saliency-guided modulation of rotational positional encoding (RoPE) that loosens the positional constraints to continuously control the attention field of view. By relaxing RoPE in this manner, our method smoothly steers the model's focus between faithful preservation of the input image and coherent harmonization of the inserted object, enabling a balanced trade-off between identity retention and contextual blending. Our approach provides a flexible and intuitive framework for image editing, achieving seamless compositional results without textual descriptions or complex user input.",
      "authors": [
        "Etai Sella",
        "Yoav Baron",
        "Hadar Averbuch-Elor",
        "Daniel Cohen-Or",
        "Or Patashnik"
      ],
      "primary_category": "cs.GR",
      "categories": [
        "cs.GR"
      ],
      "published": "2026-01-08 17:17:47+00:00",
      "link": "https://arxiv.org/pdf/2601.05127v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.05125v1",
      "title": "VERSE: Visual Embedding Reduction and Space Exploration. Clustering-Guided Insights for Training Data Enhancement in Visually-Rich Document Understanding",
      "abstract": "This work introduces VERSE, a methodology for analyzing and improving Vision-Language Models applied to Visually-rich Document Understanding by exploring their visual embedding space. VERSE enables the visualization of latent representations, supporting the assessment of model feasibility. It also facilitates the identification of problematic regions and guides the generation of synthetic data to enhance performance in those clusters. We validate the methodology by training on the synthetic MERIT Dataset and evaluating on its real-world counterpart, MERIT Secret. Results show that VERSE helps uncover the visual features associated with error-prone clusters, and that retraining with samples containing these features substantially boosts F1 performance without degrading generalization. Furthermore, we demonstrate that on-premise models such as Donut and Idefics2, when optimized with VERSE, match or even surpass the performance of SaaS solutions like GPT-4 and Pixtral.",
      "authors": [
        "Ignacio de Rodrigo",
        "Alvaro J. Lopez-Lopez",
        "Jaime Boal"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-08 17:15:15+00:00",
      "link": "https://arxiv.org/pdf/2601.05125v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05116v1",
      "title": "From Rays to Projections: Better Inputs for Feed-Forward View Synthesis",
      "abstract": "Feed-forward view synthesis models predict a novel view in a single pass with minimal 3D inductive bias. Existing works encode cameras as Plücker ray maps, which tie predictions to the arbitrary world coordinate gauge and make them sensitive to small camera transformations, thereby undermining geometric consistency. In this paper, we ask what inputs best condition a model for robust and consistent view synthesis. We propose projective conditioning, which replaces raw camera parameters with a target-view projective cue that provides a stable 2D input. This reframes the task from a brittle geometric regression problem in ray space to a well-conditioned target-view image-to-image translation problem. Additionally, we introduce a masked autoencoding pretraining strategy tailored to this cue, enabling the use of large-scale uncalibrated data for pretraining. Our method shows improved fidelity and stronger cross-view consistency compared to ray-conditioned baselines on our view-consistency benchmark. It also achieves state-of-the-art quality on standard novel view synthesis benchmarks.",
      "authors": [
        "Zirui Wu",
        "Zeren Jiang",
        "Martin R. Oswald",
        "Jie Song"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 17:03:44+00:00",
      "link": "https://arxiv.org/pdf/2601.05116v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.05111v1",
      "title": "Agent-as-a-Judge",
      "abstract": "LLM-as-a-Judge has revolutionized AI evaluation by leveraging large language models for scalable assessments. However, as evaluands become increasingly complex, specialized, and multi-step, the reliability of LLM-as-a-Judge has become constrained by inherent biases, shallow single-pass reasoning, and the inability to verify assessments against real-world observations. This has catalyzed the transition to Agent-as-a-Judge, where agentic judges employ planning, tool-augmented verification, multi-agent collaboration, and persistent memory to enable more robust, verifiable, and nuanced evaluations. Despite the rapid proliferation of agentic evaluation systems, the field lacks a unified framework to navigate this shifting landscape. To bridge this gap, we present the first comprehensive survey tracing this evolution. Specifically, we identify key dimensions that characterize this paradigm shift and establish a developmental taxonomy. We organize core methodologies and survey applications across general and professional domains. Furthermore, we analyze frontier challenges and identify promising research directions, ultimately providing a clear roadmap for the next generation of agentic evaluation.",
      "authors": [
        "Runyang You",
        "Hongru Cai",
        "Caiqi Zhang",
        "Qiancheng Xu",
        "Meng Liu",
        "Tiezheng Yu",
        "Yongqi Li",
        "Wenjie Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-08 16:58:10+00:00",
      "link": "https://arxiv.org/pdf/2601.05111v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.05107v1",
      "title": "Controllable Memory Usage: Balancing Anchoring and Innovation in Long-Term Human-Agent Interaction",
      "abstract": "As LLM-based agents are increasingly used in long-term interactions, cumulative memory is critical for enabling personalization and maintaining stylistic consistency. However, most existing systems adopt an ``all-or-nothing'' approach to memory usage: incorporating all relevant past information can lead to \\textit{Memory Anchoring}, where the agent is trapped by past interactions, while excluding memory entirely results in under-utilization and the loss of important interaction history. We show that an agent's reliance on memory can be modeled as an explicit and user-controllable dimension. We first introduce a behavioral metric of memory dependence to quantify the influence of past interactions on current outputs. We then propose \\textbf{Stee}rable \\textbf{M}emory Agent, \\texttt{SteeM}, a framework that allows users to dynamically regulate memory reliance, ranging from a fresh-start mode that promotes innovation to a high-fidelity mode that closely follows interaction history. Experiments across different scenarios demonstrate that our approach consistently outperforms conventional prompting and rigid memory masking strategies, yielding a more nuanced and effective control for personalized human-agent collaboration.",
      "authors": [
        "Muzhao Tian",
        "Zisu Huang",
        "Xiaohua Wang",
        "Jingwen Xu",
        "Zhengkang Guo",
        "Qi Qian",
        "Yuanzhe Shen",
        "Kaitao Song",
        "Jiakang Yuan",
        "Changze Lv",
        "Xiaoqing Zheng"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 16:54:30+00:00",
      "link": "https://arxiv.org/pdf/2601.05107v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.05106v1",
      "title": "Token-Level LLM Collaboration via FusionRoute",
      "abstract": "Large language models (LLMs) exhibit strengths across diverse domains. However, achieving strong performance across these domains with a single general-purpose model typically requires scaling to sizes that are prohibitively expensive to train and deploy. On the other hand, while smaller domain-specialized models are much more efficient, they struggle to generalize beyond their training distributions. To address this dilemma, we propose FusionRoute, a robust and effective token-level multi-LLM collaboration framework in which a lightweight router simultaneously (i) selects the most suitable expert at each decoding step and (ii) contributes a complementary logit that refines or corrects the selected expert's next-token distribution via logit addition. Unlike existing token-level collaboration methods that rely solely on fixed expert outputs, we provide a theoretical analysis showing that pure expert-only routing is fundamentally limited: unless strong global coverage assumptions hold, it cannot in general realize the optimal decoding policy. By augmenting expert selection with a trainable complementary generator, FusionRoute expands the effective policy class and enables recovery of optimal value functions under mild conditions. Empirically, across both Llama-3 and Gemma-2 families and diverse benchmarks spanning mathematical reasoning, code generation, and instruction following, FusionRoute outperforms both sequence- and token-level collaboration, model merging, and direct fine-tuning, while remaining competitive with domain experts on their respective tasks.",
      "authors": [
        "Nuoya Xiong",
        "Yuhang Zhou",
        "Hanqing Zeng",
        "Zhaorun Chen",
        "Furong Huang",
        "Shuchao Bi",
        "Lizhu Zhang",
        "Zhuokai Zhao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-08 16:53:16+00:00",
      "link": "https://arxiv.org/pdf/2601.05106v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05103v1",
      "title": "Semantically Orthogonal Framework for Citation Classification: Disentangling Intent and Content",
      "abstract": "Understanding the role of citations is essential for research assessment and citation-aware digital libraries. However, existing citation classification frameworks often conflate citation intent (why a work is cited) with cited content type (what part is cited), limiting their effectiveness in auto classification due to a dilemma between fine-grained type distinctions and practical classification reliability. We introduce SOFT, a Semantically Orthogonal Framework with Two dimensions that explicitly separates citation intent from cited content type, drawing inspiration from semantic role theory. We systematically re-annotate the ACL-ARC dataset using SOFT and release a cross-disciplinary test set sampled from ACT2. Evaluation with both zero-shot and fine-tuned Large Language Models demonstrates that SOFT enables higher agreement between human annotators and LLMs, and supports stronger classification performance and robust cross-domain generalization compared to ACL-ARC and SciCite annotation frameworks. These results confirm SOFT's value as a clear, reusable annotation standard, improving clarity, consistency, and generalizability for digital libraries and scholarly communication infrastructures. All code and data are publicly available on GitHub https://github.com/zhiyintan/SOFT.",
      "authors": [
        "Changxu Duan",
        "Zhiyin Tan"
      ],
      "primary_category": "cs.DL",
      "categories": [
        "cs.DL",
        "cs.CL"
      ],
      "published": "2026-01-08 16:48:36+00:00",
      "link": "https://arxiv.org/pdf/2601.05103v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05101v1",
      "title": "Arabic Prompts with English Tools: A Benchmark",
      "abstract": "Large Language Models (LLMs) are now integral to numerous industries, increasingly serving as the core reasoning engine for autonomous agents that perform complex tasks through tool-use. While the development of Arabic-native LLMs is accelerating, the benchmarks for evaluating their capabilities lag behind, with most existing frameworks focusing on English. A critical and overlooked area is tool-calling, where the performance of models prompted in non-English languages like Arabic is poorly understood, especially since these models are often pretrained on predominantly English data. This paper addresses this critical gap by introducing the first dedicated benchmark for evaluating the tool-calling and agentic capabilities of LLMs in the Arabic language. Our work provides a standardized framework to measure the functional accuracy and robustness of models in Arabic agentic workflows. Our findings reveal a huge performance gap: when users interact in Arabic, tool-calling accuracy drops by an average of 5-10\\%, regardless of whether the tool descriptions themselves are in Arabic or English. By shedding light on these critical challenges, this benchmark aims to foster the development of more reliable and linguistically equitable AI agents for Arabic-speaking users.",
      "authors": [
        "Konstantin Kubrak",
        "Ahmed El-Moselhy",
        "Ammar Alsulami",
        "Remaz Altuwaim",
        "Hassan Ismail Fawaz",
        "Faisal Alsaby"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 16:47:09+00:00",
      "link": "https://arxiv.org/pdf/2601.05101v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05099v1",
      "title": "Multi-Disciplinary Dataset Discovery from Citation-Verified Literature Contexts",
      "abstract": "Identifying suitable datasets for a research question remains challenging because existing dataset search engines rely heavily on metadata quality and keyword overlap, which often fail to capture the semantic intent of scientific investigation. We introduce a literature-driven framework that discovers datasets from citation contexts in scientific papers, enabling retrieval grounded in actual research use rather than metadata availability. Our approach combines large-scale citation-context extraction, schema-guided dataset recognition with Large Language Models, and provenance-preserving entity resolution. We evaluate the system on eight survey-derived computer science queries and find that it achieves substantially higher recall than Google Dataset Search and DataCite Commons, with normalized recall ranging from an average of 47.47% to a highest value of 81.82%. Beyond recovering gold-standard datasets, the method also surfaces additional datasets not documented in the surveys. Expert assessments across five top-level Fields of Science indicate that a substantial portion of the additional datasets are considered high utility, and some are regarded as novel for the specific topics chosen by the experts. These findings establish citation-context mining as an effective and generalizable paradigm for dataset discovery, particularly in settings where datasets lack sufficient or reliable metadata. To support reproducibility and future extensions, we release our code, evaluation datasets, and results on GitHub (https://github.com/Fireblossom/citation-context-dataset-discovery).",
      "authors": [
        "Zhiyin Tan",
        "Changxu Duan"
      ],
      "primary_category": "cs.DL",
      "categories": [
        "cs.DL",
        "cs.CL",
        "cs.IR"
      ],
      "published": "2026-01-08 16:46:06+00:00",
      "link": "https://arxiv.org/pdf/2601.05099v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05091v1",
      "title": "Code-Mix Sentiment Analysis on Hinglish Tweets",
      "abstract": "The effectiveness of brand monitoring in India is increasingly challenged by the rise of Hinglish--a hybrid of Hindi and English--used widely in user-generated content on platforms like Twitter. Traditional Natural Language Processing (NLP) models, built for monolingual data, often fail to interpret the syntactic and semantic complexity of this code-mixed language, resulting in inaccurate sentiment analysis and misleading market insights. To address this gap, we propose a high-performance sentiment classification framework specifically designed for Hinglish tweets. Our approach fine-tunes mBERT (Multilingual BERT), leveraging its multilingual capabilities to better understand the linguistic diversity of Indian social media. A key component of our methodology is the use of subword tokenization, which enables the model to effectively manage spelling variations, slang, and out-of-vocabulary terms common in Romanized Hinglish. This research delivers a production-ready AI solution for brand sentiment tracking and establishes a strong benchmark for multilingual NLP in low-resource, code-mixed environments.",
      "authors": [
        "Aashi Garg",
        "Aneshya Das",
        "Arshi Arya",
        "Anushka Goyal",
        "Aditi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 16:39:26+00:00",
      "link": "https://arxiv.org/pdf/2601.05091v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05082v1",
      "title": "Exploring Student Expectations and Confidence in Learning Analytics",
      "abstract": "Learning Analytics (LA) is nowadays ubiquitous in many educational systems, providing the ability to collect and analyze student data in order to understand and optimize learning and the environments in which it occurs. On the other hand, the collection of data requires to comply with the growing demand regarding privacy legislation. In this paper, we use the Student Expectation of Learning Analytics Questionnaire (SELAQ) to analyze the expectations and confidence of students from different faculties regarding the processing of their data for Learning Analytics purposes. This allows us to identify four clusters of students through clustering algorithms: Enthusiasts, Realists, Cautious and Indifferents. This structured analysis provides valuable insights into the acceptance and criticism of Learning Analytics among students.",
      "authors": [
        "Hayk Asatryan",
        "Basile Tousside",
        "Janis Mohr",
        "Malte Neugebauer",
        "Hildo Bijl",
        "Paul Spiegelberg",
        "Claudia Frohn-Schauf",
        "Jörg Frochte"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CY",
        "cs.HC"
      ],
      "published": "2026-01-08 16:27:09+00:00",
      "link": "https://arxiv.org/pdf/2601.05082v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.05053v1",
      "title": "Reinforced Efficient Reasoning via Semantically Diverse Exploration",
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has proven effective in enhancing the reasoning of large language models (LLMs). Monte Carlo Tree Search (MCTS)-based extensions improve upon vanilla RLVR (e.g., GRPO) by providing tree-based reasoning rollouts that enable fine-grained and segment-level credit assignment. However, existing methods still suffer from limited exploration diversity and inefficient reasoning. To address the above challenges, we propose reinforced efficient reasoning via semantically diverse explorations, i.e., ROSE, for LLMs. To encourage more diverse reasoning exploration, our method incorporates a semantic-entropy-based branching strategy and an $\\varepsilon$-exploration mechanism. The former operates on already sampled reasoning rollouts to capture semantic uncertainty and select branching points with high semantic divergence to generate new successive reasoning paths, whereas the latter stochastically initiates reasoning rollouts from the root, preventing the search process from becoming overly local. To improve efficiency, we design a length-aware segment-level advantage estimator that rewards concise and correct reasoning while penalizing unnecessarily long reasoning chains. Extensive experiments on various mathematical reasoning benchmarks with Qwen and Llama models validate the effectiveness and efficiency of ROSE. Codes are available at https://github.com/ZiqiZhao1/ROSE-rl.",
      "authors": [
        "Ziqi Zhao",
        "Zhaochun Ren",
        "Jiahong Zou",
        "Liu Yang",
        "Zhiwei Xu",
        "Xuri Ge",
        "Zhumin Chen",
        "Xinyu Ma",
        "Daiting Shi",
        "Shuaiqiang Wang",
        "Dawei Yin",
        "Xin Xin"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 15:56:44+00:00",
      "link": "https://arxiv.org/pdf/2601.05053v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.05052v1",
      "title": "DeepWeightFlow: Re-Basined Flow Matching for Generating Neural Network Weights",
      "abstract": "Building efficient and effective generative models for neural network weights has been a research focus of significant interest that faces challenges posed by the high-dimensional weight spaces of modern neural networks and their symmetries. Several prior generative models are limited to generating partial neural network weights, particularly for larger models, such as ResNet and ViT. Those that do generate complete weights struggle with generation speed or require finetuning of the generated models. In this work, we present DeepWeightFlow, a Flow Matching model that operates directly in weight space to generate diverse and high-accuracy neural network weights for a variety of architectures, neural network sizes, and data modalities. The neural networks generated by DeepWeightFlow do not require fine-tuning to perform well and can scale to large networks. We apply Git Re-Basin and TransFusion for neural network canonicalization in the context of generative weight models to account for the impact of neural network permutation symmetries and to improve generation efficiency for larger model sizes. The generated networks excel at transfer learning, and ensembles of hundreds of neural networks can be generated in minutes, far exceeding the efficiency of diffusion-based methods. DeepWeightFlow models pave the way for more efficient and scalable generation of diverse sets of neural networks.",
      "authors": [
        "Saumya Gupta",
        "Scott Biggs",
        "Moritz Laber",
        "Zohair Shafi",
        "Robin Walters",
        "Ayan Paul"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-01-08 15:56:28+00:00",
      "link": "https://arxiv.org/pdf/2601.05052v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.05051v1",
      "title": "Publishing FAIR and Machine-actionable Reviews in Materials Science: The Case for Symbolic Knowledge in Neuro-symbolic Artificial Intelligence",
      "abstract": "Scientific reviews are central to knowledge integration in materials science, yet their key insights remain locked in narrative text and static PDF tables, limiting reuse by humans and machines alike. This article presents a case study in atomic layer deposition and etching (ALD/E) where we publish review tables as FAIR, machine-actionable comparisons in the Open Research Knowledge Graph (ORKG), turning them into structured, queryable knowledge. Building on this, we contrast symbolic querying over ORKG with large language model-based querying, and argue that a curated symbolic layer should remain the backbone of reliable neurosymbolic AI in materials science, with LLMs serving as complementary, symbolically grounded interfaces rather than standalone sources of truth.",
      "authors": [
        "Jennifer D'Souza",
        "Soren Auer",
        "Eleni Poupaki",
        "Alex Watkins",
        "Anjana Devi",
        "Riikka L. Puurunen",
        "Bora Karasulu",
        "Adrie Mackus",
        "Erwin Kessels"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DL",
        "cs.IT"
      ],
      "published": "2026-01-08 15:56:17+00:00",
      "link": "https://arxiv.org/pdf/2601.05051v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05049v1",
      "title": "How to Set the Learning Rate for Large-Scale Pre-training?",
      "abstract": "Optimal configuration of the learning rate (LR) is a fundamental yet formidable challenge in large-scale pre-training. Given the stringent trade-off between training costs and model performance, the pivotal question is whether the optimal LR can be accurately extrapolated from low-cost experiments. In this paper, we formalize this investigation into two distinct research paradigms: Fitting and Transfer. Within the Fitting Paradigm, we innovatively introduce a Scaling Law for search factor, effectively reducing the search complexity from O(n^3) to O(n*C_D*C_η) via predictive modeling. Within the Transfer Paradigm, we extend the principles of $μ$Transfer to the Mixture of Experts (MoE) architecture, broadening its applicability to encompass model depth, weight decay, and token horizons. By pushing the boundaries of existing hyperparameter research in terms of scale, we conduct a comprehensive comparison between these two paradigms. Our empirical results challenge the scalability of the widely adopted $μ$ Transfer in large-scale pre-training scenarios. Furthermore, we provide a rigorous analysis through the dual lenses of training stability and feature learning to elucidate the underlying reasons why module-wise parameter tuning underperforms in large-scale settings. This work offers systematic practical guidelines and a fresh theoretical perspective for optimizing industrial-level pre-training.",
      "authors": [
        "Yunhua Zhou",
        "Shuhao Xing",
        "Junhao Huang",
        "Xipeng Qiu",
        "Qipeng Guo"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 15:55:13+00:00",
      "link": "https://arxiv.org/pdf/2601.05049v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.05047v1",
      "title": "Challenges and Research Directions for Large Language Model Inference Hardware",
      "abstract": "Large Language Model (LLM) inference is hard. The autoregressive Decode phase of the underlying Transformer model makes LLM inference fundamentally different from training. Exacerbated by recent AI trends, the primary challenges are memory and interconnect rather than compute. To address these challenges, we highlight four architecture research opportunities: High Bandwidth Flash for 10X memory capacity with HBM-like bandwidth; Processing-Near-Memory and 3D memory-logic stacking for high memory bandwidth; and low-latency interconnect to speedup communication. While our focus is datacenter AI, we also review their applicability for mobile devices.",
      "authors": [
        "Xiaoyu Ma",
        "David Patterson"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 15:52:11+00:00",
      "link": "https://arxiv.org/pdf/2601.05047v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05039v1",
      "title": "FinDeepForecast: A Live Multi-Agent System for Benchmarking Deep Research Agents in Financial Forecasting",
      "abstract": "Deep Research (DR) Agents powered by advanced Large Language Models (LLMs) have fundamentally shifted the paradigm for completing complex research tasks. Yet, a comprehensive and live evaluation of their forecasting performance on real-world, research-oriented tasks in high-stakes domains (e.g., finance) remains underexplored. We introduce FinDeepForecast, the first live, end-to-end multi-agent system for automatically evaluating DR agents by continuously generating research-oriented financial forecasting tasks. This system is equipped with a dual-track taxonomy, enabling the dynamic generation of recurrent and non-recurrent forecasting tasks at both corporate and macro levels. With this system, we generate FinDeepForecastBench, a weekly evaluation benchmark over a ten-week horizon, encompassing 8 global economies and 1,314 listed companies, and evaluate 13 representative methods. Extensive experiments show that, while DR agents consistently outperform strong baselines, their performance still falls short of genuine forward-looking financial reasoning. We expect the proposed FinDeepForecast system to consistently facilitate future advancements of DR agents in research-oriented financial forecasting tasks. The benchmark and leaderboard are publicly available on the OpenFinArena Platform.",
      "authors": [
        "Xiangyu Li",
        "Xuan Yao",
        "Guohao Qi",
        "Fengbin Zhu",
        "Kelvin J. L. Koa",
        "Xiang Yao Ng",
        "Ziyang Liu",
        "Xingyu Ni",
        "Chang Liu",
        "Yonghui Yang",
        "Yang Zhang",
        "Wenjie Wang",
        "Fuli Feng",
        "Chao Wang",
        "Huanbo Luan",
        "Xiaofen Xing",
        "Xiangmin Xu",
        "Tat-Seng Chua",
        "Ke-Wei Huang"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA"
      ],
      "published": "2026-01-08 15:45:09+00:00",
      "link": "https://arxiv.org/pdf/2601.05039v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05038v1",
      "title": "ArcAligner: Adaptive Recursive Aligner for Compressed Context Embeddings in RAG",
      "abstract": "Retrieval-Augmented Generation (RAG) helps LLMs stay accurate, but feeding long documents into a prompt makes the model slow and expensive. This has motivated context compression, ranging from token pruning and summarization to embedding-based compression. While researchers have tried ''compressing'' these documents into smaller summaries or mathematical embeddings, there is a catch: the more you compress the data, the more the LLM struggles to understand it. To address this challenge, we propose ArcAligner (Adaptive recursive context *Aligner*), a lightweight module integrated into the language model layers to help the model better utilize highly compressed context representations for downstream generation. It uses an adaptive ''gating'' system that only adds extra processing power when the information is complex, keeping the system fast. Across knowledge-intensive QA benchmarks, ArcAligner consistently beats compression baselines at comparable compression rates, especially on multi-hop and long-tail settings. The source code is publicly available.",
      "authors": [
        "Jianbo Li",
        "Yi Jiang",
        "Sendong Zhao",
        "Bairui Hu",
        "Haochun Wang",
        "Bing Qin"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-08 15:44:52+00:00",
      "link": "https://arxiv.org/pdf/2601.05038v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05027v1",
      "title": "OptiSet: Unified Optimizing Set Selection and Ranking for Retrieval-Augmented Generation",
      "abstract": "Retrieval-Augmented Generation (RAG) improves generation quality by incorporating evidence retrieved from large external corpora. However, most existing methods rely on statically selecting top-k passages based on individual relevance, which fails to exploit combinatorial gains among passages and often introduces substantial redundancy. To address this limitation, we propose OptiSet, a set-centric framework that unifies set selection and set-level ranking for RAG. OptiSet adopts an \"Expand-then-Refine\" paradigm: it first expands a query into multiple perspectives to enable a diverse candidate pool and then refines the candidate pool via re-selection to form a compact evidence set. We then devise a self-synthesis strategy without strong LLM supervision to derive preference labels from the set conditional utility changes of the generator, thereby identifying complementary and redundant evidence. Finally, we introduce a set-list wise training strategy that jointly optimizes set selection and set-level ranking, enabling the model to favor compact, high-gain evidence sets. Extensive experiments demonstrate that OptiSet improves performance on complex combinatorial problems and makes generation more efficient. The source code is publicly available.",
      "authors": [
        "Yi Jiang",
        "Sendong Zhao",
        "Jianbo Li",
        "Bairui Hu",
        "Yanrui Du",
        "Haochun Wang",
        "Bing Qin"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 15:35:01+00:00",
      "link": "https://arxiv.org/pdf/2601.05027v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05017v1",
      "title": "HMVI: Unifying Heterogeneous Attributes with Natural Neighbors for Missing Value Inference",
      "abstract": "Missing value imputation is a fundamental challenge in machine intelligence, heavily dependent on data completeness. Current imputation methods often handle numerical and categorical attributes independently, overlooking critical interdependencies among heterogeneous features. To address these limitations, we propose a novel imputation approach that explicitly models cross-type feature dependencies within a unified framework. Our method leverages both complete and incomplete instances to ensure accurate and consistent imputation in tabular data. Extensive experimental results demonstrate that the proposed approach achieves superior performance over existing techniques and significantly enhances downstream machine learning tasks, providing a robust solution for real-world systems with missing data.",
      "authors": [
        "Xiaopeng Luo",
        "Zexi Tan",
        "Zhuowei Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 15:18:36+00:00",
      "link": "https://arxiv.org/pdf/2601.05017v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.05016v1",
      "title": "From Idea to Co-Creation: A Planner-Actor-Critic Framework for Agent Augmented 3D Modeling",
      "abstract": "We present a framework that extends the Actor-Critic architecture to creative 3D modeling through multi-agent self-reflection and human-in-the-loop supervision. While existing approaches rely on single-prompt agents that directly execute modeling commands via tools like Blender MCP, our approach introduces a Planner-Actor-Critic architecture. In this design, the Planner coordinates modeling steps, the Actor executes them, and the Critic provides iterative feedback, while human users act as supervisors and advisors throughout the process. Through systematic comparison between single-prompt modeling and our reflective multi-agent approach, we demonstrate improvements in geometric accuracy, aesthetic quality, and task completion rates across diverse 3D modeling scenarios. Our evaluation reveals that critic-guided reflection, combined with human supervisory input, reduces modeling errors and increases complexity and quality of the result compared to direct single-prompt execution. This work establishes that structured agent self-reflection, when augmented by human oversight and advisory guidance, produces higher-quality 3D models while maintaining efficient workflow integration through real-time Blender synchronization.",
      "authors": [
        "Jin Gao",
        "Saichandu Juluri"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GR",
        "cs.HC"
      ],
      "published": "2026-01-08 15:18:12+00:00",
      "link": "https://arxiv.org/pdf/2601.05016v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.05014v1",
      "title": "The RoboSense Challenge: Sense Anything, Navigate Anywhere, Adapt Across Platforms",
      "abstract": "Autonomous systems are increasingly deployed in open and dynamic environments -- from city streets to aerial and indoor spaces -- where perception models must remain reliable under sensor noise, environmental variation, and platform shifts. However, even state-of-the-art methods often degrade under unseen conditions, highlighting the need for robust and generalizable robot sensing. The RoboSense 2025 Challenge is designed to advance robustness and adaptability in robot perception across diverse sensing scenarios. It unifies five complementary research tracks spanning language-grounded decision making, socially compliant navigation, sensor configuration generalization, cross-view and cross-modal correspondence, and cross-platform 3D perception. Together, these tasks form a comprehensive benchmark for evaluating real-world sensing reliability under domain shifts, sensor failures, and platform discrepancies. RoboSense 2025 provides standardized datasets, baseline models, and unified evaluation protocols, enabling large-scale and reproducible comparison of robust perception methods. The challenge attracted 143 teams from 85 institutions across 16 countries, reflecting broad community engagement. By consolidating insights from 23 winning solutions, this report highlights emerging methodological trends, shared design principles, and open challenges across all tracks, marking a step toward building robots that can sense reliably, act robustly, and adapt across platforms in real-world environments.",
      "authors": [
        "Lingdong Kong",
        "Shaoyuan Xie",
        "Zeying Gong",
        "Ye Li",
        "Meng Chu",
        "Ao Liang",
        "Yuhao Dong",
        "Tianshuai Hu",
        "Ronghe Qiu",
        "Rong Li",
        "Hanjiang Hu",
        "Dongyue Lu",
        "Wei Yin",
        "Wenhao Ding",
        "Linfeng Li",
        "Hang Song",
        "Wenwei Zhang",
        "Yuexin Ma",
        "Junwei Liang",
        "Zhedong Zheng",
        "Lai Xing Ng",
        "Benoit R. Cottereau",
        "Wei Tsang Ooi",
        "Ziwei Liu",
        "Zhanpeng Zhang",
        "Weichao Qiu",
        "Wei Zhang",
        "Ji Ao",
        "Jiangpeng Zheng",
        "Siyu Wang",
        "Guang Yang",
        "Zihao Zhang",
        "Yu Zhong",
        "Enzhu Gao",
        "Xinhan Zheng",
        "Xueting Wang",
        "Shouming Li",
        "Yunkai Gao",
        "Siming Lan",
        "Mingfei Han",
        "Xing Hu",
        "Dusan Malic",
        "Christian Fruhwirth-Reisinger",
        "Alexander Prutsch",
        "Wei Lin",
        "Samuel Schulter",
        "Horst Possegger",
        "Linfeng Li",
        "Jian Zhao",
        "Zepeng Yang",
        "Yuhang Song",
        "Bojun Lin",
        "Tianle Zhang",
        "Yuchen Yuan",
        "Chi Zhang",
        "Xuelong Li",
        "Youngseok Kim",
        "Sihwan Hwang",
        "Hyeonjun Jeong",
        "Aodi Wu",
        "Xubo Luo",
        "Erjia Xiao",
        "Lingfeng Zhang",
        "Yingbo Tang",
        "Hao Cheng",
        "Renjing Xu",
        "Wenbo Ding",
        "Lei Zhou",
        "Long Chen",
        "Hangjun Ye",
        "Xiaoshuai Hao",
        "Shuangzhi Li",
        "Junlong Shen",
        "Xingyu Li",
        "Hao Ruan",
        "Jinliang Lin",
        "Zhiming Luo",
        "Yu Zang",
        "Cheng Wang",
        "Hanshi Wang",
        "Xijie Gong",
        "Yixiang Yang",
        "Qianli Ma",
        "Zhipeng Zhang",
        "Wenxiang Shi",
        "Jingmeng Zhou",
        "Weijun Zeng",
        "Kexin Xu",
        "Yuchen Zhang",
        "Haoxiang Fu",
        "Ruibin Hu",
        "Yanbiao Ma",
        "Xiyan Feng",
        "Wenbo Zhang",
        "Lu Zhang",
        "Yunzhi Zhuge",
        "Huchuan Lu",
        "You He",
        "Seungjun Yu",
        "Junsung Park",
        "Youngsun Lim",
        "Hyunjung Shim",
        "Faduo Liang",
        "Zihang Wang",
        "Yiming Peng",
        "Guanyu Zong",
        "Xu Li",
        "Binghao Wang",
        "Hao Wei",
        "Yongxin Ma",
        "Yunke Shi",
        "Shuaipeng Liu",
        "Dong Kong",
        "Yongchun Lin",
        "Huitong Yang",
        "Liang Lei",
        "Haoang Li",
        "Xinliang Zhang",
        "Zhiyong Wang",
        "Xiaofeng Wang",
        "Yuxia Fu",
        "Yadan Luo",
        "Djamahl Etchegaray",
        "Yang Li",
        "Congfei Li",
        "Yuxiang Sun",
        "Wenkai Zhu",
        "Wang Xu",
        "Linru Li",
        "Longjie Liao",
        "Jun Yan",
        "Benwu Wang",
        "Xueliang Ren",
        "Xiaoyu Yue",
        "Jixian Zheng",
        "Jinfeng Wu",
        "Shurui Qin",
        "Wei Cong",
        "Yao He"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-08 15:16:18+00:00",
      "link": "https://arxiv.org/pdf/2601.05014v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.05009v1",
      "title": "An Empirical Investigation of Robustness in Large Language Models under Tabular Distortions",
      "abstract": "We investigate how large language models (LLMs) fail when tabular data in an otherwise canonical representation is subjected to semantic and structural distortions. Our findings reveal that LLMs lack an inherent ability to detect and correct subtle distortions in table representations. Only when provided with an explicit prior, via a system prompt, do models partially adjust their reasoning strategies and correct some distortions, though not consistently or completely. To study this phenomenon, we introduce a small, expert-curated dataset that explicitly evaluates LLMs on table question answering (TQA) tasks requiring an additional error-correction step prior to analysis. Our results reveal systematic differences in how LLMs ingest and interpret tabular information under distortion, with even SoTA models such as GPT-5.2 model exhibiting a drop of minimum 22% accuracy under distortion. These findings raise important questions for future research, particularly regarding when and how models should autonomously decide to realign tabular inputs, analogous to human behavior, without relying on explicit prompts or tabular data pre-processing.",
      "authors": [
        "Avik Dutta",
        "Harshit Nigam",
        "Hosein Hasanbeig",
        "Arjun Radhakrishna",
        "Sumit Gulwani"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 15:10:32+00:00",
      "link": "https://arxiv.org/pdf/2601.05009v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.05002v1",
      "title": "On the Hidden Objective Biases of Group-based Reinforcement Learning",
      "abstract": "Group-based reinforcement learning methods, like Group Relative Policy Optimization (GRPO), are widely used nowadays to post-train large language models. Despite their empirical success, they exhibit structural mismatches between reward optimization and the underlying training objective. In this paper, we present a theoretical analysis of GRPO style methods by studying them within a unified surrogate formulation. This perspective reveals recurring properties that affect all the methods under analysis: (i) non-uniform group weighting induces systematic gradient biases on shared prefix tokens; (ii) interactions with the AdamW optimizer make training dynamics largely insensitive to reward scaling; and (iii) optimizer momentum can push policy updates beyond the intended clipping region under repeated optimization steps. We believe that these findings highlight fundamental limitations of current approaches and provide principled guidance for the design of future formulations.",
      "authors": [
        "Aleksandar Fontana",
        "Marco Simoni",
        "Giulio Rossolini",
        "Andrea Saracino",
        "Paolo Mori"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 15:00:35+00:00",
      "link": "https://arxiv.org/pdf/2601.05002v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04996v1",
      "title": "AlgBench: To What Extent Do Large Reasoning Models Understand Algorithms?",
      "abstract": "Reasoning ability has become a central focus in the advancement of Large Reasoning Models (LRMs). Although notable progress has been achieved on several reasoning benchmarks such as MATH500 and LiveCodeBench, existing benchmarks for algorithmic reasoning remain limited, failing to answer a critical question: Do LRMs truly master algorithmic reasoning? To answer this question, we propose AlgBench, an expert-curated benchmark that evaluates LRMs under an algorithm-centric paradigm.   AlgBench consists of over 3,000 original problems spanning 27 algorithms, constructed by ACM algorithmic experts and organized under a comprehensive taxonomy, including Euclidean-structured, non-Euclidean-structured, non-optimized, local-optimized, global-optimized, and heuristic-optimized categories. Empirical evaluations on leading LRMs (e.g., Gemini-3-Pro, DeepSeek-v3.2-Speciale and GPT-o3) reveal substantial performance heterogeneity: while models perform well on non-optimized tasks (up to 92%), accuracy drops sharply to around 49% on globally optimized algorithms such as dynamic programming. Further analysis uncovers \\textbf{strategic over-shifts}, wherein models prematurely abandon correct algorithmic designs due to necessary low-entropy tokens. These findings expose fundamental limitations of problem-centric reinforcement learning and highlight the necessity of an algorithm-centric training paradigm for robust algorithmic reasoning.",
      "authors": [
        "Henan Sun",
        "Kaichi Yu",
        "Yuyao Wang",
        "Bowen Liu",
        "Xunkai Li",
        "Rong-Hua Li",
        "Nuo Chen",
        "Jia Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 14:54:44+00:00",
      "link": "https://arxiv.org/pdf/2601.04996v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04992v1",
      "title": "Learning from Mistakes: Negative Reasoning Samples Enhance Out-of-Domain Generalization",
      "abstract": "Supervised fine-tuning (SFT) on chain-of-thought (CoT) trajectories demonstrations is a common approach for enabling reasoning in large language models. Standard practices typically only retain trajectories with correct final answers (positives) while ignoring the rest (negatives). We argue that this paradigm discards substantial supervision and exacerbates overfitting, limiting out-of-domain (OOD) generalization. Specifically, we surprisingly find that incorporating negative trajectories into SFT yields substantial OOD generalization gains over positive-only training, as these trajectories often retain valid intermediate reasoning despite incorrect final answers. To understand this effect in depth, we systematically analyze data, training dynamics, and inference behavior, identifying 22 recurring patterns in negative chains that serve a dual role: they moderate loss descent to mitigate overfitting during training and boost policy entropy by 35.67% during inference to facilitate exploration. Motivated by these observations, we further propose Gain-based LOss Weighting (GLOW), an adaptive, sample-aware scheme that exploits such distinctive training dynamics by rescaling per-sample loss based on inter-epoch progress. Empirically, GLOW efficiently leverages unfiltered trajectories, yielding a 5.51% OOD gain over positive-only SFT on Qwen2.5-7B and boosting MMLU from 72.82% to 76.47% as an RL initialization.",
      "authors": [
        "Xueyun Tian",
        "Minghua Ma",
        "Bingbing Xu",
        "Nuoyan Lyu",
        "Wei Li",
        "Heng Dong",
        "Zheng Chu",
        "Yuanzhuo Wang",
        "Huawei Shen"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 14:49:10+00:00",
      "link": "https://arxiv.org/pdf/2601.04992v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04984v1",
      "title": "OceanSplat: Object-aware Gaussian Splatting with Trinocular View Consistency for Underwater Scene Reconstruction",
      "abstract": "We introduce OceanSplat, a novel 3D Gaussian Splatting-based approach for accurately representing 3D geometry in underwater scenes. To overcome multi-view inconsistencies caused by underwater optical degradation, our method enforces trinocular view consistency by rendering horizontally and vertically translated camera views relative to each input view and aligning them via inverse warping. Furthermore, these translated camera views are used to derive a synthetic epipolar depth prior through triangulation, which serves as a self-supervised depth regularizer. These geometric constraints facilitate the spatial optimization of 3D Gaussians and preserve scene structure in underwater environments. We also propose a depth-aware alpha adjustment that modulates the opacity of 3D Gaussians during early training based on their $z$-component and viewing direction, deterring the formation of medium-induced primitives. With our contributions, 3D Gaussians are disentangled from the scattering medium, enabling robust representation of object geometry and significantly reducing floating artifacts in reconstructed underwater scenes. Experiments on real-world underwater and simulated scenes demonstrate that OceanSplat substantially outperforms existing methods for both scene reconstruction and restoration in scattering media.",
      "authors": [
        "Minseong Kweon",
        "Jinsun Park"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 14:38:39+00:00",
      "link": "https://arxiv.org/pdf/2601.04984v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04973v1",
      "title": "ConMax: Confidence-Maximizing Compression for Efficient Chain-of-Thought Reasoning",
      "abstract": "Recent breakthroughs in Large Reasoning Models (LRMs) have demonstrated that extensive Chain-of-Thought (CoT) generation is critical for enabling intricate cognitive behaviors, such as self-verification and backtracking, to solve complex tasks. However, this capability often leads to ``overthinking'', where models generate redundant reasoning paths that inflate computational costs without improving accuracy. While Supervised Fine-Tuning (SFT) on reasoning traces is a standard paradigm for the 'cold start' phase, applying existing compression techniques to these traces often compromises logical coherence or incurs prohibitive sampling costs. In this paper, we introduce ConMax (Confidence-Maximizing Compression), a novel reinforcement learning framework designed to automatically compress reasoning traces while preserving essential reasoning patterns. ConMax formulates compression as a reward-driven optimization problem, training a policy to prune redundancy by maximizing a weighted combination of answer confidence for predictive fidelity and thinking confidence for reasoning validity through a frozen auxiliary LRM. Extensive experiments across five reasoning datasets demonstrate that ConMax achieves a superior efficiency-performance trade-off. Specifically, it reduces inference length by 43% over strong baselines at the cost of a mere 0.7% dip in accuracy, proving its effectiveness in generating high-quality, efficient training data for LRMs.",
      "authors": [
        "Minda Hu",
        "Zexuan Qiu",
        "Zenan Xu",
        "Kun Li",
        "Bo Zhou",
        "Irwin King"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 14:22:58+00:00",
      "link": "https://arxiv.org/pdf/2601.04973v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04954v1",
      "title": "Precision over Diversity: High-Precision Reward Generalizes to Robust Instruction Following",
      "abstract": "A central belief in scaling reinforcement learning with verifiable rewards for instruction following (IF) tasks is that, a diverse mixture of verifiable hard and unverifiable soft constraints is essential for generalizing to unseen instructions. In this work, we challenge this prevailing consensus through a systematic empirical investigation. Counter-intuitively, we find that models trained on hard-only constraints consistently outperform those trained on mixed datasets. Extensive experiments reveal that reward precision, rather than constraint diversity, is the primary driver of effective alignment. The LLM judge suffers from a low recall rate in detecting false response, which leads to severe reward hacking, thereby undermining the benefits of diversity. Furthermore, analysis of the attention mechanism reveals that high-precision rewards develop a transferable meta-skill for IF. Motivated by these insights, we propose a simple yet effective data-centric refinement strategy that prioritizes reward precision. Evaluated on five benchmarks, our approach outperforms competitive baselines by 13.4\\% in performance while achieving a 58\\% reduction in training time, maintaining strong generalization beyond instruction following. Our findings advocate for a paradigm shift: moving away from the indiscriminate pursuit of data diversity toward high-precision rewards.",
      "authors": [
        "Yirong Zeng",
        "Yufei Liu",
        "Xiao Ding",
        "Yutai Hou",
        "Yuxian Wang",
        "Haonan Song",
        "Wu Ning",
        "Dandan Tu",
        "Qixun Zhang",
        "Bibo Cai",
        "Yuxiang He",
        "Ting Liu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 14:00:51+00:00",
      "link": "https://arxiv.org/pdf/2601.04954v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04945v1",
      "title": "T-Retriever: Tree-based Hierarchical Retrieval Augmented Generation for Textual Graphs",
      "abstract": "Retrieval-Augmented Generation (RAG) has significantly enhanced Large Language Models' ability to access external knowledge, yet current graph-based RAG approaches face two critical limitations in managing hierarchical information: they impose rigid layer-specific compression quotas that damage local graph structures, and they prioritize topological structure while neglecting semantic content. We introduce T-Retriever, a novel framework that reformulates attributed graph retrieval as tree-based retrieval using a semantic and structure-guided encoding tree. Our approach features two key innovations: (1) Adaptive Compression Encoding, which replaces artificial compression quotas with a global optimization strategy that preserves the graph's natural hierarchical organization, and (2) Semantic-Structural Entropy ($S^2$-Entropy), which jointly optimizes for both structural cohesion and semantic consistency when creating hierarchical partitions. Experiments across diverse graph reasoning benchmarks demonstrate that T-Retriever significantly outperforms state-of-the-art RAG methods, providing more coherent and contextually relevant responses to complex queries.",
      "authors": [
        "Chunyu Wei",
        "Huaiyu Qin",
        "Siyuan He",
        "Yunhai Wang",
        "Yueguo Chen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 13:49:12+00:00",
      "link": "https://arxiv.org/pdf/2601.04945v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04941v1",
      "title": "Cardinality augmented loss functions",
      "abstract": "Class imbalance is a common and pernicious issue for the training of neural networks. Often, an imbalanced majority class can dominate training to skew classifier performance towards the majority outcome. To address this problem we introduce cardinality augmented loss functions, derived from cardinality-like invariants in modern mathematics literature such as magnitude and the spread. These invariants enrich the concept of cardinality by evaluating the `effective diversity' of a metric space, and as such represent a natural solution to overly homogeneous training data. In this work, we establish a methodology for applying cardinality augmented loss functions in the training of neural networks and report results on both artificially imbalanced datasets as well as a real-world imbalanced material science dataset. We observe significant performance improvement among minority classes, as well as improvement in overall performance metrics.",
      "authors": [
        "Miguel O'Malley"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 13:43:55+00:00",
      "link": "https://arxiv.org/pdf/2601.04941v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04932v1",
      "title": "GenProve: Learning to Generate Text with Fine-Grained Provenance",
      "abstract": "Large language models (LLM) often hallucinate, and while adding citations is a common solution, it is frequently insufficient for accountability as users struggle to verify how a cited source supports a generated claim. Existing methods are typically coarse-grained and fail to distinguish between direct quotes and complex reasoning. In this paper, we introduce Generation-time Fine-grained Provenance, a task where models must generate fluent answers while simultaneously producing structured, sentence-level provenance triples. To enable this, we present ReFInE (Relation-aware Fine-grained Interpretability & Evidence), a dataset featuring expert verified annotations that distinguish between Quotation, Compression, and Inference. Building on ReFInE, we propose GenProve, a framework that combines Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO). By optimizing a composite reward for answer fidelity and provenance correctness, GenProve significantly outperforms 14 strong LLMs in joint evaluation. Crucially, our analysis uncovers a reasoning gap where models excel at surface-level quotation but struggle significantly with inference-based provenance, suggesting that verifiable reasoning remains a frontier challenge distinct from surface-level citation.",
      "authors": [
        "Jingxuan Wei",
        "Xingyue Wang",
        "Yanghaoyu Liao",
        "Jie Dong",
        "Yuchen Liu",
        "Caijun Jia",
        "Bihui Yu",
        "Junnan Zhu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 13:30:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04932v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04919v1",
      "title": "What Students Ask, How a Generative AI Assistant Responds: Exploring Higher Education Students' Dialogues on Learning Analytics Feedback",
      "abstract": "Learning analytics dashboards (LADs) aim to support students' regulation of learning by translating complex data into feedback. Yet students, especially those with lower self-regulated learning (SRL) competence, often struggle to engage with and interpret analytics feedback. Conversational generative artificial intelligence (GenAI) assistants have shown potential to scaffold this process through real-time, personalised, dialogue-based support. Further advancing this potential, we explored authentic dialogues between students and GenAI assistant integrated into LAD during a 10-week semester. The analysis focused on questions students with different SRL levels posed, the relevance and quality of the assistant's answers, and how students perceived the assistant's role in their learning. Findings revealed distinct query patterns. While low SRL students sought clarification and reassurance, high SRL students queried technical aspects and requested personalised strategies. The assistant provided clear and reliable explanations but limited in personalisation, handling emotionally charged queries, and integrating multiple data points for tailored responses. Findings further extend that GenAI interventions can be especially valuable for low SRL students, offering scaffolding that supports engagement with feedback and narrows gaps with their higher SRL peers. At the same time, students' reflections underscored the importance of trust, need for greater adaptivity, context-awareness, and technical refinement in future systems.",
      "authors": [
        "Yildiz Uzun",
        "Andrea Gauthier",
        "Mutlu Cukurova"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "published": "2026-01-08 13:17:44+00:00",
      "link": "https://arxiv.org/pdf/2601.04919v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04918v1",
      "title": "Breaking Robustness Barriers in Cognitive Diagnosis: A One-Shot Neural Architecture Search Perspective",
      "abstract": "With the advancement of network technologies, intelligent tutoring systems (ITS) have emerged to deliver increasingly precise and tailored personalized learning services. Cognitive diagnosis (CD) has emerged as a core research task in ITS, aiming to infer learners' mastery of specific knowledge concepts by modeling the mapping between learning behavior data and knowledge states. However, existing research prioritizes model performance enhancement while neglecting the pervasive noise contamination in observed response data, significantly hindering practical deployment. Furthermore, current cognitive diagnosis models (CDMs) rely heavily on researchers' domain expertise for structural design, which fails to exhaustively explore architectural possibilities, thus leaving model architectures' full potential untapped. To address this issue, we propose OSCD, an evolutionary multi-objective One-Shot neural architecture search method for Cognitive Diagnosis, designed to efficiently and robustly improve the model's capability in assessing learner proficiency. Specifically, OSCD operates through two distinct stages: training and searching. During the training stage, we construct a search space encompassing diverse architectural combinations and train a weight-sharing supernet represented via the complete binary tree topology, enabling comprehensive exploration of potential architectures beyond manual design priors. In the searching stage, we formulate the optimal architecture search under heterogeneous noise scenarios as a multi-objective optimization problem (MOP), and develop an optimization framework integrating a Pareto-optimal solution search strategy with cross-scenario performance evaluation for resolution. Extensive experiments on real-world educational datasets validate the effectiveness and robustness of the optimal architectures discovered by our OSCD model for CD tasks.",
      "authors": [
        "Ziwen Wang",
        "Shangshang Yang",
        "Xiaoshan Yu",
        "Haiping Ma",
        "Xingyi Zhang"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2026-01-08 13:17:40+00:00",
      "link": "https://arxiv.org/pdf/2601.04918v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04912v1",
      "title": "Decentralized Privacy-Preserving Federal Learning of Computer Vision Models on Edge Devices",
      "abstract": "Collaborative training of a machine learning model comes with a risk of sharing sensitive or private data. Federated learning offers a way of collectively training a single global model without the need to share client data, by sharing only the updated parameters from each client's local model. A central server is then used to aggregate parameters from all clients and redistribute the aggregated model back to the clients. Recent findings have shown that even in this scenario, private data can be reconstructed only using information about model parameters. Current efforts to mitigate this are mainly focused on reducing privacy risks on the server side, assuming that other clients will not act maliciously. In this work, we analyzed various methods for improving the privacy of client data concerning both the server and other clients for neural networks. Some of these methods include homomorphic encryption, gradient compression, gradient noising, and discussion on possible usage of modified federated learning systems such as split learning, swarm learning or fully encrypted models. We have analyzed the negative effects of gradient compression and gradient noising on the accuracy of convolutional neural networks used for classification. We have shown the difficulty of data reconstruction in the case of segmentation networks. We have also implemented a proof of concept on the NVIDIA Jetson TX2 module used in edge devices and simulated a federated learning process.",
      "authors": [
        "Damian Harenčák",
        "Lukáš Gajdošech",
        "Martin Madaras"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.CV"
      ],
      "published": "2026-01-08 13:10:33+00:00",
      "link": "https://arxiv.org/pdf/2601.04912v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04895v1",
      "title": "DVD: A Robust Method for Detecting Variant Contamination in Large Language Model Evaluation",
      "abstract": "Evaluating large language models (LLMs) is increasingly confounded by \\emph{variant contamination}: the training corpus contains semantically equivalent yet lexically or syntactically altered versions of test items. Unlike verbatim leakage, these paraphrased or structurally transformed variants evade existing detectors based on sampling consistency or perplexity, thereby inflating benchmark scores via memorization rather than genuine reasoning. We formalize this problem and introduce \\textbf{DVD} (\\textbf{D}etection via \\textbf{V}ariance of generation \\textbf{D}istribution), a single-sample detector that models the local output distribution induced by temperature sampling. Our key insight is that contaminated items trigger alternation between a \\emph{memory-adherence} state and a \\emph{perturbation-drift} state, yielding abnormally high variance in the synthetic difficulty of low-probability tokens; uncontaminated items remain in drift with comparatively smooth variance. We construct the first benchmark for variant contamination across two domains Omni-MATH and SuperGPQA by generating and filtering semantically equivalent variants, and simulate contamination via fine-tuning models of different scales and architectures (Qwen2.5 and Llama3.1). Across datasets and models, \\textbf{DVD} consistently outperforms perplexity-based, Min-$k$\\%++, edit-distance (CDD), and embedding-similarity baselines, while exhibiting strong robustness to hyperparameters. Our results establish variance of the generation distribution as a principled and practical fingerprint for detecting variant contamination in LLM evaluation.",
      "authors": [
        "Renzhao Liang",
        "Jingru Chen",
        "Bo Jia",
        "Bo Deng",
        "Chenggang Xie",
        "Yidong Wang",
        "Ke Jin",
        "Xin Wang",
        "Linfeng Zhang",
        "Cunxiang Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 12:48:40+00:00",
      "link": "https://arxiv.org/pdf/2601.04895v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04891v1",
      "title": "Scaling Vision Language Models for Pharmaceutical Long Form Video Reasoning on Industrial GenAI Platform",
      "abstract": "Vision Language Models (VLMs) have shown strong performance on multimodal reasoning tasks, yet most evaluations focus on short videos and assume unconstrained computational resources. In industrial settings such as pharmaceutical content understanding, practitioners must process long-form videos under strict GPU, latency, and cost constraints, where many existing approaches fail to scale. In this work, we present an industrial GenAI framework that processes over 200,000 PDFs, 25,326 videos across eight formats (e.g., MP4, M4V, etc.), and 888 multilingual audio files in more than 20 languages. Our study makes three contributions: (i) an industrial large-scale architecture for multimodal reasoning in pharmaceutical domains; (ii) empirical analysis of over 40 VLMs on two leading benchmarks (Video-MME and MMBench) and proprietary dataset of 25,326 videos across 14 disease areas; and (iii) four findings relevant to long-form video reasoning: the role of multimodality, attention mechanism trade-offs, temporal reasoning limits, and challenges of video splitting under GPU constraints. Results show 3-8 times efficiency gains with SDPA attention on commodity GPUs, multimodality improving up to 8/12 task domains (especially length-dependent tasks), and clear bottlenecks in temporal alignment and keyframe detection across open- and closed-source VLMs. Rather than proposing a new \"A+B\" model, this paper characterizes practical limits, trade-offs, and failure patterns of current VLMs under realistic deployment constraints, and provide actionable guidance for both researchers and practitioners designing scalable multimodal systems for long-form video understanding in industrial domains.",
      "authors": [
        "Suyash Mishra",
        "Qiang Li",
        "Srikanth Patil",
        "Satyanarayan Pati",
        "Baddu Narendra"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-08 12:42:17+00:00",
      "link": "https://arxiv.org/pdf/2601.04891v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04890v1",
      "title": "Learnable Multipliers: Freeing the Scale of Language Model Matrix Layers",
      "abstract": "Applying weight decay (WD) to matrix layers is standard practice in large-language-model pretraining. Prior work suggests that stochastic gradient noise induces a Brownian-like expansion of the weight matrices W, whose growth is counteracted by WD, leading to a WD-noise equilibrium with a certain weight norm ||W||. In this work, we view the equilibrium norm as a harmful artifact of the training procedure, and address it by introducing learnable multipliers to learn the optimal scale. First, we attach a learnable scalar multiplier to W and confirm that the WD-noise equilibrium norm is suboptimal: the learned scale adapts to data and improves performance. We then argue that individual row and column norms are similarly constrained, and free their scale by introducing learnable per-row and per-column multipliers. Our method can be viewed as a learnable, more expressive generalization of muP multipliers. It outperforms a well-tuned muP baseline, reduces the computational overhead of multiplier tuning, and surfaces practical questions such as forward-pass symmetries and the width-scaling of the learned multipliers. Finally, we validate learnable multipliers with both Adam and Muon optimizers, where it shows improvement in downstream evaluations matching the improvement of the switching from Adam to Muon.",
      "authors": [
        "Maksim Velikanov",
        "Ilyas Chahed",
        "Jingwei Zuo",
        "Dhia Eddine Rhaiem",
        "Younes Belkada",
        "Hakim Hacid"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 12:41:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04890v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04889v1",
      "title": "Faithful Summarisation under Disagreement via Belief-Level Aggregation",
      "abstract": "Opinion and multi-document summarisation often involve genuinely conflicting viewpoints, yet many existing approaches, particularly LLM-based systems, implicitly smooth disagreement and over-represent majority opinions. This limits the faithfulness of generated summaries in opinion-heavy settings. We introduce a disagreement-aware synthesis pipeline that separates belief-level aggregation from language generation. Documents are first represented as structured belief sets and aggregated using distance-based belief merging operators that explicitly model conflict. Large language models are then used only to realise the aggregated beliefs as natural language summaries. We evaluate the approach across multiple model families and scales, comparing it to methods that perform explicit aggregation during generation. Our results show that while sufficiently large models can match belief-level aggregation when aggregation is handled at generation time, this behaviour is not stable across architectures or capacities. In contrast, belief-level aggregation combined with simple prompting yields consistently strong disagreement-aware performance across models, while maintaining fluent and grounded summaries.",
      "authors": [
        "Favour Yahdii Aghaebe",
        "Tanefa Apekey",
        "Elizabeth Williams",
        "Nafise Sadat Moosavi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 12:40:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04889v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04888v1",
      "title": "SmartSearch: Process Reward-Guided Query Refinement for Search Agents",
      "abstract": "Large language model (LLM)-based search agents have proven promising for addressing knowledge-intensive problems by incorporating information retrieval capabilities. Existing works largely focus on optimizing the reasoning paradigms of search agents, yet the quality of intermediate search queries during reasoning remains overlooked. As a result, the generated queries often remain inaccurate, leading to unexpected retrieval results and ultimately limiting search agents' overall effectiveness. To mitigate this issue, we introduce SmartSearch, a framework built upon two key mechanisms: (1) Process rewards, which provide fine-grained supervision for the quality of each intermediate search query through Dual-Level Credit Assessment. (2) Query refinement, which promotes the optimization of query generation by selectively refining low-quality search queries and regenerating subsequent search rounds based on these refinements. To enable the search agent to progressively internalize the ability to improve query quality under the guidance of process rewards, we design a three-stage curriculum learning framework. This framework guides the agent through a progression from imitation, to alignment, and ultimately to generalization. Experimental results show that SmartSearch consistently surpasses existing baselines, and additional quantitative analyses further confirm its significant gains in both search efficiency and query quality. The code is available at https://github.com/MYVAE/SmartSearch.",
      "authors": [
        "Tongyu Wen",
        "Guanting Dong",
        "Zhicheng Dou"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 12:39:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04888v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04887v1",
      "title": "Flexible Manufacturing Systems Intralogistics: Dynamic Optimization of AGVs and Tool Sharing Using Coloured-Timed Petri Nets and Actor-Critic RL with Actions Masking",
      "abstract": "Flexible Manufacturing Systems (FMS) are pivotal in optimizing production processes in today's rapidly evolving manufacturing landscape. This paper advances the traditional job shop scheduling problem by incorporating additional complexities through the simultaneous integration of automated guided vehicles (AGVs) and tool-sharing systems. We propose a novel approach that combines Colored-Timed Petri Nets (CTPNs) with actor-critic model-based reinforcement learning (MBRL), effectively addressing the multifaceted challenges associated with FMS. CTPNs provide a formal modeling structure and dynamic action masking, significantly reducing the action search space, while MBRL ensures adaptability to changing environments through the learned policy. Leveraging the advantages of MBRL, we incorporate a lookahead strategy for optimal positioning of AGVs, improving operational efficiency. Our approach was evaluated on small-sized public benchmarks and a newly developed large-scale benchmark inspired by the Taillard benchmark. The results show that our approach matches traditional methods on smaller instances and outperforms them on larger ones in terms of makespan while achieving a tenfold reduction in computation time. To ensure reproducibility, we propose a gym-compatible environment and an instance generator. Additionally, an ablation study evaluates the contribution of each framework component to its overall performance.",
      "authors": [
        "Sofiene Lassoued",
        "Laxmikant Shrikant Bahetic",
        "Nathalie Weiß-Borkowskib",
        "Stefan Lierc",
        "Andreas Schwunga"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 12:37:02+00:00",
      "link": "https://arxiv.org/pdf/2601.04887v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04885v1",
      "title": "CuMA: Aligning LLMs with Sparse Cultural Values via Demographic-Aware Mixture of Adapters",
      "abstract": "As Large Language Models (LLMs) serve a global audience, alignment must transition from enforcing universal consensus to respecting cultural pluralism. We demonstrate that dense models, when forced to fit conflicting value distributions, suffer from \\textbf{Mean Collapse}, converging to a generic average that fails to represent diverse groups. We attribute this to \\textbf{Cultural Sparsity}, where gradient interference prevents dense parameters from spanning distinct cultural modes. To resolve this, we propose \\textbf{\\textsc{CuMA}} (\\textbf{Cu}ltural \\textbf{M}ixture of \\textbf{A}dapters), a framework that frames alignment as a \\textbf{conditional capacity separation} problem. By incorporating demographic-aware routing, \\textsc{CuMA} internalizes a \\textit{Latent Cultural Topology} to explicitly disentangle conflicting gradients into specialized expert subspaces. Extensive evaluations on WorldValuesBench, Community Alignment, and PRISM demonstrate that \\textsc{CuMA} achieves state-of-the-art performance, significantly outperforming both dense baselines and semantic-only MoEs. Crucially, our analysis confirms that \\textsc{CuMA} effectively mitigates mean collapse, preserving cultural diversity. Our code is available at https://github.com/Throll/CuMA.",
      "authors": [
        "Ao Sun",
        "Xiaoyu Wang",
        "Zhe Tan",
        "Yu Li",
        "Jiachen Zhu",
        "Shu Su",
        "Yuheng Jia"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 12:30:43+00:00",
      "link": "https://arxiv.org/pdf/2601.04885v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04879v1",
      "title": "Mind2Report: A Cognitive Deep Research Agent for Expert-Level Commercial Report Synthesis",
      "abstract": "Synthesizing informative commercial reports from massive and noisy web sources is critical for high-stakes business decisions. Although current deep research agents achieve notable progress, their reports still remain limited in terms of quality, reliability, and coverage. In this work, we propose Mind2Report, a cognitive deep research agent that emulates the commercial analyst to synthesize expert-level reports. Specifically, it first probes fine-grained intent, then searches web sources and records distilled information on the fly, and subsequently iteratively synthesizes the report. We design Mind2Report as a training-free agentic workflow that augments general large language models (LLMs) with dynamic memory to support these long-form cognitive processes. To rigorously evaluate Mind2Report, we further construct QRC-Eval comprising 200 real-world commercial tasks and establish a holistic evaluation strategy to assess report quality, reliability, and coverage. Experiments demonstrate that Mind2Report outperforms leading baselines, including OpenAI and Gemini deep research agents. Although this is a preliminary study, we expect it to serve as a foundation for advancing the future design of commercial deep research agents. Our code and data are available at https://github.com/Melmaphother/Mind2Report.",
      "authors": [
        "Mingyue Cheng",
        "Daoyu Wang",
        "Qi Liu",
        "Shuo Yu",
        "Xiaoyu Tao",
        "Yuqian Wang",
        "Chengzhong Chu",
        "Yu Duan",
        "Mingkang Long",
        "Enhong Chen"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 12:27:52+00:00",
      "link": "https://arxiv.org/pdf/2601.04879v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04878v1",
      "title": "Higher-Order Knowledge Representations for Agentic Scientific Reasoning",
      "abstract": "Scientific inquiry requires systems-level reasoning that integrates heterogeneous experimental data, cross-domain knowledge, and mechanistic evidence into coherent explanations. While Large Language Models (LLMs) offer inferential capabilities, they often depend on retrieval-augmented contexts that lack structural depth. Traditional Knowledge Graphs (KGs) attempt to bridge this gap, yet their pairwise constraints fail to capture the irreducible higher-order interactions that govern emergent physical behavior. To address this, we introduce a methodology for constructing hypergraph-based knowledge representations that faithfully encode multi-entity relationships. Applied to a corpus of ~1,100 manuscripts on biocomposite scaffolds, our framework constructs a global hypergraph of 161,172 nodes and 320,201 hyperedges, revealing a scale-free topology (power law exponent ~1.23) organized around highly connected conceptual hubs. This representation prevents the combinatorial explosion typical of pairwise expansions and explicitly preserves the co-occurrence context of scientific formulations. We further demonstrate that equipping agentic systems with hypergraph traversal tools, specifically using node-intersection constraints, enables them to bridge semantically distant concepts. By exploiting these higher-order pathways, the system successfully generates grounded mechanistic hypotheses for novel composite materials, such as linking cerium oxide to PCL scaffolds via chitosan intermediates. This work establishes a \"teacherless\" agentic reasoning system where hypergraph topology acts as a verifiable guardrail, accelerating scientific discovery by uncovering relationships obscured by traditional graph methods.",
      "authors": [
        "Isabella A. Stewart",
        "Markus J. Buehler"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cond-mat.mtrl-sci",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-08 12:25:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04878v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04864v1",
      "title": "Key-Value Pair-Free Continual Learner via Task-Specific Prompt-Prototype",
      "abstract": "Continual learning aims to enable models to acquire new knowledge while retaining previously learned information. Prompt-based methods have shown remarkable performance in this domain; however, they typically rely on key-value pairing, which can introduce inter-task interference and hinder scalability. To overcome these limitations, we propose a novel approach employing task-specific Prompt-Prototype (ProP), thereby eliminating the need for key-value pairs. In our method, task-specific prompts facilitate more effective feature learning for the current task, while corresponding prototypes capture the representative features of the input. During inference, predictions are generated by binding each task-specific prompt with its associated prototype. Additionally, we introduce regularization constraints during prompt initialization to penalize excessively large values, thereby enhancing stability. Experiments on several widely used datasets demonstrate the effectiveness of the proposed method. In contrast to mainstream prompt-based approaches, our framework removes the dependency on key-value pairs, offering a fresh perspective for future continual learning research.",
      "authors": [
        "Haihua Luo",
        "Xuming Ran",
        "Zhengji Li",
        "Huiyan Xue",
        "Tingting Jiang",
        "Jiangrong Shen",
        "Tommi Kärkkäinen",
        "Qi Xu",
        "Fengyu Cong"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 11:59:35+00:00",
      "link": "https://arxiv.org/pdf/2601.04864v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04861v1",
      "title": "Orchestrating Intelligence: Confidence-Aware Routing for Efficient Multi-Agent Collaboration across Multi-Scale Models",
      "abstract": "While multi-agent systems (MAS) have demonstrated superior performance over single-agent approaches in complex reasoning tasks, they often suffer from significant computational inefficiencies. Existing frameworks typically deploy large language models (LLMs) uniformly across all agent roles, failing to account for the varying cognitive demands of different reasoning stages. We address this inefficiency by proposing OI-MAS framework, a novel multi-agent framework that implements an adaptive model-selection policy across a heterogeneous pool of multi-scale LLMs. Specifically, OI-MAS introduces a state-dependent routing mechanism that dynamically selects agent roles and model scales throughout the reasoning process. In addition, we introduce a confidence-aware mechanism that selects appropriate model scales conditioned on task complexity, thus reducing unnecessary reliance on large-scale models. Experimental results show that OI-MAS consistently outperforms baseline multi-agent systems, improving accuracy by up to 12.88\\% while reducing cost by up to 79.78\\%.",
      "authors": [
        "Jingbo Wang",
        "Sendong Zhao",
        "Jiatong Liu",
        "Haochun Wang",
        "Wanting Li",
        "Bing Qin",
        "Ting Liu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 11:56:09+00:00",
      "link": "https://arxiv.org/pdf/2601.04861v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04859v1",
      "title": "A Navigational Approach for Comprehensive RAG via Traversal over Proposition Graphs",
      "abstract": "Standard RAG pipelines based on chunking excel at simple factual retrieval but fail on complex multi-hop queries due to a lack of structural connectivity. Conversely, initial strategies that interleave retrieval with reasoning often lack global corpus awareness, while Knowledge Graph (KG)-based RAG performs strongly on complex multi-hop tasks but suffers on fact-oriented single-hop queries. To bridge this gap, we propose a novel RAG framework: ToPG (Traversal over Proposition Graphs). ToPG models its knowledge base as a heterogeneous graph of propositions, entities, and passages, effectively combining the granular fact density of propositions with graph connectivity. We leverage this structure using iterative Suggestion-Selection cycles, where the Suggestion phase enables a query-aware traversal of the graph, and the Selection phase provides LLM feedback to prune irrelevant propositions and seed the next iteration. Evaluated on three distinct QA tasks (Simple, Complex, and Abstract QA), ToPG demonstrates strong performance across both accuracy- and quality-based metrics. Overall, ToPG shows that query-aware graph traversal combined with factual granularity is a critical component for efficient structured RAG systems. ToPG is available at https://github.com/idiap/ToPG.",
      "authors": [
        "Maxime Delmas",
        "Lei Xu",
        "André Freitas"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 11:50:40+00:00",
      "link": "https://arxiv.org/pdf/2601.04859v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04855v1",
      "title": "Rethinking GNNs and Missing Features: Challenges, Evaluation and a Robust Solution",
      "abstract": "Handling missing node features is a key challenge for deploying Graph Neural Networks (GNNs) in real-world domains such as healthcare and sensor networks. Existing studies mostly address relatively benign scenarios, namely benchmark datasets with (a) high-dimensional but sparse node features and (b) incomplete data generated under Missing Completely At Random (MCAR) mechanisms. For (a), we theoretically prove that high sparsity substantially limits the information loss caused by missingness, making all models appear robust and preventing a meaningful comparison of their performance. To overcome this limitation, we introduce one synthetic and three real-world datasets with dense, semantically meaningful features. For (b), we move beyond MCAR and design evaluation protocols with more realistic missingness mechanisms. Moreover, we provide a theoretical background to state explicit assumptions on the missingness process and analyze their implications for different methods. Building on this analysis, we propose GNNmim, a simple yet effective baseline for node classification with incomplete feature data. Experiments show that GNNmim is competitive with respect to specialized architectures across diverse datasets and missingness regimes.",
      "authors": [
        "Francesco Ferrini",
        "Veronica Lachi",
        "Antonio Longa",
        "Bruno Lepri",
        "Matono Akiyoshi",
        "Andrea Passerini",
        "Xin Liu",
        "Manfred Jaeger"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 11:45:59+00:00",
      "link": "https://arxiv.org/pdf/2601.04855v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04854v1",
      "title": "Token Maturation: Autoregressive Language Generation via Continuous Token Dynamics",
      "abstract": "Autoregressive language models are conventionally defined over discrete token sequences, committing to a specific token at every generation step. This early discretization forces uncertainty to be resolved through token-level sampling, often leading to instability, repetition, and sensitivity to decoding heuristics.   In this work, we introduce a continuous autoregressive formulation of language generation in which tokens are represented as continuous vectors that \\emph{mature} over multiple update steps before being discretized. Rather than sampling tokens, the model evolves continuous token representations through a deterministic dynamical process, committing to a discrete token only when the representation has sufficiently converged. Discrete text is recovered via hard decoding, while uncertainty is maintained and resolved in the continuous space.   We show that this maturation process alone is sufficient to produce coherent and diverse text using deterministic decoding (argmax), without reliance on token-level sampling, diffusion-style denoising, or auxiliary stabilization mechanisms. Additional perturbations, such as stochastic dynamics or history smoothing, can be incorporated naturally but are not required for the model to function.   To our knowledge, this is the first autoregressive language model that generates text by evolving continuous token representations to convergence prior to discretization, enabling stable generation without token-level sampling.",
      "authors": [
        "Oshri Naparstek"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 11:44:34+00:00",
      "link": "https://arxiv.org/pdf/2601.04854v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04853v1",
      "title": "RAAR: Retrieval Augmented Agentic Reasoning for Cross-Domain Misinformation Detection",
      "abstract": "Cross-domain misinformation detection is challenging, as misinformation arises across domains with substantial differences in knowledge and discourse. Existing methods often rely on single-perspective cues and struggle to generalize to challenging or underrepresented domains, while reasoning large language models (LLMs), though effective on complex tasks, are limited to same-distribution data. To address these gaps, we introduce RAAR, the first retrieval-augmented agentic reasoning framework for cross-domain misinformation detection. To enable cross-domain transfer beyond same-distribution assumptions, RAAR retrieves multi-perspective source-domain evidence aligned with each target sample's semantics, sentiment, and writing style. To overcome single-perspective modeling and missing systematic reasoning, RAAR constructs verifiable multi-step reasoning paths through specialized multi-agent collaboration, where perspective-specific agents produce complementary analyses and a summary agent integrates them under verifier guidance. RAAR further applies supervised fine-tuning and reinforcement learning to train a single multi-task verifier to enhance verification and reasoning capabilities. Based on RAAR, we trained the RAAR-8b and RAAR-14b models. Evaluation on three cross-domain misinformation detection tasks shows that RAAR substantially enhances the capabilities of the base models and outperforms other cross-domain methods, advanced LLMs, and LLM-based adaptation approaches. The project will be released at https://github.com/lzw108/RAAR.",
      "authors": [
        "Zhiwei Liu",
        "Runteng Guo",
        "Baojie Qu",
        "Yuechen Jiang",
        "Min Peng",
        "Qianqian Xie",
        "Sophia Ananiadou"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 11:43:16+00:00",
      "link": "https://arxiv.org/pdf/2601.04853v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04842v1",
      "title": "Intelligent resource allocation in wireless networks via deep reinforcement learning",
      "abstract": "This study addresses the challenge of optimal power allocation in stochastic wireless networks by employing a Deep Reinforcement Learning (DRL) framework. Specifically, we design a Deep Q-Network (DQN) agent capable of learning adaptive power control policies directly from channel state observations, effectively bypassing the need for explicit system models. We formulate the resource allocation problem as a Markov Decision Process (MDP) and benchmark the proposed approach against classical heuristics, including fixed allocation, random assignment, and the theoretical water-filling algorithm. Empirical results demonstrate that the DQN agent achieves a system throughput of 3.88 Mbps, effectively matching the upper limit of the water fill, while outperforming the random and fixed allocation strategies by approximately 73% and 27%, respectively. Moreover, the agent exhibits emergent fairness, maintaining a Jain's Index of 0.91, and successfully optimizes the trade-off between spectral efficiency and energy consumption. These findings substantiate the efficacy of model-free DRL as a robust and scalable solution for resource management in next-generation communication systems.",
      "authors": [
        "Marie Diane Iradukunda",
        "Chabi F. Elégbédé",
        "Yaé Ulrich Gaba"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI"
      ],
      "published": "2026-01-08 11:22:59+00:00",
      "link": "https://arxiv.org/pdf/2601.04842v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04833v1",
      "title": "When AI Settles Down: Late-Stage Stability as a Signature of AI-Generated Text Detection",
      "abstract": "Zero-shot detection methods for AI-generated text typically aggregate token-level statistics across entire sequences, overlooking the temporal dynamics inherent to autoregressive generation. We analyze over 120k text samples and reveal Late-Stage Volatility Decay: AI-generated text exhibits rapidly stabilizing log probability fluctuations as generation progresses, while human writing maintains higher variability throughout. This divergence peaks in the second half of sequences, where AI-generated text shows 24--32\\% lower volatility. Based on this finding, we propose two simple features: Derivative Dispersion and Local Volatility, which computed exclusively from late-stage statistics. Without perturbation sampling or additional model access, our method achieves state-of-the-art performance on EvoBench and MAGE benchmarks and demonstrates strong complementarity with existing global methods.",
      "authors": [
        "Ke Sun",
        "Guangsheng Bao",
        "Han Cui",
        "Yue Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 11:11:00+00:00",
      "link": "https://arxiv.org/pdf/2601.04833v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04825v1",
      "title": "Illumination Angular Spectrum Encoding for Controlling the Functionality of Diffractive Networks",
      "abstract": "Diffractive neural networks have recently emerged as a promising framework for all-optical computing. However, these networks are typically trained for a single task, limiting their potential adoption in systems requiring multiple functionalities. Existing approaches to achieving multi-task functionality either modify the mechanical configuration of the network per task or use a different illumination wavelength or polarization state for each task. In this work, we propose a new control mechanism, which is based on the illumination's angular spectrum. Specifically, we shape the illumination using an amplitude mask that selectively controls its angular spectrum. We employ different illumination masks for achieving different network functionalities, so that the mask serves as a unique task encoder. Interestingly, we show that effective control can be achieved over a very narrow angular range, within the paraxial regime. We numerically illustrate the proposed approach by training a single diffractive network to perform multiple image-to-image translation tasks. In particular, we demonstrate translating handwritten digits into typeset digits of different values, and translating handwritten English letters into typeset numbers and typeset Greek letters, where the type of the output is determined by the illumination's angular components. As we show, the proposed framework can work under different coherence conditions, and can be combined with existing control strategies, such as different wavelengths. Our results establish the illumination angular spectrum as a powerful degree of freedom for controlling diffractive networks, enabling a scalable and versatile framework for multi-task all-optical computing.",
      "authors": [
        "Matan Kleiner",
        "Lior Michaeli",
        "Tomer Michaeli"
      ],
      "primary_category": "physics.optics",
      "categories": [
        "physics.optics",
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-08 11:00:40+00:00",
      "link": "https://arxiv.org/pdf/2601.04825v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04824v1",
      "title": "SOVABench: A Vehicle Surveillance Action Retrieval Benchmark for Multimodal Large Language Models",
      "abstract": "Automatic identification of events and recurrent behavior analysis are critical for video surveillance. However, most existing content-based video retrieval benchmarks focus on scene-level similarity and do not evaluate the action discrimination required in surveillance. To address this gap, we introduce SOVABench (Surveillance Opposite Vehicle Actions Benchmark), a real-world retrieval benchmark built from surveillance footage and centered on vehicle-related actions. SOVABench defines two evaluation protocols (inter-pair and intra-pair) to assess cross-action discrimination and temporal direction understanding. Although action distinctions are generally intuitive for human observers, our experiments show that they remain challenging for state-of-the-art vision and multimodal models.   Leveraging the visual reasoning and instruction-following capabilities of Multimodal Large Language Models (MLLMs), we present a training-free framework for producing interpretable embeddings from MLLM-generated descriptions for both images and videos. The framework achieves strong performance on SOVABench as well as on several spatial and counting benchmarks where contrastive Vision-Language Models often fail. The code, annotations, and instructions to construct the benchmark are publicly available.",
      "authors": [
        "Oriol Rabasseda",
        "Zenjie Li",
        "Kamal Nasrollahi",
        "Sergio Escalera"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 10:58:59+00:00",
      "link": "https://arxiv.org/pdf/2601.04824v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04823v1",
      "title": "DR-LoRA: Dynamic Rank LoRA for Mixture-of-Experts Adaptation",
      "abstract": "Mixture-of-Experts (MoE) has become a prominent paradigm for scaling Large Language Models (LLMs). Parameter-efficient fine-tuning (PEFT), such as LoRA, is widely adopted to adapt pretrained MoE LLMs to downstream tasks. However, existing approaches assign identical LoRA ranks to all experts, overlooking the intrinsic functional specialization within MoE LLMs. This uniform allocation leads to resource mismatch, task-relevant experts are under-provisioned while less relevant ones receive redundant parameters. We propose a Dynamic Rank LoRA framework named DR-LoRA, which dynamically grows expert LoRA ranks during fine-tuning based on task-specific demands. DR-LoRA employs an Expert Saliency Scoring mechanism that integrates expert routing frequency and LoRA rank importance to quantify each expert's demand for additional capacity. Experts with higher saliency scores are prioritized for rank expansion, enabling the automatic formation of a heterogeneous rank distribution tailored to the target task. Experiments on multiple benchmarks demonstrate that DR-LoRA consistently outperforms standard LoRA and static allocation strategies under the same parameter budget, achieving superior task performance with more efficient parameter utilization.",
      "authors": [
        "Guanzhi Deng",
        "Bo Li",
        "Ronghao Chen",
        "Huacan Wang",
        "Linqi Song",
        "Lijie Wen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 10:58:51+00:00",
      "link": "https://arxiv.org/pdf/2601.04823v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04819v1",
      "title": "AECV-Bench: Benchmarking Multimodal Models on Architectural and Engineering Drawings Understanding",
      "abstract": "AEC drawings encode geometry and semantics through symbols, layout conventions, and dense annotation, yet it remains unclear whether modern multimodal and vision-language models can reliably interpret this graphical language. We present AECV-Bench, a benchmark for evaluating multimodal and vision-language models on realistic AEC artefacts via two complementary use cases: (i) object counting on 120 high-quality floor plans (doors, windows, bedrooms, toilets), and (ii) drawing-grounded document QA spanning 192 question-answer pairs that test text extraction (OCR), instance counting, spatial reasoning, and comparative reasoning over common drawing regions. Object-counting performance is reported using per-field exact-match accuracy and MAPE results, while document-QA performance is reported using overall accuracy and per-category breakdowns with an LLM-as-a-judge scoring pipeline and targeted human adjudication for edge cases. Evaluating a broad set of state-of-the-art models under a unified protocol, we observe a stable capability gradient; OCR and text-centric document QA are strongest (up to 0.95 accuracy), spatial reasoning is moderate, and symbol-centric drawing understanding - especially reliable counting of doors and windows - remains unsolved (often 0.40-0.55 accuracy) with substantial proportional errors. These results suggest that current systems function well as document assistants but lack robust drawing literacy, motivating domain-specific representations and tool-augmented, human-in-the-loop workflows for an efficient AEC automation.",
      "authors": [
        "Aleksei Kondratenko",
        "Mussie Birhane",
        "Houssame E. Hsain",
        "Guido Maciocci"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 10:54:32+00:00",
      "link": "https://arxiv.org/pdf/2601.04819v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04809v1",
      "title": "SCALER:Synthetic Scalable Adaptive Learning Environment for Reasoning",
      "abstract": "Reinforcement learning (RL) offers a principled way to enhance the reasoning capabilities of large language models, yet its effectiveness hinges on training signals that remain informative as models evolve. In practice, RL progress often slows when task difficulty becomes poorly aligned with model capability, or when training is dominated by a narrow set of recurring problem patterns. To jointly address these issues, we propose SCALER (Synthetic sCalable Adaptive Learning Environment for Reasoning), a framework that sustains effective learning signals through adaptive environment design. SCALER introduces a scalable synthesis pipeline that converts real-world programming problems into verifiable reasoning environments with controllable difficulty and unbounded instance generation, enabling RL training beyond finite datasets while preserving strong correctness guarantees. Building on this, SCALER further employs an adaptive multi-environment RL strategy that dynamically adjusts instance difficulty and curates the active set of environments to track the model's capability frontier and maintain distributional diversity. This co-adaptation prevents reward sparsity, mitigates overfitting to narrow task patterns, and supports sustained improvement throughout training. Extensive experiments show that SCALER consistently outperforms dataset-based RL baselines across diverse reasoning benchmarks and exhibits more stable, long-horizon training dynamics.",
      "authors": [
        "Caijun Xu",
        "Changyi Xiao",
        "Zhongyuan Peng",
        "Xinrun Wang",
        "Yixin Cao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 10:42:04+00:00",
      "link": "https://arxiv.org/pdf/2601.04809v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04807v1",
      "title": "Parallelizing Node-Level Explainability in Graph Neural Networks",
      "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable performance in a wide range of tasks, such as node classification, link prediction, and graph classification, by exploiting the structural information in graph-structured data. However, in node classification, computing node-level explainability becomes extremely time-consuming as the size of the graph increases, while batching strategies often degrade explanation quality. This paper introduces a novel approach to parallelizing node-level explainability in GNNs through graph partitioning. By decomposing the graph into disjoint subgraphs, we enable parallel computation of explainability for node neighbors, significantly improving the scalability and efficiency without affecting the correctness of the results, provided sufficient memory is available. For scenarios where memory is limited, we further propose a dropout-based reconstruction mechanism that offers a controllable trade-off between memory usage and explanation fidelity. Experimental results on real-world datasets demonstrate substantial speedups, enabling scalable and transparent explainability for large-scale GNN models.",
      "authors": [
        "Oscar Llorente",
        "Jaime Boal",
        "Eugenio F. Sánchez-Úbeda",
        "Antonio Diaz-Cano",
        "Miguel Familiar"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 10:39:48+00:00",
      "link": "https://arxiv.org/pdf/2601.04807v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04805v1",
      "title": "Thinking-Based Non-Thinking: Solving the Reward Hacking Problem in Training Hybrid Reasoning Models via Reinforcement Learning",
      "abstract": "Large reasoning models (LRMs) have attracted much attention due to their exceptional performance. However, their performance mainly stems from thinking, a long Chain of Thought (CoT), which significantly increase computational overhead. To address this overthinking problem, existing work focuses on using reinforcement learning (RL) to train hybrid reasoning models that automatically decide whether to engage in thinking or not based on the complexity of the query. Unfortunately, using RL will suffer the the reward hacking problem, e.g., the model engages in thinking but is judged as not doing so, resulting in incorrect rewards. To mitigate this problem, existing works either employ supervised fine-tuning (SFT), which incurs high computational costs, or enforce uniform token limits on non-thinking responses, which yields limited mitigation of the problem. In this paper, we propose Thinking-Based Non-Thinking (TNT). It does not employ SFT, and sets different maximum token usage for responses not using thinking across various queries by leveraging information from the solution component of the responses using thinking. Experiments on five mathematical benchmarks demonstrate that TNT reduces token usage by around 50% compared to DeepSeek-R1-Distill-Qwen-1.5B/7B and DeepScaleR-1.5B, while significantly improving accuracy. In fact, TNT achieves the optimal trade-off between accuracy and efficiency among all tested methods. Additionally, the probability of reward hacking problem in TNT's responses, which are classified as not using thinking, remains below 10% across all tested datasets.",
      "authors": [
        "Siyuan Gan",
        "Jiaheng Liu",
        "Boyan Wang",
        "Tianpei Yang",
        "Runqing Miao",
        "Yuyao Zhang",
        "Fanyu Meng",
        "Junlan Feng",
        "Linjian Meng",
        "Jing Huo",
        "Yang Gao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 10:38:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04805v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04801v1",
      "title": "MPM-LLM4DSE: Reaching the Pareto Frontier in HLS with Multimodal Learning and LLM-Driven Exploration",
      "abstract": "High-Level Synthesis (HLS) design space exploration (DSE) seeks Pareto-optimal designs within expansive pragma configuration spaces. To accelerate HLS DSE, graph neural networks (GNNs) are commonly employed as surrogates for HLS tools to predict quality of results (QoR) metrics, while multi-objective optimization algorithms expedite the exploration. However, GNN-based prediction methods may not fully capture the rich semantic features inherent in behavioral descriptions, and conventional multi-objective optimization algorithms often do not explicitly account for the domain-specific knowledge regarding how pragma directives influence QoR. To address these limitations, this paper proposes the MPM-LLM4DSE framework, which incorporates a multimodal prediction model (MPM) that simultaneously fuses features from behavioral descriptions and control and data flow graphs. Furthermore, the framework employs a large language model (LLM) as an optimizer, accompanied by a tailored prompt engineering methodology. This methodology incorporates pragma impact analysis on QoR to guide the LLM in generating high-quality configurations (LLM4DSE). Experimental results demonstrate that our multimodal predictive model significantly outperforms state-of-the-art work ProgSG by up to 10.25$\\times$. Furthermore, in DSE tasks, the proposed LLM4DSE achieves an average performance gain of 39.90\\% over prior methods, validating the effectiveness of our prompting methodology. Code and models are available at https://github.com/wslcccc/MPM-LLM4DSE.",
      "authors": [
        "Lei Xu",
        "Shanshan Wang",
        "Chenglong Xiao"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR",
        "cs.LG"
      ],
      "published": "2026-01-08 10:32:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04801v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04799v1",
      "title": "Neural-Symbolic Integration with Evolvable Policies",
      "abstract": "Neural-Symbolic (NeSy) Artificial Intelligence has emerged as a promising approach for combining the learning capabilities of neural networks with the interpretable reasoning of symbolic systems. However, existing NeSy frameworks typically require either predefined symbolic policies or policies that are differentiable, limiting their applicability when domain expertise is unavailable or when policies are inherently non-differentiable. We propose a framework that addresses this limitation by enabling the concurrent learning of both non-differentiable symbolic policies and neural network weights through an evolutionary process. Our approach casts NeSy systems as organisms in a population that evolve through mutations (both symbolic rule additions and neural weight changes), with fitness-based selection guiding convergence toward hidden target policies. The framework extends the NEUROLOG architecture to make symbolic policies trainable, adapts Valiant's Evolvability framework to the NeSy context, and employs Machine Coaching semantics for mutable symbolic representations. Neural networks are trained through abductive reasoning from the symbolic component, eliminating differentiability requirements. Through extensive experimentation, we demonstrate that NeSy systems starting with empty policies and random neural weights can successfully approximate hidden non-differentiable target policies, achieving median correct performance approaching 100%. This work represents a step toward enabling NeSy research in domains where the acquisition of symbolic knowledge from experts is challenging or infeasible.",
      "authors": [
        "Marios Thoma",
        "Vassilis Vassiliades",
        "Loizos Michael"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.NE"
      ],
      "published": "2026-01-08 10:29:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04799v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04792v1",
      "title": "PyramidalWan: On Making Pretrained Video Model Pyramidal for Efficient Inference",
      "abstract": "Recently proposed pyramidal models decompose the conventional forward and backward diffusion processes into multiple stages operating at varying resolutions. These models handle inputs with higher noise levels at lower resolutions, while less noisy inputs are processed at higher resolutions. This hierarchical approach significantly reduces the computational cost of inference in multi-step denoising models. However, existing open-source pyramidal video models have been trained from scratch and tend to underperform compared to state-of-the-art systems in terms of visual plausibility. In this work, we present a pipeline that converts a pretrained diffusion model into a pyramidal one through low-cost finetuning, achieving this transformation without degradation in quality of output videos. Furthermore, we investigate and compare various strategies for step distillation within pyramidal models, aiming to further enhance the inference efficiency. Our results are available at https://qualcomm-ai-research.github.io/PyramidalWan.",
      "authors": [
        "Denis Korzhenkov",
        "Adil Karjauv",
        "Animesh Karnewar",
        "Mohsen Ghafoorian",
        "Amirhossein Habibian"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 10:16:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04792v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04791v1",
      "title": "Measurement-Consistent Langevin Corrector: A Remedy for Latent Diffusion Inverse Solvers",
      "abstract": "With recent advances in generative models, diffusion models have emerged as powerful priors for solving inverse problems in each domain. Since Latent Diffusion Models (LDMs) provide generic priors, several studies have explored their potential as domain-agnostic zero-shot inverse solvers. Despite these efforts, existing latent diffusion inverse solvers suffer from their instability, exhibiting undesirable artifacts and degraded quality. In this work, we first identify the instability as a discrepancy between the solver's and true reverse diffusion dynamics, and show that reducing this gap stabilizes the solver. Building on this, we introduce Measurement-Consistent Langevin Corrector (MCLC), a theoretically grounded plug-and-play correction module that remedies the LDM-based inverse solvers through measurement-consistent Langevin updates. Compared to prior approaches that rely on linear manifold assumptions, which often do not hold in latent space, MCLC operates without this assumption, leading to more stable and reliable behavior. We experimentally demonstrate the effectiveness of MCLC and its compatibility with existing solvers across diverse image restoration tasks. Additionally, we analyze blob artifacts and offer insights into their underlying causes. We highlight that MCLC is a key step toward more robust zero-shot inverse problem solvers.",
      "authors": [
        "Lee Hyoseok",
        "Sohwi Lim",
        "Eunju Cha",
        "Tae-Hyun Oh"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-08 10:15:35+00:00",
      "link": "https://arxiv.org/pdf/2601.04791v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04789v1",
      "title": "NC2C: Automated Convexification of Generic Non-Convex Optimization Problems",
      "abstract": "Non-convex optimization problems are pervasive across mathematical programming, engineering design, and scientific computing, often posing intractable challenges for traditional solvers due to their complex objective functions and constrained landscapes. To address the inefficiency of manual convexification and the over-reliance on expert knowledge, we propose NC2C, an LLM-based end-to-end automated framework designed to transform generic non-convex optimization problems into solvable convex forms using large language models. NC2C leverages LLMs' mathematical reasoning capabilities to autonomously detect non-convex components, select optimal convexification strategies, and generate rigorous convex equivalents. The framework integrates symbolic reasoning, adaptive transformation techniques, and iterative validation, equipped with error correction loops and feasibility domain correction mechanisms to ensure the robustness and validity of transformed problems. Experimental results on a diverse dataset of 100 generic non-convex problems demonstrate that NC2C achieves an 89.3\\% execution rate and a 76\\% success rate in producing feasible, high-quality convex transformations. This outperforms baseline methods by a significant margin, highlighting NC2C's ability to leverage LLMs for automated non-convex to convex transformation, reduce expert dependency, and enable efficient deployment of convex solvers for previously intractable optimization tasks.",
      "authors": [
        "Xinyue Peng",
        "Yanming Liu",
        "Yihan Cang",
        "Yuwei Zhang",
        "Xinyi Wang",
        "Songhang Deng",
        "Jiannan Cao"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-08 10:12:45+00:00",
      "link": "https://arxiv.org/pdf/2601.04789v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04786v1",
      "title": "AgentOCR: Reimagining Agent History via Optical Self-Compression",
      "abstract": "Recent advances in large language models (LLMs) enable agentic systems trained with reinforcement learning (RL) over multi-turn interaction trajectories, but practical deployment is bottlenecked by rapidly growing textual histories that inflate token budgets and memory usage. We introduce AgentOCR, a framework that exploits the superior information density of visual tokens by representing the accumulated observation-action history as a compact rendered image. To make multi-turn rollouts scalable, AgentOCR proposes segment optical caching. By decomposing history into hashable segments and maintaining a visual cache, this mechanism eliminates redundant re-rendering. Beyond fixed rendering, AgentOCR introduces agentic self-compression, where the agent actively emits a compression rate and is trained with compression-aware reward to adaptively balance task success and token efficiency. We conduct extensive experiments on challenging agentic benchmarks, ALFWorld and search-based QA. Remarkably, results demonstrate that AgentOCR preserves over 95\\% of text-based agent performance while substantially reducing token consumption (>50\\%), yielding consistent token and memory efficiency. Our further analysis validates a 20x rendering speedup from segment optical caching and the effective strategic balancing of self-compression.",
      "authors": [
        "Lang Feng",
        "Fuchao Yang",
        "Feng Chen",
        "Xin Cheng",
        "Haiyang Xu",
        "Zhenglin Wan",
        "Ming Yan",
        "Bo An"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 10:10:20+00:00",
      "link": "https://arxiv.org/pdf/2601.04786v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04785v1",
      "title": "SRU-Pix2Pix: A Fusion-Driven Generator Network for Medical Image Translation with Few-Shot Learning",
      "abstract": "Magnetic Resonance Imaging (MRI) provides detailed tissue information, but its clinical application is limited by long acquisition time, high cost, and restricted resolution. Image translation has recently gained attention as a strategy to address these limitations. Although Pix2Pix has been widely applied in medical image translation, its potential has not been fully explored. In this study, we propose an enhanced Pix2Pix framework that integrates Squeeze-and-Excitation Residual Networks (SEResNet) and U-Net++ to improve image generation quality and structural fidelity. SEResNet strengthens critical feature representation through channel attention, while U-Net++ enhances multi-scale feature fusion. A simplified PatchGAN discriminator further stabilizes training and refines local anatomical realism. Experimental results demonstrate that under few-shot conditions with fewer than 500 images, the proposed method achieves consistent structural fidelity and superior image quality across multiple intra-modality MRI translation tasks, showing strong generalization ability. These results suggest an effective extension of Pix2Pix for medical image translation.",
      "authors": [
        "Xihe Qiu",
        "Yang Dai",
        "Xiaoyu Tan",
        "Sijia Li",
        "Fenghao Sun",
        "Lu Gan",
        "Liang Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-08 10:10:03+00:00",
      "link": "https://arxiv.org/pdf/2601.04785v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04778v1",
      "title": "CounterVid: Counterfactual Video Generation for Mitigating Action and Temporal Hallucinations in Video-Language Models",
      "abstract": "Video-language models (VLMs) achieve strong multimodal understanding but remain prone to hallucinations, especially when reasoning about actions and temporal order. Existing mitigation strategies, such as textual filtering or random video perturbations, often fail to address the root cause: over-reliance on language priors rather than fine-grained visual dynamics. We propose a scalable framework for counterfactual video generation that synthesizes videos differing only in actions or temporal structure while preserving scene context. Our pipeline combines multimodal LLMs for action proposal and editing guidance with diffusion-based image and video models to generate semantic hard negatives at scale. Using this framework, we build CounterVid, a synthetic dataset of ~26k preference pairs targeting action recognition and temporal reasoning. We further introduce MixDPO, a unified Direct Preference Optimization approach that jointly leverages textual and visual preferences. Fine-tuning Qwen2.5-VL with MixDPO yields consistent improvements, notably in temporal ordering, and transfers effectively to standard video hallucination benchmarks. Code and models will be made publicly available.",
      "authors": [
        "Tobia Poppi",
        "Burak Uzkent",
        "Amanmeet Garg",
        "Lucas Porto",
        "Garin Kessler",
        "Yezhou Yang",
        "Marcella Cornia",
        "Lorenzo Baraldi",
        "Rita Cucchiara",
        "Florian Schiffers"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "published": "2026-01-08 10:03:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04778v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04777v1",
      "title": "GeM-VG: Towards Generalized Multi-image Visual Grounding with Multimodal Large Language Models",
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated impressive progress in single-image grounding and general multi-image understanding. Recently, some methods begin to address multi-image grounding. However, they are constrained by single-target localization and limited types of practical tasks, due to the lack of unified modeling for generalized grounding tasks. Therefore, we propose GeM-VG, an MLLM capable of Generalized Multi-image Visual Grounding. To support this, we systematically categorize and organize existing multi-image grounding tasks according to their reliance of cross-image cues and reasoning, and introduce the MG-Data-240K dataset, addressing the limitations of existing datasets regarding target quantity and image relation. To tackle the challenges of robustly handling diverse multi-image grounding tasks, we further propose a hybrid reinforcement finetuning strategy that integrates chain-of-thought (CoT) reasoning and direct answering, considering their complementary strengths. This strategy adopts an R1-like algorithm guided by a carefully designed rule-based reward, effectively enhancing the model's overall perception and reasoning capabilities. Extensive experiments demonstrate the superior generalized grounding capabilities of our model. For multi-image grounding, it outperforms the previous leading MLLMs by 2.0% and 9.7% on MIG-Bench and MC-Bench, respectively. In single-image grounding, it achieves a 9.1% improvement over the base model on ODINW. Furthermore, our model retains strong capabilities in general multi-image understanding.",
      "authors": [
        "Shurong Zheng",
        "Yousong Zhu",
        "Hongyin Zhao",
        "Fan Yang",
        "Yufei Zhan",
        "Ming Tang",
        "Jinqiao Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-08 09:58:35+00:00",
      "link": "https://arxiv.org/pdf/2601.04777v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04770v1",
      "title": "SciIF: Benchmarking Scientific Instruction Following Towards Rigorous Scientific Intelligence",
      "abstract": "As large language models (LLMs) transition from general knowledge retrieval to complex scientific discovery, their evaluation standards must also incorporate the rigorous norms of scientific inquiry. Existing benchmarks exhibit a critical blind spot: general instruction-following metrics focus on superficial formatting, while domain-specific scientific benchmarks assess only final-answer correctness, often rewarding models that arrive at the right result with the wrong reasons. To address this gap, we introduce scientific instruction following: the capability to solve problems while strictly adhering to the constraints that establish scientific validity. Specifically, we introduce SciIF, a multi-discipline benchmark that evaluates this capability by pairing university-level problems with a fixed catalog of constraints across three pillars: scientific conditions (e.g., boundary checks and assumptions), semantic stability (e.g., unit and symbol conventions), and specific processes(e.g., required numerical methods). Uniquely, SciIF emphasizes auditability, requiring models to provide explicit evidence of constraint satisfaction rather than implicit compliance. By measuring both solution correctness and multi-constraint adherence, SciIF enables finegrained diagnosis of compositional reasoning failures, ensuring that LLMs can function as reliable agents within the strict logical frameworks of science.",
      "authors": [
        "Encheng Su",
        "Jianyu Wu",
        "Chen Tang",
        "Lintao Wang",
        "Pengze Li",
        "Aoran Wang",
        "Jinouwen Zhang",
        "Yizhou Wang",
        "Yuan Meng",
        "Xinzhu Ma",
        "Shixiang Tang",
        "Houqiang Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "published": "2026-01-08 09:45:58+00:00",
      "link": "https://arxiv.org/pdf/2601.04770v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04768v1",
      "title": "LANGSAE EDITING: Improving Multilingual Information Retrieval via Post-hoc Language Identity Removal",
      "abstract": "Dense retrieval in multilingual settings often searches over mixed-language collections, yet multilingual embeddings encode language identity alongside semantics. This language signal can inflate similarity for same-language pairs and crowd out relevant evidence written in other languages. We propose LANGSAE EDITING, a post-hoc sparse autoencoder trained on pooled embeddings that enables controllable removal of language-identity signal directly in vector space. The method identifies language-associated latent units using cross-language activation statistics, suppresses these units at inference time, and reconstructs embeddings in the original dimensionality, making it compatible with existing vector databases without retraining the base encoder or re-encoding raw text. Experiments across multiple languages show consistent improvements in ranking quality and cross-language coverage, with especially strong gains for script-distinct languages.",
      "authors": [
        "Dongjun Kim",
        "Jeongho Yoon",
        "Chanjun Park",
        "Heuiseok Lim"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "published": "2026-01-08 09:36:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04768v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04767v1",
      "title": "AT$^2$PO: Agentic Turn-based Policy Optimization via Tree Search",
      "abstract": "LLM agents have emerged as powerful systems for tackling multi-turn tasks by interleaving internal reasoning and external tool interactions. Agentic Reinforcement Learning has recently drawn significant research attention as a critical post-training paradigm to further refine these capabilities. In this paper, we present AT$^2$PO (Agentic Turn-based Policy Optimization via Tree Search), a unified framework for multi-turn agentic RL that addresses three core challenges: limited exploration diversity, sparse credit assignment, and misaligned policy optimization. AT$^2$PO introduces a turn-level tree structure that jointly enables Entropy-Guided Tree Expansion for strategic exploration and Turn-wise Credit Assignment for fine-grained reward propagation from sparse outcomes. Complementing this, we propose Agentic Turn-based Policy Optimization, a turn-level learning objective that aligns policy updates with the natural decision granularity of agentic interactions. ATPO is orthogonal to tree search and can be readily integrated into any multi-turn RL pipeline. Experiments across seven benchmarks demonstrate consistent improvements over the state-of-the-art baseline by up to 1.84 percentage points in average, with ablation studies validating the effectiveness of each component. Our code is available at https://github.com/zzfoutofspace/ATPO.",
      "authors": [
        "Zefang Zong",
        "Dingwei Chen",
        "Yang Li",
        "Qi Yi",
        "Bo Zhou",
        "Chengming Li",
        "Bo Qian",
        "Peng Chen",
        "Jie Jiang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 09:35:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04767v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04766v1",
      "title": "Revisiting Judge Decoding from First Principles via Training-Free Distributional Divergence",
      "abstract": "Judge Decoding accelerates LLM inference by relaxing the strict verification of Speculative Decoding, yet it typically relies on expensive and noisy supervision. In this work, we revisit this paradigm from first principles, revealing that the ``criticality'' scores learned via costly supervision are intrinsically encoded in the draft-target distributional divergence. We theoretically prove a structural correspondence between learned linear judges and Kullback-Leibler (KL) divergence, demonstrating they rely on the same underlying logit primitives. Guided by this, we propose a simple, training-free verification mechanism based on KL divergence. Extensive experiments across reasoning and coding benchmarks show that our method matches or outperforms complex trained judges (e.g., AutoJudge), offering superior robustness to domain shifts and eliminating the supervision bottleneck entirely.",
      "authors": [
        "Shengyin Sun",
        "Yiming Li",
        "Renxi Liu",
        "Weizhe Lin",
        "Hui-Ling Zhen",
        "Xianzhi Yu",
        "Mingxuan Yuan",
        "Chen Ma"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 09:34:54+00:00",
      "link": "https://arxiv.org/pdf/2601.04766v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04764v1",
      "title": "Orion-RAG: Path-Aligned Hybrid Retrieval for Graphless Data",
      "abstract": "Retrieval-Augmented Generation (RAG) has proven effective for knowledge synthesis, yet it encounters significant challenges in practical scenarios where data is inherently discrete and fragmented. In most environments, information is distributed across isolated files like reports and logs that lack explicit links. Standard search engines process files independently, ignoring the connections between them. Furthermore, manually building Knowledge Graphs is impractical for such vast data. To bridge this gap, we present Orion-RAG. Our core insight is simple yet effective: we do not need heavy algorithms to organize this data. Instead, we use a low-complexity strategy to extract lightweight paths that naturally link related concepts. We demonstrate that this streamlined approach suffices to transform fragmented documents into semi-structured data, enabling the system to link information across different files effectively. Extensive experiments demonstrate that Orion-RAG consistently outperforms mainstream frameworks across diverse domains, supporting real-time updates and explicit Human-in-the-Loop verification with high cost-efficiency. Experiments on FinanceBench demonstrate superior precision with a 25.2% relative improvement over strong baselines.",
      "authors": [
        "Zhen Chen",
        "Weihao Xie",
        "Peilin Chen",
        "Shiqi Wang",
        "Jianping Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 09:32:01+00:00",
      "link": "https://arxiv.org/pdf/2601.04764v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04757v1",
      "title": "Structural Indexing of Relational Databases for the Evaluation of Free-Connex Acyclic Conjunctive Queries",
      "abstract": "We present an index structure to boost the evaluation of free-connex acyclic conjunctive queries (fc-ACQs) over relational databases. The main ingredient of the index associated with a given database $D$ is an auxiliary database $D_{col}$. Our main result states that for any fc-ACQ $Q$ over $D$, we can count the number of answers of $Q$ or enumerate them with constant delay after a preprocessing phase that takes time linear in the size of $D_{col}$.   Unlike previous indexing methods based on values or order (e.g., B+ trees), our index is based on structural symmetries among tuples in a database, and the size of $D_{col}$ is related to the number of colors assigned to $D$ by Scheidt and Schweikardt's \"relational color refinement\" (2025). In the particular case of graphs, this coincides with the minimal size of an equitable partition of the graph. For example, the size of $D_{col}$ is logarithmic in the case of binary trees and constant for regular graphs. Even in the worst-case that $D$ has no structural symmetries among tuples at all, the size of $D_{col}$ is still linear in the size of $D$.   Given that the size of $D_{col}$ is bounded by the size of $D$ and can be much smaller (even constant for some families of databases), our index is the first foundational result on indexing internal structural symmetries of a database to evaluate all fc-ACQs with performance potentially strictly smaller than the database size.",
      "authors": [
        "Cristian Riveros",
        "Benjamin Scheidt",
        "Nicole Schweikardt"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB",
        "cs.LO"
      ],
      "published": "2026-01-08 09:25:48+00:00",
      "link": "https://arxiv.org/pdf/2601.04757v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04754v1",
      "title": "ProFuse: Efficient Cross-View Context Fusion for Open-Vocabulary 3D Gaussian Splatting",
      "abstract": "We present ProFuse, an efficient context-aware framework for open-vocabulary 3D scene understanding with 3D Gaussian Splatting (3DGS). The pipeline enhances cross-view consistency and intra-mask cohesion within a direct registration setup, adding minimal overhead and requiring no render-supervised fine-tuning. Instead of relying on a pretrained 3DGS scene, we introduce a dense correspondence-guided pre-registration phase that initializes Gaussians with accurate geometry while jointly constructing 3D Context Proposals via cross-view clustering. Each proposal carries a global feature obtained through weighted aggregation of member embeddings, and this feature is fused onto Gaussians during direct registration to maintain per-primitive language coherence across views. With associations established in advance, semantic fusion requires no additional optimization beyond standard reconstruction, and the model retains geometric refinement without densification. ProFuse achieves strong open-vocabulary 3DGS understanding while completing semantic attachment in about five minutes per scene, which is two times faster than SOTA.",
      "authors": [
        "Yen-Jen Chiou",
        "Wei-Tse Cheng",
        "Yuan-Fu Yang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 09:20:46+00:00",
      "link": "https://arxiv.org/pdf/2601.04754v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04752v1",
      "title": "Skeletonization-Based Adversarial Perturbations on Large Vision Language Model's Mathematical Text Recognition",
      "abstract": "This work explores the visual capabilities and limitations of foundation models by introducing a novel adversarial attack method utilizing skeletonization to reduce the search space effectively. Our approach specifically targets images containing text, particularly mathematical formula images, which are more challenging due to their LaTeX conversion and intricate structure. We conduct a detailed evaluation of both character and semantic changes between original and adversarially perturbed outputs to provide insights into the models' visual interpretation and reasoning abilities. The effectiveness of our method is further demonstrated through its application to ChatGPT, which shows its practical implications in real-world scenarios.",
      "authors": [
        "Masatomo Yoshida",
        "Haruto Namura",
        "Nicola Adami",
        "Masahiro Okuda"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 09:15:27+00:00",
      "link": "https://arxiv.org/pdf/2601.04752v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04750v1",
      "title": "Cognitive Infrastructure: A Unified DCIM Framework for AI Data Centers",
      "abstract": "This work presents DCIM 3.0, a unified framework integrating semantic reasoning, predictive analytics, autonomous orchestration, and unified connectivity for next-generation AI data center management. The framework addresses critical challenges in infrastructure automation, sustainability, and digital-twin design through knowledge graph-based intelligence, thermal modeling, and the Unified Device Connectivity Protocol (UDCP).Keywords-Data Center Infrastructure Management, DCIM, AI Data Centers, Knowledge Graphs, Digital Twin, Thermal Management, Infrastructure Automation, Sustainability, GPU Computing, Data Center",
      "authors": [
        "Krishna Chaitanya Sunkara"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC",
        "cs.NI"
      ],
      "published": "2026-01-08 09:14:59+00:00",
      "link": "https://arxiv.org/pdf/2601.04750v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04748v1",
      "title": "When Single-Agent with Skills Replace Multi-Agent Systems and When They Fail",
      "abstract": "Multi-agent AI systems have proven effective for complex reasoning. These systems are compounded by specialized agents, which collaborate through explicit communication, but incur substantial computational overhead. A natural question arises: can we achieve similar modularity benefits with a single agent that selects from a library of skills? We explore this question by viewing skills as internalized agent behaviors. From this perspective, a multi-agent system can be compiled into an equivalent single-agent system, trading inter-agent communication for skill selection. Our preliminary experiments suggest this approach can substantially reduce token usage and latency while maintaining competitive accuracy on reasoning benchmarks. However, this efficiency raises a deeper question that has received little attention: how does skill selection scale as libraries grow?   Drawing on principles from cognitive science, we propose that LLM skill selection exhibits bounded capacity analogous to human decision-making. We investigate the scaling behavior of skill selection and observe a striking pattern. Rather than degrading gradually, selection accuracy remains stable up to a critical library size, then drops sharply, indicating a phase transition reminiscent of capacity limits in human cognition. Furthermore, we find evidence that semantic confusability among similar skills, rather than library size alone, plays a central role in this degradation. This perspective suggests that hierarchical organization, which has long helped humans manage complex choices, may similarly benefit AI systems. Our initial results with hierarchical routing support this hypothesis. This work opens new questions about the fundamental limits of semantic-based skill selection in LLMs and offers a cognitive-grounded framework and practical guidelines for designing scalable skill-based agents.",
      "authors": [
        "Xiaoxiao Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "published": "2026-01-08 09:14:26+00:00",
      "link": "https://arxiv.org/pdf/2601.04748v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04742v1",
      "title": "Tool-MAD: A Multi-Agent Debate Framework for Fact Verification with Diverse Tool Augmentation and Adaptive Retrieval",
      "abstract": "Large Language Models (LLMs) suffer from hallucinations and factual inaccuracies, especially in complex reasoning and fact verification tasks. Multi-Agent Debate (MAD) systems aim to improve answer accuracy by enabling multiple LLM agents to engage in dialogue, promoting diverse reasoning and mutual verification. However, existing MAD frameworks primarily rely on internal knowledge or static documents, making them vulnerable to hallucinations. While MADKE introduces external evidence to mitigate this, its one-time retrieval mechanism limits adaptability to new arguments or emerging information during the debate. To address these limitations, We propose Tool-MAD, a multi-agent debate framework that enhances factual verification by assigning each agent a distinct external tool, such as a search API or RAG module. Tool-MAD introduces three key innovations: (1) a multi-agent debate framework where agents leverage heterogeneous external tools, encouraging diverse perspectives, (2) an adaptive query formulation mechanism that iteratively refines evidence retrieval based on the flow of the debate, and (3) the integration of Faithfulness and Answer Relevance scores into the final decision process, allowing the Judge agent to quantitatively assess the coherence and question alignment of each response and effectively detect hallucinations. Experimental results on four fact verification benchmarks demonstrate that Tool-MAD consistently outperforms state-of-the-art MAD frameworks, achieving up to 5.5% accuracy improvement. Furthermore, in medically specialized domains, Tool-MAD exhibits strong robustness and adaptability across various tool configurations and domain conditions, confirming its potential for broader real-world fact-checking applications.",
      "authors": [
        "Seyeon Jeong",
        "Yeonjun Choi",
        "JongWook Kim",
        "Beakcheol Jang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 09:07:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04742v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04734v1",
      "title": "AIVD: Adaptive Edge-Cloud Collaboration for Accurate and Efficient Industrial Visual Detection",
      "abstract": "Multimodal large language models (MLLMs) demonstrate exceptional capabilities in semantic understanding and visual reasoning, yet they still face challenges in precise object localization and resource-constrained edge-cloud deployment. To address this, this paper proposes the AIVD framework, which achieves unified precise localization and high-quality semantic generation through the collaboration between lightweight edge detectors and cloud-based MLLMs. To enhance the cloud MLLM's robustness against edge cropped-box noise and scenario variations, we design an efficient fine-tuning strategy with visual-semantic collaborative augmentation, significantly improving classification accuracy and semantic consistency. Furthermore, to maintain high throughput and low latency across heterogeneous edge devices and dynamic network conditions, we propose a heterogeneous resource-aware dynamic scheduling algorithm. Experimental results demonstrate that AIVD substantially reduces resource consumption while improving MLLM classification performance and semantic generation quality. The proposed scheduling strategy also achieves higher throughput and lower latency across diverse scenarios.",
      "authors": [
        "Yunqing Hu",
        "Zheming Yang",
        "Chang Zhao",
        "Qi Guo",
        "Meng Gao",
        "Pengcheng Li",
        "Wen Ji"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 08:56:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04734v1",
      "tags": [
        "keyword:resnet",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04731v1",
      "title": "Miner:Mining Intrinsic Mastery for Data-Efficient RL in Large Reasoning Models",
      "abstract": "Current critic-free RL methods for large reasoning models suffer from severe inefficiency when training on positive homogeneous prompts (where all rollouts are correct), resulting in waste of rollouts due to zero advantage estimates. We introduce a radically simple yet powerful solution to \\uline{M}ine \\uline{in}trinsic mast\\uline{er}y (Miner), that repurposes the policy's intrinsic uncertainty as a self-supervised reward signal, with no external supervision, auxiliary models, or additional inference cost. Our method pioneers two key innovations: (1) a token-level focal credit assignment mechanism that dynamically amplifies gradients on critical uncertain tokens while suppressing overconfident ones, and (2) adaptive advantage calibration to seamlessly integrate intrinsic and verifiable rewards. Evaluated across six reasoning benchmarks on Qwen3-4B and Qwen3-8B base models, Miner achieves state-of-the-art performance among the other four algorithms, yielding up to \\textbf{4.58} absolute gains in Pass@1 and \\textbf{6.66} gains in Pass@K compared to GRPO. Comparison with other methods targeted at exploration enhancement further discloses the superiority of the two newly proposed innovations. This demonstrates that latent uncertainty exploitation is both necessary and sufficient for efficient and scalable RL training of reasoning models.",
      "authors": [
        "Shuyang Jiang",
        "Yuhao Wang",
        "Ya Zhang",
        "Yanfeng Wang",
        "Yu Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 08:52:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04731v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04728v1",
      "title": "Excess Description Length of Learning Generalizable Predictors",
      "abstract": "Understanding whether fine-tuning elicits latent capabilities or teaches new ones is a fundamental question for language model evaluation and safety. We develop a formal information-theoretic framework for quantifying how much predictive structure fine-tuning extracts from the train dataset and writes into a model's parameters. Our central quantity, Excess Description Length (EDL), is defined via prequential coding and measures the gap between the bits required to encode training labels sequentially using an evolving model (trained online) and the residual encoding cost under the final trained model. We establish that EDL is non-negative in expectation, converges to surplus description length in the infinite-data limit, and provides bounds on expected generalization gain. Through a series of toy models, we clarify common confusions about information in learning: why random labels yield EDL near zero, how a single example can eliminate many bits of uncertainty about the underlying rule(s) that describe the data distribution, why structure learned on rare inputs contributes proportionally little to expected generalization, and how format learning creates early transients distinct from capability acquisition. This framework provides rigorous foundations for the empirical observation that capability elicitation and teaching exhibit qualitatively distinct scaling signatures.",
      "authors": [
        "Elizabeth Donoway",
        "Hailey Joren",
        "Fabien Roger",
        "Jan Leike"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 08:46:42+00:00",
      "link": "https://arxiv.org/pdf/2601.04728v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04727v1",
      "title": "Training a Custom CNN on Five Heterogeneous Image Datasets",
      "abstract": "Deep learning has transformed visual data analysis, with Convolutional Neural Networks (CNNs) becoming highly effective in learning meaningful feature representations directly from images. Unlike traditional manual feature engineering methods, CNNs automatically extract hierarchical visual patterns, enabling strong performance across diverse real-world contexts. This study investigates the effectiveness of CNN-based architectures across five heterogeneous datasets spanning agricultural and urban domains: mango variety classification, paddy variety identification, road surface condition assessment, auto-rickshaw detection, and footpath encroachment monitoring. These datasets introduce varying challenges, including differences in illumination, resolution, environmental complexity, and class imbalance, necessitating adaptable and robust learning models.   We evaluate a lightweight, task-specific custom CNN alongside established deep architectures, including ResNet-18 and VGG-16, trained both from scratch and using transfer learning. Through systematic preprocessing, augmentation, and controlled experimentation, we analyze how architectural complexity, model depth, and pre-training influence convergence, generalization, and performance across datasets of differing scale and difficulty. The key contributions of this work are: (1) the development of an efficient custom CNN that achieves competitive performance across multiple application domains, and (2) a comprehensive comparative analysis highlighting when transfer learning and deep architectures provide substantial advantages, particularly in data-constrained environments. These findings offer practical insights for deploying deep learning models in resource-limited yet high-impact real-world visual classification tasks.",
      "authors": [
        "Anika Tabassum",
        "Tasnuva Mahazabin Tuba",
        "Nafisa Naznin"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.NE"
      ],
      "published": "2026-01-08 08:44:17+00:00",
      "link": "https://arxiv.org/pdf/2601.04727v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04726v1",
      "title": "Memory Matters More: Event-Centric Memory as a Logic Map for Agent Searching and Reasoning",
      "abstract": "Large language models (LLMs) are increasingly deployed as intelligent agents that reason, plan, and interact with their environments. To effectively scale to long-horizon scenarios, a key capability for such agents is a memory mechanism that can retain, organize, and retrieve past experiences to support downstream decision-making. However, most existing approaches organize and store memories in a flat manner and rely on simple similarity-based retrieval techniques. Even when structured memory is introduced, existing methods often struggle to explicitly capture the logical relationships among experiences or memory units. Moreover, memory access is largely detached from the constructed structure and still depends on shallow semantic retrieval, preventing agents from reasoning logically over long-horizon dependencies. In this work, we propose CompassMem, an event-centric memory framework inspired by Event Segmentation Theory. CompassMem organizes memory as an Event Graph by incrementally segmenting experiences into events and linking them through explicit logical relations. This graph serves as a logic map, enabling agents to perform structured and goal-directed navigation over memory beyond superficial retrieval, progressively gathering valuable memories to support long-horizon reasoning. Experiments on LoCoMo and NarrativeQA demonstrate that CompassMem consistently improves both retrieval and reasoning performance across multiple backbone models.",
      "authors": [
        "Yuyang Hu",
        "Jiongnan Liu",
        "Jiejun Tan",
        "Yutao Zhu",
        "Zhicheng Dou"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 08:44:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04726v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04722v1",
      "title": "Does Provenance Interact?",
      "abstract": "Data provenance (the process of determining the origin and derivation of data outputs) has applications across multiple domains including explaining database query results and auditing scientific workflows. Despite decades of research, provenance tracing remains challenging due to computational costs and storage overhead. In streaming systems such as Apache Flink, provenance graphs can grow super-linearly with data volume, posing significant scalability challenges. Temporal provenance is a promising direction, attaching timestamps to provenance information, enabling time-focused queries without maintaining complete historical records. However, existing temporal provenance methods primarily focus on system-level debugging, leaving a gap in data management applications. This paper proposes an agenda that uses Temporal Interaction Networks (TINs) to represent temporal provenance efficiently. We demonstrate TINs' applicability across streaming systems, transportation networks, and financial networks. We classify data into discrete and liquid types, define five temporal provenance query types, and propose a state-based indexing approach. Our vision outlines research directions toward making temporal provenance a practical tool for large-scale dataflows.",
      "authors": [
        "Chrysanthi Kosyfaki",
        "Ruiyuan Zhang",
        "Nikos Mamoulis",
        "Xiaofang Zhou"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB"
      ],
      "published": "2026-01-08 08:37:09+00:00",
      "link": "https://arxiv.org/pdf/2601.04722v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04720v1",
      "title": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking",
      "abstract": "In this report, we introduce the Qwen3-VL-Embedding and Qwen3-VL-Reranker model series, the latest extensions of the Qwen family built on the Qwen3-VL foundation model. Together, they provide an end-to-end pipeline for high-precision multimodal search by mapping diverse modalities, including text, images, document images, and video, into a unified representation space. The Qwen3-VL-Embedding model employs a multi-stage training paradigm, progressing from large-scale contrastive pre-training to reranking model distillation, to generate semantically rich high-dimensional vectors. It supports Matryoshka Representation Learning, enabling flexible embedding dimensions, and handles inputs up to 32k tokens. Complementing this, Qwen3-VL-Reranker performs fine-grained relevance estimation for query-document pairs using a cross-encoder architecture with cross-attention mechanisms. Both model series inherit the multilingual capabilities of Qwen3-VL, supporting more than 30 languages, and are released in $\\textbf{2B}$ and $\\textbf{8B}$ parameter sizes to accommodate diverse deployment requirements. Empirical evaluations demonstrate that the Qwen3-VL-Embedding series achieves state-of-the-art results across diverse multimodal embedding evaluation benchmarks. Specifically, Qwen3-VL-Embedding-8B attains an overall score of $\\textbf{77.8}$ on MMEB-V2, ranking first among all models (as of January 8, 2025). This report presents the architecture, training methodology, and practical capabilities of the series, demonstrating their effectiveness on various multimodal retrieval tasks, including image-text retrieval, visual question answering, and video-text matching.",
      "authors": [
        "Mingxin Li",
        "Yanzhao Zhang",
        "Dingkun Long",
        "Keqin Chen",
        "Sibo Song",
        "Shuai Bai",
        "Zhibo Yang",
        "Pengjun Xie",
        "An Yang",
        "Dayiheng Liu",
        "Jingren Zhou",
        "Junyang Lin"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 08:36:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04720v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04719v1",
      "title": "GPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models",
      "abstract": "The key-value (KV) cache in large language models presents a significant memory bottleneck during inference, growing linearly with sequence length and often exceeding the memory footprint of model weights themselves. We implement and evaluate GPU-accelerated INT8 quantization for KV cache compression, achieving 4$\\times$ memory reduction with minimal accuracy degradation. We develop four CUDA kernel variants -- naive, tiled, coarsened, and vectorized -- and benchmark them across realistic workload sizes up to 1 billion elements. Our vectorized kernel achieves up to 1,694$\\times$ speedup over CPU baselines while maintaining reconstruction error below 0.004 and attention score error below 0.1 even for 8K-dimensional heads. These results demonstrate that INT8 quantization provides a practical approach for reducing memory pressure in LLM inference with negligible computational overhead (6--58ms) and minimal impact on downstream model behavior",
      "authors": [
        "Maanas Taneja",
        "Purab Shingvi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.PF"
      ],
      "published": "2026-01-08 08:35:56+00:00",
      "link": "https://arxiv.org/pdf/2601.04719v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04714v1",
      "title": "ThinkDrive: Chain-of-Thought Guided Progressive Reinforcement Learning Fine-Tuning for Autonomous Driving",
      "abstract": "With the rapid advancement of large language models (LLMs) technologies, their application in the domain of autonomous driving has become increasingly widespread. However, existing methods suffer from unstructured reasoning, poor generalization, and misalignment with human driving intent. While Chain-of-Thought (CoT) reasoning enhances decision transparency, conventional supervised fine-tuning (SFT) fails to fully exploit its potential, and reinforcement learning (RL) approaches face instability and suboptimal reasoning depth. We propose ThinkDrive, a CoT guided progressive RL fine-tuning framework for autonomous driving that synergizes explicit reasoning with difficulty-aware adaptive policy optimization. Our method employs a two-stage training strategy. First, we perform SFT using CoT explanations. Then, we apply progressive RL with a difficulty-aware adaptive policy optimizer that dynamically adjusts learning intensity based on sample complexity. We evaluate our approach on a public dataset. The results show that ThinkDrive outperforms strong RL baselines by 1.45%, 1.95%, and 1.01% on exam, easy-exam, and accuracy, respectively. Moreover, a 2B-parameter model trained with our method surpasses the much larger GPT-4o by 3.28% on the exam metric.",
      "authors": [
        "Chang Zhao",
        "Zheming Yang",
        "Yunqing Hu",
        "Qi Guo",
        "Zijian Wang",
        "Pengcheng Li",
        "Wen Ji"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 08:30:36+00:00",
      "link": "https://arxiv.org/pdf/2601.04714v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04707v1",
      "title": "MQ-GNN: A Multi-Queue Pipelined Architecture for Scalable and Efficient GNN Training",
      "abstract": "Graph Neural Networks (GNNs) are powerful tools for learning graph-structured data, but their scalability is hindered by inefficient mini-batch generation, data transfer bottlenecks, and costly inter-GPU synchronization. Existing training frameworks fail to overlap these stages, leading to suboptimal resource utilization. This paper proposes MQ-GNN, a multi-queue pipelined framework that maximizes training efficiency by interleaving GNN training stages and optimizing resource utilization. MQ-GNN introduces Ready-to-Update Asynchronous Consistent Model (RaCoM), which enables asynchronous gradient sharing and model updates while ensuring global consistency through adaptive periodic synchronization. Additionally, it employs global neighbor sampling with caching to reduce data transfer overhead and an adaptive queue-sizing strategy to balance computation and memory efficiency. Experiments on four large-scale datasets and ten baseline models demonstrate that MQ-GNN achieves up to \\boldmath $\\bm{4.6\\,\\times}$ faster training time and 30% improved GPU utilization while maintaining competitive accuracy. These results establish MQ-GNN as a scalable and efficient solution for multi-GPU GNN training.",
      "authors": [
        "Irfan Ullah",
        "Young-Koo Lee"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.PF"
      ],
      "published": "2026-01-08 08:19:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04707v1",
      "tags": [
        "keyword:resnet",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04703v1",
      "title": "Beyond Monolithic Architectures: A Multi-Agent Search and Knowledge Optimization Framework for Agentic Search",
      "abstract": "Agentic search has emerged as a promising paradigm for complex information seeking by enabling Large Language Models (LLMs) to interleave reasoning with tool use. However, prevailing systems rely on monolithic agents that suffer from structural bottlenecks, including unconstrained reasoning outputs that inflate trajectories, sparse outcome-level rewards that complicate credit assignment, and stochastic search noise that destabilizes learning. To address these challenges, we propose \\textbf{M-ASK} (Multi-Agent Search and Knowledge), a framework that explicitly decouples agentic search into two complementary roles: Search Behavior Agents, which plan and execute search actions, and Knowledge Management Agents, which aggregate, filter, and maintain a compact internal context. This decomposition allows each agent to focus on a well-defined subtask and reduces interference between search and context construction. Furthermore, to enable stable coordination, M-ASK employs turn-level rewards to provide granular supervision for both search decisions and knowledge updates. Experiments on multi-hop QA benchmarks demonstrate that M-ASK outperforms strong baselines, achieving not only superior answer accuracy but also significantly more stable training dynamics.\\footnote{The source code for M-ASK is available at https://github.com/chenyiqun/M-ASK.}",
      "authors": [
        "Yiqun Chen",
        "Lingyong Yan",
        "Zixuan Yang",
        "Erhan Zhang",
        "Jiashu Zhao",
        "Shuaiqiang Wang",
        "Dawei Yin",
        "Jiaxin Mao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 08:13:27+00:00",
      "link": "https://arxiv.org/pdf/2601.04703v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04700v1",
      "title": "PRISM: A Unified Framework for Post-Training LLMs Without Verifiable Rewards",
      "abstract": "Current techniques for post-training Large Language Models (LLMs) rely either on costly human supervision or on external verifiers to boost performance on tasks such as mathematical reasoning and code generation. However, as LLMs improve their problem-solving, any further improvement will potentially require high-quality solutions to difficult problems that are not available to humans. As a result, learning from unlabeled data is becoming increasingly attractive in the research community. Existing methods extract learning signal from a model's consistency, either by majority voting or by converting the model's internal confidence into reward. Although internal consistency metric such as entropy or self-certainty require no human intervention, as we show in this work, these are unreliable signals for large-scale and long-term training. To address the unreliability, we propose PRISM, a unified training framework that uses a Process Reward Model (PRM) to guide learning alongside model's internal confidence in the absence of ground-truth labels. We show that effectively combining PRM with self-certainty can lead to both stable training and better test-time performance, and also keep the model's internal confidence in check.",
      "authors": [
        "Mukesh Ghimire",
        "Aosong Feng",
        "Liwen You",
        "Youzhi Luo",
        "Fang Liu",
        "Xuan Zhu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 08:09:29+00:00",
      "link": "https://arxiv.org/pdf/2601.04700v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04699v1",
      "title": "SeqWalker: Sequential-Horizon Vision-and-Language Navigation with Hierarchical Planning",
      "abstract": "Sequential-Horizon Vision-and-Language Navigation (SH-VLN) presents a challenging scenario where agents should sequentially execute multi-task navigation guided by complex, long-horizon language instructions. Current vision-and-language navigation models exhibit significant performance degradation with such multi-task instructions, as information overload impairs the agent's ability to attend to observationally relevant details. To address this problem, we propose SeqWalker, a navigation model built on a hierarchical planning framework. Our SeqWalker features: i) A High-Level Planner that dynamically selects global instructions into contextually relevant sub-instructions based on the agent's current visual observations, thus reducing cognitive load; ii) A Low-Level Planner incorporating an Exploration-Verification strategy that leverages the inherent logical structure of instructions for trajectory error correction. To evaluate SH-VLN performance, we also extend the IVLN dataset and establish a new benchmark. Extensive experiments are performed to demonstrate the superiority of the proposed SeqWalker.",
      "authors": [
        "Zebin Han",
        "Xudong Wang",
        "Baichen Liu",
        "Qi Lyu",
        "Zhenduo Shang",
        "Jiahua Dong",
        "Lianqing Liu",
        "Zhi Han"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-01-08 08:09:24+00:00",
      "link": "https://arxiv.org/pdf/2601.04699v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04698v1",
      "title": "TourPlanner: A Competitive Consensus Framework with Constraint-Gated Reinforcement Learning for Travel Planning",
      "abstract": "Travel planning is a sophisticated decision-making process that requires synthesizing multifaceted information to construct itineraries. However, existing travel planning approaches face several challenges: (1) Pruning candidate points of interest (POIs) while maintaining a high recall rate; (2) A single reasoning path restricts the exploration capability within the feasible solution space for travel planning; (3) Simultaneously optimizing hard constraints and soft constraints remains a significant difficulty. To address these challenges, we propose TourPlanner, a comprehensive framework featuring multi-path reasoning and constraint-gated reinforcement learning. Specifically, we first introduce a Personalized Recall and Spatial Optimization (PReSO) workflow to construct spatially-aware candidate POIs' set. Subsequently, we propose Competitive consensus Chain-of-Thought (CCoT), a multi-path reasoning paradigm that improves the ability of exploring the feasible solution space. To further refine the plan, we integrate a sigmoid-based gating mechanism into the reinforcement learning stage, which dynamically prioritizes soft-constraint satisfaction only after hard constraints are met. Experimental results on travel planning benchmarks demonstrate that TourPlanner achieves state-of-the-art performance, significantly surpassing existing methods in both feasibility and user-preference alignment.",
      "authors": [
        "Yinuo Wang",
        "Mining Tan",
        "Wenxiang Jiao",
        "Xiaoxi Li",
        "Hao Wang",
        "Xuanyu Zhang",
        "Yuan Lu",
        "Weiming Dong"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-08 08:08:35+00:00",
      "link": "https://arxiv.org/pdf/2601.04698v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04696v1",
      "title": "A Method for Constructing a Digital Transformation Driving Mechanism Based on Semantic Understanding of Large Models",
      "abstract": "In the process of digital transformation, enterprises are faced with problems such as insufficient semantic understanding of unstructured data and lack of intelligent decision-making basis in driving mechanisms. This study proposes a method that combines a large language model (LLM) and a knowledge graph. First, a fine-tuned BERT (Bidirectional Encoder Representations from Transformers) model is used to perform entity recognition and relationship extraction on multi-source heterogeneous texts, and GPT-4 is used to generate semantically enhanced vector representations; secondly, a two-layer graph neural network (GNN) architecture is designed to fuse the semantic vectors output by LLM with business metadata to construct a dynamic and scalable enterprise knowledge graph; then reinforcement learning is introduced to optimize decision path generation, and the reward function is used to drive the mechanism iteration. In the case of the manufacturing industry, this mechanism reduced the response time for equipment failure scenarios from 7.8 hours to 3.7 hours, the F1 value reached 94.3%, and the compensation for decision errors in the annual digital transformation cost decreased by 45.3%. This method significantly enhances the intelligence level and execution efficiency of the digital transformation driving mechanism by integrating large model semantic understanding with structured knowledge.",
      "authors": [
        "Huayi Liu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 08:06:58+00:00",
      "link": "https://arxiv.org/pdf/2601.04696v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04695v1",
      "title": "Tape: A Cellular Automata Benchmark for Evaluating Rule-Shift Generalization in Reinforcement Learning",
      "abstract": "We present Tape, a controlled reinforcement-learning benchmark designed to isolate out-of-distribution (OOD) failure under latent rule shifts.Tape is derived from one-dimensional cellular automata, enabling precise train/test splits where observation and action spaces are held fixed while transition rules change. Using a reproducible evaluation pipeline, we compare model-free baselines, model-based planning with learned world models, and task-inference (meta-RL) methods. A consistent pattern emerges: methods that are strong in-distribution (ID) can collapse under heldout-rule OOD, and high-variance OOD evaluation can make rankings unstable unless experiments are sufficiently replicated.We provide (i) standardized OOD protocols, (ii) statistical reporting requirements (seeds, confidence intervals, and hypothesis tests), and (iii) information-theoretic identities connecting entropy reduction to conditional mutual information and expected posterior KL divergence, clarifying what \"uncertainty reduction\" objectives can and cannot guarantee under rule shifts.",
      "authors": [
        "Enze Pan"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 08:05:42+00:00",
      "link": "https://arxiv.org/pdf/2601.04695v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04694v1",
      "title": "ResMAS: Resilience Optimization in LLM-based Multi-agent Systems",
      "abstract": "Large Language Model-based Multi-Agent Systems (LLM-based MAS), where multiple LLM agents collaborate to solve complex tasks, have shown impressive performance in many areas. However, MAS are typically distributed across different devices or environments, making them vulnerable to perturbations such as agent failures. While existing works have studied the adversarial attacks and corresponding defense strategies, they mainly focus on reactively detecting and mitigating attacks after they occur rather than proactively designing inherently resilient systems. In this work, we study the resilience of LLM-based MAS under perturbations and find that both the communication topology and prompt design significantly influence system resilience. Motivated by these findings, we propose ResMAS: a two-stage framework for enhancing MAS resilience. First, we train a reward model to predict the MAS's resilience, based on which we train a topology generator to automatically design resilient topology for specific tasks through reinforcement learning. Second, we introduce a topology-aware prompt optimization method that refines each agent's prompt based on its connections and interactions with other agents. Extensive experiments across a range of tasks show that our approach substantially improves MAS resilience under various constraints. Moreover, our framework demonstrates strong generalization ability to new tasks and models, highlighting its potential for building resilient MASs.",
      "authors": [
        "Zhilun Zhou",
        "Zihan Liu",
        "Jiahe Liu",
        "Qingyu Shao",
        "Yihan Wang",
        "Kun Shao",
        "Depeng Jin",
        "Fengli Xu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 08:03:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04694v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04682v1",
      "title": "HATIR: Heat-Aware Diffusion for Turbulent Infrared Video Super-Resolution",
      "abstract": "Infrared video has been of great interest in visual tasks under challenging environments, but often suffers from severe atmospheric turbulence and compression degradation. Existing video super-resolution (VSR) methods either neglect the inherent modality gap between infrared and visible images or fail to restore turbulence-induced distortions. Directly cascading turbulence mitigation (TM) algorithms with VSR methods leads to error propagation and accumulation due to the decoupled modeling of degradation between turbulence and resolution. We introduce HATIR, a Heat-Aware Diffusion for Turbulent InfraRed Video Super-Resolution, which injects heat-aware deformation priors into the diffusion sampling path to jointly model the inverse process of turbulent degradation and structural detail loss. Specifically, HATIR constructs a Phasor-Guided Flow Estimator, rooted in the physical principle that thermally active regions exhibit consistent phasor responses over time, enabling reliable turbulence-aware flow to guide the reverse diffusion process. To ensure the fidelity of structural recovery under nonuniform distortions, a Turbulence-Aware Decoder is proposed to selectively suppress unstable temporal cues and enhance edge-aware feature aggregation via turbulence gating and structure-aware attention. We built FLIR-IVSR, the first dataset for turbulent infrared VSR, comprising paired LR-HR sequences from a FLIR T1050sc camera (1024 X 768) spanning 640 diverse scenes with varying camera and object motion conditions. This encourages future research in infrared VSR. Project page: https://github.com/JZ0606/HATIR",
      "authors": [
        "Yang Zou",
        "Xingyue Zhu",
        "Kaiqi Han",
        "Jun Ma",
        "Xingyuan Li",
        "Zhiying Jiang",
        "Jinyuan Liu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-08 07:49:02+00:00",
      "link": "https://arxiv.org/pdf/2601.04682v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04675v1",
      "title": "LLM-Guided Quantified SMT Solving over Uninterpreted Functions",
      "abstract": "Quantified formulas with Uninterpreted Functions (UFs) over non-linear real arithmetic pose fundamental challenges for Satisfiability Modulo Theories (SMT) solving. Traditional quantifier instantiation methods struggle because they lack semantic understanding of UF constraints, forcing them to search through unbounded solution spaces with limited guidance. We present AquaForte, a framework that leverages Large Language Models to provide semantic guidance for UF instantiation by generating instantiated candidates for function definitions that satisfy the constraints, thereby significantly reducing the search space and complexity for solvers. Our approach preprocesses formulas through constraint separation, uses structured prompts to extract mathematical reasoning from LLMs, and integrates the results with traditional SMT algorithms through adaptive instantiation. AquaForte maintains soundness through systematic validation: LLM-guided instantiations yielding SAT solve the original problem, while UNSAT results generate exclusion clauses for iterative refinement. Completeness is preserved by fallback to traditional solvers augmented with learned constraints. Experimental evaluation on SMT-COMP benchmarks demonstrates that AquaForte solves numerous instances where state-of-the-art solvers like Z3 and CVC5 timeout, with particular effectiveness on satisfiable formulas. Our work shows that LLMs can provide valuable mathematical intuition for symbolic reasoning, establishing a new paradigm for SMT constraint solving.",
      "authors": [
        "Kunhang Lv",
        "Yuhang Dong",
        "Rui Han",
        "Fuqi Jia",
        "Feifei Ma",
        "Jian Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 07:40:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04675v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04670v1",
      "title": "Learning Dynamics in RL Post-Training for Language Models",
      "abstract": "Reinforcement learning (RL) post-training is a critical stage in modern language model development, playing a key role in improving alignment and reasoning ability. However, several phenomena remain poorly understood, including the reduction in output diversity. To gain a broader understanding of RL post-training, we analyze the learning dynamics of RL post-training from a perspective that has been studied in supervised learning but remains underexplored in RL. We adopt an empirical neural tangent kernel (NTK) framework and decompose the NTK into two components to characterize how RL updates propagate across training samples. Our analysis reveals that limited variability in feature representations can cause RL updates to systematically increase model confidence, providing an explanation for the commonly observed reduction in output diversity after RL post-training. Furthermore, we show that effective learning in this regime depends on rapidly shaping the classifier, which directly affects the gradient component of the NTK. Motivated by these insights, we propose classifier-first reinforcement learning (CF-RL), a simple two-stage training strategy that prioritizes classifier updates before standard RL optimization. Experimental results validate our theoretical analysis by demonstrating increased model confidence and accelerated optimization under CF-RL. Additional analysis shows that the mechanism underlying CF-RL differs from that of linear-probing-then-fine-tuning in supervised learning. Overall, our study formalizes the learning dynamics of RL post-training and motivates further analysis and improvement.",
      "authors": [
        "Akiyoshi Tomihari"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 07:32:15+00:00",
      "link": "https://arxiv.org/pdf/2601.04670v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04668v1",
      "title": "Optimizing Path Planning using Deep Reinforcement Learning for UGVs in Precision Agriculture",
      "abstract": "This study focuses on optimizing path planning for unmanned ground vehicles (UGVs) in precision agriculture using deep reinforcement learning (DRL) techniques in continuous action spaces. The research begins with a review of traditional grid-based methods, such as A* and Dijkstra's algorithms, and discusses their limitations in dynamic agricultural environments, highlighting the need for adaptive learning strategies. The study then explores DRL approaches, including Deep Q-Networks (DQN), which demonstrate improved adaptability and performance in two-dimensional simulations. Enhancements such as Double Q-Networks and Dueling Networks are evaluated to further improve decision-making. Building on these results, the focus shifts to continuous action space models, specifically Deep Deterministic Policy Gradient (DDPG) and Twin Delayed Deep Deterministic Policy Gradient (TD3), which are tested in increasingly complex environments. Experiments conducted in a three-dimensional environment using ROS and Gazebo demonstrate the effectiveness of continuous DRL algorithms in navigating dynamic agricultural scenarios. Notably, the pretrained TD3 agent achieves a 95 percent success rate in dynamic environments, demonstrating the robustness of the proposed approach in handling moving obstacles while ensuring safety for both crops and the robot.",
      "authors": [
        "Laukik Patade",
        "Rohan Rane",
        "Sandeep Pillai"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-01-08 07:28:11+00:00",
      "link": "https://arxiv.org/pdf/2601.04668v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04651v1",
      "title": "Adversarial Yet Cooperative: Multi-Perspective Reasoning in Retrieved-Augmented Language Models",
      "abstract": "Recent advances in synergizing large reasoning models (LRMs) with retrieval-augmented generation (RAG) have shown promising results, yet two critical challenges remain: (1) reasoning models typically operate from a single, unchallenged perspective, limiting their ability to conduct deep, self-correcting reasoning over external documents, and (2) existing training paradigms rely excessively on outcome-oriented rewards, which provide insufficient signal for shaping the complex, multi-step reasoning process. To address these issues, we propose an Reasoner-Verifier framework named Adversarial Reasoning RAG (ARR). The Reasoner and Verifier engage in reasoning on retrieved evidence and critiquing each other's logic while being guided by process-aware advantage that requires no external scoring model. This reward combines explicit observational signals with internal model uncertainty to jointly optimize reasoning fidelity and verification rigor. Experiments on multiple benchmarks demonstrate the effectiveness of our method.",
      "authors": [
        "Can Xu",
        "Lingyong Yan",
        "Jiayi Wu",
        "Haosen Wang",
        "Shuaiqiang Wang",
        "Yuchen Li",
        "Jizhou Huang",
        "Dawei Yin",
        "Xiang Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.MA"
      ],
      "published": "2026-01-08 06:57:03+00:00",
      "link": "https://arxiv.org/pdf/2601.04651v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04646v1",
      "title": "Succeeding at Scale: Automated Multi-Retriever Fusion and Query-Side Adaptation for Multi-Tenant Search",
      "abstract": "Large-scale multi-tenant retrieval systems amass vast user query logs yet critically lack the curated relevance labels required for effective domain adaptation. This \"dark data\" problem is exacerbated by the operational cost of model updates: jointly fine-tuning query and document encoders requires re-indexing the entire corpus, which is prohibitive in multi-tenant environments with thousands of isolated indices. To address these dual challenges, we introduce \\textbf{DevRev Search}, a passage retrieval benchmark for technical customer support constructed through a fully automatic pipeline. We employ a \\textbf{fusion-based candidate generation} strategy, pooling results from diverse sparse and dense retrievers, and utilize an LLM-as-a-Judge to perform rigorous \\textbf{consistency filtering} and relevance assignment. We further propose a practical \\textbf{Index-Preserving Adaptation} strategy: by fine-tuning only the query encoder via Low-Rank Adaptation (LoRA), we achieve competitive performance improvements while keeping the document index frozen. Our experiments on DevRev Search and SciFact demonstrate that targeting specific transformer layers in the query encoder yields optimal quality-efficiency trade-offs, offering a scalable path for personalized enterprise search.",
      "authors": [
        "Prateek Jain",
        "Shabari S Nair",
        "Ritesh Goru",
        "Prakhar Agarwal",
        "Ajay Yadav",
        "Yoga Sri Varshan Varadharajan",
        "Constantine Caramanis"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-08 06:44:40+00:00",
      "link": "https://arxiv.org/pdf/2601.04646v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04643v1",
      "title": "MMFCTUB: Multi-Modal Financial Credit Table Understanding Benchmark",
      "abstract": "The advent of multi-modal language models (MLLMs) has spurred research into their application across various table understanding tasks. However, their performance in credit table understanding (CTU) for financial credit review remains largely unexplored due to the following barriers: low data consistency, high annotation costs stemming from domain-specific knowledge and complex calculations, and evaluation paradigm gaps between benchmark and real-world scenarios. To address these challenges, we introduce MMFCTUB (Multi-Modal Financial Credit Table Understanding Benchmark), a practical benchmark, encompassing more than 7,600 high quality CTU samples across 5 table types. MMFCTUB employ a minimally supervised pipeline that adheres to inter-table constraints and maintains data distributions consistency. The benchmark leverages capacity-driven questions and mask-and-recovery strategy to evaluate models' cross-table structure perception, domain knowledge utilization, and numerical calculation capabilities. Utilizing MMFCTUB, we conduct comprehensive evaluations of both proprietary and open-source MLLMs, revealing their strengths and limitations in CTU tasks. MMFCTUB serves as a valuable resource for the research community, facilitating rigorous evaluation of MLLMs in the domain of CTU.",
      "authors": [
        "Cui Yakun",
        "Yanting Zhang",
        "Zhu Lei",
        "Jian Xie",
        "Zhizhuo Kou",
        "Hang Du",
        "Zhenghao Zhu",
        "Sirui Han"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE"
      ],
      "published": "2026-01-08 06:34:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04643v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04633v1",
      "title": "MAGA-Bench: Machine-Augment-Generated Text via Alignment Detection Benchmark",
      "abstract": "Large Language Models (LLMs) alignment is constantly evolving. Machine-Generated Text (MGT) is becoming increasingly difficult to distinguish from Human-Written Text (HWT). This has exacerbated abuse issues such as fake news and online fraud. Fine-tuned detectors' generalization ability is highly dependent on dataset quality, and simply expanding the sources of MGT is insufficient. Further augment of generation process is required. According to HC-Var's theory, enhancing the alignment of generated text can not only facilitate attacks on existing detectors to test their robustness, but also help improve the generalization ability of detectors fine-tuned on it. Therefore, we propose \\textbf{M}achine-\\textbf{A}ugment-\\textbf{G}enerated Text via \\textbf{A}lignment (MAGA). MAGA's pipeline achieves comprehensive alignment from prompt construction to reasoning process, among which \\textbf{R}einforced \\textbf{L}earning from \\textbf{D}etectors \\textbf{F}eedback (RLDF), systematically proposed by us, serves as a key component. In our experiments, the RoBERTa detector fine-tuned on MAGA training set achieved an average improvement of 4.60\\% in generalization detection AUC. MAGA Dataset caused an average decrease of 8.13\\% in the AUC of the selected detectors, expecting to provide indicative significance for future research on the generalization detection ability of detectors.",
      "authors": [
        "Anyang Song",
        "Ying Cheng",
        "Yiqian Xu",
        "Rui Feng"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 06:07:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04633v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04632v1",
      "title": "From National Curricula to Cultural Awareness: Constructing Open-Ended Culture-Specific Question Answering Dataset",
      "abstract": "Large language models (LLMs) achieve strong performance on many tasks, but their progress remains uneven across languages and cultures, often reflecting values latent in English-centric training data. To enable practical cultural alignment, we propose a scalable approach that leverages national social studies curricula as a foundation for culture-aware supervision. We introduce CuCu, an automated multi-agent LLM framework that transforms national textbook curricula into open-ended, culture-specific question-answer pairs. Applying CuCu to the Korean national social studies curriculum, we construct KCaQA, comprising 34.1k open-ended QA pairs. Our quantitative and qualitative analyses suggest that KCaQA covers culture-specific topics and produces responses grounded in local sociocultural contexts.",
      "authors": [
        "Haneul Yoo",
        "Won Ik Cho",
        "Geunhye Kim",
        "Jiyoon Han"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-08 06:04:59+00:00",
      "link": "https://arxiv.org/pdf/2601.04632v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04618v1",
      "title": "Adaptive Retrieval for Reasoning-Intensive Retrieval",
      "abstract": "We study leveraging adaptive retrieval to ensure sufficient \"bridge\" documents are retrieved for reasoning-intensive retrieval. Bridge documents are those that contribute to the reasoning process yet are not directly relevant to the initial query. While existing reasoning-based reranker pipelines attempt to surface these documents in ranking, they suffer from bounded recall. Naive solution with adaptive retrieval into these pipelines often leads to planning error propagation. To address this, we propose REPAIR, a framework that bridges this gap by repurposing reasoning plans as dense feedback signals for adaptive retrieval. Our key distinction is enabling mid-course correction during reranking through selective adaptive retrieval, retrieving documents that support the pivotal plan. Experimental results on reasoning-intensive retrieval and complex QA tasks demonstrate that our method outperforms existing baselines by 5.6%pt.",
      "authors": [
        "Jongho Kim",
        "Jaeyoung Kim",
        "Seung-won Hwang",
        "Jihyuk Kim",
        "Yu Jin Kim",
        "Moontae Lee"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-08 05:46:50+00:00",
      "link": "https://arxiv.org/pdf/2601.04618v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04616v1",
      "title": "DeepHalo: A Neural Choice Model with Controllable Context Effects",
      "abstract": "Modeling human decision-making is central to applications such as recommendation, preference learning, and human-AI alignment. While many classic models assume context-independent choice behavior, a large body of behavioral research shows that preferences are often influenced by the composition of the choice set itself -- a phenomenon known as the context effect or Halo effect. These effects can manifest as pairwise (first-order) or even higher-order interactions among the available alternatives. Recent models that attempt to capture such effects either focus on the featureless setting or, in the feature-based setting, rely on restrictive interaction structures or entangle interactions across all orders, which limits interpretability. In this work, we propose DeepHalo, a neural modeling framework that incorporates features while enabling explicit control over interaction order and principled interpretation of context effects. Our model enables systematic identification of interaction effects by order and serves as a universal approximator of context-dependent choice functions when specialized to a featureless setting. Experiments on synthetic and real-world datasets demonstrate strong predictive performance while providing greater transparency into the drivers of choice.",
      "authors": [
        "Shuhan Zhang",
        "Zhi Wang",
        "Rui Gao",
        "Shuang Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 05:46:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04616v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04611v1",
      "title": "Character-R1: Enhancing Role-Aware Reasoning in Role-Playing Agents via RLVR",
      "abstract": "Current role-playing agents (RPAs) are typically constructed by imitating surface-level behaviors, but this approach lacks internal cognitive consistency, often causing out-of-character errors in complex situations. To address this, we propose Character-R1, a framework designed to provide comprehensive verifiable reward signals for effective role-aware reasoning, which are missing in recent studies. Specifically, our framework comprises three core designs: (1) Cognitive Focus Reward, which enforces explicit label-based analysis of 10 character elements (e.g., worldview) to structure internal cognition; (2) Reference-Guided Reward, which utilizes overlap-based metrics with reference responses as optimization anchors to enhance exploration and performance; and (3) Character-Conditioned Reward Normalization, which adjusts reward distributions based on character categories to ensure robust optimization across heterogeneous roles. Extensive experiments demonstrate that Character-R1 significantly outperforms existing methods in knowledge, memory and others.",
      "authors": [
        "Yihong Tang",
        "Kehai Chen",
        "Xuefeng Bai",
        "Benyou Wang",
        "Zeming Liu",
        "Haifeng Wang",
        "Min Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 05:33:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04611v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04597v1",
      "title": "THaLLE-ThaiLLM: Domain-Specialized Small LLMs for Finance and Thai -- Technical Report",
      "abstract": "Large Language Models (LLMs) have demonstrated significant potential across various domains, particularly in banking and finance, where they can automate complex tasks and enhance decision-making at scale. Due to privacy, security, and regulatory concerns, organizations often prefer on-premise deployment of LLMs. The ThaiLLM initiative aims to enhance Thai language capabilities in open-LLMs, enabling Thai industry to leverage advanced language models. However, organizations often face a trade-off between deploying multiple specialized models versus the prohibitive expense of training a single multi-capability model. To address this, we explore model merging as a resource-efficient alternative for developing high-performance, multi-capability LLMs. We present results from two key experiments: first, merging Qwen-8B with ThaiLLM-8B demonstrates how ThaiLLM-8B enhances Thai general capabilities, showing an uplift of M3 and M6 O-NET exams over the general instruction-following Qwen-8B. Second, we merge Qwen-8B with both ThaiLLM-8B and THaLLE-CFA-8B. This combination results in further improvements in performance across both general and financial domains, by demonstrating an uplift in both M3 and M6 O-NET, Flare-CFA, and Thai-IC benchmarks. The report showcases the viability of model merging for efficiently creating multi-capability LLMs.",
      "authors": [
        "KBTG Labs",
        ":",
        "Anuruth Lertpiya",
        "Danupat Khamnuansin",
        "Kantapong Sucharitpongpan",
        "Pornchanan Balee",
        "Tawunrat Chalothorn",
        "Thadpong Pongthawornkamol",
        "Monchai Lertsutthiwong"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 05:01:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04597v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04587v1",
      "title": "FedKDX: Federated Learning with Negative Knowledge Distillation for Enhanced Healthcare AI Systems",
      "abstract": "This paper introduces FedKDX, a federated learning framework that addresses limitations in healthcare AI through Negative Knowledge Distillation (NKD). Unlike existing approaches that focus solely on positive knowledge transfer, FedKDX captures both target and non-target information to improve model generalization in healthcare applications. The framework integrates multiple knowledge transfer techniques--including traditional knowledge distillation, contrastive learning, and NKD--within a unified architecture that maintains privacy while reducing communication costs. Through experiments on healthcare datasets (SLEEP, UCI-HAR, and PAMAP2), FedKDX demonstrates improved accuracy (up to 2.53% over state-of-the-art methods), faster convergence, and better performance on non-IID data distributions. Theoretical analysis supports NKD's contribution to addressing statistical heterogeneity in distributed healthcare data. The approach shows promise for privacy-sensitive medical applications under regulatory frameworks like HIPAA and GDPR, offering a balanced solution between performance and practical implementation requirements in decentralized healthcare settings. The code and model are available at https://github.com/phamdinhdat-ai/Fed_2024.",
      "authors": [
        "Quang-Tu Pham",
        "Hoang-Dieu Vu",
        "Dinh-Dat Pham",
        "Hieu H. Pham"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 04:35:28+00:00",
      "link": "https://arxiv.org/pdf/2601.04587v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04582v1",
      "title": "Aligning Text, Code, and Vision: A Multi-Objective Reinforcement Learning Framework for Text-to-Visualization",
      "abstract": "Text-to-Visualization (Text2Vis) systems translate natural language queries over tabular data into concise answers and executable visualizations. While closed-source LLMs generate functional code, the resulting charts often lack semantic alignment and clarity, qualities that can only be assessed post-execution. Open-source models struggle even more, frequently producing non-executable or visually poor outputs. Although supervised fine-tuning can improve code executability, it fails to enhance overall visualization quality, as traditional SFT loss cannot capture post-execution feedback. To address this gap, we propose RL-Text2Vis, the first reinforcement learning framework for Text2Vis generation. Built on Group Relative Policy Optimization (GRPO), our method uses a novel multi-objective reward that jointly optimizes textual accuracy, code validity, and visualization quality using post-execution feedback. By training Qwen2.5 models (7B and 14B), RL-Text2Vis achieves a 22% relative improvement in chart quality over GPT-4o on the Text2Vis benchmark and boosts code execution success from 78% to 97% relative to its zero-shot baseline. Our models significantly outperform strong zero-shot and supervised baselines and also demonstrate robust generalization to out-of-domain datasets like VIS-Eval and NVBench. These results establish GRPO as an effective strategy for structured, multimodal reasoning in visualization generation. We release our code at https://github.com/vis-nlp/RL-Text2Vis.",
      "authors": [
        "Mizanur Rahman",
        "Mohammed Saidul Islam",
        "Md Tahmid Rahman Laskar",
        "Shafiq Joty",
        "Enamul Hoque"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 04:29:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04582v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04577v1",
      "title": "Sci-Reasoning: A Dataset Decoding AI Innovation Patterns",
      "abstract": "While AI innovation accelerates rapidly, the intellectual process behind breakthroughs -- how researchers identify gaps, synthesize prior work, and generate insights -- remains poorly understood. The lack of structured data on scientific reasoning hinders systematic analysis and development of AI research agents. We introduce Sci-Reasoning, the first dataset capturing the intellectual synthesis behind high-quality AI research. Using community-validated quality signals and an LLM-accelerated, human-verified pipeline, we trace Oral and Spotlight papers across NeurIPS, ICML, and ICLR (2023-2025) to its key predecessors, articulating specific reasoning links in a structured format. Our analysis identifies 15 distinct thinking patterns, with three dominant strategies accounting for 52.7%: Gap-Driven Reframing (24.2%), Cross-Domain Synthesis (18.0%), and Representation Shift (10.5%). The most powerful innovation recipes combine multiple patterns: Gap-Driven Reframing + Representation Shift, Cross-Domain Synthesis + Representation Shift, and Gap-Driven Reframing + Cross-Domain Synthesis. This dataset enables quantitative studies of scientific progress and provides structured reasoning trajectories for training the next generation AI research agents.",
      "authors": [
        "Jiachen Liu",
        "Maestro Harmon",
        "Zechen Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 04:12:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04577v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04574v1",
      "title": "FeedEval: Pedagogically Aligned Evaluation of LLM-Generated Essay Feedback",
      "abstract": "Going beyond the prediction of numerical scores, recent research in automated essay scoring has increasingly emphasized the generation of high-quality feedback that provides justification and actionable guidance. To mitigate the high cost of expert annotation, prior work has commonly relied on LLM-generated feedback to train essay assessment models. However, such feedback is often incorporated without explicit quality validation, resulting in the propagation of noise in downstream applications. To address this limitation, we propose FeedEval, an LLM-based framework for evaluating LLM-generated essay feedback along three pedagogically grounded dimensions: specificity, helpfulness, and validity. FeedEval employs dimension-specialized LLM evaluators trained on datasets curated in this study to assess multiple feedback candidates and select high-quality feedback for downstream use. Experiments on the ASAP++ benchmark show that FeedEval closely aligns with human expert judgments and that essay scoring models trained with FeedEval-filtered high-quality feedback achieve superior scoring performance. Furthermore, revision experiments using small LLMs show that the high-quality feedback identified by FeedEval leads to more effective essay revisions. We will release our code and curated datasets upon accepted.",
      "authors": [
        "Seongyeub Chu",
        "Jongwoo Kim",
        "Munyong Yi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 04:04:29+00:00",
      "link": "https://arxiv.org/pdf/2601.04574v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04572v1",
      "title": "Spatial-Temporal Feedback Diffusion Guidance for Controlled Traffic Imputation",
      "abstract": "Imputing missing values in spatial-temporal traffic data is essential for intelligent transportation systems. Among advanced imputation methods, score-based diffusion models have demonstrated competitive performance. These models generate data by reversing a noising process, using observed values as conditional guidance. However, existing diffusion models typically apply a uniform guidance scale across both spatial and temporal dimensions, which is inadequate for nodes with high missing data rates. Sparse observations provide insufficient conditional guidance, causing the generative process to drift toward the learned prior distribution rather than closely following the conditional observations, resulting in suboptimal imputation performance.   To address this, we propose FENCE, a spatial-temporal feedback diffusion guidance method designed to adaptively control guidance scales during imputation. First, FENCE introduces a dynamic feedback mechanism that adjusts the guidance scale based on the posterior likelihood approximations. The guidance scale is increased when generated values diverge from observations and reduced when alignment improves, preventing overcorrection. Second, because alignment to observations varies across nodes and denoising steps, a global guidance scale for all nodes is suboptimal. FENCE computes guidance scales at the cluster level by grouping nodes based on their attention scores, leveraging spatial-temporal correlations to provide more accurate guidance. Experimental results on real-world traffic datasets show that FENCE significantly enhances imputation accuracy.",
      "authors": [
        "Xiaowei Mao",
        "Huihu Ding",
        "Yan Lin",
        "Tingrui Wu",
        "Shengnan Guo",
        "Dazhuo Qiu",
        "Feiling Fang",
        "Jilin Hu",
        "Huaiyu Wan"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-08 04:03:32+00:00",
      "link": "https://arxiv.org/pdf/2601.04572v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04571v1",
      "title": "Enhancing Multimodal Retrieval via Complementary Information Extraction and Alignment",
      "abstract": "Multimodal retrieval has emerged as a promising yet challenging research direction in recent years. Most existing studies in multimodal retrieval focus on capturing information in multimodal data that is similar to their paired texts, but often ignores the complementary information contained in multimodal data. In this study, we propose CIEA, a novel multimodal retrieval approach that employs Complementary Information Extraction and Alignment, which transforms both text and images in documents into a unified latent space and features a complementary information extractor designed to identify and preserve differences in the image representations. We optimize CIEA using two complementary contrastive losses to ensure semantic integrity and effectively capture the complementary information contained in images. Extensive experiments demonstrate the effectiveness of CIEA, which achieves significant improvements over both divide-and-conquer models and universal dense retrieval models. We provide an ablation study, further discussions, and case studies to highlight the advancements achieved by CIEA. To promote further research in the community, we have released the source code at https://github.com/zengdlong/CIEA.",
      "authors": [
        "Delong Zeng",
        "Yuexiang Xie",
        "Yaliang Li",
        "Ying Shen"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.MM"
      ],
      "published": "2026-01-08 04:02:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04571v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04569v1",
      "title": "Industrial Data-Service-Knowledge Governance: Toward Integrated and Trusted Intelligence for Industry 5.0",
      "abstract": "The convergence of artificial intelligence, cyber-physical systems, and cross-enterprise data ecosystems has propelled industrial intelligence to unprecedented scales. Yet, the absence of a unified trust foundation across data, services, and knowledge layers undermines reliability, accountability, and regulatory compliance in real-world deployments. While existing surveys address isolated aspects, such as data governance, service orchestration, and knowledge representation, none provides a holistic, cross-layer perspective on trustworthiness tailored to industrial settings. To bridge this gap, we present \\textsc{Trisk} (TRusted Industrial Data-Service-Knowledge governance), a novel conceptual and taxonomic framework for trustworthy industrial intelligence. Grounded in a five-dimensional trust model (quality, security, privacy, fairness, and explainability), \\textsc{Trisk} unifies 120+ representative studies along three orthogonal axes: governance scope (data, service, and knowledge), architectural paradigm (centralized, federated, or edge-embedded), and enabling technology (knowledge graphs, zero-trust policies, causal inference, etc.). We systematically analyze how trust propagates across digital layers, identify critical gaps in semantic interoperability, runtime policy enforcement, and operational/information technologies alignment, and evaluate the maturity of current industrial implementations. Finally, we articulate a forward-looking research agenda for Industry 5.0, advocating for an integrated governance fabric that embeds verifiable trust semantics into every layer of the industrial intelligence stack. This survey serves as both a foundational reference for researchers and a practical roadmap for engineers to deploy trustworthy AI in complex and multi-stakeholder environments.",
      "authors": [
        "Hailiang Zhao",
        "Ziqi Wang",
        "Daojiang Hu",
        "Zhiwei Ling",
        "Wenzhuo Qian",
        "Jiahui Zhai",
        "Yuhao Yang",
        "Zhipeng Gao",
        "Mingyi Liu",
        "Kai Di",
        "Xinkui Zhao",
        "Zhongjie Wang",
        "Jianwei Yin",
        "MengChu Zhou",
        "Shuiguang Deng"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE"
      ],
      "published": "2026-01-08 03:53:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04569v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04568v1",
      "title": "Neurosymbolic Retrievers for Retrieval-augmented Generation",
      "abstract": "Retrieval Augmented Generation (RAG) has made significant strides in overcoming key limitations of large language models, such as hallucination, lack of contextual grounding, and issues with transparency. However, traditional RAG systems consist of three interconnected neural components - the retriever, re-ranker, and generator - whose internal reasoning processes remain opaque. This lack of transparency complicates interpretability, hinders debugging efforts, and erodes trust, especially in high-stakes domains where clear decision-making is essential. To address these challenges, we introduce the concept of Neurosymbolic RAG, which integrates symbolic reasoning using a knowledge graph with neural retrieval techniques. This new framework aims to answer two primary questions: (a) Can retrievers provide a clear and interpretable basis for document selection? (b) Can symbolic knowledge enhance the clarity of the retrieval process? We propose three methods to improve this integration. First is MAR (Knowledge Modulation Aligned Retrieval) that employs modulation networks to refine query embeddings using interpretable symbolic features, thereby making document matching more explicit. Second, KG-Path RAG enhances queries by traversing knowledge graphs to improve overall retrieval quality and interpretability. Lastly, Process Knowledge-infused RAG utilizes domain-specific tools to reorder retrieved content based on validated workflows. Preliminary results from mental health risk assessment tasks indicate that this neurosymbolic approach enhances both transparency and overall performance",
      "authors": [
        "Yash Saxena",
        "Manas Gaur"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "published": "2026-01-08 03:53:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04568v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04544v1",
      "title": "TCAndon-Router: Adaptive Reasoning Router for Multi-Agent Collaboration",
      "abstract": "Multi-Agent Systems(MAS) have become a powerful paradigm for building high performance intelligent applications. Within these systems, the router responsible for determining which expert agents should handle a given query plays a crucial role in overall performance. Existing routing strategies generally fall into two categories: performance routing, which balances latency and cost across models of different sizes, and task routing, which assigns queries to domain-specific experts to improve accuracy. In real-world enterprise applications, task routing is more suitable; however, most existing approaches rely on static single-label decisions, which introduce two major limitations: (i) difficulty in seamlessly integrating new agents as business domains expand, and (ii) routing conflicts caused by overlapping agent capabilities, ultimately degrading accuracy and robustness.To address these challenges, we propose TCAndon-Router(TCAR): an adaptive reasoning router for multi-agent collaboration. Unlike traditional routers, TCAR supports dynamic agent onboarding and first generates a natural-language reasoning chain before predicting a set of candidate agents capable of handling the query. In addition, we design a collaborative execution pipeline in which selected agents independently produce responses, which are then aggregated and refined into a single high-quality response by a dedicated Refining Agent.Experiments on public datasets and real enterprise data demonstrate that TCAR significantly improves routing accuracy, reduces routing conflicts, and remains robust in ambiguous scenarios. We have released TCAR at https://huggingface.co/tencent/TCAndon-Router to support future research on explainable and collaborative multi-agent routing.",
      "authors": [
        "Jiuzhou Zhao",
        "Chunrong Chen",
        "Chenqi Qiao",
        "Lebin Zheng",
        "Minqi Han",
        "Yanchi Liu Yongzhou Xu Xiaochuan Xu Min Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 03:17:33+00:00",
      "link": "https://arxiv.org/pdf/2601.04544v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04539v1",
      "title": "Paradoxical noise preference in RNNs",
      "abstract": "In recurrent neural networks (RNNs) used to model biological neural networks, noise is typically introduced during training to emulate biological variability and regularize learning. The expectation is that removing the noise at test time should preserve or improve performance. Contrary to this intuition, we find that continuous-time recurrent neural networks (CTRNNs) often perform best at a nonzero noise level, specifically, the same level used during training. This noise preference typically arises when noise is injected inside the neural activation function; networks trained with noise injected outside the activation function perform best with zero noise. Through analyses of simple function approximation, maze navigation, and single neuron regulator tasks, we show that the phenomenon stems from noise-induced shifts of fixed points (stationary distributions) in the underlying stochastic dynamics of the RNNs. These fixed point shifts are noise-level dependent and bias the network outputs when the noise is removed, degrading performance. Analytical and numerical results show that the bias arises when neural states operate near activation function nonlinearities, where noise is asymmetrically attenuated, and that performance optimization incentivizes operation near these nonlinearities. Thus, networks can overfit to the stochastic training environment itself rather than just to the input-output data. The phenomenon is distinct from stochastic resonance, wherein nonzero noise enhances signal processing. Our findings reveal that training noise can become an integral part of the computation learned by recurrent networks, with implications for understanding neural population dynamics and for the design of robust artificial RNNs.",
      "authors": [
        "Noah Eckstein",
        "Manoj Srinivasan"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 03:11:51+00:00",
      "link": "https://arxiv.org/pdf/2601.04539v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04537v1",
      "title": "Not All Steps are Informative: On the Linearity of LLMs' RLVR Training",
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has become a central component of large language model (LLM) post-training. Unlike supervised fine-tuning (SFT), RLVR lets an LLM generate multiple candidate solutions and reinforces those that lead to a verifiably correct final answer. However, in practice, RLVR often requires thousands of training steps to reach strong performance, incurring substantial computation largely attributed to prolonged exploration. In this work, we make a surprising observation: during RLVR, LLMs evolve in a strongly linear manner. Specifically, both model weights and model output log-probabilities exhibit strong linear correlations with RL training steps. This suggests that RLVR predominantly amplifies trends that emerge early in training, rather than continuously discovering new behaviors throughout the entire optimization trajectory. Motivated by this linearity, we investigate whether future model states can be predicted from intermediate checkpoints via extrapolation, avoiding continued expensive training. We show that Weight Extrapolation produces models with performance comparable to standard RL training while requiring significantly less computation. Moreover, Logits Extrapolation consistently outperforms continued RL training on all four benchmarks by extrapolating beyond the step range where RL training remains stable.",
      "authors": [
        "Tianle Wang",
        "Zhongyuan Wu",
        "Shenghao Jin",
        "Hao Xu",
        "Wei Chen",
        "Ning Miao"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-01-08 03:06:18+00:00",
      "link": "https://arxiv.org/pdf/2601.04537v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04526v1",
      "title": "Advancing Language Models for Code-related Tasks",
      "abstract": "Recent advances in language models (LMs) have driven significant progress in various software engineering tasks. However, existing LMs still struggle with complex programming scenarios due to limitations in data quality, model architecture, and reasoning capability. This research systematically addresses these challenges through three complementary directions: (1) improving code data quality with a code difference-guided adversarial augmentation technique (CODA) and a code denoising technique (CodeDenoise); (2) enhancing model architecture via syntax-guided code LMs (LEAM and LEAM++); and (3) advancing model reasoning with a prompting technique (muFiX) and an agent-based technique (Specine). These techniques aim to promote the practical adoption of LMs in software development and further advance intelligent software engineering.",
      "authors": [
        "Zhao Tian"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-08 02:48:01+00:00",
      "link": "https://arxiv.org/pdf/2601.04526v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04525v1",
      "title": "GRACE: Reinforcement Learning for Grounded Response and Abstention under Contextual Evidence",
      "abstract": "Retrieval-Augmented Generation (RAG) integrates external knowledge to enhance Large Language Models (LLMs), yet systems remain susceptible to two critical flaws: providing correct answers without explicit grounded evidence and producing fabricated responses when the retrieved context is insufficient. While prior research has addressed these issues independently, a unified framework that integrates evidence-based grounding and reliable abstention is currently lacking. In this paper, we propose GRACE, a reinforcement-learning framework that simultaneously mitigates both types of flaws. GRACE employs a data construction method that utilizes heterogeneous retrievers to generate diverse training samples without manual annotation. A multi-stage gated reward function is then employed to train the model to assess evidence sufficiency, extract key supporting evidence, and provide answers or explicitly abstain. Experimental results on two benchmarks demonstrate that GRACE achieves state-of-the-art overall accuracy and strikes a favorable balance between accurate response and rejection, while requiring only 10% of the annotation costs of prior methods. Our code is available at https://github.com/YiboZhao624/Grace..",
      "authors": [
        "Yibo Zhao",
        "Jiapeng Zhu",
        "Zichen Ding",
        "Xiang Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 02:47:33+00:00",
      "link": "https://arxiv.org/pdf/2601.04525v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04524v1",
      "title": "BioPIE: A Biomedical Protocol Information Extraction Dataset for High-Reasoning-Complexity Experiment Question Answer",
      "abstract": "Question Answer (QA) systems for biomedical experiments facilitate cross-disciplinary communication, and serve as a foundation for downstream tasks, e.g., laboratory automation. High Information Density (HID) and Multi-Step Reasoning (MSR) pose unique challenges for biomedical experimental QA. While extracting structured knowledge, e.g., Knowledge Graphs (KGs), can substantially benefit biomedical experimental QA. Existing biomedical datasets focus on general or coarsegrained knowledge and thus fail to support the fine-grained experimental reasoning demanded by HID and MSR. To address this gap, we introduce Biomedical Protocol Information Extraction Dataset (BioPIE), a dataset that provides procedure-centric KGs of experimental entities, actions, and relations at a scale that supports reasoning over biomedical experiments across protocols. We evaluate information extraction methods on BioPIE, and implement a QA system that leverages BioPIE, showcasing performance gains on test, HID, and MSR question sets, showing that the structured experimental knowledge in BioPIE underpins both AI-assisted and more autonomous biomedical experimentation.",
      "authors": [
        "Haofei Hou",
        "Shunyi Zhao",
        "Fanxu Meng",
        "Kairui Yang",
        "Lecheng Ruan",
        "Qining Wang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 02:44:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04524v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04518v1",
      "title": "Integrating Distribution Matching into Semi-Supervised Contrastive Learning for Labeled and Unlabeled Data",
      "abstract": "The advancement of deep learning has greatly improved supervised image classification. However, labeling data is costly, prompting research into unsupervised learning methods such as contrastive learning. In real-world scenarios, fully unlabeled datasets are rare, making semi-supervised learning (SSL) highly relevant in scenarios where a small amount of labeled data coexists with a large volume of unlabeled data. A well-known semi-supervised contrastive learning approach involves assigning pseudo-labels to unlabeled data. This study aims to enhance pseudo-label-based SSL by incorporating distribution matching between labeled and unlabeled feature embeddings to improve image classification accuracy across multiple datasets.",
      "authors": [
        "Shogo Nakayama",
        "Masahiro Okuda"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-08 02:32:12+00:00",
      "link": "https://arxiv.org/pdf/2601.04518v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04516v1",
      "title": "LinguaGame: A Linguistically Grounded Game-Theoretic Paradigm for Multi-Agent Dialogue Generation",
      "abstract": "Large Language Models (LLMs) have enabled Multi-Agent Systems (MASs) where agents interact through natural language to solve complex tasks or simulate multi-party dialogues. Recent work on LLM-based MASs has mainly focused on architecture design, such as role assignment and workflow orchestration. In contrast, this paper targets the interaction process itself, aiming to improve agents' communication efficiency by helping them convey their intended meaning more effectively through language. To this end, we propose LinguaGame, a linguistically-grounded game-theoretic paradigm for multi-agent dialogue generation. Our approach models dialogue as a signalling game over communicative intents and strategies, solved with a training-free equilibrium approximation algorithm for inference-time decision adjustment. Unlike prior game-theoretic MASs, whose game designs are often tightly coupled with task-specific objectives, our framework relies on linguistically informed reasoning with minimal task-specific coupling. Specifically, it treats dialogue as intentional and strategic communication, requiring agents to infer what others aim to achieve (intents) and how they pursue those goals (strategies). We evaluate our framework in simulated courtroom proceedings and debates, with human expert assessments showing significant gains in communication efficiency.",
      "authors": [
        "Yuxiao Ye",
        "Yiming Zhang",
        "Yiran Ma",
        "Huiyuan Xie",
        "Huining Zhu",
        "Zhiyuan Liu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-08 02:30:43+00:00",
      "link": "https://arxiv.org/pdf/2601.04516v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04511v1",
      "title": "Multiagent Reinforcement Learning with Neighbor Action Estimation",
      "abstract": "Multiagent reinforcement learning, as a prominent intelligent paradigm, enables collaborative decision-making within complex systems. However, existing approaches often rely on explicit action exchange between agents to evaluate action value functions, which is frequently impractical in real-world engineering environments due to communication constraints, latency, energy consumption, and reliability requirements. From an artificial intelligence perspective, this paper proposes an enhanced multiagent reinforcement learning framework that employs action estimation neural networks to infer agent behaviors. By integrating a lightweight action estimation module, each agent infers neighboring agents' behaviors using only locally observable information, enabling collaborative policy learning without explicit action sharing. This approach is fully compatible with standard TD3 algorithms and scalable to larger multiagent systems. At the engineering application level, this framework has been implemented and validated in dual-arm robotic manipulation tasks: two robotic arms collaboratively lift objects. Experimental results demonstrate that this approach significantly enhances the robustness and deployment feasibility of real-world robotic systems while reducing dependence on information infrastructure. Overall, this research advances the development of decentralized multiagent artificial intelligence systems while enabling AI to operate effectively in dynamic, information-constrained real-world environments.",
      "authors": [
        "Zhenglong Luo",
        "Zhiyong Chen",
        "Aoxiang Liu"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.LG"
      ],
      "published": "2026-01-08 02:26:57+00:00",
      "link": "https://arxiv.org/pdf/2601.04511v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04509v1",
      "title": "A General Neural Backbone for Mixed-Integer Linear Optimization via Dual Attention",
      "abstract": "Mixed-integer linear programming (MILP), a widely used modeling framework for combinatorial optimization, are central to many scientific and engineering applications, yet remains computationally challenging at scale. Recent advances in deep learning address this challenge by representing MILP instances as variable-constraint bipartite graphs and applying graph neural networks (GNNs) to extract latent structural patterns and enhance solver efficiency. However, this architecture is inherently limited by the local-oriented mechanism, leading to restricted representation power and hindering neural approaches for MILP. Here we present an attention-driven neural architecture that learns expressive representations beyond the pure graph view. A dual-attention mechanism is designed to perform parallel self- and cross-attention over variables and constraints, enabling global information exchange and deeper representation learning. We apply this general backbone to various downstream tasks at the instance level, element level, and solving state level. Extensive experiments across widely used benchmarks show consistent improvements of our approach over state-of-the-art baselines, highlighting attention-based neural architectures as a powerful foundation for learning-enhanced mixed-integer linear optimization.",
      "authors": [
        "Peixin Huang",
        "Yaoxin Wu",
        "Yining Ma",
        "Cathy Wu",
        "Wen Song",
        "Wei Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 02:23:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04509v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04498v1",
      "title": "IGenBench: Benchmarking the Reliability of Text-to-Infographic Generation",
      "abstract": "Infographics are composite visual artifacts that combine data visualizations with textual and illustrative elements to communicate information. While recent text-to-image (T2I) models can generate aesthetically appealing images, their reliability in generating infographics remains unclear. Generated infographics may appear correct at first glance but contain easily overlooked issues, such as distorted data encoding or incorrect textual content. We present IGENBENCH, the first benchmark for evaluating the reliability of text-to-infographic generation, comprising 600 curated test cases spanning 30 infographic types. We design an automated evaluation framework that decomposes reliability verification into atomic yes/no questions based on a taxonomy of 10 question types. We employ multimodal large language models (MLLMs) to verify each question, yielding question-level accuracy (Q-ACC) and infographic-level accuracy (I-ACC). We comprehensively evaluate 10 state-of-the-art T2I models on IGENBENCH. Our systematic analysis reveals key insights for future model development: (i) a three-tier performance hierarchy with the top model achieving Q-ACC of 0.90 but I-ACC of only 0.49; (ii) data-related dimensions emerging as universal bottlenecks (e.g., Data Completeness: 0.21); and (iii) the challenge of achieving end-to-end correctness across all models. We release IGENBENCH at https://igen-bench.vercel.app/.",
      "authors": [
        "Yinghao Tang",
        "Xueding Liu",
        "Boyuan Zhang",
        "Tingfeng Lan",
        "Yupeng Xie",
        "Jiale Lao",
        "Yiyao Wang",
        "Haoxuan Li",
        "Tingting Gao",
        "Bo Pan",
        "Luoxuan Weng",
        "Xiuqi Huang",
        "Minfeng Zhu",
        "Yingchaojie Feng",
        "Yuyu Luo",
        "Wei Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "published": "2026-01-08 02:06:53+00:00",
      "link": "https://arxiv.org/pdf/2601.04498v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04494v1",
      "title": "Differential Locally Injective Grid Deformation and Optimization",
      "abstract": "Grids are a general representation for capturing regularly-spaced information, but since they are uniform in space, they cannot dynamically allocate resolution to regions with varying levels of detail. There has been some exploration of indirect grid adaptivity by replacing uniform grids with tetrahedral meshes or locally subdivided grids, as inversion-free deformation of grids is difficult. This work develops an inversion-free grid deformation method that optimizes differential weight to adaptively compress space. The method is the first to optimize grid vertices as differential elements using vertex-colorings, decomposing a dense input linear system into many independent sets of vertices which can be optimized concurrently. This method is then also extended to optimize UV meshes with convex boundaries. Experimentally, this differential representation leads to a smoother optimization manifold than updating extrinsic vertex coordinates. By optimizing each sets of vertices in a coloring separately, local injectivity checks are straightforward since the valid region for each vertex is fixed. This enables the use of optimizers such as Adam, as each vertex can be optimized independently of other vertices. We demonstrate the generality and efficacy of this approach through applications in isosurface extraction for inverse rendering, image compaction, and mesh parameterization.",
      "authors": [
        "Julian Knodt",
        "Seung-Hwan Baek"
      ],
      "primary_category": "cs.GR",
      "categories": [
        "cs.GR"
      ],
      "published": "2026-01-08 01:58:20+00:00",
      "link": "https://arxiv.org/pdf/2601.04494v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04483v1",
      "title": "Hybrid Federated Learning for Noise-Robust Training",
      "abstract": "Federated learning (FL) and federated distillation (FD) are distributed learning paradigms that train UE models with enhanced privacy, each offering different trade-offs between noise robustness and learning speed. To mitigate their respective weaknesses, we propose a hybrid federated learning (HFL) framework in which each user equipment (UE) transmits either gradients or logits, and the base station (BS) selects the per-round weights of FL and FD updates. We derive convergence of HFL framework and introduce two methods to exploit degrees of freedom (DoF) in HFL, which are (i) adaptive UE clustering via Jenks optimization and (ii) adaptive weight selection via a damped Newton method. Numerical results show that HFL achieves superior test accuracy at low SNR when both DoF are exploited.",
      "authors": [
        "Yongjun Kim",
        "Hyeongjun Park",
        "Hwanjin Kim",
        "Junil Choi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "eess.SP"
      ],
      "published": "2026-01-08 01:34:51+00:00",
      "link": "https://arxiv.org/pdf/2601.04483v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04476v1",
      "title": "Memory-Guided Unified Hardware Accelerator for Mixed-Precision Scientific Computing",
      "abstract": "Recent hardware acceleration advances have enabled powerful specialized accelerators for finite element computations, spiking neural network inference, and sparse tensor operations. However, existing approaches face fundamental limitations: (1) finite element methods lack comprehensive rounding error analysis for reduced-precision implementations and use fixed precision assignment strategies that cannot adapt to varying numerical conditioning; (2) spiking neural network accelerators cannot handle non-spike operations and suffer from bit-width escalation as network depth increases; and (3) FPGA tensor accelerators optimize only for dense computations while requiring manual configuration for each sparsity pattern. To address these challenges, we introduce \\textbf{Memory-Guided Unified Hardware Accelerator for Mixed-Precision Scientific Computing}, a novel framework that integrates three enhanced modules with memory-guided adaptation for efficient mixed-workload processing on unified platforms. Our approach employs memory-guided precision selection to overcome fixed precision limitations, integrates experience-driven bit-width management and dynamic parallelism adaptation for enhanced spiking neural network acceleration, and introduces curriculum learning for automatic sparsity pattern discovery. Extensive experiments on FEniCS, COMSOL, ANSYS benchmarks, MNIST, CIFAR-10, CIFAR-100, DVS-Gesture datasets, and COCO 2017 demonstrate 2.8\\% improvement in numerical accuracy, 47\\% throughput increase, 34\\% energy reduction, and 45-65\\% throughput improvement compared to specialized accelerators. Our work enables unified processing of finite element methods, spiking neural networks, and sparse computations on a single platform while eliminating data transfer overhead between separate units.",
      "authors": [
        "Chuanzhen Wang",
        "Leo Zhang",
        "Eric Liu"
      ],
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR"
      ],
      "published": "2026-01-08 01:28:45+00:00",
      "link": "https://arxiv.org/pdf/2601.04476v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04474v1",
      "title": "Computational Compliance for AI Regulation: Blueprint for a New Research Domain",
      "abstract": "The era of AI regulation (AIR) is upon us. But AI systems, we argue, will not be able to comply with these regulations at the necessary speed and scale by continuing to rely on traditional, analogue methods of compliance. Instead, we posit that compliance with these regulations will only realistically be achieved computationally: that is, with algorithms that run across the life cycle of an AI system, automatically steering it toward AIR compliance in the face of dynamic conditions. Yet despite their (we would argue) inevitability, the research community has yet to specify exactly how these algorithms for computational AIR compliance should behave - or how we should benchmark their performance. To fill these gaps, we specify a set of design goals for such algorithms. In addition, we specify a benchmark dataset that can be used to quantitatively measure whether individual algorithms satisfy these design goals. By delivering this blueprint, we hope to give shape to an important but uncrystallized new domain of research - and, in doing so, incite necessary investment in it.",
      "authors": [
        "Bill Marino",
        "Nicholas D. Lane"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-08 01:22:45+00:00",
      "link": "https://arxiv.org/pdf/2601.04474v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04473v1",
      "title": "Convergence Rates for Learning Pseudo-Differential Operators",
      "abstract": "This paper establishes convergence rates for learning elliptic pseudo-differential operators, a fundamental operator class in partial differential equations and mathematical physics. In a wavelet-Galerkin framework, we formulate learning over this class as a structured infinite-dimensional regression problem with multiscale sparsity. Building on this structure, we propose a sparse, data- and computation-efficient estimator, which leverages a novel matrix compression scheme tailored to the learning task and a nested-support strategy to balance approximation and estimation errors. In addition to obtaining convergence rates for the estimator, we show that the learned operator induces an efficient and stable Galerkin solver whose numerical error matches its statistical accuracy. Our results therefore contribute to bringing together operator learning, data-driven solvers, and wavelet methods in scientific computing.",
      "authors": [
        "Jiaheng Chen",
        "Daniel Sanz-Alonso"
      ],
      "primary_category": "math.ST",
      "categories": [
        "math.ST",
        "cs.LG",
        "math.NA",
        "stat.ML"
      ],
      "published": "2026-01-08 01:21:08+00:00",
      "link": "https://arxiv.org/pdf/2601.04473v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04458v1",
      "title": "Using Large Language Models to Detect Socially Shared Regulation of Collaborative Learning",
      "abstract": "The field of learning analytics has made notable strides in automating the detection of complex learning processes in multimodal data. However, most advancements have focused on individualized problem-solving instead of collaborative, open-ended problem-solving, which may offer both affordances (richer data) and challenges (low cohesion) to behavioral prediction. Here, we extend predictive models to automatically detect socially shared regulation of learning (SSRL) behaviors in collaborative computational modeling environments using embedding-based approaches. We leverage large language models (LLMs) as summarization tools to generate task-aware representations of student dialogue aligned with system logs. These summaries, combined with text-only embeddings, context-enriched embeddings, and log-derived features, were used to train predictive models. Results show that text-only embeddings often achieve stronger performance in detecting SSRL behaviors related to enactment or group dynamics (e.g., off-task behavior or requesting assistance). In contrast, contextual and multimodal features provide complementary benefits for constructs such as planning and reflection. Overall, our findings highlight the promise of embedding-based models for extending learning analytics by enabling scalable detection of SSRL behaviors, ultimately supporting real-time feedback and adaptive scaffolding in collaborative learning environments that teachers value.",
      "authors": [
        "Jiayi Zhang",
        "Conrad Borchers",
        "Clayton Cohn",
        "Namrata Srivastava",
        "Caitlin Snyder",
        "Siyuan Guo",
        "Ashwin T S",
        "Naveeduddin Mohammed",
        "Haley Noh",
        "Gautam Biswas"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-08 00:30:46+00:00",
      "link": "https://arxiv.org/pdf/2601.04458v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04455v1",
      "title": "Re-Rankers as Relevance Judges",
      "abstract": "Using large language models (LLMs) to predict relevance judgments has shown promising results. Most studies treat this task as a distinct research line, e.g., focusing on prompt design for predicting relevance labels given a query and passage. However, predicting relevance judgments is essentially a form of relevance prediction, a problem extensively studied in tasks such as re-ranking. Despite this potential overlap, little research has explored reusing or adapting established re-ranking methods to predict relevance judgments, leading to potential resource waste and redundant development. To bridge this gap, we reproduce re-rankers in a re-ranker-as-relevance-judge setup. We design two adaptation strategies: (i) using binary tokens (e.g., \"true\" and \"false\") generated by a re-ranker as direct judgments, and (ii) converting continuous re-ranking scores into binary labels via thresholding. We perform extensive experiments on TREC-DL 2019 to 2023 with 8 re-rankers from 3 families, ranging from 220M to 32B, and analyse the evaluation bias exhibited by re-ranker-based judges. Results show that re-ranker-based relevance judges, under both strategies, can outperform UMBRELA, a state-of-the-art LLM-based relevance judge, in around 40% to 50% of the cases; they also exhibit strong self-preference towards their own and same-family re-rankers, as well as cross-family bias.",
      "authors": [
        "Chuan Meng",
        "Jiqun Liu",
        "Mohammad Aliannejadi",
        "Fengran Mo",
        "Jeff Dalton",
        "Maarten de Rijke"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-08 00:02:59+00:00",
      "link": "https://arxiv.org/pdf/2601.04455v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04447v1",
      "title": "When Predictions Shape Reality: A Socio-Technical Synthesis of Performative Predictions in Machine Learning",
      "abstract": "Machine learning models are increasingly used in high-stakes domains where their predictions can actively shape the environments in which they operate, a phenomenon known as performative prediction. This dynamic, in which the deployment of the model influences the very outcome it seeks to predict, can lead to unintended consequences, including feedback loops, performance issues, and significant societal risks. While the literature in the field has grown rapidly in recent years, a socio-technical synthesis that systemises the phenomenon concepts and provides practical guidance has been lacking. This Systematisation of Knowledge (SoK) addresses this gap by providing a comprehensive review of the literature on performative predictions. We provide an overview of the primary mechanisms through which performativity manifests, present a typology of associated risks, and survey the proposed solutions offered in the literature. Our primary contribution is the ``Performative Strength vs. Impact Matrix\" assessment framework. This practical tool is designed to help practitioners assess the potential influence and severity of performativity on their deployed predictive models and select the appropriate level of algorithmic or human intervention.",
      "authors": [
        "Gal Fybish",
        "Teo Susnjak"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 23:28:29+00:00",
      "link": "https://arxiv.org/pdf/2601.04447v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04442v1",
      "title": "Addressing Overthinking in Large Vision-Language Models via Gated Perception-Reasoning Optimization",
      "abstract": "Large Vision-Language Models (LVLMs) have exhibited strong reasoning capabilities through chain-of-thought mechanisms that generate step-by-step rationales. However, such slow-thinking approaches often lead to overthinking, where models produce excessively verbose responses even for simple queries, resulting in test-time inefficiency and even degraded accuracy. Prior work has attempted to mitigate this issue via adaptive reasoning strategies, but these methods largely overlook a fundamental bottleneck: visual perception failures. We argue that stable reasoning critically depends on low-level visual grounding, and that reasoning errors often originate from imperfect perception rather than insufficient deliberation. To address this limitation, we propose Gated Perception-Reasoning Optimization (GPRO), a meta-reasoning controller that dynamically routes computation among three decision paths at each generation step: a lightweight fast path, a slow perception path for re-examining visual inputs, and a slow reasoning path for internal self-reflection. To learn this distinction, we derive large-scale failure attribution supervision from approximately 790k samples, using teacher models to distinguish perceptual hallucinations from reasoning errors. We then train the controller with multi-objective reinforcement learning to optimize the trade-off between task accuracy and computational cost under uncertainty. Experiments on five benchmarks demonstrate that GPRO substantially improves both accuracy and efficiency, outperforming recent slow-thinking methods while generating significantly shorter responses.",
      "authors": [
        "Xingjian Diao",
        "Zheyuan Liu",
        "Chunhui Zhang",
        "Weiyi Wu",
        "Keyi Kong",
        "Lin Shi",
        "Kaize Ding",
        "Soroush Vosoughi",
        "Jiang Gui"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.CL"
      ],
      "published": "2026-01-07 23:05:17+00:00",
      "link": "https://arxiv.org/pdf/2601.04442v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04441v1",
      "title": "Improving and Accelerating Offline RL in Large Discrete Action Spaces with Structured Policy Initialization",
      "abstract": "Reinforcement learning in discrete combinatorial action spaces requires searching over exponentially many joint actions to simultaneously select multiple sub-actions that form coherent combinations. Existing approaches either simplify policy learning by assuming independence across sub-actions, which often yields incoherent or invalid actions, or attempt to learn action structure and control jointly, which is slow and unstable. We introduce Structured Policy Initialization (SPIN), a two-stage framework that first pre-trains an Action Structure Model (ASM) to capture the manifold of valid actions, then freezes this representation and trains lightweight policy heads for control. On challenging discrete DM Control benchmarks, SPIN improves average return by up to 39% over the state of the art while reducing time to convergence by up to 12.8$\\times$.",
      "authors": [
        "Matthew Landers",
        "Taylor W. Killian",
        "Thomas Hartvigsen",
        "Afsaneh Doryab"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 22:57:21+00:00",
      "link": "https://arxiv.org/pdf/2601.04441v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04424v1",
      "title": "Gavel: Agent Meets Checklist for Evaluating LLMs on Long-Context Legal Summarization",
      "abstract": "Large language models (LLMs) now support contexts of up to 1M tokens, but their effectiveness on complex long-context tasks remains unclear. In this paper, we study multi-document legal case summarization, where a single case often spans many documents totaling 100K-500K tokens. We introduce Gavel-Ref, a reference-based evaluation framework with multi-value checklist evaluation over 26 items, as well as residual fact and writing-style evaluations. Using Gavel-Ref, we go beyond the single aggregate scores reported in prior work and systematically evaluate 12 frontier LLMs on 100 legal cases ranging from 32K to 512K tokens, primarily from 2025. Our results show that even the strongest model, Gemini 2.5 Pro, achieves only around 50 of $S_{\\text{Gavel-Ref}}$, highlighting the difficulty of the task. Models perform well on simple checklist items (e.g., filing date) but struggle on multi-value or rare ones such as settlements and monitor reports. As LLMs continue to improve and may surpass human-written summaries -- making human references less reliable -- we develop Gavel-Agent, an efficient and autonomous agent scaffold that equips LLMs with six tools to navigate and extract checklists directly from case documents. With Qwen3, Gavel-Agent reduces token usage by 36% while resulting in only a 7% drop in $S_{\\text{checklist}}$ compared to end-to-end extraction with GPT-4.1.",
      "authors": [
        "Yao Dou",
        "Wei Xu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 22:08:17+00:00",
      "link": "https://arxiv.org/pdf/2601.04424v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04423v1",
      "title": "Learning Multinomial Logits in $O(n \\log n)$ time",
      "abstract": "A Multinomial Logit (MNL) model is composed of a finite universe of items $[n]=\\{1,..., n\\}$, each assigned a positive weight. A query specifies an admissible subset -- called a slate -- and the model chooses one item from that slate with probability proportional to its weight. This query model is also known as the Plackett-Luce model or conditional sampling oracle in the literature. Although MNLs have been studied extensively, a basic computational question remains open: given query access to slates, how efficiently can we learn weights so that, for every slate, the induced choice distribution is within total variation distance $\\varepsilon$ of the ground truth? This question is central to MNL learning and has direct implications for modern recommender system interfaces.   We provide two algorithms for this task, one with adaptive queries and one with non-adaptive queries. Each algorithm outputs an MNL $M'$ that induces, for each slate $S$, a distribution $M'_S$ on $S$ that is within $\\varepsilon$ total variation distance of the true distribution. Our adaptive algorithm makes $O\\left(\\frac{n}{\\varepsilon^{3}}\\log n\\right)$ queries, while our non-adaptive algorithm makes $O\\left(\\frac{n^{2}}{\\varepsilon^{3}}\\log n \\log\\frac{n}{\\varepsilon}\\right)$ queries. Both algorithms query only slates of size two and run in time proportional to their query complexity.   We complement these upper bounds with lower bounds of $Ω\\left(\\frac{n}{\\varepsilon^{2}}\\log n\\right)$ for adaptive queries and $Ω\\left(\\frac{n^{2}}{\\varepsilon^{2}}\\log n\\right)$ for non-adaptive queries, thus proving that our adaptive algorithm is optimal in its dependence on the support size $n$, while the non-adaptive one is tight within a $\\log n$ factor.",
      "authors": [
        "Flavio Chierichetti",
        "Mirko Giacchini",
        "Ravi Kumar",
        "Silvio Lattanzi",
        "Alessandro Panconesi",
        "Erasmo Tani",
        "Andrew Tomkins"
      ],
      "primary_category": "cs.DS",
      "categories": [
        "cs.DS",
        "cs.LG",
        "math.ST",
        "stat.ML"
      ],
      "published": "2026-01-07 22:07:44+00:00",
      "link": "https://arxiv.org/pdf/2601.04423v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04411v1",
      "title": "Rate or Fate? RLV$^\\varepsilon$R: Reinforcement Learning with Verifiable Noisy Rewards",
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) is a simple but powerful paradigm for training LLMs: sample a completion, verify it, and update. In practice, however, the verifier is almost never clean--unit tests probe only limited corner cases; human and synthetic labels are imperfect; and LLM judges (e.g., RLAIF) are noisy and can be exploited--and this problem worsens on harder domains (especially coding) where tests are sparse and increasingly model-generated. We ask a pragmatic question: does the verification noise merely slow down the learning (rate), or can it flip the outcome (fate)?   To address this, we develop an analytically tractable multi-armed bandit view of RLVR dynamics, instantiated with GRPO and validated in controlled experiments. Modeling false positives and false negatives and grouping completions into recurring reasoning modes yields a replicator-style (natural-selection) flow on the probability simplex. The dynamics decouples into within-correct-mode competition and a one-dimensional evolution for the mass on incorrect modes, whose drift is determined solely by Youden's index J=TPR-FPR. This yields a sharp phase transition: when J>0, the incorrect mass is driven toward extinction (learning); when J=0, the process is neutral; and when J<0, incorrect modes amplify until they dominate (anti-learning and collapse). In the learning regime J>0, noise primarily rescales convergence time (\"rate, not fate\"). Experiments on verifiable programming tasks under synthetic noise reproduce the predicted J=0 boundary. Beyond noise, the framework offers a general lens for analyzing RLVR stability, convergence, and algorithmic interventions.",
      "authors": [
        "Ali Rad",
        "Khashayar Filom",
        "Darioush Keivan",
        "Peyman Mohajerin Esfahani",
        "Ehsan Kamalinejad"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-07 21:31:26+00:00",
      "link": "https://arxiv.org/pdf/2601.04411v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04404v1",
      "title": "3D-Agent:Tri-Modal Multi-Agent Collaboration for Scalable 3D Object Annotation",
      "abstract": "Driven by applications in autonomous driving robotics and augmented reality 3D object annotation presents challenges beyond 2D annotation including spatial complexity occlusion and viewpoint inconsistency Existing approaches based on single models often struggle to address these issues effectively We propose Tri MARF a novel framework that integrates tri modal inputs including 2D multi view images textual descriptions and 3D point clouds within a multi agent collaborative architecture to enhance large scale 3D annotation Tri MARF consists of three specialized agents a vision language model agent for generating multi view descriptions an information aggregation agent for selecting optimal descriptions and a gating agent that aligns textual semantics with 3D geometry for refined captioning Extensive experiments on Objaverse LVIS Objaverse XL and ABO demonstrate that Tri MARF substantially outperforms existing methods achieving a CLIPScore of 88 point 7 compared to prior state of the art methods retrieval accuracy of 45 point 2 and 43 point 8 on ViLT R at 5 and a throughput of up to 12000 objects per hour on a single NVIDIA A100 GPU",
      "authors": [
        "Jusheng Zhang",
        "Yijia Fan",
        "Zimo Wen",
        "Jian Wang",
        "Keze Wang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 21:23:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04404v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04401v1",
      "title": "Transformer-based Multi-agent Reinforcement Learning for Separation Assurance in Structured and Unstructured Airspaces",
      "abstract": "Conventional optimization-based metering depends on strict adherence to precomputed schedules, which limits the flexibility required for the stochastic operations of Advanced Air Mobility (AAM). In contrast, multi-agent reinforcement learning (MARL) offers a decentralized, adaptive framework that can better handle uncertainty, required for safe aircraft separation assurance. Despite this advantage, current MARL approaches often overfit to specific airspace structures, limiting their adaptability to new configurations. To improve generalization, we recast the MARL problem in a relative polar state space and train a transformer encoder model across diverse traffic patterns and intersection angles. The learned model provides speed advisories to resolve conflicts while maintaining aircraft near their desired cruising speeds. In our experiments, we evaluated encoder depths of 1, 2, and 3 layers in both structured and unstructured airspaces, and found that a single encoder configuration outperformed deeper variants, yielding near-zero near mid-air collision rates and shorter loss-of-separation infringements than the deeper configurations. Additionally, we showed that the same configuration outperforms a baseline model designed purely with attention. Together, our results suggest that the newly formulated state representation, novel design of neural network architecture, and proposed training strategy provide an adaptable and scalable decentralized solution for aircraft separation assurance in both structured and unstructured airspaces.",
      "authors": [
        "Arsyi Aziz",
        "Peng Wei"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.LG",
        "cs.MA"
      ],
      "published": "2026-01-07 21:18:28+00:00",
      "link": "https://arxiv.org/pdf/2601.04401v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04397v1",
      "title": "Performance Analysis of Image Classification on Bangladeshi Datasets",
      "abstract": "Convolutional Neural Networks (CNNs) have demonstrated remarkable success in image classification tasks; however, the choice between designing a custom CNN from scratch and employing established pre-trained architectures remains an important practical consideration. In this work, we present a comparative analysis of a custom-designed CNN and several widely used deep learning architectures, including VGG-16, ResNet-50, and MobileNet, for an image classification task. The custom CNN is developed and trained from scratch, while the popular architectures are employed using transfer learning under identical experimental settings. All models are evaluated using standard performance metrics such as accuracy, precision, recall, and F1-score. Experimental results show that pre-trained CNN architectures consistently outperform the custom CNN in terms of classification accuracy and convergence speed, particularly when training data is limited. However, the custom CNN demonstrates competitive performance with significantly fewer parameters and reduced computational complexity. This study highlights the trade-offs between model complexity, performance, and computational efficiency, and provides practical insights into selecting appropriate CNN architectures for image classification problems.",
      "authors": [
        "Mohammed Sami Khan",
        "Fabiha Muniat",
        "Rowzatul Zannat"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 21:15:16+00:00",
      "link": "https://arxiv.org/pdf/2601.04397v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04395v1",
      "title": "The Overlooked Role of Graded Relevance Thresholds in Multilingual Dense Retrieval",
      "abstract": "Dense retrieval models are typically fine-tuned with contrastive learning objectives that require binary relevance judgments, even though relevance is inherently graded. We analyze how graded relevance scores and the threshold used to convert them into binary labels affect multilingual dense retrieval. Using a multilingual dataset with LLM-annotated relevance scores, we examine monolingual, multilingual mixture, and cross-lingual retrieval scenarios. Our findings show that the optimal threshold varies systematically across languages and tasks, often reflecting differences in resource level. A well-chosen threshold can improve effectiveness, reduce the amount of fine-tuning data required, and mitigate annotation noise, whereas a poorly chosen one can degrade performance. We argue that graded relevance is a valuable but underutilized signal for dense retrieval, and that threshold calibration should be treated as a principled component of the fine-tuning pipeline.",
      "authors": [
        "Tomer Wullach",
        "Ori Shapira",
        "Amir DN Cohen"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR"
      ],
      "published": "2026-01-07 21:14:48+00:00",
      "link": "https://arxiv.org/pdf/2601.04395v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04392v1",
      "title": "Enhanced-FQL($λ$), an Efficient and Interpretable RL with novel Fuzzy Eligibility Traces and Segmented Experience Replay",
      "abstract": "This paper introduces a fuzzy reinforcement learning framework, Enhanced-FQL($λ$), that integrates novel Fuzzified Eligibility Traces (FET) and Segmented Experience Replay (SER) into fuzzy Q-learning with Fuzzified Bellman Equation (FBE) for continuous control tasks. The proposed approach employs an interpretable fuzzy rule base instead of complex neural architectures, while maintaining competitive performance through two key innovations: a fuzzified Bellman equation with eligibility traces for stable multi-step credit assignment, and a memory-efficient segment-based experience replay mechanism for enhanced sample efficiency. Theoretical analysis proves the proposed method convergence under standard assumptions. Extensive evaluations in continuous control domains demonstrate that Enhanced-FQL($λ$) achieves superior sample efficiency and reduced variance compared to n-step fuzzy TD and fuzzy SARSA($λ$) baselines, while maintaining substantially lower computational complexity than deep RL alternatives such as DDPG. The framework's inherent interpretability, combined with its computational efficiency and theoretical convergence guarantees, makes it particularly suitable for safety-critical applications where transparency and resource constraints are essential.",
      "authors": [
        "Mohsen Jalaeian-Farimani"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "eess.SY",
        "math.OC"
      ],
      "published": "2026-01-07 20:59:18+00:00",
      "link": "https://arxiv.org/pdf/2601.04392v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04390v1",
      "title": "SciFig: Towards Automating Scientific Figure Generation",
      "abstract": "Creating high-quality figures and visualizations for scientific papers is a time-consuming task that requires both deep domain knowledge and professional design skills. Despite over 2.5 million scientific papers published annually, the figure generation process remains largely manual. We introduce $\\textbf{SciFig}$, an end-to-end AI agent system that generates publication-ready pipeline figures directly from research paper texts. SciFig uses a hierarchical layout generation strategy, which parses research descriptions to identify component relationships, groups related elements into functional modules, and generates inter-module connections to establish visual organization. Furthermore, an iterative chain-of-thought (CoT) feedback mechanism progressively improves layouts through multiple rounds of visual analysis and reasoning. We introduce a rubric-based evaluation framework that analyzes 2,219 real scientific figures to extract evaluation rubrics and automatically generates comprehensive evaluation criteria. SciFig demonstrates remarkable performance: achieving 70.1$\\%$ overall quality on dataset-level evaluation and 66.2$\\%$ on paper-specific evaluation, and consistently high scores across metrics such as visual clarity, structural organization, and scientific accuracy. SciFig figure generation pipeline and our evaluation benchmark will be open-sourced.",
      "authors": [
        "Siyuan Huang",
        "Yutong Gao",
        "Juyang Bai",
        "Yifan Zhou",
        "Zi Yin",
        "Xinxin Liu",
        "Rama Chellappa",
        "Chun Pong Lau",
        "Sayan Nag",
        "Cheng Peng",
        "Shraman Pramanick"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 20:56:58+00:00",
      "link": "https://arxiv.org/pdf/2601.04390v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04378v1",
      "title": "Aligned explanations in neural networks",
      "abstract": "Feature attribution is the dominant paradigm for explaining deep neural networks. However, most existing methods only loosely reflect the model's prediction-making process, thereby merely white-painting the black box. We argue that explanatory alignment is a key aspect of trustworthiness in prediction tasks: explanations must be directly linked to predictions, rather than serving as post-hoc rationalizations. We present model readability as a design principle enabling alignment, and PiNets as a modeling framework to pursue it in a deep learning context. PiNets are pseudo-linear networks that produce instance-wise linear predictions in an arbitrary feature space, making them linearly readable. We illustrate their use on image classification and segmentation tasks, demonstrating how PiNets produce explanations that are faithful across multiple criteria in addition to alignment.",
      "authors": [
        "Corentin Lobet",
        "Francesca Chiaromonte"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV",
        "stat.ML"
      ],
      "published": "2026-01-07 20:35:02+00:00",
      "link": "https://arxiv.org/pdf/2601.04378v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04377v1",
      "title": "Disco-RAG: Discourse-Aware Retrieval-Augmented Generation",
      "abstract": "Retrieval-Augmented Generation (RAG) has emerged as an important means of enhancing the performance of large language models (LLMs) in knowledge-intensive tasks. However, most existing RAG strategies treat retrieved passages in a flat and unstructured way, which prevents the model from capturing structural cues and constrains its ability to synthesize knowledge from dispersed evidence across documents. To overcome these limitations, we propose Disco-RAG, a discourse-aware framework that explicitly injects discourse signals into the generation process. Our method constructs intra-chunk discourse trees to capture local hierarchies and builds inter-chunk rhetorical graphs to model cross-passage coherence. These structures are jointly integrated into a planning blueprint that conditions the generation. Experiments on question answering and long-document summarization benchmarks show the efficacy of our approach. Disco-RAG achieves state-of-the-art results on the benchmarks without fine-tuning. These findings underscore the important role of discourse structure in advancing RAG systems.",
      "authors": [
        "Dongqi Liu",
        "Hang Ding",
        "Qiming Feng",
        "Jian Li",
        "Xurong Xie",
        "Zhucun Xue",
        "Chengjie Wang",
        "Jiangning Zhang",
        "Yabiao Wang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-07 20:32:50+00:00",
      "link": "https://arxiv.org/pdf/2601.04377v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04365v1",
      "title": "Survival Dynamics of Neural and Programmatic Policies in Evolutionary Reinforcement Learning",
      "abstract": "In evolutionary reinforcement learning tasks (ERL), agent policies are often encoded as small artificial neural networks (NERL). Such representations lack explicit modular structure, limiting behavioral interpretation. We investigate whether programmatic policies (PERL), implemented as soft, differentiable decision lists (SDDL), can match the performance of NERL. To support reproducible evaluation, we provide the first fully specified and open-source reimplementation of the classic 1992 Artificial Life (ALife) ERL testbed. We conduct a rigorous survival analysis across 4000 independent trials utilizing Kaplan-Meier curves and Restricted Mean Survival Time (RMST) metrics absent in the original study. We find a statistically significant difference in survival probability between PERL and NERL. PERL agents survive on average 201.69 steps longer than NERL agents. Moreover, SDDL agents using learning alone (no evolution) survive on average 73.67 steps longer than neural agents using both learning and evaluation. These results demonstrate that programmatic policies can exceed the survival performance of neural policies in ALife.",
      "authors": [
        "Anton Roupassov-Ruiz",
        "Yiyang Zuo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 20:09:28+00:00",
      "link": "https://arxiv.org/pdf/2601.04365v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04361v1",
      "title": "Causally-Aware Information Bottleneck for Domain Adaptation",
      "abstract": "We tackle a common domain adaptation setting in causal systems. In this setting, the target variable is observed in the source domain but is entirely missing in the target domain. We aim to impute the target variable in the target domain from the remaining observed variables under various shifts. We frame this as learning a compact, mechanism-stable representation. This representation preserves information relevant for predicting the target while discarding spurious variation. For linear Gaussian causal models, we derive a closed-form Gaussian Information Bottleneck (GIB) solution. This solution reduces to a canonical correlation analysis (CCA)-style projection and offers Directed Acyclic Graph (DAG)-aware options when desired. For nonlinear or non-Gaussian data, we introduce a Variational Information Bottleneck (VIB) encoder-predictor. This approach scales to high dimensions and can be trained on source data and deployed zero-shot to the target domain. Across synthetic and real datasets, our approach consistently attains accurate imputations, supporting practical use in high-dimensional causal models and furnishing a unified, lightweight toolkit for causal domain adaptation.",
      "authors": [
        "Mohammad Ali Javidian"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 19:54:58+00:00",
      "link": "https://arxiv.org/pdf/2601.04361v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04359v1",
      "title": "PackCache: A Training-Free Acceleration Method for Unified Autoregressive Video Generation via Compact KV-Cache",
      "abstract": "A unified autoregressive model is a Transformer-based framework that addresses diverse multimodal tasks (e.g., text, image, video) as a single sequence modeling problem under a shared token space. Such models rely on the KV-cache mechanism to reduce attention computation from O(T^2) to O(T); however, KV-cache size grows linearly with the number of generated tokens, and it rapidly becomes the dominant bottleneck limiting inference efficiency and generative length. Unified autoregressive video generation inherits this limitation. Our analysis reveals that KV-cache tokens exhibit distinct spatiotemporal properties: (i) text and conditioning-image tokens act as persistent semantic anchors that consistently receive high attention, and (ii) attention to previous frames naturally decays with temporal distance. Leveraging these observations, we introduce PackCache, a training-free KV-cache management method that dynamically compacts the KV cache through three coordinated mechanisms: condition anchoring that preserves semantic references, cross-frame decay modeling that allocates cache budget according to temporal distance, and spatially preserving position embedding that maintains coherent 3D structure under cache removal. In terms of efficiency, PackCache accelerates end-to-end generation by 1.7-2.2x on 48-frame long sequences, showcasing its strong potential for enabling longer-sequence video generation. Notably, the final four frames - the portion most impacted by the progressively expanding KV-cache and thus the most expensive segment of the clip - PackCache delivers a 2.6x and 3.7x acceleration on A40 and H200, respectively, for 48-frame videos.",
      "authors": [
        "Kunyang Li",
        "Mubarak Shah",
        "Yuzhang Shang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 19:51:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04359v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04352v1",
      "title": "Comparative Analysis of Custom CNN Architectures versus Pre-trained Models and Transfer Learning: A Study on Five Bangladesh Datasets",
      "abstract": "This study presents a comprehensive comparative analysis of custom-built Convolutional Neural Networks (CNNs) against popular pre-trained architectures (ResNet-18 and VGG-16) using both feature extraction and transfer learning approaches. We evaluated these models across five diverse image classification datasets from Bangladesh: Footpath Vision, Auto Rickshaw Detection, Mango Image Classification, Paddy Variety Recognition, and Road Damage Detection. Our experimental results demonstrate that transfer learning with fine-tuning consistently outperforms both custom CNNs built from scratch and feature extraction methods, achieving accuracy improvements ranging from 3% to 76% across different datasets. Notably, ResNet-18 with fine-tuning achieved perfect 100% accuracy on the Road Damage BD dataset. While custom CNNs offer advantages in model size (3.4M parameters vs. 11-134M for pre-trained models) and training efficiency on simpler tasks, pre-trained models with transfer learning provide superior performance, particularly on complex classification tasks with limited training data. This research provides practical insights for practitioners in selecting appropriate deep learning approaches based on dataset characteristics, computational resources, and performance requirements.",
      "authors": [
        "Ibrahim Tanvir",
        "Alif Ruslan",
        "Sartaj Solaiman"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-07 19:36:41+00:00",
      "link": "https://arxiv.org/pdf/2601.04352v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04350v1",
      "title": "RIGOURATE: Quantifying Scientific Exaggeration with Evidence-Aligned Claim Evaluation",
      "abstract": "Scientific rigour tends to be sidelined in favour of bold statements, leading authors to overstate claims beyond what their results support. We present RIGOURATE, a two-stage multimodal framework that retrieves supporting evidence from a paper's body and assigns each claim an overstatement score. The framework consists of a dataset of over 10K claim-evidence sets from ICLR and NeurIPS papers, annotated using eight LLMs, with overstatement scores calibrated using peer-review comments and validated through human evaluation. It employes a fine-tuned reranker for evidence retrieval and a fine-tuned model to predict overstatement scores with justification. Compared to strong baselines, RIGOURATE enables improved evidence retrieval and overstatement detection. Overall, our work operationalises evidential proportionality and supports clearer, more transparent scientific communication.",
      "authors": [
        "Joseph James",
        "Chenghao Xiao",
        "Yucheng Li",
        "Nafise Sadat Moosavi",
        "Chenghua Lin"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 19:36:08+00:00",
      "link": "https://arxiv.org/pdf/2601.04350v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04349v1",
      "title": "Hybrid Cloud Architectures for Research Computing: Applications and Use Cases",
      "abstract": "Scientific research increasingly depends on robust and scalable IT infrastructures to support complex computational workflows. With the proliferation of services provided by research infrastructures, NRENs, and commercial cloud providers, researchers must navigate a fragmented ecosystem of computing environments, balancing performance, cost, scalability, and accessibility. Hybrid cloud architectures offer a compelling solution by integrating multiple computing environments to enhance flexibility, resource efficiency, and access to specialised hardware.   This paper provides a comprehensive overview of hybrid cloud deployment models, focusing on grid and cloud platforms (OpenPBS, SLURM, OpenStack, Kubernetes) and workflow management tools (Nextflow, Snakemake, CWL). We explore strategies for federated computing, multi-cloud orchestration, and workload scheduling, addressing key challenges such as interoperability, data security, reproducibility, and network performance. Drawing on implementations from life sciences, as coordinated by the ELIXIR Compute Platform and their integration into a wider EOSC context, we propose a roadmap for accelerating hybrid cloud adoption in research computing, emphasising governance frameworks and technical solutions that can drive sustainable and scalable infrastructure development.",
      "authors": [
        "Xaver Stiensmeier",
        "Alexander Kanitz",
        "Jan Krüger",
        "Santiago Insua",
        "Adrián Rošinec",
        "Viktória Spišáková",
        "Lukáš Hejtmánek",
        "David Yuan",
        "Gavin Farrell",
        "Jonathan Tedds",
        "Juha Törnroos",
        "Harald Wagener",
        "Alex Sczyrba",
        "Nils Hoffmann",
        "Matej Antol"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC"
      ],
      "published": "2026-01-07 19:35:10+00:00",
      "link": "https://arxiv.org/pdf/2601.04349v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04348v1",
      "title": "SCAR-GS: Spatial Context Attention for Residuals in Progressive Gaussian Splatting",
      "abstract": "Recent advances in 3D Gaussian Splatting have allowed for real-time, high-fidelity novel view synthesis. Nonetheless, these models have significant storage requirements for large and medium-sized scenes, hindering their deployment over cloud and streaming services. Some of the most recent progressive compression techniques for these models rely on progressive masking and scalar quantization techniques to reduce the bitrate of Gaussian attributes using spatial context models. While effective, scalar quantization may not optimally capture the correlations of high-dimensional feature vectors, which can potentially limit the rate-distortion performance.   In this work, we introduce a novel progressive codec for 3D Gaussian Splatting that replaces traditional methods with a more powerful Residual Vector Quantization approach to compress the primitive features. Our key contribution is an auto-regressive entropy model, guided by a multi-resolution hash grid, that accurately predicts the conditional probability of each successive transmitted index, allowing for coarse and refinement layers to be compressed with high efficiency.",
      "authors": [
        "Diego Revilla",
        "Pooja Suresh",
        "Anand Bhojan",
        "Ooi Wei Tsang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.GR"
      ],
      "published": "2026-01-07 19:34:51+00:00",
      "link": "https://arxiv.org/pdf/2601.04348v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04342v1",
      "title": "ReHyAt: Recurrent Hybrid Attention for Video Diffusion Transformers",
      "abstract": "Recent advances in video diffusion models have shifted towards transformer-based architectures, achieving state-of-the-art video generation but at the cost of quadratic attention complexity, which severely limits scalability for longer sequences. We introduce ReHyAt, a Recurrent Hybrid Attention mechanism that combines the fidelity of softmax attention with the efficiency of linear attention, enabling chunk-wise recurrent reformulation and constant memory usage. Unlike the concurrent linear-only SANA Video, ReHyAt's hybrid design allows efficient distillation from existing softmax-based models, reducing the training cost by two orders of magnitude to ~160 GPU hours, while being competitive in the quality. Our light-weight distillation and finetuning pipeline provides a recipe that can be applied to future state-of-the-art bidirectional softmax-based models. Experiments on VBench and VBench-2.0, as well as a human preference study, demonstrate that ReHyAt achieves state-of-the-art video quality while reducing attention cost from quadratic to linear, unlocking practical scalability for long-duration and on-device video generation. Project page is available at https://qualcomm-ai-research.github.io/rehyat.",
      "authors": [
        "Mohsen Ghafoorian",
        "Amirhossein Habibian"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 19:26:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04342v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04336v1",
      "title": "Pilot Study on Student Public Opinion Regarding GAI",
      "abstract": "The emergence of generative AI (GAI) has sparked diverse opinions regarding its appropriate use across various domains, including education. This pilot study investigates university students' perceptions of GAI in higher education classrooms, aiming to lay the groundwork for understanding these attitudes. With a participation rate of approximately 4.4%, the study highlights the challenges of engaging students in GAI-related research and underscores the need for larger sample sizes in future studies. By gaining insights into student perspectives, instructors can better prepare to integrate discussions of GAI into their classrooms, fostering informed and critical engagement with this transformative technology.",
      "authors": [
        "William Franz Lamberti",
        "Sunbin Kim",
        "Samantha Rose Lawrence"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.HC",
        "stat.AP"
      ],
      "published": "2026-01-07 19:16:50+00:00",
      "link": "https://arxiv.org/pdf/2601.04336v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04334v1",
      "title": "Autonomous Reasoning for Spacecraft Control: A Large Language Model Framework with Group Relative Policy Optimization",
      "abstract": "This paper presents a learning-based guidance-and-control approach that couples a reasoning-enabled Large Language Model (LLM) with Group Relative Policy Optimization (GRPO). A two-stage procedure consisting of Supervised Fine-Tuning (SFT) to learn formatting and control primitives, followed by GRPO for interaction-driven policy improvement, trains controllers for each environment. The framework is demonstrated on four control problems spanning a gradient of dynamical complexity, from canonical linear systems through nonlinear oscillatory dynamics to three-dimensional spacecraft attitude control with gyroscopic coupling and thrust constraints. Results demonstrate that an LLM with explicit reasoning, optimized via GRPO, can synthesize feasible stabilizing policies under consistent training settings across both linear and nonlinear systems. The two-stage training methodology enables models to generate control sequences while providing human-readable explanations of their decision-making process. This work establishes a foundation for applying GRPO-based reasoning to autonomous control systems, with potential applications in aerospace and other safety-critical domains.",
      "authors": [
        "Amit Jain",
        "Richard Linares"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "math.OC"
      ],
      "published": "2026-01-07 19:13:22+00:00",
      "link": "https://arxiv.org/pdf/2601.04334v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04302v1",
      "title": "Embedding Textual Information in Images Using Quinary Pixel Combinations",
      "abstract": "This paper presents a novel technique for embedding textual data into images using quinary combinations of pixel intensities in RGB space. Existing methods predominantly rely on least and most significant bit (LSB & MSB) manipulation, Pixel Value Differencing (PVD), spatial perturbations in RGB channels, transform domain based methods, Quantization methods, Edge and Region based methods and more recently through deep learning methods and generative AI techniques for hiding textual information in spatial domain of images. Most of them are dependent on pixel intensity flipping over multiple pixels, such as LSB and combination of LSB based methodologies, and on transform coefficients, often resulting in the form of noise. Encoding and Decoding are deterministic in most of the existing approaches and are computationally heavy in case of higher models such as deep learning and gen AI approaches. The proposed method works on quinary pixel intensity combinations in RGB space, where five controlled different pixel intensity variations in each of the R, G, and B channels formulate up to one hundred and twenty five distinct pixel intensity combinations. These combinations are mapped to textual symbols, enabling the representation of uppercase and lowercase alphabetic characters, numeric digits, whitespace, and commonly used special characters. Different metrics such as MSE, MAE, SNR, PSNR, SSIM, Histogram Comparison and Heatmap analysis, were evaluated for both original and encoded images resulting in no significant distortion in the images. Furthermore, the method achieves improved embedding efficiency by encoding a complete textual symbol within a single RGB pixel, in contrast to LSB and MSB based approaches that typically require multiple pixels or multi-step processes, as well as transform and learning based methods that incur higher computational overhead.",
      "authors": [
        "A V Uday Kiran Kandala"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 18:58:00+00:00",
      "link": "https://arxiv.org/pdf/2601.04302v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04191v1",
      "title": "Embedding Autonomous Agents in Resource-Constrained Robotic Platforms",
      "abstract": "Many embedded devices operate under resource constraints and in dynamic environments, requiring local decision-making capabilities. Enabling devices to make independent decisions in such environments can improve the responsiveness of the system and reduce the dependence on constant external control. In this work, we integrate an autonomous agent, programmed using AgentSpeak, with a small two-wheeled robot that explores a maze using its own decision-making and sensor data. Experimental results show that the agent successfully solved the maze in 59 seconds using 287 reasoning cycles, with decision phases taking less than one millisecond. These results indicate that the reasoning process is efficient enough for real-time execution on resource-constrained hardware. This integration demonstrates how high-level agent-based control can be applied to resource-constrained embedded systems for autonomous operation.",
      "authors": [
        "Negar Halakou",
        "Juan F. Gutierrez",
        "Ye Sun",
        "Han Jiang",
        "Xueming Wu",
        "Yilun Song",
        "Andres Gomez"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "published": "2026-01-07 18:57:32+00:00",
      "link": "https://arxiv.org/pdf/2601.04191v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04301v1",
      "title": "Quantifying the Effect of Test Set Contamination on Generative Evaluations",
      "abstract": "As frontier AI systems are pretrained on web-scale data, test set contamination has become a critical concern for accurately assessing their capabilities. While research has thoroughly investigated the impact of test set contamination on discriminative evaluations like multiple-choice question-answering, comparatively little research has studied the impact of test set contamination on generative evaluations. In this work, we quantitatively assess the effect of test set contamination on generative evaluations through the language model lifecycle. We pretrain language models on mixtures of web data and the MATH benchmark, sweeping model sizes and number of test set replicas contaminating the pretraining corpus; performance improves with contamination and model size. Using scaling laws, we make a surprising discovery: including even a single test set replica enables models to achieve lower loss than the irreducible error of training on the uncontaminated corpus. We then study further training: overtraining with fresh data reduces the effects of contamination, whereas supervised finetuning on the training set can either increase or decrease performance on test data, depending on the amount of pretraining contamination. Finally, at inference, we identify factors that modulate memorization: high sampling temperatures mitigate contamination effects, and longer solutions are exponentially more difficult to memorize than shorter ones, presenting a contrast with discriminative evaluations, where solutions are only a few tokens in length. By characterizing how generation and memorization interact, we highlight a new layer of complexity for trustworthy evaluation of AI systems.",
      "authors": [
        "Rylan Schaeffer",
        "Joshua Kazdan",
        "Baber Abbasi",
        "Ken Ziyu Liu",
        "Brando Miranda",
        "Ahmed Ahmed",
        "Abhay Puri",
        "Niloofar Mireshghallah",
        "Sanmi Koyejo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-01-07 18:46:22+00:00",
      "link": "https://arxiv.org/pdf/2601.04301v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04177v1",
      "title": "Hierarchical GNN-Based Multi-Agent Learning for Dynamic Queue-Jump Lane and Emergency Vehicle Corridor Formation",
      "abstract": "Emergency vehicles require rapid passage through congested traffic, yet existing strategies fail to adapt to dynamic conditions. We propose a novel hierarchical graph neural network (GNN)-based multi-agent reinforcement learning framework to coordinate connected vehicles for emergency corridor formation. Our approach uses a high-level planner for global strategy and low-level controllers for trajectory execution, utilizing graph attention networks to scale with variable agent counts. Trained via Multi-Agent Proximal Policy Optimization (MAPPO), the system reduces emergency vehicle travel time by 28.3% compared to baselines and 44.6% compared to uncoordinated traffic in simulations. The design achieves near-zero collision rates (0.3%) while maintaining 81% of background traffic efficiency. Ablation and generalization studies confirm the framework's robustness across diverse scenarios. These results demonstrate the effectiveness of combining GNNs with hierarchical learning for intelligent transportation systems.",
      "authors": [
        "Haoran Su"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "eess.SY"
      ],
      "published": "2026-01-07 18:43:18+00:00",
      "link": "https://arxiv.org/pdf/2601.04177v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04176v1",
      "title": "Robust Physics Discovery from Highly Corrupted Data: A PINN Framework Applied to the Nonlinear Schrödinger Equation",
      "abstract": "We demonstrate a deep learning framework capable of recovering physical parameters from the Nonlinear Schrodinger Equation (NLSE) under severe noise conditions. By integrating Physics-Informed Neural Networks (PINNs) with automatic differentiation, we achieve reconstruction of the nonlinear coefficient beta with less than 0.2 percent relative error using only 500 sparse, randomly sampled data points corrupted by 20 percent additive Gaussian noise, a regime where traditional finite difference methods typically fail due to noise amplification in numerical derivatives. We validate the method's generalization capabilities across different physical regimes (beta between 0.5 and 2.0) and varying data availability (between 100 and 1000 training points), demonstrating consistent sub-1 percent accuracy. Statistical analysis over multiple independent runs confirms robustness (standard deviation less than 0.15 percent for beta equals 1.0). The complete pipeline executes in approximately 80 minutes on modest cloud GPU resources (NVIDIA Tesla T4), making the approach accessible for widespread adoption. Our results indicate that physics-based regularization acts as an effective filter against high measurement uncertainty, positioning PINNs as a viable alternative to traditional optimization methods for inverse problems in spatiotemporal dynamics where experimental data is scarce and noisy. All code is made publicly available to facilitate reproducibility.",
      "authors": [
        "Pietro de Oliveira Esteves"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "physics.comp-ph"
      ],
      "published": "2026-01-07 18:43:11+00:00",
      "link": "https://arxiv.org/pdf/2601.04176v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04171v1",
      "title": "Agentic Rubrics as Contextual Verifiers for SWE Agents",
      "abstract": "Verification is critical for improving agents: it provides the reward signal for Reinforcement Learning and enables inference-time gains through Test-Time Scaling (TTS). Despite its importance, verification in software engineering (SWE) agent settings often relies on code execution, which can be difficult to scale due to environment setup overhead. Scalable alternatives such as patch classifiers and heuristic methods exist, but they are less grounded in codebase context and harder to interpret. To this end, we explore Agentic Rubrics: an expert agent interacts with the repository to create a context-grounded rubric checklist, and candidate patches are then scored against it without requiring test execution. On SWE-Bench Verified under parallel TTS evaluation, Agentic Rubrics achieve a score of 54.2% on Qwen3-Coder-30B-A3B and 40.6% on Qwen3-32B, with at least a +3.5 percentage-point gain over the strongest baseline in our comparison set. We further analyze rubric behavior, showing that rubric scores are consistent with ground-truth tests while also flagging issues that tests do not capture. Our ablations show that agentic context gathering is essential for producing codebase-specific, unambiguous criteria. Together, these results suggest that Agentic Rubrics provide an efficient, scalable, and granular verification signal for SWE agents.",
      "authors": [
        "Mohit Raghavendra",
        "Anisha Gunjal",
        "Bing Liu",
        "Yunzhong He"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 18:38:23+00:00",
      "link": "https://arxiv.org/pdf/2601.04171v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04170v1",
      "title": "Agent Drift: Quantifying Behavioral Degradation in Multi-Agent LLM Systems Over Extended Interactions",
      "abstract": "Multi-agent Large Language Model (LLM) systems have emerged as powerful architectures for complex task decomposition and collaborative problem-solving. However, their long-term behavioral stability remains largely unexamined. This study introduces the concept of agent drift, defined as the progressive degradation of agent behavior, decision quality, and inter-agent coherence over extended interaction sequences. We present a comprehensive theoretical framework for understanding drift phenomena, proposing three distinct manifestations: semantic drift (progressive deviation from original intent), coordination drift (breakdown in multi-agent consensus mechanisms), and behavioral drift (emergence of unintended strategies).   We introduce the Agent Stability Index (ASI), a novel composite metric framework for quantifying drift across twelve dimensions, including response consistency, tool usage patterns, reasoning pathway stability, and inter-agent agreement rates. Through simulation-based analysis and theoretical modeling, we demonstrate how unchecked agent drift can lead to substantial reductions in task completion accuracy and increased human intervention requirements.   We propose three mitigation strategies: episodic memory consolidation, drift-aware routing protocols, and adaptive behavioral anchoring. Theoretical analysis suggests these approaches can significantly reduce drift-related errors while maintaining system throughput. This work establishes a foundational methodology for monitoring, measuring, and mitigating agent drift in production agentic AI systems, with direct implications for enterprise deployment reliability and AI safety research.",
      "authors": [
        "Abhishek Rath"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 18:37:26+00:00",
      "link": "https://arxiv.org/pdf/2601.04170v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04157v1",
      "title": "FLEx: Language Modeling with Few-shot Language Explanations",
      "abstract": "Language models have become effective at a wide range of tasks, from math problem solving to open-domain question answering. However, they still make mistakes, and these mistakes are often repeated across related queries. Natural language explanations can help correct these errors, but collecting them at scale may be infeasible, particularly in domains where expert annotators are required. To address this issue, we introduce FLEx ($\\textbf{F}$ew-shot $\\textbf{L}$anguage $\\textbf{Ex}$planations), a method for improving model behavior using a small number of explanatory examples. FLEx selects representative model errors using embedding-based clustering, verifies that the associated explanations correct those errors, and summarizes them into a prompt prefix that is prepended at inference-time. This summary guides the model to avoid similar errors on new inputs, without modifying model weights. We evaluate FLEx on CounterBench, GSM8K, and ReasonIF. We find that FLEx consistently outperforms chain-of-thought (CoT) prompting across all three datasets and reduces up to 83\\% of CoT's remaining errors.",
      "authors": [
        "Adar Avsian",
        "Christopher Richardson",
        "Anirudh Sundar",
        "Larry Heck"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-07 18:12:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04157v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04153v1",
      "title": "Diffusion-DRF: Differentiable Reward Flow for Video Diffusion Fine-Tuning",
      "abstract": "Direct Preference Optimization (DPO) has recently improved Text-to-Video (T2V) generation by enhancing visual fidelity and text alignment. However, current methods rely on non-differentiable preference signals from human annotations or learned reward models. This reliance makes training label-intensive, bias-prone, and easy-to-game, which often triggers reward hacking and unstable training. We propose Diffusion-DRF, a differentiable reward flow for fine-tuning video diffusion models using a frozen, off-the-shelf Vision-Language Model (VLM) as a training-free critic. Diffusion-DRF directly backpropagates VLM feedback through the diffusion denoising chain, converting logit-level responses into token-aware gradients for optimization. We propose an automated, aspect-structured prompting pipeline to obtain reliable multi-dimensional VLM feedback, while gradient checkpointing enables efficient updates through the final denoising steps. Diffusion-DRF improves video quality and semantic alignment while mitigating reward hacking and collapse -- without additional reward models or preference datasets. It is model-agnostic and readily generalizes to other diffusion-based generative tasks.",
      "authors": [
        "Yifan Wang",
        "Yanyu Li",
        "Sergey Tulyakov",
        "Yun Fu",
        "Anil Kag"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 18:05:08+00:00",
      "link": "https://arxiv.org/pdf/2601.04153v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04137v1",
      "title": "Wow, wo, val! A Comprehensive Embodied World Model Evaluation Turing Test",
      "abstract": "As world models gain momentum in Embodied AI, an increasing number of works explore using video foundation models as predictive world models for downstream embodied tasks like 3D prediction or interactive generation. However, before exploring these downstream tasks, video foundation models still have two critical questions unanswered: (1) whether their generative generalization is sufficient to maintain perceptual fidelity in the eyes of human observers, and (2) whether they are robust enough to serve as a universal prior for real-world embodied agents. To provide a standardized framework for answering these questions, we introduce the Embodied Turing Test benchmark: WoW-World-Eval (Wow,wo,val). Building upon 609 robot manipulation data, Wow-wo-val examines five core abilities, including perception, planning, prediction, generalization, and execution. We propose a comprehensive evaluation protocol with 22 metrics to assess the models' generation ability, which achieves a high Pearson Correlation between the overall score and human preference (>0.93) and establishes a reliable foundation for the Human Turing Test. On Wow-wo-val, models achieve only 17.27 on long-horizon planning and at best 68.02 on physical consistency, indicating limited spatiotemporal consistency and physical reasoning. For the Inverse Dynamic Model Turing Test, we first use an IDM to evaluate the video foundation models' execution accuracy in the real world. However, most models collapse to $\\approx$ 0% success, while WoW maintains a 40.74% success rate. These findings point to a noticeable gap between the generated videos and the real world, highlighting the urgency and necessity of benchmarking World Model in Embodied AI.",
      "authors": [
        "Chun-Kai Fan",
        "Xiaowei Chi",
        "Xiaozhu Ju",
        "Hao Li",
        "Yong Bao",
        "Yu-Kai Wang",
        "Lizhang Chen",
        "Zhiyuan Jiang",
        "Kuangzhi Ge",
        "Ying Li",
        "Weishi Mi",
        "Qingpo Wuwu",
        "Peidong Jia",
        "Yulin Luo",
        "Kevin Zhang",
        "Zhiyuan Qin",
        "Yong Dai",
        "Sirui Han",
        "Yike Guo",
        "Shanghang Zhang",
        "Jian Tang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-01-07 17:50:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04137v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04131v1",
      "title": "ContextFocus: Activation Steering for Contextual Faithfulness in Large Language Models",
      "abstract": "Large Language Models (LLMs) encode vast amounts of parametric knowledge during pre-training. As world knowledge evolves, effective deployment increasingly depends on their ability to faithfully follow externally retrieved context. When such evidence conflicts with the model's internal knowledge, LLMs often default to memorized facts, producing unfaithful outputs. In this work, we introduce ContextFocus, a lightweight activation steering approach that improves context faithfulness in such knowledge-conflict settings while preserving fluency and efficiency. Unlike prior approaches, our solution requires no model finetuning and incurs minimal inference-time overhead, making it highly efficient. We evaluate ContextFocus on the ConFiQA benchmark, comparing it against strong baselines including ContextDPO, COIECD, and prompting-based methods. Furthermore, we show that our method is complementary to prompting strategies and remains effective on larger models. Extensive experiments show that ContextFocus significantly improves contextual-faithfulness. Our results highlight the effectiveness, robustness, and efficiency of ContextFocus in improving contextual-faithfulness of LLM outputs.",
      "authors": [
        "Nikhil Anand",
        "Shwetha Somasundaram",
        "Anirudh Phukan",
        "Apoorv Saxena",
        "Koyel Mukherjee"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-07 17:45:20+00:00",
      "link": "https://arxiv.org/pdf/2601.04131v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04126v2",
      "title": "InfiniteWeb: Scalable Web Environment Synthesis for GUI Agent Training",
      "abstract": "GUI agents that interact with graphical interfaces on behalf of users represent a promising direction for practical AI assistants. However, training such agents is hindered by the scarcity of suitable environments. We present InfiniteWeb, a system that automatically generates functional web environments at scale for GUI agent training. While LLMs perform well on generating a single webpage, building a realistic and functional website with many interconnected pages faces challenges. We address these challenges through unified specification, task-centric test-driven development, and a combination of website seed with reference design image to ensure diversity. Our system also generates verifiable task evaluators enabling dense reward signals for reinforcement learning. Experiments show that InfiniteWeb surpasses commercial coding agents at realistic website construction, and GUI agents trained on our generated environments achieve significant performance improvements on OSWorld and Online-Mind2Web, demonstrating the effectiveness of proposed system.",
      "authors": [
        "Ziyun Zhang",
        "Zezhou Wang",
        "Xiaoyi Zhang",
        "Zongyu Guo",
        "Jiahao Li",
        "Bin Li",
        "Yan Lu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "published": "2026-01-07 17:40:08+00:00",
      "link": "https://arxiv.org/pdf/2601.04126v2",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04121v1",
      "title": "MORPHFED: Federated Learning for Cross-institutional Blood Morphology Analysis",
      "abstract": "Automated blood morphology analysis can support hematological diagnostics in low- and middle-income countries (LMICs) but remains sensitive to dataset shifts from staining variability, imaging differences, and rare morphologies. Building centralized datasets to capture this diversity is often infeasible due to privacy regulations and data-sharing restrictions. We introduce a federated learning framework for white blood cell morphology analysis that enables collaborative training across institutions without exchanging training data. Using blood films from multiple clinical sites, our federated models learn robust, domain-invariant representations while preserving complete data privacy. Evaluations across convolutional and transformer-based architectures show that federated training achieves strong cross-site performance and improved generalization to unseen institutions compared to centralized training. These findings highlight federated learning as a practical and privacy-preserving approach for developing equitable, scalable, and generalizable medical imaging AI in resource-limited healthcare environments.",
      "authors": [
        "Gabriel Ansah",
        "Eden Ruffell",
        "Delmiro Fernandez-Reyes",
        "Petru Manescu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "published": "2026-01-07 17:32:24+00:00",
      "link": "https://arxiv.org/pdf/2601.04121v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04120v1",
      "title": "A Single-Loop Bilevel Deep Learning Method for Optimal Control of Obstacle Problems",
      "abstract": "Optimal control of obstacle problems arises in a wide range of applications and is computationally challenging due to its nonsmoothness, nonlinearity, and bilevel structure. Classical numerical approaches rely on mesh-based discretization and typically require solving a sequence of costly subproblems. In this work, we propose a single-loop bilevel deep learning method, which is mesh-free, scalable to high-dimensional and complex domains, and avoids repeated solution of discretized subproblems. The method employs constraint-embedding neural networks to approximate the state and control and preserves the bilevel structure. To train the neural networks efficiently, we propose a Single-Loop Stochastic First-Order Bilevel Algorithm (S2-FOBA), which eliminates nested optimization and does not rely on restrictive lower-level uniqueness assumptions. We analyze the convergence behavior of S2-FOBA under mild assumptions. Numerical experiments on benchmark examples, including distributed and obstacle control problems with regular and irregular obstacles on complex domains, demonstrate that the proposed method achieves satisfactory accuracy while reducing computational cost compared to classical numerical methods.",
      "authors": [
        "Yongcun Song",
        "Shangzhi Zeng",
        "Jin Zhang",
        "Lvgang Zhang"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.LG"
      ],
      "published": "2026-01-07 17:30:42+00:00",
      "link": "https://arxiv.org/pdf/2601.04120v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04110v1",
      "title": "Causal Data Augmentation for Robust Fine-Tuning of Tabular Foundation Models",
      "abstract": "Fine-tuning tabular foundation models (TFMs) under data scarcity is challenging, as early stopping on even scarcer validation data often fails to capture true generalization performance. We propose CausalMixFT, a method that enhances fine-tuning robustness and downstream performance by generating structurally consistent synthetic samples using Structural Causal Models (SCMs) fitted on the target dataset. This approach augments limited real data with causally informed synthetic examples, preserving feature dependencies while expanding training diversity. Evaluated across 33 classification datasets from TabArena and over 2300 fine-tuning runs, our CausalMixFT method consistently improves median normalized ROC-AUC from 0.10 (standard fine-tuning) to 0.12, outperforming purely statistical generators such as CTGAN (-0.01), TabEBM (-0.04), and TableAugment (-0.09). Moreover, it narrows the median validation-test performance correlation gap from 0.67 to 0.30, enabling more reliable validation-based early stopping, a key step toward improving fine-tuning stability under data scarcity. These results demonstrate that incorporating causal structure into data augmentation provides an effective and principled route to fine-tuning tabular foundation models in low-data regimes.",
      "authors": [
        "Magnus Bühler",
        "Lennart Purucker",
        "Frank Hutter"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 17:16:39+00:00",
      "link": "https://arxiv.org/pdf/2601.04110v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04100v1",
      "title": "Quantifying the Impact of Modules and Their Interactions in the PSO-X Framework",
      "abstract": "The PSO-X framework incorporates dozens of modules that have been proposed for solving single-objective continuous optimization problems using particle swarm optimization. While modular frameworks enable users to automatically generate and configure algorithms tailored to specific optimization problems, the complexity of this process increases with the number of modules in the framework and the degrees of freedom defined for their interaction. Understanding how modules affect the performance of algorithms for different problems is critical to making the process of finding effective implementations more efficient and identifying promising areas for further investigation. Despite their practical applications and scientific relevance, there is a lack of empirical studies investigating which modules matter most in modular optimization frameworks and how they interact. In this paper, we analyze the performance of 1424 particle swarm optimization algorithms instantiated from the PSO-X framework on the 25 functions in the CEC'05 benchmark suite with 10 and 30 dimensions. We use functional ANOVA to quantify the impact of modules and their combinations on performance in different problem classes. In practice, this allows us to identify which modules have greater influence on PSO-X performance depending on problem features such as multimodality, mathematical transformations and varying dimensionality. We then perform a cluster analysis to identify groups of problem classes that share similar module effect patterns. Our results show low variability in the importance of modules in all problem classes, suggesting that particle swarm optimization performance is driven by a few influential modules.",
      "authors": [
        "Christian L. Camacho-Villalón",
        "Ana Nikolikj",
        "Katharina Dost",
        "Eva Tuba",
        "Sašo Džeroski",
        "Tome Eftimov"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "published": "2026-01-07 17:06:05+00:00",
      "link": "https://arxiv.org/pdf/2601.04100v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04094v1",
      "title": "The Bathtub of European AI Governance: Identifying Technical Sandboxes as the Micro-Foundation of Regulatory Learning",
      "abstract": "The EU AI Act adopts a horizontal and adaptive approach to govern AI technologies characterised by rapid development and unpredictable emerging capabilities. To maintain relevance, the Act embeds provisions for regulatory learning. However, these provisions operate within a complex network of actors and mechanisms that lack a clearly defined technical basis for scalable information flow. This paper addresses this gap by establishing a theoretical model of regulatory learning space defined by the AI Act, decomposed into micro, meso, and macro levels. Drawing from this functional perspective of this model, we situate the diverse stakeholders - ranging from the EU Commission at the macro level to AI developers at the micro level - within the transitions of enforcement (macro-micro) and evidence aggregation (micro-macro). We identify AI Technical Sandboxes as the essential engine for evidence generation at the micro level, providing the necessary data to drive scalable learning across all levels of the model. By providing an extensive discussion of the requirements and challenges for AITSes to serve as this micro-level evidence generator, we aim to bridge the gap between legislative commands and technical operationalisation, thereby enabling a structured discourse between technical and legal experts.",
      "authors": [
        "Tom Deckenbrunnen",
        "Alessio Buscemi",
        "Marco Almada",
        "Alfredo Capozucca",
        "German Castignani"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY"
      ],
      "published": "2026-01-07 17:01:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04094v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04090v1",
      "title": "Gen3R: 3D Scene Generation Meets Feed-Forward Reconstruction",
      "abstract": "We present Gen3R, a method that bridges the strong priors of foundational reconstruction models and video diffusion models for scene-level 3D generation. We repurpose the VGGT reconstruction model to produce geometric latents by training an adapter on its tokens, which are regularized to align with the appearance latents of pre-trained video diffusion models. By jointly generating these disentangled yet aligned latents, Gen3R produces both RGB videos and corresponding 3D geometry, including camera poses, depth maps, and global point clouds. Experiments demonstrate that our approach achieves state-of-the-art results in single- and multi-image conditioned 3D scene generation. Additionally, our method can enhance the robustness of reconstruction by leveraging generative priors, demonstrating the mutual benefit of tightly coupling reconstruction and generative models.",
      "authors": [
        "Jiaxin Huang",
        "Yuanbo Yang",
        "Bangbang Yang",
        "Lin Ma",
        "Yuewen Ma",
        "Yiyi Liao"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 16:57:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04090v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04085v1",
      "title": "CSSG: Measuring Code Similarity with Semantic Graphs",
      "abstract": "Existing code similarity metrics, such as BLEU, CodeBLEU, and TSED, largely rely on surface-level string overlap or abstract syntax tree structures, and often fail to capture deeper semantic relationships between programs.We propose CSSG (Code Similarity using Semantic Graphs), a novel metric that leverages program dependence graphs to explicitly model control dependencies and variable interactions, providing a semantics-aware representation of code.Experiments on the CodeContests+ dataset show that CSSG consistently outperforms existing metrics in distinguishing more similar code from less similar code under both monolingual and cross-lingual settings, demonstrating that dependency-aware graph representations offer a more effective alternative to surface-level or syntax-based similarity measures.",
      "authors": [
        "Jingwen Xu",
        "Yiyang Lu",
        "Changze Lv",
        "Zisu Huang",
        "Zhengkang Guo",
        "Zhengyuan Wang",
        "Muzhao Tian",
        "Xuanjing Huang",
        "Xiaoqing Zheng"
      ],
      "primary_category": "cs.PL",
      "categories": [
        "cs.PL",
        "cs.AI"
      ],
      "published": "2026-01-07 16:54:02+00:00",
      "link": "https://arxiv.org/pdf/2601.04085v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04083v2",
      "title": "Cells on Autopilot: Adaptive Cell (Re)Selection via Reinforcement Learning",
      "abstract": "The widespread deployment of 5G networks, together with the coexistence of 4G/LTE networks, provides mobile devices a diverse set of candidate cells to connect to. However, associating mobile devices to cells to maximize overall network performance, a.k.a. cell (re)selection, remains a key challenge for mobile operators. Today, cell (re)selection parameters are typically configured manually based on operator experience and rarely adapted to dynamic network conditions. In this work, we ask: Can an agent automatically learn and adapt cell (re)selection parameters to consistently improve network performance? We present a reinforcement learning (RL)-based framework called CellPilot that adaptively tunes cell (re)selection parameters by learning spatiotemporal patterns of mobile network dynamics. Our study with real-world data demonstrates that even a lightweight RL agent can outperform conventional heuristic reconfigurations by up to 167%, while generalizing effectively across different network scenarios. These results indicate that data-driven approaches can significantly improve cell (re)selection configurations and enhance mobile network performance.",
      "authors": [
        "Marvin Illian",
        "Ramin Khalili",
        "Antonio A. de A. Rocha",
        "Lin Wang"
      ],
      "primary_category": "cs.NI",
      "categories": [
        "cs.NI",
        "cs.LG"
      ],
      "published": "2026-01-07 16:51:33+00:00",
      "link": "https://arxiv.org/pdf/2601.04083v2",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04068v2",
      "title": "Mind the Generative Details: Direct Localized Detail Preference Optimization for Video Diffusion Models",
      "abstract": "Aligning text-to-video diffusion models with human preferences is crucial for generating high-quality videos. Existing Direct Preference Otimization (DPO) methods rely on multi-sample ranking and task-specific critic models, which is inefficient and often yields ambiguous global supervision. To address these limitations, we propose LocalDPO, a novel post-training framework that constructs localized preference pairs from real videos and optimizes alignment at the spatio-temporal region level. We design an automated pipeline to efficiently collect preference pair data that generates preference pairs with a single inference per prompt, eliminating the need for external critic models or manual annotation. Specifically, we treat high-quality real videos as positive samples and generate corresponding negatives by locally corrupting them with random spatio-temporal masks and restoring only the masked regions using the frozen base model. During training, we introduce a region-aware DPO loss that restricts preference learning to corrupted areas for rapid convergence. Experiments on Wan2.1 and CogVideoX demonstrate that LocalDPO consistently improves video fidelity, temporal coherence and human preference scores over other post-training approaches, establishing a more efficient and fine-grained paradigm for video generator alignment.",
      "authors": [
        "Zitong Huang",
        "Kaidong Zhang",
        "Yukang Ding",
        "Chao Gao",
        "Rui Ding",
        "Ying Chen",
        "Wangmeng Zuo"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 16:32:17+00:00",
      "link": "https://arxiv.org/pdf/2601.04068v2",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04061v1",
      "title": "CLAP: Contrastive Latent Action Pretraining for Learning Vision-Language-Action Models from Human Videos",
      "abstract": "Generalist Vision-Language-Action models are currently hindered by the scarcity of robotic data compared to the abundance of human video demonstrations. Existing Latent Action Models attempt to leverage video data but often suffer from visual entanglement, capturing noise rather than manipulation skills. To address this, we propose Contrastive Latent Action Pretraining (CLAP), a framework that aligns the visual latent space from videos with a proprioceptive latent space from robot trajectories. By employing contrastive learning, CLAP maps video transitions onto a quantized, physically executable codebook. Building on this representation, we introduce a dual-formulation VLA framework offering both CLAP-NTP, an autoregressive model excelling at instruction following and object generalization, and CLAP-RF, a Rectified Flow-based policy designed for high-frequency, precise manipulation. Furthermore, we propose a Knowledge Matching (KM) regularization strategy to mitigate catastrophic forgetting during fine-tuning. Extensive experiments demonstrate that CLAP significantly outperforms strong baselines, enabling the effective transfer of skills from human videos to robotic execution. Project page: https://lin-shan.com/CLAP/.",
      "authors": [
        "Chubin Zhang",
        "Jianan Wang",
        "Zifeng Gao",
        "Yue Su",
        "Tianru Dai",
        "Cai Zhou",
        "Jiwen Lu",
        "Yansong Tang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "published": "2026-01-07 16:26:33+00:00",
      "link": "https://arxiv.org/pdf/2601.04061v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04060v1",
      "title": "ComfySearch: Autonomous Exploration and Reasoning for ComfyUI Workflows",
      "abstract": "AI-generated content has progressed from monolithic models to modular workflows, especially on platforms like ComfyUI, allowing users to customize complex creative pipelines. However, the large number of components in ComfyUI and the difficulty of maintaining long-horizon structural consistency under strict graph constraints frequently lead to low pass rates and workflows of limited quality. To tackle these limitations, we present ComfySearch, an agentic framework that can effectively explore the component space and generate functional ComfyUI pipelines via validation-guided workflow construction. Experiments demonstrate that ComfySearch substantially outperforms existing methods on complex and creative tasks, achieving higher executability (pass) rates, higher solution rates, and stronger generalization.",
      "authors": [
        "Jinwei Su",
        "Qizhen Lan",
        "Zeyu Wang",
        "Yinghui Xia",
        "Hairu Wen",
        "Yiqun Duan",
        "Xi Xiao",
        "Tianyu Shi",
        "Yang Jingsong",
        "Lewei He"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 16:24:01+00:00",
      "link": "https://arxiv.org/pdf/2601.04060v1",
      "tags": [
        "keyword:RL",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04058v1",
      "title": "Minimum distance classification for nonlinear dynamical systems",
      "abstract": "We address the problem of classifying trajectory data generated by some nonlinear dynamics, where each class corresponds to a distinct dynamical system. We propose Dynafit, a kernel-based method for learning a distance metric between training trajectories and the underlying dynamics. New observations are assigned to the class with the most similar dynamics according to the learned metric. The learning algorithm approximates the Koopman operator which globally linearizes the dynamics in a (potentially infinite) feature space associated with a kernel function. The distance metric is computed in feature space independently of its dimensionality by using the kernel trick common in machine learning. We also show that the kernel function can be tailored to incorporate partial knowledge of the dynamics when available. Dynafit is applicable to various classification tasks involving nonlinear dynamical systems and sensors. We illustrate its effectiveness on three examples: chaos detection with the logistic map, recognition of handwritten dynamics and of visual dynamic textures.",
      "authors": [
        "Dominique Martinez"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 16:21:47+00:00",
      "link": "https://arxiv.org/pdf/2601.04058v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04056v1",
      "title": "Bridging the Discrete-Continuous Gap: Unified Multimodal Generation via Coupled Manifold Discrete Absorbing Diffusion",
      "abstract": "The bifurcation of generative modeling into autoregressive approaches for discrete data (text) and diffusion approaches for continuous data (images) hinders the development of truly unified multimodal systems. While Masked Language Models (MLMs) offer efficient bidirectional context, they traditionally lack the generative fidelity of autoregressive models and the semantic continuity of diffusion models. Furthermore, extending masked generation to multimodal settings introduces severe alignment challenges and training instability. In this work, we propose \\textbf{CoM-DAD} (\\textbf{Co}upled \\textbf{M}anifold \\textbf{D}iscrete \\textbf{A}bsorbing \\textbf{D}iffusion), a novel probabilistic framework that reformulates multimodal generation as a hierarchical dual-process. CoM-DAD decouples high-level semantic planning from low-level token synthesis. First, we model the semantic manifold via a continuous latent diffusion process; second, we treat token generation as a discrete absorbing diffusion process, regulated by a \\textbf{Variable-Rate Noise Schedule}, conditioned on these evolving semantic priors. Crucially, we introduce a \\textbf{Stochastic Mixed-Modal Transport} strategy that aligns disparate modalities without requiring heavy contrastive dual-encoders. Our method demonstrates superior stability over standard masked modeling, establishing a new paradigm for scalable, unified text-image generation.",
      "authors": [
        "Yuanfeng Xu",
        "Yuhao Chen",
        "Liang Lin",
        "Guangrun Wang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 16:21:19+00:00",
      "link": "https://arxiv.org/pdf/2601.04056v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04054v1",
      "title": "LinkD: AutoRegressive Diffusion Model for Mechanical Linkage Synthesis",
      "abstract": "Designing mechanical linkages to achieve target end-effector trajectories presents a fundamental challenge due to the intricate coupling between continuous node placements, discrete topological configurations, and nonlinear kinematic constraints. The highly nonlinear motion-to-configuration relationship means small perturbations in joint positions drastically alter trajectories, while the combinatorially expanding design space renders conventional optimization and heuristic methods computationally intractable. We introduce an autoregressive diffusion framework that exploits the dyadic nature of linkage assembly by representing mechanisms as sequentially constructed graphs, where nodes correspond to joints and edges to rigid links. Our approach combines a causal transformer with a Denoising Diffusion Probabilistic Model (DDPM), both conditioned on target trajectories encoded via a transformer encoder. The causal transformer autoregressively predicts discrete topology node-by-node, while the DDPM refines each node's spatial coordinates and edge connectivity to previously generated nodes. This sequential generation enables adaptive trial-and-error synthesis where problematic nodes exhibiting kinematic locking or collisions can be selectively regenerated, allowing autonomous correction of degenerate configurations during design. Our graph-based, data-driven methodology surpasses traditional optimization approaches, enabling scalable inverse design that generalizes to mechanisms with arbitrary node counts. We demonstrate successful synthesis of linkage systems containing up to 20 nodes with extensibility to N-node architectures. This work advances autoregressive graph generation methodologies and computational kinematic synthesis, establishing new paradigms for scalable inverse design of complex mechanical systems.",
      "authors": [
        "Yayati Jadhav",
        "Amir Barati Farimani"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 16:19:11+00:00",
      "link": "https://arxiv.org/pdf/2601.04054v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04052v1",
      "title": "Stable Language Guidance for Vision-Language-Action Models",
      "abstract": "Vision-Language-Action (VLA) models have demonstrated impressive capabilities in generalized robotic control; however, they remain notoriously brittle to linguistic perturbations. We identify a critical ``modality collapse'' phenomenon where strong visual priors overwhelm sparse linguistic signals, causing agents to overfit to specific instruction phrasings while ignoring the underlying semantic intent. To address this, we propose \\textbf{Residual Semantic Steering (RSS)}, a probabilistic framework that disentangles physical affordance from semantic execution. RSS introduces two theoretical innovations: (1) \\textbf{Monte Carlo Syntactic Integration}, which approximates the true semantic posterior via dense, LLM-driven distributional expansion, and (2) \\textbf{Residual Affordance Steering}, a dual-stream decoding mechanism that explicitly isolates the causal influence of language by subtracting the visual affordance prior. Theoretical analysis suggests that RSS effectively maximizes the mutual information between action and intent while suppressing visual distractors. Empirical results across diverse manipulation benchmarks demonstrate that RSS achieves state-of-the-art robustness, maintaining performance even under adversarial linguistic perturbations.",
      "authors": [
        "Zhihao Zhan",
        "Yuhao Chen",
        "Jiaying Zhou",
        "Qinhan Lv",
        "Hao Liu",
        "Keze Wang",
        "Liang Lin",
        "Guangrun Wang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.CL"
      ],
      "published": "2026-01-07 16:16:10+00:00",
      "link": "https://arxiv.org/pdf/2601.04052v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04051v1",
      "title": "Symbolic Regression for Shared Expressions: Introducing Partial Parameter Sharing",
      "abstract": "Symbolic Regression aims to find symbolic expressions that describe datasets. Due to better interpretability, it is a machine learning paradigm particularly powerful for scientific discovery. In recent years, several works have expanded the concept to allow the description of similar phenomena using a single expression with varying sets of parameters, thereby introducing categorical variables. Some previous works allow only \"non-shared\" (category-value-specific) parameters, and others also incorporate \"shared\" (category-value-agnostic) parameters. We expand upon those efforts by considering multiple categorical variables, and introducing intermediate levels of parameter sharing. With two categorical variables, an intermediate level of parameter sharing emerges, i.e., parameters which are shared across either category but change across the other. The new approach potentially decreases the number of parameters, while revealing additional information about the problem. Using a synthetic, fitting-only example, we test the limits of this setup in terms of data requirement reduction and transfer learning. As a real-world symbolic regression example, we demonstrate the benefits of the proposed approach on an astrophysics dataset used in a previous study, which considered only one categorical variable. We achieve a similar fit quality but require significantly fewer individual parameters, and extract additional information about the problem.",
      "authors": [
        "Viktor Martinek",
        "Roland Herzog"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 16:12:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04051v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04036v1",
      "title": "Analyzing and Improving Cross-lingual Knowledge Transfer for Machine Translation",
      "abstract": "Multilingual machine translation systems aim to make knowledge accessible across languages, yet learning effective cross-lingual representations remains challenging. These challenges are especially pronounced for low-resource languages, where limited parallel data constrains generalization and transfer. Understanding how multilingual models share knowledge across languages requires examining the interaction between representations, data availability, and training strategies. In this thesis, we study cross-lingual knowledge transfer in neural models and develop methods to improve robustness and generalization in multilingual settings, using machine translation as a central testbed. We analyze how similarity between languages influences transfer, how retrieval and auxiliary supervision can strengthen low-resource translation, and how fine-tuning on parallel data can introduce unintended trade-offs in large language models. We further examine the role of language diversity during training and show that increasing translation coverage improves generalization and reduces off-target behavior. Together, this work highlights how modeling choices and data composition shape multilingual learning and offers insights toward more inclusive and resilient multilingual NLP systems.",
      "authors": [
        "David Stap"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 15:51:54+00:00",
      "link": "https://arxiv.org/pdf/2601.04036v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04035v1",
      "title": "MobileDreamer: Generative Sketch World Model for GUI Agent",
      "abstract": "Mobile GUI agents have shown strong potential in real-world automation and practical applications. However, most existing agents remain reactive, making decisions mainly from current screen, which limits their performance on long-horizon tasks. Building a world model from repeated interactions enables forecasting action outcomes and supports better decision making for mobile GUI agents. This is challenging because the model must predict post-action states with spatial awareness while remaining efficient enough for practical deployment. In this paper, we propose MobileDreamer, an efficient world-model-based lookahead framework to equip the GUI agents based on the future imagination provided by the world model. It consists of textual sketch world model and rollout imagination for GUI agent. Textual sketch world model forecasts post-action states through a learning process to transform digital images into key task-related sketches, and designs a novel order-invariant learning strategy to preserve the spatial information of GUI elements. The rollout imagination strategy for GUI agent optimizes the action-selection process by leveraging the prediction capability of world model. Experiments on Android World show that MobileDreamer achieves state-of-the-art performance and improves task success by 5.25%. World model evaluations further verify that our textual sketch modeling accurately forecasts key GUI elements.",
      "authors": [
        "Yilin Cao",
        "Yufeng Zhong",
        "Zhixiong Zeng",
        "Liming Zheng",
        "Jing Huang",
        "Haibo Qiu",
        "Peng Shi",
        "Wenji Mao",
        "Wan Guanglu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 15:51:44+00:00",
      "link": "https://arxiv.org/pdf/2601.04035v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04019v1",
      "title": "Modeling Behavioral Patterns in News Recommendations Using Fuzzy Neural Networks",
      "abstract": "News recommender systems are increasingly driven by black-box models, offering little transparency for editorial decision-making. In this work, we introduce a transparent recommender system that uses fuzzy neural networks to learn human-readable rules from behavioral data for predicting article clicks. By extracting the rules at configurable thresholds, we can control rule complexity and thus, the level of interpretability. We evaluate our approach on two publicly available news datasets (i.e., MIND and EB-NeRD) and show that we can accurately predict click behavior compared to several established baselines, while learning human-readable rules. Furthermore, we show that the learned rules reveal news consumption patterns, enabling editors to align content curation goals with target audience behavior.",
      "authors": [
        "Kevin Innerebner",
        "Stephan Bartl",
        "Markus Reiter-Haas",
        "Elisabeth Lex"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.IR"
      ],
      "published": "2026-01-07 15:34:15+00:00",
      "link": "https://arxiv.org/pdf/2601.04019v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04005v1",
      "title": "Padé Neurons for Efficient Neural Models",
      "abstract": "Neural networks commonly employ the McCulloch-Pitts neuron model, which is a linear model followed by a point-wise non-linear activation. Various researchers have already advanced inherently non-linear neuron models, such as quadratic neurons, generalized operational neurons, generative neurons, and super neurons, which offer stronger non-linearity compared to point-wise activation functions. In this paper, we introduce a novel and better non-linear neuron model called Padé neurons (Paons), inspired by Padé approximants. Paons offer several advantages, such as diversity of non-linearity, since each Paon learns a different non-linear function of its inputs, and layer efficiency, since Paons provide stronger non-linearity in much fewer layers compared to piecewise linear approximation. Furthermore, Paons include all previously proposed neuron models as special cases, thus any neuron model in any network can be replaced by Paons. We note that there has been a proposal to employ the Padé approximation as a generalized point-wise activation function, which is fundamentally different from our model. To validate the efficacy of Paons, in our experiments, we replace classic neurons in some well-known neural image super-resolution, compression, and classification models based on the ResNet architecture with Paons. Our comprehensive experimental results and analyses demonstrate that neural models built by Paons provide better or equal performance than their classic counterparts with a smaller number of layers. The PyTorch implementation code for Paon is open-sourced at https://github.com/onur-keles/Paon.",
      "authors": [
        "Onur Keleş",
        "A. Murat Tekalp"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "eess.IV"
      ],
      "published": "2026-01-07 15:15:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04005v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03992v1",
      "title": "A Scheduling Framework for Efficient MoE Inference on Edge GPU-NDP Systems",
      "abstract": "Mixture-of-Experts (MoE) models facilitate edge deployment by decoupling model capacity from active computation, yet their large memory footprint drives the need for GPU systems with near-data processing (NDP) capabilities that offload experts to dedicated processing units. However, deploying MoE models on such edge-based GPU-NDP systems faces three critical challenges: 1) severe load imbalance across NDP units due to non-uniform expert selection and expert parallelism, 2) insufficient GPU utilization during expert computation within NDP units, and 3) extensive data pre-profiling necessitated by unpredictable expert activation patterns for pre-fetching. To address these challenges, this paper proposes an efficient inference framework featuring three key optimizations. First, the underexplored tensor parallelism in MoE inference is exploited to partition and compute large expert parameters across multiple NDP units simultaneously towards edge low-batch scenarios. Second, a load-balancing-aware scheduling algorithm distributes expert computations across NDP units and GPU to maximize resource utilization. Third, a dataset-free pre-fetching strategy proactively loads frequently accessed experts to minimize activation delays. Experimental results show that our framework enables GPU-NDP systems to achieve 2.41x on average and up to 2.56x speedup in end-to-end latency compared to state-of-the-art approaches, significantly enhancing MoE inference efficiency in resource-constrained environments.",
      "authors": [
        "Qi Wu",
        "Chao Fang",
        "Jiayuan Chen",
        "Ye Lin",
        "Yueqi Zhang",
        "Yichuan Bai",
        "Yuan Du",
        "Li Du"
      ],
      "primary_category": "cs.DC",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "published": "2026-01-07 15:02:57+00:00",
      "link": "https://arxiv.org/pdf/2601.03992v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03988v1",
      "title": "Using Small Language Models to Reverse-Engineer Machine Learning Pipelines Structures",
      "abstract": "Background: Extracting the stages that structure Machine Learning (ML) pipelines from source code is key for gaining a deeper understanding of data science practices. However, the diversity caused by the constant evolution of the ML ecosystem (e.g., algorithms, libraries, datasets) makes this task challenging. Existing approaches either depend on non-scalable, manual labeling, or on ML classifiers that do not properly support the diversity of the domain. These limitations highlight the need for more flexible and reliable solutions.   Objective: We evaluate whether Small Language Models (SLMs) can leverage their code understanding and classification abilities to address these limitations, and subsequently how they can advance our understanding of data science practices.   Method: We conduct a confirmatory study based on two reference works selected for their relevance regarding current state-of-the-art's limitations. First, we compare several SLMs using Cochran's Q test. The best-performing model is then evaluated against the reference studies using two distinct McNemar's tests. We further analyze how variations in taxonomy definitions affect performance through an additional Cochran's Q test. Finally, a goodness-of-fit analysis is conducted using Pearson's chi-squared tests to compare our insights on data science practices with those from prior studies.",
      "authors": [
        "Nicolas Lacroix",
        "Mireille Blay-Fornarino",
        "Sébastien Mosser",
        "Frederic Precioso"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.LG"
      ],
      "published": "2026-01-07 15:00:22+00:00",
      "link": "https://arxiv.org/pdf/2601.03988v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03986v1",
      "title": "Benchmark^2: Systematic Evaluation of LLM Benchmarks",
      "abstract": "The rapid proliferation of benchmarks for evaluating large language models (LLMs) has created an urgent need for systematic methods to assess benchmark quality itself. We propose Benchmark^2, a comprehensive framework comprising three complementary metrics: (1) Cross-Benchmark Ranking Consistency, measuring whether a benchmark produces model rankings aligned with peer benchmarks; (2) Discriminability Score, quantifying a benchmark's ability to differentiate between models; and (3) Capability Alignment Deviation, identifying problematic instances where stronger models fail but weaker models succeed within the same model family. We conduct extensive experiments across 15 benchmarks spanning mathematics, reasoning, and knowledge domains, evaluating 11 LLMs across four model families. Our analysis reveals significant quality variations among existing benchmarks and demonstrates that selective benchmark construction based on our metrics can achieve comparable evaluation performance with substantially reduced test sets.",
      "authors": [
        "Qi Qian",
        "Chengsong Huang",
        "Jingwen Xu",
        "Changze Lv",
        "Muling Wu",
        "Wenhao Liu",
        "Xiaohua Wang",
        "Zhenghua Wang",
        "Zisu Huang",
        "Muzhao Tian",
        "Jianhan Xu",
        "Kun Hu",
        "He-Da Wang",
        "Yao Hu",
        "Xuanjing Huang",
        "Xiaoqing Zheng"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 14:59:03+00:00",
      "link": "https://arxiv.org/pdf/2601.03986v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04288v1",
      "title": "Human-in-the-Loop Testing of AI Agents for Air Traffic Control with a Regulated Assessment Framework",
      "abstract": "We present a rigorous, human-in-the-loop evaluation framework for assessing the performance of AI agents on the task of Air Traffic Control, grounded in a regulator-certified simulator-based curriculum used for training and testing real-world trainee controllers. By leveraging legally regulated assessments and involving expert human instructors in the evaluation process, our framework enables a more authentic and domain-accurate measurement of AI performance. This work addresses a critical gap in the existing literature: the frequent misalignment between academic representations of Air Traffic Control and the complexities of the actual operational environment. It also lays the foundations for effective future human-machine teaming paradigms by aligning machine performance with human assessment targets.",
      "authors": [
        "Ben Carvell",
        "Marc Thomas",
        "Andrew Pace",
        "Christopher Dorney",
        "George De Ath",
        "Richard Everson",
        "Nick Pepper",
        "Adam Keane",
        "Samuel Tomlinson",
        "Richard Cannon"
      ],
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC",
        "cs.LG",
        "cs.MA"
      ],
      "published": "2026-01-07 14:50:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04288v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03976v1",
      "title": "On-Device Deep Reinforcement Learning for Decentralized Task Offloading Performance trade-offs in the training process",
      "abstract": "Allowing less capable devices to offload computational tasks to more powerful devices or servers enables the development of new applications that may not run correctly on the device itself. Deciding where and why to run each of those applications is a complex task. Therefore, different approaches have been adopted to make offloading decisions. In this work, we propose a decentralized Deep Reinforcement Learning (DRL) agent to address the selection of computing locations. Unlike most existing work, we analyze it in a real testbed composed of various edge devices running the agent to determine where to execute each task. These devices are connected to a Multi-Access Edge Computing (MEC) server and a Cloud server through 5G communications. We evaluate not only the agent's performance in meeting task requirements but also the implications of running this type of agent locally, assessing the trade-offs of training locally versus remotely in terms of latency and energy consumption.",
      "authors": [
        "Gorka Nieto",
        "Idoia de la Iglesia",
        "Cristina Perfecto",
        "Unai Lopez-Novoa"
      ],
      "primary_category": "cs.ET",
      "categories": [
        "cs.ET",
        "eess.SY"
      ],
      "published": "2026-01-07 14:43:35+00:00",
      "link": "https://arxiv.org/pdf/2601.03976v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03969v1",
      "title": "Anti-Length Shift: Dynamic Outlier Truncation for Training Efficient Reasoning Models",
      "abstract": "Large reasoning models enhanced by reinforcement learning with verifiable rewards have achieved significant performance gains by extending their chain-of-thought. However, this paradigm incurs substantial deployment costs as models often exhibit excessive verbosity on simple queries. Existing efficient reasoning methods relying on explicit length penalties often introduce optimization conflicts and leave the generative mechanisms driving overthinking largely unexamined. In this paper, we identify a phenomenon termed length shift where models increasingly generate unnecessary reasoning on trivial inputs during training. To address this, we introduce Dynamic Outlier Truncation (DOT), a training-time intervention that selectively suppresses redundant tokens. This method targets only the extreme tail of response lengths within fully correct rollout groups while preserving long-horizon reasoning capabilities for complex problems. To complement this intervention and ensure stable convergence, we further incorporate auxiliary KL regularization and predictive dynamic sampling. Experimental results across multiple model scales demonstrate that our approach significantly pushes the efficiency-performance Pareto frontier outward. Notably, on the AIME-24, our method reduces inference token usage by 78% while simultaneously increasing accuracy compared to the initial policy and surpassing state-of-the-art efficient reasoning methods.",
      "authors": [
        "Wei Wu",
        "Liyi Chen",
        "Congxi Xiao",
        "Tianfu Wang",
        "Qimeng Wang",
        "Chengqiang Lu",
        "Yan Gao",
        "Yi Wu",
        "Yao Hu",
        "Hui Xiong"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-07 14:31:07+00:00",
      "link": "https://arxiv.org/pdf/2601.03969v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04287v1",
      "title": "Online Action-Stacking Improves Reinforcement Learning Performance for Air Traffic Control",
      "abstract": "We introduce online action-stacking, an inference-time wrapper for reinforcement learning policies that produces realistic air traffic control commands while allowing training on a much smaller discrete action space. Policies are trained with simple incremental heading or level adjustments, together with an action-damping penalty that reduces instruction frequency and leads agents to issue commands in short bursts. At inference, online action-stacking compiles these bursts of primitive actions into domain-appropriate compound clearances. Using Proximal Policy Optimisation and the BluebirdDT digital twin platform, we train agents to navigate aircraft along lateral routes, manage climb and descent to target flight levels, and perform two-aircraft collision avoidance under a minimum separation constraint. In our lateral navigation experiments, action stacking greatly reduces the number of issued instructions relative to a damped baseline and achieves comparable performance to a policy trained with a 37-dimensional action space, despite operating with only five actions. These results indicate that online action-stacking helps bridge a key gap between standard reinforcement learning formulations and operational ATC requirements, and provides a simple mechanism for scaling to more complex control scenarios.",
      "authors": [
        "Ben Carvell",
        "George De Ath",
        "Eseoghene Benjamin",
        "Richard Everson"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ],
      "published": "2026-01-07 14:28:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04287v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03956v1",
      "title": "CoINS: Counterfactual Interactive Navigation via Skill-Aware VLM",
      "abstract": "Recent Vision-Language Models (VLMs) have demonstrated significant potential in robotic planning. However, they typically function as semantic reasoners, lacking an intrinsic understanding of the specific robot's physical capabilities. This limitation is particularly critical in interactive navigation, where robots must actively modify cluttered environments to create traversable paths. Existing VLM-based navigators are predominantly confined to passive obstacle avoidance, failing to reason about when and how to interact with objects to clear blocked paths. To bridge this gap, we propose Counterfactual Interactive Navigation via Skill-aware VLM (CoINS), a hierarchical framework that integrates skill-aware reasoning and robust low-level execution. Specifically, we fine-tune a VLM, named InterNav-VLM, which incorporates skill affordance and concrete constraint parameters into the input context and grounds them into a metric-scale environmental representation. By internalizing the logic of counterfactual reasoning through fine-tuning on the proposed InterNav dataset, the model learns to implicitly evaluate the causal effects of object removal on navigation connectivity, thereby determining interaction necessity and target selection. To execute the generated high-level plans, we develop a comprehensive skill library through reinforcement learning, specifically introducing traversability-oriented strategies to manipulate diverse objects for path clearance. A systematic benchmark in Isaac Sim is proposed to evaluate both the reasoning and execution aspects of interactive navigation. Extensive simulations and real-world experiments demonstrate that CoINS significantly outperforms representative baselines, achieving a 17\\% higher overall success rate and over 80\\% improvement in complex long-horizon scenarios compared to the best-performing baseline",
      "authors": [
        "Kangjie Zhou",
        "Zhejia Wen",
        "Zhiyong Zhuo",
        "Zike Yan",
        "Pengying Wu",
        "Ieng Hou U",
        "Shuaiyang Li",
        "Han Gao",
        "Kang Ding",
        "Wenhan Cao",
        "Wei Pan",
        "Chang Liu"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-07 14:10:46+00:00",
      "link": "https://arxiv.org/pdf/2601.03956v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03955v1",
      "title": "ResTok: Learning Hierarchical Residuals in 1D Visual Tokenizers for Autoregressive Image Generation",
      "abstract": "Existing 1D visual tokenizers for autoregressive (AR) generation largely follow the design principles of language modeling, as they are built directly upon transformers whose priors originate in language, yielding single-hierarchy latent tokens and treating visual data as flat sequential token streams. However, this language-like formulation overlooks key properties of vision, particularly the hierarchical and residual network designs that have long been essential for convergence and efficiency in visual models. To bring \"vision\" back to vision, we propose the Residual Tokenizer (ResTok), a 1D visual tokenizer that builds hierarchical residuals for both image tokens and latent tokens. The hierarchical representations obtained through progressively merging enable cross-level feature fusion at each layer, substantially enhancing representational capacity. Meanwhile, the semantic residuals between hierarchies prevent information overlap, yielding more concentrated latent distributions that are easier for AR modeling. Cross-level bindings consequently emerge without any explicit constraints. To accelerate the generation process, we further introduce a hierarchical AR generator that substantially reduces sampling steps by predicting an entire level of latent tokens at once rather than generating them strictly token-by-token. Extensive experiments demonstrate that restoring hierarchical residual priors in visual tokenization significantly improves AR image generation, achieving a gFID of 2.34 on ImageNet-256 with only 9 sampling steps. Code is available at https://github.com/Kwai-Kolors/ResTok.",
      "authors": [
        "Xu Zhang",
        "Cheng Da",
        "Huan Yang",
        "Kun Gai",
        "Ming Lu",
        "Zhan Ma"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 14:09:18+00:00",
      "link": "https://arxiv.org/pdf/2601.03955v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03940v1",
      "title": "Large-Scale Aspect-Based Sentiment Analysis with Reasoning-Infused LLMs",
      "abstract": "We introduce Arctic-ABSA, a collection of powerful models for real-life aspect-based sentiment analysis (ABSA). Our models are tailored to commercial needs, trained on a large corpus of public data alongside carefully generated synthetic data, resulting in a dataset 20 times larger than SemEval14. We extend typical ABSA models by expanding the number of sentiment classes from the standard three (positive, negative, neutral) to five, adding mixed and unknown classes, while also jointly predicting overall text sentiment and supporting multiple languages. We experiment with reasoning injection by fine-tuning on Chain-of-Thought (CoT) examples and introduce a novel reasoning pretraining technique for encoder-only models that significantly improves downstream fine-tuning and generalization. Our 395M-parameter encoder and 8B-parameter decoder achieve up to 10 percentage points higher accuracy than GPT-4o and Claude 3.5 Sonnet, while setting new state-of-the-art results on the SemEval14 benchmark. A single multilingual model maintains 87-91% accuracy across six languages without degrading English performance. We release ABSA-mix, a large-scale benchmark aggregating 17 public ABSA datasets across 92 domains.",
      "authors": [
        "Paweł Liskowski",
        "Krzysztof Jankowski"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 13:58:29+00:00",
      "link": "https://arxiv.org/pdf/2601.03940v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03926v1",
      "title": "Doc-PP: Document Policy Preservation Benchmark for Large Vision-Language Models",
      "abstract": "The deployment of Large Vision-Language Models (LVLMs) for real-world document question answering is often constrained by dynamic, user-defined policies that dictate information disclosure based on context. While ensuring adherence to these explicit constraints is critical, existing safety research primarily focuses on implicit social norms or text-only settings, overlooking the complexities of multimodal documents. In this paper, we introduce Doc-PP (Document Policy Preservation Benchmark), a novel benchmark constructed from real-world reports requiring reasoning across heterogeneous visual and textual elements under strict non-disclosure policies. Our evaluation highlights a systemic Reasoning-Induced Safety Gap: models frequently leak sensitive information when answers must be inferred through complex synthesis or aggregated across modalities, effectively circumventing existing safety constraints. Furthermore, we identify that providing extracted text improves perception but inadvertently facilitates leakage. To address these vulnerabilities, we propose DVA (Decompose-Verify-Aggregation), a structural inference framework that decouples reasoning from policy verification. Experimental results demonstrate that DVA significantly outperforms standard prompting defenses, offering a robust baseline for policy-compliant document understanding",
      "authors": [
        "Haeun Jang",
        "Hwan Chang",
        "Hwanhee Lee"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 13:45:39+00:00",
      "link": "https://arxiv.org/pdf/2601.03926v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03924v1",
      "title": "A low-complexity method for efficient depth-guided image deblurring",
      "abstract": "Image deblurring is a challenging problem in imaging due to its highly ill-posed nature. Deep learning models have shown great success in tackling this problem but the quest for the best image quality has brought their computational complexity up, making them impractical on anything but powerful servers. Meanwhile, recent works have shown that mobile Lidars can provide complementary information in the form of depth maps that enhance deblurring quality. In this paper, we introduce a novel low-complexity neural network for depth-guided image deblurring. We show that the use of the wavelet transform to separate structural details and reduce spatial redundancy as well as efficient feature conditioning on the depth information are essential ingredients in developing a low-complexity model. Experimental results show competitive image quality against recent state-of-the-art models while reducing complexity by up to two orders of magnitude.",
      "authors": [
        "Ziyao Yi",
        "Diego Valsesia",
        "Tiziano Bianchi",
        "Enrico Magli"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "published": "2026-01-07 13:45:20+00:00",
      "link": "https://arxiv.org/pdf/2601.03924v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03919v2",
      "title": "A Gap Between Decision Trees and Neural Networks",
      "abstract": "We study when geometric simplicity of decision boundaries, used here as a notion of interpretability, can conflict with accurate approximation of axis-aligned decision trees by shallow neural networks. Decision trees induce rule-based, axis-aligned decision regions (finite unions of boxes), whereas shallow ReLU networks are typically trained as score models whose predictions are obtained by thresholding. We analyze the infinite-width, bounded-norm, single-hidden-layer ReLU class through the Radon total variation ($\\mathrm{R}\\mathrm{TV}$) seminorm, which controls the geometric complexity of level sets.   We first show that the hard tree indicator $1_A$ has infinite $\\mathrm{R}\\mathrm{TV}$. Moreover, two natural split-wise continuous surrogates--piecewise-linear ramp smoothing and sigmoidal (logistic) smoothing--also have infinite $\\mathrm{R}\\mathrm{TV}$ in dimensions $d>1$, while Gaussian convolution yields finite $\\mathrm{R}\\mathrm{TV}$ but with an explicit exponential dependence on $d$.   We then separate two goals that are often conflated: classification after thresholding (recovering the decision set) versus score learning (learning a calibrated score close to $1_A$). For classification, we construct a smooth barrier score $S_A$ with finite $\\mathrm{R}\\mathrm{TV}$ whose fixed threshold $τ=1$ exactly recovers the box. Under a mild tube-mass condition near $\\partial A$, we prove an $L_1(P)$ calibration bound that decays polynomially in a sharpness parameter, along with an explicit $\\mathrm{R}\\mathrm{TV}$ upper bound in terms of face measures. Experiments on synthetic unions of rectangles illustrate the resulting accuracy--complexity tradeoff and how threshold selection shifts where training lands along it.",
      "authors": [
        "Akash Kumar"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-01-07 13:40:30+00:00",
      "link": "https://arxiv.org/pdf/2601.03919v2",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03910v1",
      "title": "An Algebraic Representation Theorem for Linear GENEOs in Geometric Machine Learning",
      "abstract": "Geometric and Topological Deep Learning are rapidly growing research areas that enhance machine learning through the use of geometric and topological structures. Within this framework, Group Equivariant Non-Expansive Operators (GENEOs) have emerged as a powerful class of operators for encoding symmetries and designing efficient, interpretable neural architectures. Originally introduced in Topological Data Analysis, GENEOs have since found applications in Deep Learning as tools for constructing equivariant models with reduced parameter complexity. GENEOs provide a unifying framework bridging Geometric and Topological Deep Learning and include the operator computing persistence diagrams as a special case. Their theoretical foundations rely on group actions, equivariance, and compactness properties of operator spaces, grounding them in algebra and geometry while enabling both mathematical rigor and practical relevance. While a previous representation theorem characterized linear GENEOs acting on data of the same type, many real-world applications require operators between heterogeneous data spaces. In this work, we address this limitation by introducing a new representation theorem for linear GENEOs acting between different perception pairs, based on generalized T-permutant measures. Under mild assumptions on the data domains and group actions, our result provides a complete characterization of such operators. We also prove the compactness and convexity of the space of linear GENEOs. We further demonstrate the practical impact of this theory by applying the proposed framework to improve the performance of autoencoders, highlighting the relevance of GENEOs in modern machine learning applications.",
      "authors": [
        "Francesco Conti",
        "Patrizio Frosini",
        "Nicola Quercioli"
      ],
      "primary_category": "math.RT",
      "categories": [
        "math.RT",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-07 13:21:44+00:00",
      "link": "https://arxiv.org/pdf/2601.03910v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03908v1",
      "title": "Decide Then Retrieve: A Training-Free Framework with Uncertainty-Guided Triggering and Dual-Path Retrieval",
      "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating external knowledge, but existing approaches indiscriminately trigger retrieval and rely on single-path evidence construction, often introducing noise and limiting performance gains. In this work, we propose Decide Then Retrieve (DTR), a training-free framework that adaptively determines when retrieval is necessary and how external information should be selected. DTR leverages generation uncertainty to guide retrieval triggering and introduces a dual-path retrieval mechanism with adaptive information selection to better handle sparse and ambiguous queries. Extensive experiments across five open-domain QA benchmarks, multiple model scales, and different retrievers demonstrate that DTR consistently improves EM and F1 over standard RAG and strong retrieval-enhanced baselines, while reducing unnecessary retrievals. The code and data used in this paper are available at https://github.com/ChenWangHKU/DTR.",
      "authors": [
        "Wang Chen",
        "Guanqiang Qi",
        "Weikang Li",
        "Yang Li",
        "Deguo Xia",
        "Jizhou Huang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 13:20:59+00:00",
      "link": "https://arxiv.org/pdf/2601.03908v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03905v2",
      "title": "Current Agents Fail to Leverage World Model as Tool for Foresight",
      "abstract": "Agents built on vision-language models increasingly face tasks that demand anticipating future states rather than relying on short-horizon reasoning. Generative world models offer a promising remedy: agents could use them as external simulators to foresee outcomes before acting. This paper empirically examines whether current agents can leverage such world models as tools to enhance their cognition. Across diverse agentic and visual question answering tasks, we observe that some agents rarely invoke simulation (fewer than 1%), frequently misuse predicted rollouts (approximately 15%), and often exhibit inconsistent or even degraded performance (up to 5%) when simulation is available or enforced. Attribution analysis further indicates that the primary bottleneck lies in the agents' capacity to decide when to simulate, how to interpret predicted outcomes, and how to integrate foresight into downstream reasoning. These findings underscore the need for mechanisms that foster calibrated, strategic interaction with world models, paving the way toward more reliable anticipatory cognition in future agent systems.",
      "authors": [
        "Cheng Qian",
        "Emre Can Acikgoz",
        "Bingxuan Li",
        "Xiusi Chen",
        "Yuji Zhang",
        "Bingxiang He",
        "Qinyu Luo",
        "Dilek Hakkani-Tür",
        "Gokhan Tur",
        "Yunzhu Li",
        "Heng Ji"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-07 13:15:23+00:00",
      "link": "https://arxiv.org/pdf/2601.03905v2",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03895v1",
      "title": "Adaptive-Boundary-Clipping GRPO: Ensuring Bounded Ratios for Stable and Generalizable Training",
      "abstract": "Group Relative Policy Optimization (GRPO) has emerged as a popular algorithm for reinforcement learning with large language models (LLMs). However, upon analyzing its clipping mechanism, we argue that it is suboptimal in certain scenarios. With appropriate modifications, GRPO can be significantly enhanced to improve both flexibility and generalization. To this end, we propose Adaptive-Boundary-Clipping GRPO (ABC-GRPO), an asymmetric and adaptive refinement of the original GRPO framework. We demonstrate that ABC-GRPO achieves superior performance over standard GRPO on mathematical reasoning tasks using the Qwen3 LLMs. Moreover, ABC-GRPO maintains substantially higher entropy throughout training, thereby preserving the model's exploration capacity and mitigating premature convergence. The implementation code is available online to ease reproducibility https://github.com/chi2liu/ABC-GRPO.",
      "authors": [
        "Chi Liu",
        "Xin Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-07 13:04:52+00:00",
      "link": "https://arxiv.org/pdf/2601.03895v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03889v1",
      "title": "Spectral Manifold Regularization for Stable and Modular Routing in Deep MoE Architectures",
      "abstract": "Mixture of Experts (MoE) architectures enable efficient scaling of neural networks but suffer from expert collapse, where routing converges to a few dominant experts. This reduces model capacity and causes catastrophic interference during adaptation. We propose the Spectrally-Regularized Mixture of Experts (SR-MoE), which imposes geometric constraints on the routing manifold to enforce structural modularity. Our method uses dual regularization: spectral norm constraints bound routing function Lipschitz continuity, while stable rank penalties preserve high-dimensional feature diversity in expert selection. We evaluate SR-MoE across architectural scales and dataset complexities using modular one-shot adaptation tasks. Results show that traditional linear gating fails with increasing depth (accuracy drops up to 4.72% due to expert entanglement), while SR-MoE maintains structural integrity (mean interference -0.32%). Our spectral constraints facilitate positive knowledge transfer, enabling localized expert updates without global performance decay. SR-MoE provides a general solution for building high-capacity, modular networks capable of stable lifelong learning.",
      "authors": [
        "Ibrahim Delibasoglu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 12:59:37+00:00",
      "link": "https://arxiv.org/pdf/2601.03889v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03885v1",
      "title": "Local Interpolation via Low-Rank Tensor Trains",
      "abstract": "Tensor Train (TT) decompositions provide a powerful framework to compress grid-structured data, such as sampled function values, on regular Cartesian grids. Such high compression, in turn, enables efficient high-dimensional computations. Exact TT representations are only available for simple analytic functions. Furthermore, global polynomial or Fourier expansions typically yield TT-ranks that grow proportionally with the number of basis terms. State-of-the-art methods are often prohibitively expensive or fail to recover the underlying low-rank structure. We propose a low-rank TT interpolation framework that, given a TT describing a discrete (scalar-, vector-, or tensor-valued) function on a coarse regular grid with $n$ cores, constructs a finer-scale version of the same function represented by a TT with $n+m$ cores, where the last $m$ cores maintain constant rank. Our method guarantees a $\\ell^{2}$-norm error bound independent of the total number of cores, achieves exponential compression at fixed accuracy, and admits logarithmic complexity with respect of the number of grid points. We validate its performance through numerical experiments, including 1D, 2D, and 3D applications such as: 2D and 3D airfoil mask embeddings, image super-resolution, and synthetic noise fields such as 3D synthetic turbulence. In particular, we generate fractal noise fields directly in TT format with logarithmic complexity and memory. This work opens a path to scalable TT-native solvers with complex geometries and multiscale generative models, with implications from scientific simulation to imaging and real-time graphics.",
      "authors": [
        "Siddhartha E. Guzman",
        "Egor Tiunov",
        "Leandro Aolita"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA",
        "cs.GR"
      ],
      "published": "2026-01-07 12:54:06+00:00",
      "link": "https://arxiv.org/pdf/2601.03885v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03882v1",
      "title": "Feature-Aware One-Shot Federated Learning via Hierarchical Token Sequences",
      "abstract": "One-shot federated learning (OSFL) reduces the communication cost and privacy risks of iterative federated learning by constructing a global model with a single round of communication. However, most existing methods struggle to achieve robust performance on real-world domains such as medical imaging, or are inefficient when handling non-IID (Independent and Identically Distributed) data. To address these limitations, we introduce FALCON, a framework that enhances the effectiveness of OSFL over non-IID image data. The core idea of FALCON is to leverage the feature-aware hierarchical token sequences generation and knowledge distillation into OSFL. First, each client leverages a pretrained visual encoder with hierarchical scale encoding to compress images into hierarchical token sequences, which capture multi-scale semantics. Second, a multi-scale autoregressive transformer generator is used to model the distribution of these token sequences and generate the synthetic sequences. Third, clients upload the synthetic sequences along with the local classifier trained on the real token sequences to the server. Finally, the server incorporates knowledge distillation into global training to reduce reliance on precise distribution modeling. Experiments on medical and natural image datasets validate the effectiveness of FALCON in diverse non-IID scenarios, outperforming the best OSFL baselines by 9.58% in average accuracy.",
      "authors": [
        "Shudong Liu",
        "Hanwen Zhang",
        "Xiuling Wang",
        "Yuesheng Zhu",
        "Guibo Luo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 12:48:16+00:00",
      "link": "https://arxiv.org/pdf/2601.03882v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03878v1",
      "title": "Understanding Specification-Driven Code Generation with LLMs: An Empirical Study Design",
      "abstract": "Large Language Models (LLMs) are increasingly integrated into software development workflows, yet their behavior in structured, specification-driven processes remains poorly understood. This paper presents an empirical study design using CURRANTE, a Visual Studio Code extension that enables a human-in-the-loop workflow for LLM-assisted code generation. The tool guides developers through three sequential stages--Specification, Tests, and Function--allowing them to define requirements, generate and refine test suites, and produce functions that satisfy those tests. Participants will solve medium-difficulty problems from the LiveCodeBench dataset, while the tool records fine-grained interaction logs, effectiveness metrics (e.g., pass rate, all-pass completion), efficiency indicators (e.g., time-to-pass), and iteration behaviors. The study aims to analyze how human intervention in specification and test refinement influences the quality and dynamics of LLM-generated code. The results will provide empirical insights into the design of next-generation development environments that align human reasoning with model-driven code generation.",
      "authors": [
        "Giovanni Rosa",
        "David Moreno-Lumbreras",
        "Gregorio Robles",
        "Jesús M. González-Barahona"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-01-07 12:46:57+00:00",
      "link": "https://arxiv.org/pdf/2601.03878v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04279v1",
      "title": "Generation of synthetic delay time series for air transport applications",
      "abstract": "The generation of synthetic data is receiving increasing attention from the scientific community, thanks to its ability to solve problems like data scarcity and privacy, and is starting to find applications in air transport. We here tackle the problem of generating synthetic, yet realistic, time series of delays at airports, starting from large collections of operations in Europe and the US. We specifically compare three models, two of them based on state of the art Deep Learning algorithms, and one simplified Genetic Algorithm approach. We show how the latter can generate time series that are almost indistinguishable from real ones, while maintaining a high variability. We further validate the resulting time series in a problem of detecting delay propagations between airports. We finally make the synthetic data available to the scientific community.",
      "authors": [
        "Pau Esteve",
        "Massimiliano Zanin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 12:43:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04279v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04278v1",
      "title": "From Domains to Instances: Dual-Granularity Data Synthesis for LLM Unlearning",
      "abstract": "Although machine unlearning is essential for removing private, harmful, or copyrighted content from LLMs, current benchmarks often fail to faithfully represent the true \"forgetting scope\" learned by the model. We formalize two distinct unlearning granularities, domain-level and instance-level, and propose BiForget, an automated framework for synthesizing high-quality forget sets. Unlike prior work relying on external generators, BiForget exploits the target model per se to elicit data that matches its internal knowledge distribution through seed-guided and adversarial prompting. Our experiments across diverse benchmarks show that it achieves a superior balance of relevance, diversity, and efficiency. Quantitatively, in the Harry Potter domain, it improves relevance by ${\\sim}20$ and diversity by ${\\sim}$0.05 while halving the total data size compared to SOTAs. Ultimately, it facilitates more robust forgetting and better utility preservation, providing a more rigorous foundation for evaluating LLM unlearning.",
      "authors": [
        "Xiaoyu Xu",
        "Minxin Du",
        "Zitong Li",
        "Zi Liang",
        "Zhibiao Guo",
        "Shiyu Zhang",
        "Peizhao Hu",
        "Qingqing Ye",
        "Haibo Hu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "published": "2026-01-07 12:41:07+00:00",
      "link": "https://arxiv.org/pdf/2601.04278v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03875v1",
      "title": "Staged Voxel-Level Deep Reinforcement Learning for 3D Medical Image Segmentation with Noisy Annotations",
      "abstract": "Deep learning has achieved significant advancements in medical image segmentation. Currently, obtaining accurate segmentation outcomes is critically reliant on large-scale datasets with high-quality annotations. However, noisy annotations are frequently encountered owing to the complex morphological structures of organs in medical images and variations among different annotators, which can substantially limit the efficacy of segmentation models. Motivated by the fact that medical imaging annotator can correct labeling errors during segmentation based on prior knowledge, we propose an end-to-end Staged Voxel-Level Deep Reinforcement Learning (SVL-DRL) framework for robust medical image segmentation under noisy annotations. This framework employs a dynamic iterative update strategy to automatically mitigate the impact of erroneous labels without requiring manual intervention. The key advancements of SVL-DRL over existing works include: i) formulating noisy annotations as a voxel-dependent problem and addressing it through a novel staged reinforcement learning framework which guarantees robust model convergence; ii) incorporating a voxel-level asynchronous advantage actor-critic (vA3C) module that conceptualizes each voxel as an autonomous agent, which allows each agent to dynamically refine its own state representation during training, thereby directly mitigating the influence of erroneous labels; iii) designing a novel action space for the agents, along with a composite reward function that strategically combines the Dice value and a spatial continuity metric to significantly boost segmentation accuracy while maintain semantic integrity. Experiments on three public medical image datasets demonstrates State-of-The-Art (SoTA) performance under various experimental settings, with an average improvement of over 3\\% in both Dice and IoU scores.",
      "authors": [
        "Yuyang Fu",
        "Xiuzhen Guo",
        "Ji Shi"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "published": "2026-01-07 12:39:54+00:00",
      "link": "https://arxiv.org/pdf/2601.03875v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03872v1",
      "title": "Atlas: Orchestrating Heterogeneous Models and Tools for Multi-Domain Complex Reasoning",
      "abstract": "The integration of large language models (LLMs) with external tools has significantly expanded the capabilities of AI agents. However, as the diversity of both LLMs and tools increases, selecting the optimal model-tool combination becomes a high-dimensional optimization challenge. Existing approaches often rely on a single model or fixed tool-calling logic, failing to exploit the performance variations across heterogeneous model-tool pairs. In this paper, we present ATLAS (Adaptive Tool-LLM Alignment and Synergistic Invocation), a dual-path framework for dynamic tool usage in cross-domain complex reasoning. ATLAS operates via a dual-path approach: (1) \\textbf{training-free cluster-based routing} that exploits empirical priors for domain-specific alignment, and (2) \\textbf{RL-based multi-step routing} that explores autonomous trajectories for out-of-distribution generalization. Extensive experiments across 15 benchmarks demonstrate that our method outperforms closed-source models like GPT-4o, surpassing existing routing methods on both in-distribution (+10.1%) and out-of-distribution (+13.1%) tasks. Furthermore, our framework shows significant gains in visual reasoning by orchestrating specialized multi-modal tools.",
      "authors": [
        "Jinyang Wu",
        "Guocheng Zhai",
        "Ruihan Jin",
        "Jiahao Yuan",
        "Yuhao Shen",
        "Shuai Zhang",
        "Zhengqi Wen",
        "Jianhua Tao"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 12:38:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03872v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03869v1",
      "title": "Bayesian Monocular Depth Refinement via Neural Radiance Fields",
      "abstract": "Monocular depth estimation has applications in many fields, such as autonomous navigation and extended reality, making it an essential computer vision task. However, current methods often produce smooth depth maps that lack the fine geometric detail needed for accurate scene understanding. We propose MDENeRF, an iterative framework that refines monocular depth estimates using depth information from Neural Radiance Fields (NeRFs). MDENeRF consists of three components: (1) an initial monocular estimate for global structure, (2) a NeRF trained on perturbed viewpoints, with per-pixel uncertainty, and (3) Bayesian fusion of the noisy monocular and NeRF depths. We derive NeRF uncertainty from the volume rendering process to iteratively inject high-frequency fine details. Meanwhile, our monocular prior maintains global structure. We demonstrate superior performance on key metrics and experiments using indoor scenes from the SUN RGB-D dataset.",
      "authors": [
        "Arun Muthukkumar"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.GR",
        "cs.LG",
        "cs.RO"
      ],
      "published": "2026-01-07 12:32:39+00:00",
      "link": "https://arxiv.org/pdf/2601.03869v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03858v1",
      "title": "What Does Loss Optimization Actually Teach, If Anything? Knowledge Dynamics in Continual Pre-training of LLMs",
      "abstract": "Continual Pre-Training (CPT) is widely used for acquiring and updating factual knowledge in LLMs. This practice treats loss as a proxy for knowledge learning, while offering no grounding into how it changes during training. We study CPT as a knowledge learning process rather than a solely optimization problem. We construct a controlled, distribution-matched benchmark of factual documents and interleave diagnostic probes directly into the CPT loop, enabling epoch-level measurement of knowledge acquisition dynamics and changes in Out-Of-Domain (OOD) general skills (e.g., math). We further analyze how CPT reshapes knowledge circuits during training. Across three instruction-tuned LLMs and multiple CPT strategies, optimization and learning systematically diverge as loss decreases monotonically while factual learning is unstable and non-monotonic. Acquired facts are rarely consolidated, learning is strongly conditioned on prior exposure, and OOD performance degrades from early epochs. Circuit analysis reveals rapid reconfiguration of knowledge pathways across epochs, providing an explanation for narrow acquisition windows and systematic forgetting. These results show that loss optimization is misaligned with learning progress in CPT and motivate evaluation of stopping criteria based on task-level learning dynamics.",
      "authors": [
        "Seyed Mahed Mousavi",
        "Simone Alghisi",
        "Giuseppe Riccardi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 12:14:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03858v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04275v1",
      "title": "Shadow Unlearning: A Neuro-Semantic Approach to Fidelity-Preserving Faceless Forgetting in LLMs",
      "abstract": "Machine unlearning aims to selectively remove the influence of specific training samples to satisfy privacy regulations such as the GDPR's 'Right to be Forgotten'. However, many existing methods require access to the data being removed, exposing it to membership inference attacks and potential misuse of Personally Identifiable Information (PII). We address this critical challenge by proposing Shadow Unlearning, a novel paradigm of approximate unlearning, that performs machine unlearning on anonymized forget data without exposing PII. We further propose a novel privacy-preserving framework, Neuro-Semantic Projector Unlearning (NSPU) to achieve Shadow unlearning. To evaluate our method, we compile Multi-domain Fictitious Unlearning (MuFU) forget set across five diverse domains and introduce an evaluation stack to quantify the trade-off between knowledge retention and unlearning effectiveness. Experimental results on various LLMs show that NSPU achieves superior unlearning performance, preserves model utility, and enhances user privacy. Additionally, the proposed approach is at least 10 times more computationally efficient than standard unlearning approaches. Our findings foster a new direction for privacy-aware machine unlearning that balances data protection and model fidelity.",
      "authors": [
        "Dinesh Srivasthav P",
        "Ashok Urlana",
        "Rahul Mishra",
        "Bala Mallikarjunarao Garlapati",
        "Ponnurangam Kumaraguru"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-07 12:11:25+00:00",
      "link": "https://arxiv.org/pdf/2601.04275v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03847v1",
      "title": "xDNN(ASP): Explanation Generation System for Deep Neural Networks powered by Answer Set Programming",
      "abstract": "Explainable artificial intelligence (xAI) has gained significant attention in recent years. Among other things, explainablility for deep neural networks has been a topic of intensive research due to the meteoric rise in prominence of deep neural networks and their \"black-box\" nature. xAI approaches can be characterized along different dimensions such as their scope (global versus local explanations) or underlying methodologies (statistic-based versus rule-based strategies). Methods generating global explanations aim to provide reasoning process applicable to all possible output classes while local explanation methods focus only on a single, specific class. SHAP (SHapley Additive exPlanations), a well-known statistical technique, identifies important features of a network. Deep neural network rule extraction method constructs IF-THEN rules that link input conditions to a class. Another approach focuses on generating counterfactuals which help explain how small changes to an input can affect the model's predictions. However, these techniques primarily focus on the input-output relationship and thus neglect the structure of the network in explanation generation.   In this work, we propose xDNN(ASP), an explanation generation system for deep neural networks that provides global explanations. Given a neural network model and its training data, xDNN(ASP) extracts a logic program under answer set semantics that-in the ideal case-represents the trained model, i.e., answer sets of the extracted program correspond one-to-one to input-output pairs of the network. We demonstrate experimentally, using two synthetic datasets, that not only the extracted logic program maintains a high-level of accuracy in the prediction task, but it also provides valuable information for the understanding of the model such as the importance of features as well as the impact of hidden nodes on the prediction. The latter can be used as a guide for reducing the number of nodes used in hidden layers, i.e., providing a means for optimizing the network.",
      "authors": [
        "Ly Ly Trieu",
        "Tran Cao Son"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 12:08:00+00:00",
      "link": "https://arxiv.org/pdf/2601.03847v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03846v1",
      "title": "When Numbers Start Talking: Implicit Numerical Coordination Among LLM-Based Agents",
      "abstract": "LLMs-based agents increasingly operate in multi-agent environments where strategic interaction and coordination are required. While existing work has largely focused on individual agents or on interacting agents sharing explicit communication, less is known about how interacting agents coordinate implicitly. In particular, agents may engage in covert communication, relying on indirect or non-linguistic signals embedded in their actions rather than on explicit messages. This paper presents a game-theoretic study of covert communication in LLM-driven multi-agent systems. We analyse interactions across four canonical game-theoretic settings under different communication regimes, including explicit, restricted, and absent communication. Considering heterogeneous agent personalities and both one-shot and repeated games, we characterise when covert signals emerge and how they shape coordination and strategic outcomes.",
      "authors": [
        "Alessio Buscemi",
        "Daniele Proverbio",
        "Alessandro Di Stefano",
        "The Anh Han",
        "German Castignani",
        "Pietro Liò"
      ],
      "primary_category": "cs.MA",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "published": "2026-01-07 12:07:48+00:00",
      "link": "https://arxiv.org/pdf/2601.03846v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03845v1",
      "title": "Formally Explaining Decision Tree Models with Answer Set Programming",
      "abstract": "Decision tree models, including random forests and gradient-boosted decision trees, are widely used in machine learning due to their high predictive performance.  However, their complex structures often make them difficult to interpret, especially in safety-critical applications where model decisions require formal justification.  Recent work has demonstrated that logical and abductive explanations can be derived through automated reasoning techniques.  In this paper, we propose a method for generating various types of explanations, namely, sufficient, contrastive, majority, and tree-specific explanations, using Answer Set Programming (ASP).  Compared to SAT-based approaches, our ASP-based method offers greater flexibility in encoding user preferences and supports enumeration of all possible explanations.  We empirically evaluate the approach on a diverse set of datasets and demonstrate its effectiveness and limitations compared to existing methods.",
      "authors": [
        "Akihiro Takemura",
        "Masayuki Otani",
        "Katsumi Inoue"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "published": "2026-01-07 12:07:45+00:00",
      "link": "https://arxiv.org/pdf/2601.03845v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03839v1",
      "title": "Logic Tensor Network-Enhanced Generative Adversarial Network",
      "abstract": "In this paper, we introduce Logic Tensor Network-Enhanced Generative Adversarial Network (LTN-GAN), a novel framework that enhances Generative Adversarial Networks (GANs) by incorporating Logic Tensor Networks (LTNs) to enforce domain-specific logical constraints during the sample generation process. Although GANs have shown remarkable success in generating realistic data, they often lack mechanisms to incorporate prior knowledge or enforce logical consistency, limiting their applicability in domains requiring rule adherence. LTNs provide a principled way to integrate first-order logic with neural networks, enabling models to reason over and satisfy logical constraints. By combining the strengths of GANs for realistic data synthesis with LTNs for logical reasoning, we gain valuable insights into how logical constraints influence the generative process while improving both the diversity and logical consistency of the generated samples. We evaluate LTN-GAN across multiple datasets, including synthetic datasets (gaussian, grid, rings) and the MNIST dataset, demonstrating that our model significantly outperforms traditional GANs in terms of adherence to predefined logical constraints while maintaining the quality and diversity of generated samples. This work highlights the potential of neuro-symbolic approaches to enhance generative modeling in knowledge-intensive domains.",
      "authors": [
        "Nijesh Upreti",
        "Vaishak Belle"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "published": "2026-01-07 12:04:49+00:00",
      "link": "https://arxiv.org/pdf/2601.03839v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03823v1",
      "title": "Step Potential Advantage Estimation: Harnessing Intermediate Confidence and Correctness for Efficient Mathematical Reasoning",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) elicits long chain-of-thought reasoning in large language models (LLMs), but outcome-based rewards lead to coarse-grained advantage estimation. While existing approaches improve RLVR via token-level entropy or sequence-level length control, they lack a semantically grounded, step-level measure of reasoning progress. As a result, LLMs fail to distinguish necessary deduction from redundant verification: they may continue checking after reaching a correct solution and, in extreme cases, overturn a correct trajectory into an incorrect final answer. To remedy the lack of process supervision, we introduce a training-free probing mechanism that extracts intermediate confidence and correctness and combines them into a Step Potential signal that explicitly estimates the reasoning state at each step. Building on this signal, we propose Step Potential Advantage Estimation (SPAE), a fine-grained credit assignment method that amplifies potential gains, penalizes potential drops, and applies penalty after potential saturates to encourage timely termination. Experiments across multiple benchmarks show SPAE consistently improves accuracy while substantially reducing response length, outperforming strong RL baselines and recent efficient reasoning and token-level advantage estimation methods. The code is available at https://github.com/cii030/SPAE-RL.",
      "authors": [
        "Fei Wu",
        "Zhenrong Zhang",
        "Qikai Chang",
        "Jianshu Zhang",
        "Quan Liu",
        "Jun Du"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 11:36:01+00:00",
      "link": "https://arxiv.org/pdf/2601.03823v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03822v1",
      "title": "ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition",
      "abstract": "Large language models (LLMs) can achieve strong reasoning performance with sufficient computation, but they do not inherently know how much computation a task requires. We study budgeted inference-time reasoning for multiple tasks under a strict global token constraint and formalize it as a Ordered Stochastic Multiple-Choice Knapsack Problem(OS-MCKP). This perspective highlights a meta-cognitive requirement -- anticipating task difficulty, estimating return over investment (ROI), and allocating computation strategically. We propose ROI-Reasoning, a two-stage framework that endows LLMs with intrinsic, budget-aware rationality. In the first stage, Meta-Cognitive Fine-Tuning teaches models to predict reasoning cost and expected utility before generation, enabling explicit solve-or-skip decisions. Next, Rationality-Aware Reinforcement Learning optimizes sequential decision making under a hard token budget, allowing models to learn long-horizon allocation strategies. Across budgeted mathematical reasoning benchmarks, ROI-Reasoning consistently improves overall score while substantially reducing regret under tight computation budgets.",
      "authors": [
        "Muyang Zhao",
        "Qi Qi",
        "Hao Sun"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 11:30:55+00:00",
      "link": "https://arxiv.org/pdf/2601.03822v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04270v1",
      "title": "Predictable Gradient Manifolds in Deep Learning: Temporal Path-Length and Intrinsic Rank as a Complexity Regime",
      "abstract": "Deep learning optimization exhibits structure that is not captured by worst-case gradient bounds. Empirically, gradients along training trajectories are often temporally predictable and evolve within a low-dimensional subspace. In this work we formalize this observation through a measurable framework for predictable gradient manifolds.   We introduce two computable quantities: a prediction-based path length that measures how well gradients can be forecast from past information, and a predictable rank that quantifies the intrinsic temporal dimension of gradient increments. We show how classical online and nonconvex optimization guarantees can be restated so that convergence and regret depend explicitly on these quantities, rather than on worst-case variation.   Across convolutional networks, vision transformers, language models, and synthetic control tasks, we find that gradient trajectories are locally predictable and exhibit strong low-rank structure over time. These properties are stable across architectures and optimizers, and can be diagnosed directly from logged gradients using lightweight random projections.   Our results provide a unifying lens for understanding optimization dynamics in modern deep learning, reframing standard training as operating in a low-complexity temporal regime. This perspective suggests new directions for adaptive optimizers, rank-aware tracking, and prediction-based algorithm design grounded in measurable properties of real training runs.",
      "authors": [
        "Anherutowa Calvo"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 11:23:55+00:00",
      "link": "https://arxiv.org/pdf/2601.04270v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03812v1",
      "title": "AI Generated Text Detection",
      "abstract": "The rapid development of large language models has led to an increase in AI-generated text, with students increasingly using LLM-generated content as their own work, which violates academic integrity. This paper presents an evaluation of AI text detection methods, including both traditional machine learning models and transformer-based architectures. We utilize two datasets, HC3 and DAIGT v2, to build a unified benchmark and apply a topic-based data split to prevent information leakage. This approach ensures robust generalization across unseen domains. Our experiments show that TF-IDF logistic regression achieves a reasonable baseline accuracy of 82.87%. However, deep learning models outperform it. The BiLSTM classifier achieves an accuracy of 88.86%, while DistilBERT achieves a similar accuracy of 88.11% with the highest ROC-AUC score of 0.96, demonstrating the strongest overall performance. The results indicate that contextual semantic modeling is significantly superior to lexical features and highlight the importance of mitigating topic memorization through appropriate evaluation protocols. The limitations of this work are primarily related to dataset diversity and computational constraints. In future work, we plan to expand dataset diversity and utilize parameter-efficient fine-tuning methods such as LoRA. We also plan to explore smaller or distilled models and employ more efficient batching strategies and hardware-aware optimization.",
      "authors": [
        "Adilkhan Alikhanov",
        "Aidar Amangeldi",
        "Diar Demeubay",
        "Dilnaz Akhmetzhan",
        "Nurbek Moldakhmetov",
        "Omar Polat",
        "Galymzhan Zharas"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 11:18:10+00:00",
      "link": "https://arxiv.org/pdf/2601.03812v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03808v1",
      "title": "From Brute Force to Semantic Insight: Performance-Guided Data Transformation Design with LLMs",
      "abstract": "Large language models (LLMs) have achieved notable performance in code synthesis; however, data-aware augmentation remains a limiting factor, handled via heuristic design or brute-force approaches. We introduce a performance-aware, closed-loop solution in the NNGPT ecosystem of projects that enables LLMs to autonomously engineer optimal transformations by internalizing empirical performance cues. We fine-tune LLMs with Low-Rank Adaptation on a novel repository of more than 6,000 empirically evaluated PyTorch augmentation functions, each annotated solely by downstream model accuracy. Training uses pairwise performance ordering (better-worse transformations), enabling alignment through empirical feedback without reinforcement learning, reward models, or symbolic objectives. This reduces the need for exhaustive search, achieving up to 600x times fewer evaluated candidates than brute-force discovery while maintaining competitive peak accuracy and shifting generation from random synthesis to task-aligned design. Ablation studies show that structured Chain-of-Thought prompting introduces syntactic noise and degrades performance, whereas direct prompting ensures stable optimization in performance-critical code tasks. Qualitative and quantitative analyses demonstrate that the model internalizes semantic performance cues rather than memorizing syntax. These results show that LLMs can exhibit task-level reasoning through non-textual feedback loops, bypassing explicit symbolic rewards.",
      "authors": [
        "Usha Shrestha",
        "Dmitry Ignatov",
        "Radu Timofte"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "published": "2026-01-07 11:13:02+00:00",
      "link": "https://arxiv.org/pdf/2601.03808v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03807v1",
      "title": "Generational Replacement and Learning for High-Performing and Diverse Populations in Evolvable Robots",
      "abstract": "Evolutionary Robotics offers the possibility to design robots to solve a specific task automatically by optimizing their morphology and control together. However, this co-optimization of body and control is challenging, because controllers need some time to adapt to the evolving morphology - which may make it difficult for new and promising designs to enter the evolving population. A solution to this is to add intra-life learning, defined as an additional controller optimization loop, to each individual in the evolving population. A related problem is the lack of diversity often seen in evolving populations as evolution narrows the search down to a few promising designs too quickly. This problem can be mitigated by implementing full generational replacement, where offspring robots replace the whole population. This solution for increasing diversity usually comes at the cost of lower performance compared to using elitism. In this work, we show that combining such generational replacement with intra-life learning can increase diversity while retaining performance. We also highlight the importance of performance metrics when studying learning in morphologically evolving robots, showing that evaluating according to function evaluations versus according to generations of evolution can give different conclusions.",
      "authors": [
        "K. Ege de Bruin",
        "Kyrre Glette",
        "Kai Olav Ellefsen"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-07 11:11:57+00:00",
      "link": "https://arxiv.org/pdf/2601.03807v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03794v1",
      "title": "An Algorithmic Framework for Systematic Literature Reviews: A Case Study for Financial Narratives",
      "abstract": "This paper introduces an algorithmic framework for conducting systematic literature reviews (SLRs), designed to improve efficiency, reproducibility, and selection quality assessment in the literature review process. The proposed method integrates Natural Language Processing (NLP) techniques, clustering algorithms, and interpretability tools to automate and structure the selection and analysis of academic publications. The framework is applied to a case study focused on financial narratives, an emerging area in financial economics that examines how structured accounts of economic events, formed by the convergence of individual interpretations, influence market dynamics and asset prices. Drawing from the Scopus database of peer-reviewed literature, the review highlights research efforts to model financial narratives using various NLP techniques. Results reveal that while advances have been made, the conceptualization of financial narratives remains fragmented, often reduced to sentiment analysis, topic modeling, or their combination, without a unified theoretical framework. The findings underscore the value of more rigorous and dynamic narrative modeling approaches and demonstrate the effectiveness of the proposed algorithmic SLR methodology.",
      "authors": [
        "Gabin Taibi",
        "Joerg Osterrieder"
      ],
      "primary_category": "q-fin.GN",
      "categories": [
        "q-fin.GN",
        "cs.AI"
      ],
      "published": "2026-01-07 10:50:35+00:00",
      "link": "https://arxiv.org/pdf/2601.03794v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03786v1",
      "title": "Compact Example-Based Explanations for Language Models",
      "abstract": "Training data influence estimation methods quantify the contribution of training documents to a model's output, making them a promising source of information for example-based explanations. As humans cannot interpret thousands of documents, only a small subset of the training data can be presented as an explanation. Although the choice of which documents to include directly affects explanation quality, previous evaluations of such systems have largely ignored any selection strategies. To address this, we propose a novel selection relevance score, a retraining-free metric that quantifies how useful a set of examples is for explaining a model's output. We validate this score through fine-tuning experiments, confirming that it can predict whether a set of examples supports or undermines the model's predictions. Using this metric, we further show that common selection strategies often underperform random selection. Motivated by this finding, we propose a strategy that balances influence and representativeness, enabling better use of selection budgets than naively selecting the highest-ranking examples.",
      "authors": [
        "Loris Schoenegger",
        "Benjamin Roth"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "published": "2026-01-07 10:36:46+00:00",
      "link": "https://arxiv.org/pdf/2601.03786v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03781v1",
      "title": "MVP: Enhancing Video Large Language Models via Self-supervised Masked Video Prediction",
      "abstract": "Reinforcement learning based post-training paradigms for Video Large Language Models (VideoLLMs) have achieved significant success by optimizing for visual-semantic tasks such as captioning or VideoQA. However, while these approaches effectively enhance perception abilities, they primarily target holistic content understanding, often lacking explicit supervision for intrinsic temporal coherence and inter-frame correlations. This tendency limits the models' ability to capture intricate dynamics and fine-grained visual causality. To explicitly bridge this gap, we propose a novel post-training objective: Masked Video Prediction (MVP). By requiring the model to reconstruct a masked continuous segment from a set of challenging distractors, MVP forces the model to attend to the sequential logic and temporal context of events. To support scalable training, we introduce a scalable data synthesis pipeline capable of transforming arbitrary video corpora into MVP training samples, and further employ Group Relative Policy Optimization (GRPO) with a fine-grained reward function to enhance the model's understanding of video context and temporal properties. Comprehensive evaluations demonstrate that MVP enhances video reasoning capabilities by directly reinforcing temporal reasoning and causal understanding.",
      "authors": [
        "Xiaokun Sun",
        "Zezhong Wu",
        "Zewen Ding",
        "Linli Xu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 10:25:48+00:00",
      "link": "https://arxiv.org/pdf/2601.03781v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03776v1",
      "title": "Improving Compactness and Reducing Ambiguity of CFIRE Rule-Based Explanations",
      "abstract": "Models trained on tabular data are widely used in sensitive domains, increasing the demand for explanation methods to meet transparency needs. CFIRE is a recent algorithm in this domain that constructs compact surrogate rule models from local explanations. While effective, CFIRE may assign rules associated with different classes to the same sample, introducing ambiguity. We investigate this ambiguity and propose a post-hoc pruning strategy that removes rules with low contribution or conflicting coverage, yielding smaller and less ambiguous models while preserving fidelity. Experiments across multiple datasets confirm these improvements with minimal impact on predictive performance.",
      "authors": [
        "Sebastian Müller",
        "Tobias Schneider",
        "Ruben Kemna",
        "Vanessa Toborek"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 10:13:40+00:00",
      "link": "https://arxiv.org/pdf/2601.03776v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03769v2",
      "title": "EntroCoT: Enhancing Chain-of-Thought via Adaptive Entropy-Guided Segmentation",
      "abstract": "Chain-of-Thought (CoT) prompting has significantly enhanced the mathematical reasoning capabilities of Large Language Models. We find existing fine-tuning datasets frequently suffer from the \"answer right but reasoning wrong\" probelm, where correct final answers are derived from hallucinated, redundant, or logically invalid intermediate steps. This paper proposes EntroCoT, a unified framework for automatically identifying and refining low-quality CoT supervision traces. EntroCoT first proposes an entropy-based mechanism to segment the reasoning trace into multiple steps at uncertain junctures, and then introduces a Monte Carlo rollout-based mechanism to evaluate the marginal contribution of each step. By accurately filtering deceptive reasoning samples, EntroCoT constructs a high-quality dataset where every intermediate step in each reasoning trace facilitates the final answer. Extensive experiments on mathematical benchmarks demonstrate that fine-tuning on the subset constructed by EntroCoT consistently outperforms the baseslines of full-dataset supervision.",
      "authors": [
        "Zihang Li",
        "Yuhang Wang",
        "Yikun Zong",
        "Wenhan Yu",
        "Xiaokun Yuan",
        "Runhan Jiang",
        "Zirui Liu",
        "Tong Yang",
        "Arthur Jiang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 10:02:27+00:00",
      "link": "https://arxiv.org/pdf/2601.03769v2",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03764v1",
      "title": "Learning Shrinks the Hard Tail: Training-Dependent Inference Scaling in a Solvable Linear Model",
      "abstract": "We analyze neural scaling laws in a solvable model of last-layer fine-tuning where targets have intrinsic, instance-heterogeneous difficulty. In our Latent Instance Difficulty (LID) model, each input's target variance is governed by a latent ``precision'' drawn from a heavy-tailed distribution. While generalization loss recovers standard scaling laws, our main contribution connects this to inference. The pass@$k$ failure rate exhibits a power-law decay, $k^{-β_\\text{eff}}$, but the observed exponent $β_\\text{eff}$ is training-dependent. It grows with sample size $N$ before saturating at an intrinsic limit $β$ set by the difficulty distribution's tail. This coupling reveals that learning shrinks the ``hard tail'' of the error distribution: improvements in the model's generalization error steepen the pass@$k$ curve until irreducible target variance dominates. The LID model yields testable, closed-form predictions for this behavior, including a compute-allocation rule that favors training before saturation and inference attempts after. We validate these predictions in simulations and in two real-data proxies: CIFAR-10H (human-label variance) and a maths teacher-student distillation task.",
      "authors": [
        "Noam Levi"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.AI",
        "stat.ML"
      ],
      "published": "2026-01-07 10:00:17+00:00",
      "link": "https://arxiv.org/pdf/2601.03764v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03752v1",
      "title": "Evaluation of Multilingual LLMs Personalized Text Generation Capabilities Targeting Groups and Social-Media Platforms",
      "abstract": "Capabilities of large language models to generate multilingual coherent text have continuously enhanced in recent years, which opens concerns about their potential misuse. Previous research has shown that they can be misused for generation of personalized disinformation in multiple languages. It has also been observed that personalization negatively affects detectability of machine-generated texts; however, this has been studied in the English language only. In this work, we examine this phenomenon across 10 languages, while we focus not only on potential misuse of personalization capabilities, but also on potential benefits they offer. Overall, we cover 1080 combinations of various personalization aspects in the prompts, for which the texts are generated by 16 distinct language models (17,280 texts in total). Our results indicate that there are differences in personalization quality of the generated texts when targeting demographic groups and when targeting social-media platforms across languages. Personalization towards platforms affects detectability of the generated texts in a higher scale, especially in English, where the personalization quality is the highest.",
      "authors": [
        "Dominik Macko"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 09:43:13+00:00",
      "link": "https://arxiv.org/pdf/2601.03752v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03748v1",
      "title": "Bridging OLAP and RAG: A Multidimensional Approach to the Design of Corpus Partitioning",
      "abstract": "Retrieval-Augmented Generation (RAG) systems are increasingly deployed on large-scale document collections, often comprising millions of documents and tens of millions of text chunks. In industrial-scale retrieval platforms, scalability is typically addressed through horizontal sharding and a combination of Approximate Nearest-Neighbor search, hybrid indexing, and optimized metadata filtering. Although effective from an efficiency perspective, these mechanisms rely on bottom-up, similarity-driven organization and lack a conceptual rationale for corpus partitioning. In this paper, we claim that the design of large-scale RAG systems may benefit from the combination of two orthogonal strategies: semantic clustering, which optimizes locality in embedding space, and multidimensional partitioning, which governs where retrieval should occur based on conceptual dimensions such as time and organizational context. Although such dimensions are already implicitly present in current systems, they are used in an ad hoc and poorly structured manner. We propose the Dimensional Fact Model (DFM) as a conceptual framework to guide the design of multidimensional partitions for RAG corpora. The DFM provides a principled way to reason about facts, dimensions, hierarchies, and granularity in retrieval-oriented settings. This framework naturally supports hierarchical routing and controlled fallback strategies, ensuring that retrieval remains robust even in the presence of incomplete metadata, while transforming the search process from a 'black-box' similarity matching into a governable and deterministic workflow. This work is intended as a position paper; its goal is to bridge the gap between OLAP-style multidimensional modeling and modern RAG architectures, and to stimulate further research on principled, explainable, and governable retrieval strategies at scale.",
      "authors": [
        "Dario Maio",
        "Stefano Rizzi"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "published": "2026-01-07 09:37:36+00:00",
      "link": "https://arxiv.org/pdf/2601.03748v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03746v1",
      "title": "Whose Facts Win? LLM Source Preferences under Knowledge Conflicts",
      "abstract": "As large language models (LLMs) are more frequently used in retrieval-augmented generation pipelines, it is increasingly relevant to study their behavior under knowledge conflicts. Thus far, the role of the source of the retrieved information has gone unexamined. We address this gap with a novel framework to investigate how source preferences affect LLM resolution of inter-context knowledge conflicts in English, motivated by interdisciplinary research on credibility. With a comprehensive, tightly-controlled evaluation of 13 open-weight LLMs, we find that LLMs prefer institutionally-corroborated information (e.g., government or newspaper sources) over information from people and social media. However, these source preferences can be reversed by simply repeating information from less credible sources. To mitigate repetition effects and maintain consistent preferences, we propose a novel method that reduces repetition bias by up to 99.8%, while also maintaining at least 88.8% of original preferences. We release all data and code to encourage future work on credibility and source preferences in knowledge-intensive NLP.",
      "authors": [
        "Jakob Schuster",
        "Vagrant Gautam",
        "Katja Markert"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 09:35:35+00:00",
      "link": "https://arxiv.org/pdf/2601.03746v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03743v1",
      "title": "O-Researcher: An Open Ended Deep Research Model via Multi-Agent Distillation and Agentic RL",
      "abstract": "The performance gap between closed-source and open-source large language models (LLMs) is largely attributed to disparities in access to high-quality training data. To bridge this gap, we introduce a novel framework for the automated synthesis of sophisticated, research-grade instructional data. Our approach centers on a multi-agent workflow where collaborative AI agents simulate complex tool-integrated reasoning to generate diverse and high-fidelity data end-to-end. Leveraging this synthesized data, we develop a two-stage training strategy that integrates supervised fine-tuning with a novel reinforcement learning method, designed to maximize model alignment and capability. Extensive experiments demonstrate that our framework empowers open-source models across multiple scales, enabling them to achieve new state-of-the-art performance on the major deep research benchmark. This work provides a scalable and effective pathway for advancing open-source LLMs without relying on proprietary data or models.",
      "authors": [
        "Yi Yao",
        "He Zhu",
        "Piaohong Wang",
        "Jincheng Ren",
        "Xinlong Yang",
        "Qianben Chen",
        "Xiaowan Li",
        "Dingfeng Shi",
        "Jiaxian Li",
        "Qiexiang Wang",
        "Sinuo Wang",
        "Xinpeng Liu",
        "Jiaqi Wu",
        "Minghao Liu",
        "Wangchunshu Zhou"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 09:31:10+00:00",
      "link": "https://arxiv.org/pdf/2601.03743v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03731v1",
      "title": "From Laboratory to Real-World Applications: Benchmarking Agentic Code Reasoning at the Repository Level",
      "abstract": "As large language models (LLMs) evolve into autonomous agents, evaluating repository-level reasoning, the ability to maintain logical consistency across massive, real-world, interdependent file systems, has become critical. Current benchmarks typically fluctuate between isolated code snippets and black-box evaluations. We present RepoReason, a white-box diagnostic benchmark centered on abductive assertion verification. To eliminate memorization while preserving authentic logical depth, we implement an execution-driven mutation framework that utilizes the environment as a semantic oracle to regenerate ground-truth states. Furthermore, we establish a fine-grained diagnostic system using dynamic program slicing, quantifying reasoning via three orthogonal metrics: $ESV$ (reading load), $MCL$ (simulation depth), and $DFI$ (integration width). Comprehensive evaluations of frontier models (e.g., Claude-4.5-Sonnet, DeepSeek-v3.1-Terminus) reveal a prevalent aggregation deficit, where integration width serves as the primary cognitive bottleneck. Our findings provide granular white-box insights for optimizing the next generation of agentic software engineering.",
      "authors": [
        "Jia Li",
        "Yuxin Su",
        "Michael R. Lyu"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "published": "2026-01-07 09:22:28+00:00",
      "link": "https://arxiv.org/pdf/2601.03731v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03728v1",
      "title": "CSMCIR: CoT-Enhanced Symmetric Alignment with Memory Bank for Composed Image Retrieval",
      "abstract": "Composed Image Retrieval (CIR) enables users to search for target images using both a reference image and manipulation text, offering substantial advantages over single-modality retrieval systems. However, existing CIR methods suffer from representation space fragmentation: queries and targets comprise heterogeneous modalities and are processed by distinct encoders, forcing models to bridge misaligned representation spaces only through post-hoc alignment, which fundamentally limits retrieval performance. This architectural asymmetry manifests as three distinct, well-separated clusters in the feature space, directly demonstrating how heterogeneous modalities create fundamentally misaligned representation spaces from initialization. In this work, we propose CSMCIR, a unified representation framework that achieves efficient query-target alignment through three synergistic components. First, we introduce a Multi-level Chain-of-Thought (MCoT) prompting strategy that guides Multimodal Large Language Models to generate discriminative, semantically compatible captions for target images, establishing modal symmetry. Building upon this, we design a symmetric dual-tower architecture where both query and target sides utilize the identical shared-parameter Q-Former for cross-modal encoding, ensuring consistent feature representations and further reducing the alignment gap. Finally, this architectural symmetry enables an entropy-based, temporally dynamic Memory Bank strategy that provides high-quality negative samples while maintaining consistency with the evolving model state. Extensive experiments on four benchmark datasets demonstrate that our CSMCIR achieves state-of-the-art performance with superior training efficiency. Comprehensive ablation studies further validate the effectiveness of each proposed component.",
      "authors": [
        "Zhipeng Qian",
        "Zihan Liang",
        "Yufei Ma",
        "Ben Chen",
        "Huangyu Dai",
        "Yiwei Ma",
        "Jiayi Ji",
        "Chenyi Lei",
        "Han Li",
        "Xiaoshuai Sun"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 09:21:38+00:00",
      "link": "https://arxiv.org/pdf/2601.03728v1",
      "tags": [
        "keyword:resnet",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03725v1",
      "title": "EDCO: Dynamic Curriculum Orchestration for Domain-specific Large Language Model Fine-tuning",
      "abstract": "Domain-specific large language models (LLMs), typically developed by fine-tuning a pre-trained general-purpose LLM on specialized datasets, represent a significant advancement in applied AI. A common strategy in LLM fine-tuning is curriculum learning, which pre-orders training samples based on metrics like difficulty to improve learning efficiency compared to a random sampling strategy. However, most existing methods for LLM fine-tuning rely on a static curriculum, designed prior to training, which lacks adaptability to the model's evolving needs during fine-tuning. To address this, we propose EDCO, a novel framework based on two key concepts: inference entropy and dynamic curriculum orchestration. Inspired by recent findings that maintaining high answer entropy benefits long-term reasoning gains, EDCO prioritizes samples with high inference entropy in a continuously adapted curriculum. EDCO integrates three core components: an efficient entropy estimator that uses prefix tokens to approximate full-sequence entropy, an entropy-based curriculum generator that selects data points with the highest inference entropy, and an LLM trainer that optimizes the model on the selected curriculum. Comprehensive experiments in communication, medicine and law domains, EDCO outperforms traditional curriculum strategies for fine-tuning Qwen3-4B and Llama3.2-3B models under supervised and reinforcement learning settings. Furthermore, the proposed efficient entropy estimation reduces computational time by 83.5% while maintaining high accuracy.",
      "authors": [
        "Jing-Cheng Pang",
        "Liu Sun",
        "Chang Zhou",
        "Xian Tang",
        "Haichuan Ma",
        "Kun Jiang",
        "Jianlong Wang",
        "Kai Zhang",
        "Sijie Wu",
        "Haoran Cai",
        "Chenwei Wu",
        "Xubin Li",
        "Xin Chen"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 09:20:05+00:00",
      "link": "https://arxiv.org/pdf/2601.03725v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03723v1",
      "title": "ETR: Outcome-Guided Elastic Trust Regions for Policy Optimization",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an important paradigm for unlocking reasoning capabilities in large language models, exemplified by the success of OpenAI o1 and DeepSeek-R1. Currently, Group Relative Policy Optimization (GRPO) stands as the dominant algorithm in this domain due to its stable training and critic-free efficiency. However, we argue that GRPO suffers from a structural limitation: it imposes a uniform, static trust region constraint across all samples. This design implicitly assumes signal homogeneity, a premise misaligned with the heterogeneous nature of outcome-driven learning, where advantage magnitudes and variances fluctuate significantly. Consequently, static constraints fail to fully exploit high-quality signals while insufficiently suppressing noise, often precipitating rapid entropy collapse. To address this, we propose \\textbf{E}lastic \\textbf{T}rust \\textbf{R}egions (\\textbf{ETR}), a dynamic mechanism that aligns optimization constraints with signal quality. ETR constructs a signal-aware landscape through dual-level elasticity: at the micro level, it scales clipping boundaries based on advantage magnitude to accelerate learning from high-confidence paths; at the macro level, it leverages group variance to implicitly allocate larger update budgets to tasks in the optimal learning zone. Extensive experiments on AIME and MATH benchmarks demonstrate that ETR consistently outperforms GRPO, achieving superior accuracy while effectively mitigating policy entropy degradation to ensure sustained exploration.",
      "authors": [
        "Shijie Zhang",
        "Kevin Zhang",
        "Zheyuan Gu",
        "Xiang Guo",
        "Rujun Guo",
        "Shaoyu Liu",
        "Guanjun Jiang",
        "Xiaozhao Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 09:19:53+00:00",
      "link": "https://arxiv.org/pdf/2601.03723v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03715v1",
      "title": "R$^3$L: Reflect-then-Retry Reinforcement Learning with Language-Guided Exploration, Pivotal Credit, and Positive Amplification",
      "abstract": "Reinforcement learning drives recent advances in LLM reasoning and agentic capabilities, yet current approaches struggle with both exploration and exploitation. Exploration suffers from low success rates on difficult tasks and high costs of repeated rollouts from scratch. Exploitation suffers from coarse credit assignment and training instability: Trajectory-level rewards penalize valid prefixes for later errors, and failure-dominated groups overwhelm the few positive signals, leaving optimization without constructive direction. To this end, we propose R$^3$L, Reflect-then-Retry Reinforcement Learning with Language-Guided Exploration, Pivotal Credit, and Positive Amplification. To synthesize high-quality trajectories, R$^3$L shifts from stochastic sampling to active synthesis via reflect-then-retry, leveraging language feedback to diagnose errors, transform failed attempts into successful ones, and reduce rollout costs by restarting from identified failure points. With errors diagnosed and localized, Pivotal Credit Assignment updates only the diverging suffix where contrastive signals exist, excluding the shared prefix from gradient update. Since failures dominate on difficult tasks and reflect-then-retry produces off-policy data, risking training instability, Positive Amplification upweights successful trajectories to ensure positive signals guide the optimization process. Experiments on agentic and reasoning tasks demonstrate 5\\% to 52\\% relative improvements over baselines while maintaining training stability. Our code is released at https://github.com/shiweijiezero/R3L.",
      "authors": [
        "Weijie Shi",
        "Yanxi Chen",
        "Zexi Li",
        "Xuchen Pan",
        "Yuchang Sun",
        "Jiajie Xu",
        "Xiaofang Zhou",
        "Yaliang Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 09:04:52+00:00",
      "link": "https://arxiv.org/pdf/2601.03715v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03714v2",
      "title": "Visual Merit or Linguistic Crutch? A Close Look at DeepSeek-OCR",
      "abstract": "DeepSeek-OCR utilizes an optical 2D mapping approach to achieve high-ratio vision-text compression, claiming to decode text tokens exceeding ten times the input visual tokens. While this suggests a promising solution for the LLM long-context bottleneck, we investigate a critical question: \"Visual merit or linguistic crutch - which drives DeepSeek-OCR's performance?\" By employing sentence-level and word-level semantic corruption, we isolate the model's intrinsic OCR capabilities from its language priors. Results demonstrate that without linguistic support, DeepSeek-OCR's performance plummets from approximately 90% to 20%. Comparative benchmarking against 13 baseline models reveals that traditional pipeline OCR methods exhibit significantly higher robustness to such semantic perturbations than end-to-end methods. Furthermore, we find that lower visual token counts correlate with increased reliance on priors, exacerbating hallucination risks. Context stress testing also reveals a total model collapse around 10,000 text tokens, suggesting that current optical compression techniques may paradoxically aggravate the long-context bottleneck. This study empirically defines DeepSeek-OCR's capability boundaries and offers essential insights for future optimizations of the vision-text compression paradigm. We release all data, results and scripts used in this study at https://github.com/dududuck00/DeepSeekOCR.",
      "authors": [
        "Yunhao Liang",
        "Ruixuan Ying",
        "Bo Li",
        "Hong Li",
        "Kai Yan",
        "Qingwen Li",
        "Min Yang",
        "Okamoto Satoshi",
        "Zhe Cui",
        "Shiwen Ni"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.CV"
      ],
      "published": "2026-01-07 09:01:23+00:00",
      "link": "https://arxiv.org/pdf/2601.03714v2",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.04266v1",
      "title": "State Backdoor: Towards Stealthy Real-world Poisoning Attack on Vision-Language-Action Model in State Space",
      "abstract": "Vision-Language-Action (VLA) models are widely deployed in safety-critical embodied AI applications such as robotics. However, their complex multimodal interactions also expose new security vulnerabilities. In this paper, we investigate a backdoor threat in VLA models, where malicious inputs cause targeted misbehavior while preserving performance on clean data. Existing backdoor methods predominantly rely on inserting visible triggers into visual modality, which suffer from poor robustness and low insusceptibility in real-world settings due to environmental variability. To overcome these limitations, we introduce the State Backdoor, a novel and practical backdoor attack that leverages the robot arm's initial state as the trigger. To optimize trigger for insusceptibility and effectiveness, we design a Preference-guided Genetic Algorithm (PGA) that efficiently searches the state space for minimal yet potent triggers. Extensive experiments on five representative VLA models and five real-world tasks show that our method achieves over 90% attack success rate without affecting benign task performance, revealing an underexplored vulnerability in embodied AI systems.",
      "authors": [
        "Ji Guo",
        "Wenbo Jiang",
        "Yansong Lin",
        "Yijing Liu",
        "Ruichen Zhang",
        "Guomin Lu",
        "Aiguo Chen",
        "Xinshuo Han",
        "Hongwei Li",
        "Dusit Niyato"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "published": "2026-01-07 08:54:31+00:00",
      "link": "https://arxiv.org/pdf/2601.04266v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03703v1",
      "title": "TreeAdv: Tree-Structured Advantage Redistribution for Group-Based RL",
      "abstract": "Reinforcement learning with group-based objectives, such as Group Relative Policy Optimization (GRPO), is a common framework for aligning large language models on complex reasoning tasks. However, standard GRPO treats each rollout trajectory as an independent flat sequence and assigns a single sequence-level advantage to all tokens, which leads to sample inefficiency and a length bias toward verbose, redundant chains of thought without improving logical depth. We introduce TreeAdv (Tree-Structured Advantage Redistribution for Group-Based RL), which makes the tree structure of group rollouts explicit for both exploration and advantage assignment. Specifically, TreeAdv builds a group of trees (a forest) based on an entropy-driven sampling method where each tree branches at high-uncertainty decisions while sharing low-uncertainty tokens across rollouts. Then, TreeAdv aggregates token-level advantages for internal tree segments by redistributing the advantages of complete rollouts (all leaf nodes), and TreeAdv can easily apply to group-based objectives such as GRPO or GSPO. Across 10 math reasoning benchmarks, TreeAdv consistently outperforms GRPO and GSPO, while using substantially fewer generated tokens under identical supervision, data, and decoding budgets.",
      "authors": [
        "Lang Cao",
        "Hui Ruan",
        "Yongqian Li",
        "Peng Chao",
        "Wu Ning",
        "Haonan Song",
        "Renhong Chen",
        "Yitong Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 08:42:14+00:00",
      "link": "https://arxiv.org/pdf/2601.03703v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03699v1",
      "title": "RedBench: A Universal Dataset for Comprehensive Red Teaming of Large Language Models",
      "abstract": "As large language models (LLMs) become integral to safety-critical applications, ensuring their robustness against adversarial prompts is paramount. However, existing red teaming datasets suffer from inconsistent risk categorizations, limited domain coverage, and outdated evaluations, hindering systematic vulnerability assessments. To address these challenges, we introduce RedBench, a universal dataset aggregating 37 benchmark datasets from leading conferences and repositories, comprising 29,362 samples across attack and refusal prompts. RedBench employs a standardized taxonomy with 22 risk categories and 19 domains, enabling consistent and comprehensive evaluations of LLM vulnerabilities. We provide a detailed analysis of existing datasets, establish baselines for modern LLMs, and open-source the dataset and evaluation code. Our contributions facilitate robust comparisons, foster future research, and promote the development of secure and reliable LLMs for real-world deployment. Code: https://github.com/knoveleng/redeval",
      "authors": [
        "Quy-Anh Dang",
        "Chris Ngo",
        "Truong-Son Hy"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 08:34:17+00:00",
      "link": "https://arxiv.org/pdf/2601.03699v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03698v1",
      "title": "Evaluation Framework for AI Creativity: A Case Study Based on Story Generation",
      "abstract": "Evaluating creative text generation remains a challenge because existing reference-based metrics fail to capture the subjective nature of creativity. We propose a structured evaluation framework for AI story generation comprising four components (Novelty, Value, Adherence, and Resonance) and eleven sub-components. Using controlled story generation via ``Spike Prompting'' and a crowdsourced study of 115 readers, we examine how different creative components shape both immediate and reflective human creativity judgments. Our findings show that creativity is evaluated hierarchically rather than cumulatively, with different dimensions becoming salient at different stages of judgment, and that reflective evaluation substantially alters both ratings and inter-rater agreement. Together, these results support the effectiveness of our framework in revealing dimensions of creativity that are obscured by reference-based evaluation.",
      "authors": [
        "Pharath Sathya",
        "Yin Jou Huang",
        "Fei Cheng"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 08:31:08+00:00",
      "link": "https://arxiv.org/pdf/2601.03698v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03693v1",
      "title": "Can AI Chatbots Provide Coaching in Engineering? Beyond Information Processing Toward Mastery",
      "abstract": "Engineering education faces a double disruption: traditional apprenticeship models that cultivated judgment and tacit skill are eroding, just as generative AI emerges as an informal coaching partner. This convergence rekindles long-standing questions in the philosophy of AI and cognition about the limits of computation, the nature of embodied rationality, and the distinction between information processing and wisdom. Building on this rich intellectual tradition, this paper examines whether AI chatbots can provide coaching that fosters mastery rather than merely delivering information. We synthesize critical perspectives from decades of scholarship on expertise, tacit knowledge, and human-machine interaction, situating them within the context of contemporary AI-driven education. Empirically, we report findings from a mixed-methods study (N = 75 students, N = 7 faculty) exploring the use of a coaching chatbot in engineering education. Results reveal a consistent boundary: participants accept AI for technical problem solving (convergent tasks; M = 3.84 on a 1-5 Likert scale) but remain skeptical of its capacity for moral, emotional, and contextual judgment (divergent tasks). Faculty express stronger concerns over risk (M = 4.71 vs. M = 4.14, p = 0.003), and privacy emerges as a key requirement, with 64-71 percent of participants demanding strict confidentiality. Our findings suggest that while generative AI can democratize access to cognitive and procedural support, it cannot replicate the embodied, value-laden dimensions of human mentorship. We propose a multiplex coaching framework that integrates human wisdom within expert-in-the-loop models, preserving the depth of apprenticeship while leveraging AI scalability to enrich the next generation of engineering education.",
      "authors": [
        "Junaid Qadir",
        "Muhammad Adil Attique",
        "Saleha Shoaib",
        "Syed Ibrahim Ghaznavi"
      ],
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "published": "2026-01-07 08:28:47+00:00",
      "link": "https://arxiv.org/pdf/2601.03693v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03686v1",
      "title": "Dual-Attention Heterogeneous GNN for Multi-robot Collaborative Area Search via Deep Reinforcement Learning",
      "abstract": "In multi-robot collaborative area search, a key challenge is to dynamically balance the two objectives of exploring unknown areas and covering specific targets to be rescued. Existing methods are often constrained by homogeneous graph representations, thus failing to model and balance these distinct tasks. To address this problem, we propose a Dual-Attention Heterogeneous Graph Neural Network (DA-HGNN) trained using deep reinforcement learning. Our method constructs a heterogeneous graph that incorporates three entity types: robot nodes, frontier nodes, and interesting nodes, as well as their historical states. The dual-attention mechanism comprises the relational-aware attention and type-aware attention operations. The relational-aware attention captures the complex spatio-temporal relationships among robots and candidate goals. Building on this relational-aware heterogeneous graph, the type-aware attention separately computes the relevance between robots and each goal type (frontiers vs. points of interest), thereby decoupling the exploration and coverage from the unified tasks. Extensive experiments conducted in interactive 3D scenarios within the iGibson simulator, leveraging the Gibson and MatterPort3D datasets, validate the superior scalability and generalization capability of the proposed approach.",
      "authors": [
        "Lina Zhu",
        "Jiyu Cheng",
        "Yuehu Liu",
        "Wei Zhang"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-07 08:18:49+00:00",
      "link": "https://arxiv.org/pdf/2601.03686v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03683v1",
      "title": "Rethinking Recurrent Neural Networks for Time Series Forecasting: A Reinforced Recurrent Encoder with Prediction-Oriented Proximal Policy Optimization",
      "abstract": "Time series forecasting plays a crucial role in contemporary engineering information systems for supporting decision-making across various industries, where Recurrent Neural Networks (RNNs) have been widely adopted due to their capability in modeling sequential data. Conventional RNN-based predictors adopt an encoder-only strategy with sliding historical windows as inputs to forecast future values. However, this approach treats all time steps and hidden states equally without considering their distinct contributions to forecasting, leading to suboptimal performance. To address this limitation, we propose a novel Reinforced Recurrent Encoder with Prediction-oriented Proximal Policy Optimization, RRE-PPO4Pred, which significantly improves time series modeling capacity and forecasting accuracy of the RNN models. The core innovations of this method are: (1) A novel Reinforced Recurrent Encoder (RRE) framework that enhances RNNs by formulating their internal adaptation as a Markov Decision Process, creating a unified decision environment capable of learning input feature selection, hidden skip connection, and output target selection; (2) An improved Prediction-oriented Proximal Policy Optimization algorithm, termed PPO4Pred, which is equipped with a Transformer-based agent for temporal reasoning and develops a dynamic transition sampling strategy to enhance sampling efficiency; (3) A co-evolutionary optimization paradigm to facilitate the learning of the RNN predictor and the policy agent, providing adaptive and interactive time series modeling. Comprehensive evaluations on five real-world datasets indicate that our method consistently outperforms existing baselines, and attains accuracy better than state-of-the-art Transformer models, thus providing an advanced time series predictor in engineering informatics.",
      "authors": [
        "Xin Lai",
        "Shiming Deng",
        "Lu Yu",
        "Yumin Lai",
        "Shenghao Qiao",
        "Xinze Zhang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.NE"
      ],
      "published": "2026-01-07 08:16:55+00:00",
      "link": "https://arxiv.org/pdf/2601.03683v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03682v1",
      "title": "From Implicit to Explicit: Token-Efficient Logical Supervision for Mathematical Reasoning in LLMs",
      "abstract": "Recent studies reveal that large language models (LLMs) exhibit limited logical reasoning abilities in mathematical problem-solving, instead often relying on pattern-matching and memorization. We systematically analyze this limitation, focusing on logical relationship understanding, which is a core capability underlying genuine logical reasoning, and reveal that errors related to this capability account for over 90\\% of incorrect predictions, with Chain-of-Thought Supervised Fine-Tuning (CoT-SFT) failing to substantially reduce these errors. To address this bottleneck, we propose First-Step Logical Reasoning (FSLR), a lightweight training framework targeting logical relationship understanding. Our key insight is that the first planning step-identifying which variables to use and which operation to apply-encourages the model to derive logical relationships directly from the problem statement. By training models on this isolated step, FSLR provides explicit supervision for logical relationship understanding, unlike CoT-SFT which implicitly embeds such relationships within complete solution trajectories. Extensive experiments across multiple models and datasets demonstrate that FSLR consistently outperforms CoT-SFT under both in-distribution and out-of-distribution settings, with average improvements of 3.2\\% and 4.6\\%, respectively. Moreover, FSLR achieves 4-6x faster training and reduces training token consumption by over 80\\%.",
      "authors": [
        "Shaojie Wang",
        "Liang Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 08:15:01+00:00",
      "link": "https://arxiv.org/pdf/2601.03682v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03676v1",
      "title": "Towards Compositional Generalization of LLMs via Skill Taxonomy Guided Data Synthesis",
      "abstract": "Large Language Models (LLMs) and agent-based systems often struggle with compositional generalization due to a data bottleneck in which complex skill combinations follow a long-tailed, power-law distribution, limiting both instruction-following performance and generalization in agent-centric tasks. To address this challenge, we propose STEPS, a Skill Taxonomy guided Entropy-based Post-training data Synthesis framework for generating compositionally challenging data. STEPS explicitly targets compositional generalization by uncovering latent relationships among skills and organizing them into an interpretable, hierarchical skill taxonomy using structural information theory. Building on this taxonomy, we formulate data synthesis as a constrained information maximization problem, selecting skill combinations that maximize marginal structural information within the hierarchy while preserving semantic coherence. Experiments on challenging instruction-following benchmarks show that STEPS outperforms existing data synthesis baselines, while also yielding improved compositional generalization in downstream agent-based evaluations.",
      "authors": [
        "Yifan Wei",
        "Li Du",
        "Xiaoyan Yu",
        "Yang Feng",
        "Angsheng Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 07:58:51+00:00",
      "link": "https://arxiv.org/pdf/2601.03676v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03673v1",
      "title": "Disentangling Aleatoric and Epistemic Uncertainty in Physics-Informed Neural Networks. Application to Insulation Material Degradation Prognostics",
      "abstract": "Physics-Informed Neural Networks (PINNs) provide a framework for integrating physical laws with data. However, their application to Prognostics and Health Management (PHM) remains constrained by the limited uncertainty quantification (UQ) capabilities. Most existing PINN-based prognostics approaches are deterministic or account only for epistemic uncertainty, limiting their suitability for risk-aware decision-making. This work introduces a heteroscedastic Bayesian Physics-Informed Neural Network (B-PINN) framework that jointly models epistemic and aleatoric uncertainty, yielding full predictive posteriors for spatiotemporal insulation material ageing estimation. The approach integrates Bayesian Neural Networks (BNNs) with physics-based residual enforcement and prior distributions, enabling probabilistic inference within a physics-informed learning architecture. The framework is evaluated on transformer insulation ageing application, validated with a finite-element thermal model and field measurements from a solar power plant, and benchmarked against deterministic PINNs, dropout-based PINNs (d-PINNs), and alternative B-PINN variants. Results show that the proposed B-PINN provides improved predictive accuracy and better-calibrated uncertainty estimates than competing approaches. A systematic sensitivity study further analyzes the impact of boundary-condition, initial-condition, and residual sampling strategies on accuracy, calibration, and generalization. Overall, the findings highlight the potential of Bayesian physics-informed learning to support uncertainty-aware prognostics and informed decision-making in transformer asset management.",
      "authors": [
        "Ibai Ramirez",
        "Jokin Alcibar",
        "Joel Pino",
        "Mikel Sanz",
        "Jose I. Aizpurua"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 07:54:09+00:00",
      "link": "https://arxiv.org/pdf/2601.03673v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04264v1",
      "title": "MemKD: Memory-Discrepancy Knowledge Distillation for Efficient Time Series Classification",
      "abstract": "Deep learning models, particularly recurrent neural networks and their variants, such as long short-term memory, have significantly advanced time series data analysis. These models capture complex, sequential patterns in time series, enabling real-time assessments. However, their high computational complexity and large model sizes pose challenges for deployment in resource-constrained environments, such as wearable devices and edge computing platforms. Knowledge Distillation (KD) offers a solution by transferring knowledge from a large, complex model (teacher) to a smaller, more efficient model (student), thereby retaining high performance while reducing computational demands. Current KD methods, originally designed for computer vision tasks, neglect the unique temporal dependencies and memory retention characteristics of time series models. To this end, we propose a novel KD framework termed Memory-Discrepancy Knowledge Distillation (MemKD). MemKD leverages a specialized loss function to capture memory retention discrepancies between the teacher and student models across subsequences within time series data, ensuring that the student model effectively mimics the teacher model's behaviour. This approach facilitates the development of compact, high-performing recurrent neural networks suitable for real-time, time series analysis tasks. Our extensive experiments demonstrate that MemKD significantly outperforms state-of-the-art KD methods. It reduces parameter size and memory usage by approximately 500 times while maintaining comparable performance to the teacher model.",
      "authors": [
        "Nilushika Udayangani",
        "Kishor Nandakishor",
        "Marimuthu Palaniswami"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CE"
      ],
      "published": "2026-01-07 07:45:48+00:00",
      "link": "https://arxiv.org/pdf/2601.04264v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03669v1",
      "title": "eTracer: Towards Traceable Text Generation via Claim-Level Grounding",
      "abstract": "How can system-generated responses be efficiently verified, especially in the high-stakes biomedical domain? To address this challenge, we introduce eTracer, a plug-and-play framework that enables traceable text generation by grounding claims against contextual evidence. Through post-hoc grounding, each response claim is aligned with contextual evidence that either supports or contradicts it. Building on claim-level grounding results, eTracer not only enables users to precisely trace responses back to their contextual source but also quantifies response faithfulness, thereby enabling the verifiability and trustworthiness of generated responses. Experiments show that our claim-level grounding approach alleviates the limitations of conventional grounding methods in aligning generated statements with contextual sentence-level evidence, resulting in substantial improvements in overall grounding quality and user verification efficiency. The code and data are available at https://github.com/chubohao/eTracer.",
      "authors": [
        "Bohao Chu",
        "Qianli Wang",
        "Hendrik Damm",
        "Hui Wang",
        "Ula Muhabbek",
        "Elisabeth Livingstone",
        "Christoph M. Friedrich",
        "Norbert Fuhr"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 07:44:30+00:00",
      "link": "https://arxiv.org/pdf/2601.03669v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03665v1",
      "title": "PhysVideoGenerator: Towards Physically Aware Video Generation via Latent Physics Guidance",
      "abstract": "Current video generation models produce high-quality aesthetic videos but often struggle to learn representations of real-world physics dynamics, resulting in artifacts such as unnatural object collisions, inconsistent gravity, and temporal flickering. In this work, we propose PhysVideoGenerator, a proof-of-concept framework that explicitly embeds a learnable physics prior into the video generation process. We introduce a lightweight predictor network, PredictorP, which regresses high-level physical features extracted from a pre-trained Video Joint Embedding Predictive Architecture (V-JEPA 2) directly from noisy diffusion latents. These predicted physics tokens are injected into the temporal attention layers of a DiT-based generator (Latte) via a dedicated cross-attention mechanism. Our primary contribution is demonstrating the technical feasibility of this joint training paradigm: we show that diffusion latents contain sufficient information to recover V-JEPA 2 physical representations, and that multi-task optimization remains stable over training. This report documents the architectural design, technical challenges, and validation of training stability, establishing a foundation for future large-scale evaluation of physics-aware generative models.",
      "authors": [
        "Siddarth Nilol Kundur Satish",
        "Devesh Jaiswal",
        "Hongyu Chen",
        "Abhishek Bakshi"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 07:38:58+00:00",
      "link": "https://arxiv.org/pdf/2601.03665v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04263v1",
      "title": "Learning to Reason: Temporal Saliency Distillation for Interpretable Knowledge Transfer",
      "abstract": "Knowledge distillation has proven effective for model compression by transferring knowledge from a larger network called the teacher to a smaller network called the student. Current knowledge distillation in time series is predominantly based on logit and feature aligning techniques originally developed for computer vision tasks. These methods do not explicitly account for temporal data and fall short in two key aspects. First, the mechanisms by which the transferred knowledge helps the student model learning process remain unclear due to uninterpretability of logits and features. Second, these methods transfer only limited knowledge, primarily replicating the teacher predictive accuracy. As a result, student models often produce predictive distributions that differ significantly from those of their teachers, hindering their safe substitution for teacher models. In this work, we propose transferring interpretable knowledge by extending conventional logit transfer to convey not just the right prediction but also the right reasoning of the teacher. Specifically, we induce other useful knowledge from the teacher logits termed temporal saliency which captures the importance of each input timestep to the teacher prediction. By training the student with Temporal Saliency Distillation we encourage it to make predictions based on the same input features as the teacher. Temporal Saliency Distillation requires no additional parameters or architecture specific assumptions. We demonstrate that Temporal Saliency Distillation effectively improves the performance of baseline methods while also achieving desirable properties beyond predictive accuracy. We hope our work establishes a new paradigm for interpretable knowledge distillation in time series analysis.",
      "authors": [
        "Nilushika Udayangani Hewa Dehigahawattage",
        "Kishor Nandakishor",
        "Marimuthu Palaniswami"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 07:24:26+00:00",
      "link": "https://arxiv.org/pdf/2601.04263v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03661v1",
      "title": "AMIR-GRPO: Inducing Implicit Preference Signals into GRPO",
      "abstract": "Reinforcement learning has become the primary paradigm for aligning large language models (LLMs) on complex reasoning tasks, with group relative policy optimization (GRPO) widely used in large-scale post-training. However, GRPO faces structural limitations in reasoning-heavy settings: sequence-level advantage normalization introduces systematic length bias, penalties for low-quality trajectories are diluted, and the scalar objective discards rich pairwise preference information embedded in within-group reward rankings. As a result, valuable supervision from costly rollouts remains underutilized.   We propose AMIR-GRPO, which augments GRPO with an implicit DPO-style contrastive regularizer constructed directly from intra-group reward rankings, requiring no additional annotations. This mechanism amplifies suppression of low-reward trajectories, attenuates response-level length bias, and transforms each rollout group into a denser set of supervision constraints. Across multiple mathematical reasoning benchmarks, AMIR-GRPO consistently outperforms strong GRPO baselines, yields clearer separation between correct and incorrect reasoning chains, and delivers broader coverage gains beyond the subset of instances solved by standard GRPO.",
      "authors": [
        "Amir Hossein Yari",
        "Fajri Koto"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 07:22:58+00:00",
      "link": "https://arxiv.org/pdf/2601.03661v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03660v1",
      "title": "MGPC: Multimodal Network for Generalizable Point Cloud Completion With Modality Dropout and Progressive Decoding",
      "abstract": "Point cloud completion aims to recover complete 3D geometry from partial observations caused by limited viewpoints and occlusions. Existing learning-based works, including 3D Convolutional Neural Network (CNN)-based, point-based, and Transformer-based methods, have achieved strong performance on synthetic benchmarks. However, due to the limitations of modality, scalability, and generative capacity, their generalization to novel objects and real-world scenarios remains challenging. In this paper, we propose MGPC, a generalizable multimodal point cloud completion framework that integrates point clouds, RGB images, and text within a unified architecture. MGPC introduces an innovative modality dropout strategy, a Transformer-based fusion module, and a novel progressive generator to improve robustness, scalability, and geometric modeling capability. We further develop an automatic data generation pipeline and construct MGPC-1M, a large-scale benchmark with over 1,000 categories and one million training pairs. Extensive experiments on MGPC-1M and in-the-wild data demonstrate that the proposed method consistently outperforms prior baselines and exhibits strong generalization under real-world conditions.",
      "authors": [
        "Jiangyuan Liu",
        "Hongxuan Ma",
        "Yuhao Zhao",
        "Zhe Liu",
        "Jian Wang",
        "Wei Zou"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 07:16:46+00:00",
      "link": "https://arxiv.org/pdf/2601.03660v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03658v1",
      "title": "Group and Exclusive Sparse Regularization-based Continual Learning of CNNs",
      "abstract": "We present a regularization-based approach for continual learning (CL) of fixed capacity convolutional neural networks (CNN) that does not suffer from the problem of catastrophic forgetting when learning multiple tasks sequentially. This method referred to as Group and Exclusive Sparsity based Continual Learning (GESCL) avoids forgetting of previous tasks by ensuring the stability of the CNN via a stability regularization term, which prevents filters detected as important for past tasks to deviate too much when learning a new task. On top of that, GESCL makes the network plastic via a plasticity regularization term that leverage the over-parameterization of CNNs to efficiently sparsify the network and tunes unimportant filters making them relevant for future tasks. Doing so, GESCL deals with significantly less parameters and computation compared to CL approaches that either dynamically expand the network or memorize past tasks' data. Experiments on popular CL vision benchmarks show that GESCL leads to significant improvements over state-of-the-art method in terms of overall CL performance, as measured by classification accuracy as well as in terms of avoiding catastrophic forgetting.",
      "authors": [
        "Basile Tousside",
        "Janis Mohr",
        "Jörg Frochte"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 07:15:11+00:00",
      "link": "https://arxiv.org/pdf/2601.03658v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03657v1",
      "title": "In Search of Grandmother Cells: Tracing Interpretable Neurons in Tabular Representations",
      "abstract": "Foundation models are powerful yet often opaque in their decision-making. A topic of continued interest in both neuroscience and artificial intelligence is whether some neurons behave like grandmother cells, i.e., neurons that are inherently interpretable because they exclusively respond to single concepts. In this work, we propose two information-theoretic measures that quantify the neuronal saliency and selectivity for single concepts. We apply these metrics to the representations of TabPFN, a tabular foundation model, and perform a simple search across neuron-concept pairs to find the most salient and selective pair. Our analysis provides the first evidence that some neurons in such models show moderate, statistically significant saliency and selectivity for high-level concepts. These findings suggest that interpretable neurons can emerge naturally and that they can, in some cases, be identified without resorting to more complex interpretability techniques.",
      "authors": [
        "Ricardo Knauer",
        "Erik Rodner"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 07:13:01+00:00",
      "link": "https://arxiv.org/pdf/2601.03657v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03654v1",
      "title": "Quantum Classical Ridgelet Neural Network For Time Series Model",
      "abstract": "In this study, we present a quantum computing method that incorporates ridglet transforms into the quantum processing pipelines for time series data. Here, the Ridgelet neural network is integrated with a single-qubit quantum computing method, which improves feature extraction and forecasting capabilities. Furthermore, experimental results using financial time series data demonstrate the superior performance of our model compared to existing models.",
      "authors": [
        "Bahadur Yadav",
        "Sanjay Kumar Mohanty"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.OC",
        "math.QA"
      ],
      "published": "2026-01-07 07:05:34+00:00",
      "link": "https://arxiv.org/pdf/2601.03654v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03648v1",
      "title": "ELO: Efficient Layer-Specific Optimization for Continual Pretraining of Multilingual LLMs",
      "abstract": "We propose an efficient layer-specific optimization (ELO) method designed to enhance continual pretraining (CP) for specific languages in multilingual large language models (MLLMs). This approach addresses the common challenges of high computational cost and degradation of source language performance associated with traditional CP. The ELO method consists of two main stages: (1) ELO Pretraining, where a small subset of specific layers, identified in our experiments as the critically important first and last layers, are detached from the original MLLM and trained with the target language. This significantly reduces not only the number of trainable parameters but also the total parameters computed during the forward pass, minimizing GPU memory consumption and accelerating the training process. (2) Layer Alignment, where the newly trained layers are reintegrated into the original model, followed by a brief full fine-tuning step on a small dataset to align the parameters. Experimental results demonstrate that the ELO method achieves a training speedup of up to 6.46 times compared to existing methods, while improving target language performance by up to 6.2\\% on qualitative benchmarks and effectively preserving source language (English) capabilities.",
      "authors": [
        "HanGyeol Yoo",
        "ChangSu Choi",
        "Minjun Kim",
        "Seohyun Song",
        "SeungWoo Song",
        "Inho Won",
        "Jongyoul Park",
        "Cheoneum Park",
        "KyungTae Lim"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 06:55:29+00:00",
      "link": "https://arxiv.org/pdf/2601.03648v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03646v2",
      "title": "ReLA: Representation Learning and Aggregation for Job Scheduling with Reinforcement Learning",
      "abstract": "Job scheduling is widely used in real-world manufacturing systems to assign ordered job operations to machines under various constraints. Existing solutions remain limited by long running time or insufficient schedule quality, especially when problem scale increases. In this paper, we propose ReLA, a reinforcement-learning (RL) scheduler built on structured representation learning and aggregation. ReLA first learns diverse representations from scheduling entities, including job operations and machines, using two intra-entity learning modules with self-attention and convolution and one inter-entity learning module with cross-attention. These modules are applied in a multi-scale architecture, and their outputs are aggregated to support RL decision-making. Across experiments on small, medium, and large job instances, ReLA achieves the best makespan in most tested settings over the latest solutions. On non-large instances, ReLA reduces the optimality gap of the SOTA baseline by 13.0%, while on large-scale instances it reduces the gap by 78.6%, with the average optimality gaps lowered to 7.3% and 2.1%, respectively. These results confirm that ReLA's learned representations and aggregation provide strong decision support for RL scheduling, and enable fast job completion and decision-making for real-world applications.",
      "authors": [
        "Zhengyi Kwan",
        "Wei Zhang",
        "Aik Beng Ng",
        "Zhengkui Wang",
        "Simon See"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 06:50:56+00:00",
      "link": "https://arxiv.org/pdf/2601.03646v2",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03641v2",
      "title": "Agent-Dice: Disentangling Knowledge Updates via Geometric Consensus for Agent Continual Learning",
      "abstract": "Large Language Model (LLM)-based agents significantly extend the utility of LLMs by interacting with dynamic environments. However, enabling agents to continually learn new tasks without catastrophic forgetting remains a critical challenge, known as the stability-plasticity dilemma. In this work, we argue that this dilemma fundamentally arises from the failure to explicitly distinguish between common knowledge shared across tasks and conflicting knowledge introduced by task-specific interference. To address this, we propose Agent-Dice, a parameter fusion framework based on directional consensus evaluation. Concretely, Agent-Dice disentangles knowledge updates through a two-stage process: geometric consensus filtering to prune conflicting gradients, and curvature-based importance weighting to amplify shared semantics. We provide a rigorous theoretical analysis that establishes the validity of the proposed fusion scheme and offers insight into the origins of the stability-plasticity dilemma. Extensive experiments on GUI agents and tool-use agent domains demonstrate that Agent-Dice exhibits outstanding continual learning performance with minimal computational overhead and parameter updates. The codes are available at https://github.com/Wuzheng02/Agent-Dice.",
      "authors": [
        "Zheng Wu",
        "Xingyu Lou",
        "Xinbei Ma",
        "Yansi Li",
        "Weiwen Liu",
        "Weinan Zhang",
        "Jun Wang",
        "Zhuosheng Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 06:43:50+00:00",
      "link": "https://arxiv.org/pdf/2601.03641v2",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03634v1",
      "title": "Kantorovich-Type Stochastic Neural Network Operators for the Mean-Square Approximation of Certain Second-Order Stochastic Processes",
      "abstract": "Artificial neural network operators (ANNOs) have been widely used for approximating deterministic input-output functions; however, their extension to random dynamics remains comparatively unexplored. In this paper, we construct a new class of \\textbf{Kantorovich-type Stochastic Neural Network Operators (K-SNNOs)} in which randomness is incorporated not at the coefficient level, but through \\textbf{stochastic neurons} driven by stochastic integrators. This framework enables the operator to inherit the probabilistic structure of the underlying process, making it suitable for modeling and approximating stochastic signals. We establish mean-square convergence of K-SNNOs to the target stochastic process and derive quantitative error estimates expressing the rate of approximation in terms of the modulus of continuity. Numerical simulations further validate the theoretical results by demonstrating accurate reconstruction of sample paths and rapid decay of the mean square error (MSE). Graphical results, including sample-wise approximations and empirical MSE behaviour, illustrate the robustness and effectiveness of the proposed stochastic-neuron-based operator.",
      "authors": [
        "Sachin Saini",
        "Uaday Singh"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "math.PR"
      ],
      "published": "2026-01-07 06:25:40+00:00",
      "link": "https://arxiv.org/pdf/2601.03634v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03629v1",
      "title": "Learning Shortest Paths When Data is Scarce",
      "abstract": "Digital twins and other simulators are increasingly used to support routing decisions in large-scale networks. However, simulator outputs often exhibit systematic bias, while ground-truth measurements are costly and scarce. We study a stochastic shortest-path problem in which a planner has access to abundant synthetic samples, limited real-world observations, and an edge-similarity structure capturing expected behavioral similarity across links. We model the simulator-to-reality discrepancy as an unknown, edge-specific bias that varies smoothly over the similarity graph, and estimate it using Laplacian-regularized least squares. This approach yields calibrated edge cost estimates even in data-scarce regimes. We establish finite-sample error bounds, translate estimation error into path-level suboptimality guarantees, and propose a computable, data-driven certificate that verifies near-optimality of a candidate route. For cold-start settings without initial real data, we develop a bias-aware active learning algorithm that leverages the simulator and adaptively selects edges to measure until a prescribed accuracy is met. Numerical experiments on multiple road networks and traffic graphs further demonstrate the effectiveness of our methods.",
      "authors": [
        "Dmytro Matsypura",
        "Yu Pan",
        "Hanzhao Wang"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 06:19:04+00:00",
      "link": "https://arxiv.org/pdf/2601.03629v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03624v1",
      "title": "Architecting Agentic Communities using Design Patterns",
      "abstract": "The rapid evolution of Large Language Models (LLM) and subsequent Agentic AI technologies requires systematic architectural guidance for building sophisticated, production-grade systems. This paper presents an approach for architecting such systems using design patterns derived from enterprise distributed systems standards, formal methods, and industry practice. We classify these patterns into three tiers: LLM Agents (task-specific automation), Agentic AI (adaptive goal-seekers), and Agentic Communities (organizational frameworks where AI agents and human participants coordinate through formal roles, protocols, and governance structures). We focus on Agentic Communities - coordination frameworks encompassing LLM Agents, Agentic AI entities, and humans - most relevant for enterprise and industrial applications. Drawing on established coordination principles from distributed systems, we ground these patterns in a formal framework that specifies collaboration agreements where AI agents and humans fill roles within governed ecosystems. This approach provides both practical guidance and formal verification capabilities, enabling expression of organizational, legal, and ethical rules through accountability mechanisms that ensure operational and verifiable governance of inter-agent communication, negotiation, and intent modeling. We validate this framework through a clinical trial matching case study. Our goal is to provide actionable guidance to practitioners while maintaining the formal rigor essential for enterprise deployment in dynamic, multi-agent ecosystems.",
      "authors": [
        "Zoran Milosevic",
        "Fethi Rabhi"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 06:10:07+00:00",
      "link": "https://arxiv.org/pdf/2601.03624v1",
      "tags": [
        "keyword:RL",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03621v1",
      "title": "On the Robustness of Fairness Practices: A Causal Framework for Systematic Evaluation",
      "abstract": "Machine learning (ML) algorithms are increasingly deployed to make critical decisions in socioeconomic applications such as finance, criminal justice, and autonomous driving. However, due to their data-driven and pattern-seeking nature, ML algorithms may develop decision logic that disproportionately distributes opportunities, benefits, resources, or information among different population groups, potentially harming marginalized communities. In response to such fairness concerns, the software engineering and ML communities have made significant efforts to establish the best practices for creating fair ML software. These include fairness interventions for training ML models, such as including sensitive features, selecting non-sensitive attributes, and applying bias mitigators. But how reliably can software professionals tasked with developing data-driven systems depend on these recommendations? And how well do these practices generalize in the presence of faulty labels, missing data, or distribution shifts? These questions form the core theme of this paper.",
      "authors": [
        "Verya Monjezi",
        "Ashish Kumar",
        "Ashutosh Trivedi",
        "Gang Tan",
        "Saeid Tizpaz-Niari"
      ],
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "published": "2026-01-07 06:02:53+00:00",
      "link": "https://arxiv.org/pdf/2601.03621v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03618v1",
      "title": "The Pneuma Project: Reifying Information Needs as Relational Schemas to Automate Discovery, Guide Preparation, and Align Data with Intent",
      "abstract": "Data discovery and preparation remain persistent bottlenecks in the data management lifecycle, especially when user intent is vague, evolving, or difficult to operationalize. The Pneuma Project introduces Pneuma-Seeker, a system that helps users articulate and fulfill information needs through iterative interaction with a language model-powered platform. The system reifies the user's evolving information need as a relational data model and incrementally converges toward a usable document aligned with that intent. To achieve this, the system combines three architectural ideas: context specialization to reduce LLM burden across subtasks, a conductor-style planner to assemble dynamic execution plans, and a convergence mechanism based on shared state. The system integrates recent advances in retrieval-augmented generation (RAG), agentic frameworks, and structured data preparation to support semi-automatic, language-guided workflows. We evaluate the system through LLM-based user simulations and show that it helps surface latent intent, guide discovery, and produce fit-for-purpose documents. It also acts as an emergent documentation layer, capturing institutional knowledge and supporting organizational memory.",
      "authors": [
        "Muhammad Imam Luthfi Balaka",
        "Raul Castro Fernandez"
      ],
      "primary_category": "cs.DB",
      "categories": [
        "cs.DB"
      ],
      "published": "2026-01-07 05:58:54+00:00",
      "link": "https://arxiv.org/pdf/2601.03618v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03617v1",
      "title": "Systematic Evaluation of Depth Backbones and Semantic Cues for Monocular Pseudo-LiDAR 3D Detection",
      "abstract": "Monocular 3D object detection offers a low-cost alternative to LiDAR, yet remains less accurate due to the difficulty of estimating metric depth from a single image. We systematically evaluate how depth backbones and feature engineering affect a monocular Pseudo-LiDAR pipeline on the KITTI validation split. Specifically, we compare NeWCRFs (supervised metric depth) against Depth Anything V2 Metric-Outdoor (Base) under an identical pseudo-LiDAR generation and PointRCNN detection protocol. NeWCRFs yields stronger downstream 3D detection, achieving 10.50\\% AP$_{3D}$ at IoU$=0.7$ on the Moderate split using grayscale intensity (Exp~2). We further test point-cloud augmentations using appearance cues (grayscale intensity) and semantic cues (instance segmentation confidence). Contrary to the expectation that semantics would substantially close the gap, these features provide only marginal gains, and mask-based sampling can degrade performance by removing contextual geometry. Finally, we report a depth-accuracy-versus-distance diagnostic using ground-truth 2D boxes (including Ped/Cyc), highlighting that coarse depth correctness does not fully predict strict 3D IoU. Overall, under an off-the-shelf LiDAR detector, depth-backbone choice and geometric fidelity dominate performance, outweighing secondary feature injection.",
      "authors": [
        "Samson Oseiwe Ajadalu"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "published": "2026-01-07 05:57:19+00:00",
      "link": "https://arxiv.org/pdf/2601.03617v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03607v1",
      "title": "Locomotion Beyond Feet",
      "abstract": "Most locomotion methods for humanoid robots focus on leg-based gaits, yet natural bipeds frequently rely on hands, knees, and elbows to establish additional contacts for stability and support in complex environments. This paper introduces Locomotion Beyond Feet, a comprehensive system for whole-body humanoid locomotion across extremely challenging terrains, including low-clearance spaces under chairs, knee-high walls, knee-high platforms, and steep ascending and descending stairs. Our approach addresses two key challenges: contact-rich motion planning and generalization across diverse terrains. To this end, we combine physics-grounded keyframe animation with reinforcement learning. Keyframes encode human knowledge of motor skills, are embodiment-specific, and can be readily validated in simulation or on hardware, while reinforcement learning transforms these references into robust, physically accurate motions. We further employ a hierarchical framework consisting of terrain-specific motion-tracking policies, failure recovery mechanisms, and a vision-based skill planner. Real-world experiments demonstrate that Locomotion Beyond Feet achieves robust whole-body locomotion and generalizes across obstacle sizes, obstacle instances, and terrain sequences.",
      "authors": [
        "Tae Hoon Yang",
        "Haochen Shi",
        "Jiacheng Hu",
        "Zhicong Zhang",
        "Daniel Jiang",
        "Weizhuo Wang",
        "Yao He",
        "Zhen Wu",
        "Yuming Chen",
        "Yifan Hou",
        "Monroe Kennedy",
        "Shuran Song",
        "C. Karen Liu"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-07 05:36:39+00:00",
      "link": "https://arxiv.org/pdf/2601.03607v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03606v1",
      "title": "Policy-Guided Search on Tree-of-Thoughts for Efficient Problem Solving with Bounded Language Model Queries",
      "abstract": "Recent studies explored integrating state-space search algorithms with Language Models (LM) to perform look-ahead on the token generation process, the ''Tree-of-Thoughts'' (ToT), generated by LMs, thereby improving performance on problem-solving tasks. However, the affiliated search algorithms often overlook the significant computational costs associated with LM inference, particularly in scenarios with constrained computational budgets. Consequently, we address the problem of improving LM performance on problem-solving tasks under limited computational budgets. We demonstrate how the probabilities assigned to thoughts by LMs can serve as a heuristic to guide search within the ToT framework, thereby reducing the number of thought evaluations. Building on this insight, we adapt a heuristic search algorithm, Levin Tree Search (LTS), to the ToT framework, which leverages LMs as policies to guide the tree exploration efficiently. We extend the theoretical results of LTS by showing that, for ToT (a pruned tree), LTS guarantees a bound on the number of states expanded, and consequently, on the number of thoughts generated. Additionally, we analyze the sensitivity of this bound to the temperature values commonly used in the final softmax layer of the LM. Empirical evaluation under a fixed LM query budget demonstrates that LTS consistently achieves comparable or higher accuracy than baseline search algorithms within the ToT framework, across three domains (Blocksworld, PrOntoQA, Array Sorting) and four distinct LMs. These findings highlight the efficacy of LTS on ToT, particularly in enabling cost-effective and time-efficient problem-solving, making it well-suited for latency-critical and resource-constrained applications.",
      "authors": [
        "Sumedh Pendurkar",
        "Guni Sharon"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 05:35:16+00:00",
      "link": "https://arxiv.org/pdf/2601.03606v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03605v1",
      "title": "DiVA: Fine-grained Factuality Verification with Agentic-Discriminative Verifier",
      "abstract": "Despite the significant advancements of Large Language Models (LLMs), their factuality remains a critical challenge, fueling growing interest in factuality verification. Existing research on factuality verification primarily conducts binary judgments (e.g., correct or incorrect), which fails to distinguish varying degrees of error severity. This limits its utility for applications such as fine-grained evaluation and preference optimization. To bridge this gap, we propose the Agentic Discriminative Verifier (DiVA), a hybrid framework that synergizes the agentic search capabilities of generative models with the precise scoring aptitude of discriminative models. We also construct a new benchmark, FGVeriBench, as a robust testbed for fine-grained factuality verification. Experimental results on FGVeriBench demonstrate that our DiVA significantly outperforms existing methods on factuality verification for both general and multi-hop questions.",
      "authors": [
        "Hui Huang",
        "Muyun Yang",
        "Yuki Arase"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 05:35:01+00:00",
      "link": "https://arxiv.org/pdf/2601.03605v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03597v1",
      "title": "From Chains to Graphs: Self-Structured Reasoning for General-Domain LLMs",
      "abstract": "Large Language Models (LLMs) show strong reasoning ability in open-domain question answering, yet their reasoning processes are typically linear and often logically inconsistent. In contrast, real-world reasoning requires integrating multiple premises and solving subproblems in parallel. Existing methods, such as Chain-of-Thought (CoT), express reasoning in a linear textual form, which may appear coherent but frequently leads to inconsistent conclusions. Recent approaches rely on externally provided graphs and do not explore how LLMs can construct and use their own graph-structured reasoning, particularly in open-domain QA. To fill this gap, we novelly explore graph-structured reasoning of LLMs in general-domain question answering. We propose Self-Graph Reasoning (SGR), a framework that enables LLMs to explicitly represent their reasoning process as a structured graph before producing the final answer. We further construct a graph-structured reasoning dataset that merges multiple candidate reasoning graphs into refined graph structures for model training. Experiments on five QA benchmarks across both general and specialized domains show that SGR consistently improves reasoning consistency and yields a 17.74% gain over the base model. The LLaMA-3.3-70B model fine-tuned with SGR performs comparably to GPT-4o and surpasses Claude-3.5-Haiku, demonstrating the effectiveness of graph-structured reasoning.",
      "authors": [
        "Yingjian Chen",
        "Haoran Liu",
        "Yinhong Liu",
        "Sherry T. Tong",
        "Aosong Feng",
        "Jinghui Lu",
        "Juntao Zhang",
        "Yusuke Iwasawa",
        "Yutaka Matsuo",
        "Irene Li"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 05:27:41+00:00",
      "link": "https://arxiv.org/pdf/2601.03597v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03596v1",
      "title": "Adaptive Attention Distillation for Robust Few-Shot Segmentation under Environmental Perturbations",
      "abstract": "Few-shot segmentation (FSS) aims to rapidly learn novel class concepts from limited examples to segment specific targets in unseen images, and has been widely applied in areas such as medical diagnosis and industrial inspection. However, existing studies largely overlook the complex environmental factors encountered in real world scenarios-such as illumination, background, and camera viewpoint-which can substantially increase the difficulty of test images. As a result, models trained under laboratory conditions often fall short of practical deployment requirements. To bridge this gap, in this paper, an environment-robust FSS setting is introduced that explicitly incorporates challenging test cases arising from complex environments-such as motion blur, small objects, and camouflaged targets-to enhance model's robustness under realistic, dynamic conditions. An environment robust FSS benchmark (ER-FSS) is established, covering eight datasets across multiple real world scenarios. In addition, an Adaptive Attention Distillation (AAD) method is proposed, which repeatedly contrasts and distills key shared semantics between known (support) and unknown (query) images to derive class-specific attention for novel categories. This strengthens the model's ability to focus on the correct targets in complex environments, thereby improving environmental robustness. Comparative experiments show that AAD improves mIoU by 3.3% - 8.5% across all datasets and settings, demonstrating superior performance and strong generalization. The source code and dataset are available at: https://github.com/guoqianyu-alberta/Adaptive-Attention-Distillation-for-FSS.",
      "authors": [
        "Qianyu Guo",
        "Jingrong Wu",
        "Jieji Ren",
        "Weifeng Ge",
        "Wenqiang Zhang"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 05:27:12+00:00",
      "link": "https://arxiv.org/pdf/2601.03596v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03595v1",
      "title": "Controllable LLM Reasoning via Sparse Autoencoder-Based Steering",
      "abstract": "Large Reasoning Models (LRMs) exhibit human-like cognitive reasoning strategies (e.g. backtracking, cross-verification) during reasoning process, which improves their performance on complex tasks. Currently, reasoning strategies are autonomously selected by LRMs themselves. However, such autonomous selection often produces inefficient or even erroneous reasoning paths. To make reasoning more reliable and flexible, it is important to develop methods for controlling reasoning strategies. Existing methods struggle to control fine-grained reasoning strategies due to conceptual entanglement in LRMs' hidden states. To address this, we leverage Sparse Autoencoders (SAEs) to decompose strategy-entangled hidden states into a disentangled feature space. To identify the few strategy-specific features from the vast pool of SAE features, we propose SAE-Steering, an efficient two-stage feature identification pipeline. SAE-Steering first recalls features that amplify the logits of strategy-specific keywords, filtering out over 99\\% of features, and then ranks the remaining features by their control effectiveness. Using the identified strategy-specific features as control vectors, SAE-Steering outperforms existing methods by over 15\\% in control effectiveness. Furthermore, controlling reasoning strategies can redirect LRMs from erroneous paths to correct ones, achieving a 7\\% absolute accuracy improvement.",
      "authors": [
        "Yi Fang",
        "Wenjie Wang",
        "Mingfeng Xue",
        "Boyi Deng",
        "Fengli Xu",
        "Dayiheng Liu",
        "Fuli Feng"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "published": "2026-01-07 05:26:26+00:00",
      "link": "https://arxiv.org/pdf/2601.03595v1",
      "tags": [
        "keyword:RL",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03584v1",
      "title": "Local Gradient Regulation Stabilizes Federated Learning under Client Heterogeneity",
      "abstract": "Federated learning (FL) enables collaborative model training across distributed clients without sharing raw data, yet its stability is fundamentally challenged by statistical heterogeneity in realistic deployments. Here, we show that client heterogeneity destabilizes FL primarily by distorting local gradient dynamics during client-side optimization, causing systematic drift that accumulates across communication rounds and impedes global convergence. This observation highlights local gradients as a key regulatory lever for stabilizing heterogeneous FL systems. Building on this insight, we develop a general client-side perspective that regulates local gradient contributions without incurring additional communication overhead. Inspired by swarm intelligence, we instantiate this perspective through Exploratory--Convergent Gradient Re-aggregation (ECGR), which balances well-aligned and misaligned gradient components to preserve informative updates while suppressing destabilizing effects. Theoretical analysis and extensive experiments, including evaluations on the LC25000 medical imaging dataset, demonstrate that regulating local gradient dynamics consistently stabilizes federated learning across state-of-the-art methods under heterogeneous data distributions.",
      "authors": [
        "Ping Luo",
        "Jiahuan Wang",
        "Ziqing Wen",
        "Tao Sun",
        "Dongsheng Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.DC"
      ],
      "published": "2026-01-07 04:58:18+00:00",
      "link": "https://arxiv.org/pdf/2601.03584v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03577v1",
      "title": "Variational Inference, Entropy, and Orthogonality: A Unified Theory of Mixture-of-Experts",
      "abstract": "Mixture-of-Experts models enable large language models to scale efficiently, as they only activate a subset of experts for each input. Their core mechanisms, Top-k routing and auxiliary load balancing, remain heuristic, however, lacking a cohesive theoretical underpinning to support them. To this end, we build the first unified theoretical framework that rigorously derives these practices as optimal sparse posterior approximation and prior regularization from a Bayesian perspective, while simultaneously framing them as mechanisms to minimize routing ambiguity and maximize channel capacity from an information-theoretic perspective. We also pinpoint the inherent combinatorial hardness of routing, defining it as the NP-hard sparse subset selection problem. We rigorously prove the existence of a \"Coherence Barrier\"; when expert representations exhibit high mutual coherence, greedy routing strategies theoretically fail to recover the optimal expert subset. Importantly, we formally verify that imposing geometric orthogonality in the expert feature space is sufficient to narrow the divide between the NP-hard global optimum and polynomial-time greedy approximation. Our comparative analyses confirm orthogonality regularization as the optimal engineering relaxation for large-scale models. Our work offers essential theoretical support and technical assurance for a deeper understanding and novel designs of MoE.",
      "authors": [
        "Ye Su",
        "Yong Liu"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 04:45:07+00:00",
      "link": "https://arxiv.org/pdf/2601.03577v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03566v1",
      "title": "Provably Convergent Decentralized Optimization over Directed Graphs under Generalized Smoothness",
      "abstract": "Decentralized optimization has become a fundamental tool for large-scale learning systems; however, most existing methods rely on the classical Lipschitz smoothness assumption, which is often violated in problems with rapidly varying gradients. Motivated by this limitation, we study decentralized optimization under the generalized $(L_0, L_1)$-smoothness framework, in which the Hessian norm is allowed to grow linearly with the gradient norm, thereby accommodating rapidly varying gradients beyond classical Lipschitz smoothness. We integrate gradient-tracking techniques with gradient clipping and carefully design the clipping threshold to ensure accurate convergence over directed communication graphs under generalized smoothness. In contrast to existing distributed optimization results under generalized smoothness that require a bounded gradient dissimilarity assumption, our results remain valid even when the gradient dissimilarity is unbounded, making the proposed framework more applicable to realistic heterogeneous data environments. We validate our approach via numerical experiments on standard benchmark datasets, including LIBSVM and CIFAR-10, using regularized logistic regression and convolutional neural networks, demonstrating superior stability and faster convergence over existing methods.",
      "authors": [
        "Yanan Bo",
        "Yongqiang Wang"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.LG"
      ],
      "published": "2026-01-07 04:25:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03566v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04260v1",
      "title": "Towards a Mechanistic Understanding of Propositional Logical Reasoning in Large Language Models",
      "abstract": "Understanding how Large Language Models (LLMs) perform logical reasoning internally remains a fundamental challenge. While prior mechanistic studies focus on identifying taskspecific circuits, they leave open the question of what computational strategies LLMs employ for propositional reasoning. We address this gap through comprehensive analysis of Qwen3 (8B and 14B) on PropLogic-MI, a controlled dataset spanning 11 propositional logic rule categories across one-hop and two-hop reasoning. Rather than asking ''which components are necessary,'' we ask ''how does the model organize computation?'' Our analysis reveals a coherent computational architecture comprising four interlocking mechanisms: Staged Computation (layer-wise processing phases), Information Transmission (information flow aggregation at boundary tokens), Fact Retrospection (persistent re-access of source facts), and Specialized Attention Heads (functionally distinct head types). These mechanisms generalize across model scales, rule types, and reasoning depths, providing mechanistic evidence that LLMs employ structured computational strategies for logical reasoning.",
      "authors": [
        "Danchun Chen",
        "Qiyao Yan",
        "Liangming Pan"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-07 04:20:30+00:00",
      "link": "https://arxiv.org/pdf/2601.04260v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03561v2",
      "title": "Green's-Function Spherical Neural Operators for Biological Heterogeneity",
      "abstract": "Spherical deep learning has been widely applied to a broad range of real-world problems. Existing approaches often face challenges in balancing strong spherical geometric inductive biases with the need to model real-world heterogeneity. To solve this while retaining spherical geometry, we first introduce a designable Green's function framework (DGF) to provide new spherical operator solution strategy: Design systematic Green's functions under rotational group. Based on DGF, to model biological heterogeneity, we propose Green's-Function Spherical Neural Operator (GSNO) fusing 3 operator solutions: (1) Equivariant Solution derived from Equivariant Green's Function for symmetry-consistent modeling; (2) Invariant Solution derived from Invariant Green's Function to eliminate nuisance heterogeneity, e.g., consistent background field; (3) Anisotropic Solution derived from Anisotropic Green's Function to model anisotropic systems, especially fibers with preferred direction. Therefore, the resulting model, GSNO can adapt to real-world heterogeneous systems with nuisance variability and anisotropy while retaining spectral efficiency. Evaluations on spherical MNIST, Shallow Water Equation, diffusion MRI fiber prediction, cortical parcellation and molecule structure modeling demonstrate the superiority of GSNO.",
      "authors": [
        "Hao Tang",
        "Hao Chen",
        "Hao Li",
        "Chao Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-01-07 04:01:25+00:00",
      "link": "https://arxiv.org/pdf/2601.03561v2",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03559v1",
      "title": "DiffCoT: Diffusion-styled Chain-of-Thought Reasoning in LLMs",
      "abstract": "Chain-of-Thought (CoT) reasoning improves multi-step mathematical problem solving in large language models but remains vulnerable to exposure bias and error accumulation, as early mistakes propagate irreversibly through autoregressive decoding. In this work, we propose DiffCoT, a diffusion-styled CoT framework that reformulates CoT reasoning as an iterative denoising process. DiffCoT integrates diffusion principles at the reasoning-step level via a sliding-window mechanism, enabling unified generation and retrospective correction of intermediate steps while preserving token-level autoregression. To maintain causal consistency, we further introduce a causal diffusion noise schedule that respects the temporal structure of reasoning chains. Extensive experiments on three multi-step CoT reasoning benchmarks across diverse model backbones demonstrate that DiffCoT consistently outperforms existing CoT preference optimization methods, yielding improved robustness and error-correction capability in CoT reasoning.",
      "authors": [
        "Shidong Cao",
        "Hongzhan Lin",
        "Yuxuan Gu",
        "Ziyang Luo",
        "Jing Ma"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 03:58:42+00:00",
      "link": "https://arxiv.org/pdf/2601.03559v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03555v1",
      "title": "SCRIBE: Structured Mid-Level Supervision for Tool-Using Language Models",
      "abstract": "Training reliable tool-augmented agents remains a significant challenge, largely due to the difficulty of credit assignment in multi-step reasoning. While process-level reward models offer a promising direction, existing LLM-based judges often produce noisy and inconsistent signals because they lack fine-grained, task-specific rubrics to distinguish high-level planning from low-level execution. In this work, we introduce SCRIBE (Skill-Conditioned Reward with Intermediate Behavioral Evaluation), a reinforcement learning framework that intervenes at a novel mid-level abstraction. SCRIBE grounds reward modeling in a curated library of skill prototypes, transforming open-ended LLM evaluation into a constrained verification problem. By routing each subgoal to a corresponding prototype, the reward model is equipped with precise, structured rubrics that substantially reduce reward variance.   Experimental results show that SCRIBE achieves state-of-the-art performance across a range of reasoning and tool-use benchmarks. In particular, it improves the AIME25 accuracy of a Qwen3-4B model from 43.3% to 63.3%, and significantly increases success rates in complex multi-turn tool interactions.   Further analysis of training dynamics reveals a co-evolution across abstraction levels, where mastery of mid-level skills consistently precedes the emergence of effective high-level planning behaviors. Finally, we demonstrate that SCRIBE is additive to low-level tool optimizations, providing a scalable and complementary pathway toward more autonomous and reliable tool-using agents.",
      "authors": [
        "Yuxuan Jiang",
        "Francis Ferraro"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 03:49:48+00:00",
      "link": "https://arxiv.org/pdf/2601.03555v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03550v1",
      "title": "ReEfBench: Quantifying the Reasoning Efficiency of LLMs",
      "abstract": "Test-time scaling has enabled Large Language Models (LLMs) to tackle complex reasoning, yet the limitations of current Chain-of-Thought (CoT) evaluation obscures whether performance gains stem from genuine reasoning or mere verbosity. To address this, (1) we propose a novel neuro-symbolic framework for the non-intrusive, comprehensive process-centric evaluation of reasoning. (2) Through this lens, we identify four distinct behavioral prototypes and diagnose the failure modes. (3) We examine the impact of inference mode, training strategy, and model scale. Our analysis reveals that extended token generation is not a prerequisite for deep reasoning. Furthermore, we reveal critical constraints: mixing long and short CoT data in training risks in premature saturation and collapse, while distillation into smaller models captures behavioral length but fails to replicate logical efficacy due to intrinsic capacity limits.",
      "authors": [
        "Zhizhang Fu",
        "Yuancheng Gu",
        "Chenkai Hu",
        "Hanmeng Liu",
        "Yue Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-07 03:33:07+00:00",
      "link": "https://arxiv.org/pdf/2601.03550v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03540v1",
      "title": "DeepSynth-Eval: Objectively Evaluating Information Consolidation in Deep Survey Writing",
      "abstract": "The evolution of Large Language Models (LLMs) towards autonomous agents has catalyzed progress in Deep Research. While retrieval capabilities are well-benchmarked, the post-retrieval synthesis stage--where agents must digest massive amounts of context and consolidate fragmented evidence into coherent, long-form reports--remains under-evaluated due to the subjectivity of open-ended writing. To bridge this gap, we introduce DeepSynth-Eval, a benchmark designed to objectively evaluate information consolidation capabilities. We leverage high-quality survey papers as gold standards, reverse-engineering research requests and constructing \"Oracle Contexts\" from their bibliographies to isolate synthesis from retrieval noise. We propose a fine-grained evaluation protocol using General Checklists (for factual coverage) and Constraint Checklists (for structural organization), transforming subjective judgment into verifiable metrics. Experiments across 96 tasks reveal that synthesizing information from hundreds of references remains a significant challenge. Our results demonstrate that agentic plan-and-write workflows significantly outperform single-turn generation, effectively reducing hallucinations and improving adherence to complex structural constraints.",
      "authors": [
        "Hongzhi Zhang",
        "Yuanze Hu",
        "Tinghai Zhang",
        "Jia Fu",
        "Tao Wang",
        "Junwei Jing",
        "Zhaoxin Fan",
        "Qi Wang",
        "Ruiming Tang",
        "Han Li",
        "Guorui Zhou",
        "Kun Gai"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-07 03:07:52+00:00",
      "link": "https://arxiv.org/pdf/2601.03540v1",
      "tags": [
        "keyword:RL",
        "keyword:resnet",
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03528v1",
      "title": "CloudMatch: Weak-to-Strong Consistency Learning for Semi-Supervised Cloud Detection",
      "abstract": "Due to the high cost of annotating accurate pixel-level labels, semi-supervised learning has emerged as a promising approach for cloud detection. In this paper, we propose CloudMatch, a semi-supervised framework that effectively leverages unlabeled remote sensing imagery through view-consistency learning combined with scene-mixing augmentations. An observation behind CloudMatch is that cloud patterns exhibit structural diversity and contextual variability across different scenes and within the same scene category. Our key insight is that enforcing prediction consistency across diversely augmented views, incorporating both inter-scene and intra-scene mixing, enables the model to capture the structural diversity and contextual richness of cloud patterns. Specifically, CloudMatch generates one weakly augmented view along with two complementary strongly augmented views for each unlabeled image: one integrates inter-scene patches to simulate contextual variety, while the other employs intra-scene mixing to preserve semantic coherence. This approach guides pseudolabel generation and enhances generalization. Extensive experiments show that CloudMatch achieves good performance, demonstrating its capability to utilize unlabeled data efficiently and advance semi-supervised cloud detection.",
      "authors": [
        "Jiayi Zhao",
        "Changlu Chen",
        "Jingsheng Li",
        "Tianxiang Xue",
        "Kun Zhan"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "published": "2026-01-07 02:31:17+00:00",
      "link": "https://arxiv.org/pdf/2601.03528v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03525v1",
      "title": "VeRPO: Verifiable Dense Reward Policy Optimization for Code Generation",
      "abstract": "Effective reward design is a central challenge in Reinforcement Learning (RL) for code generation. Mainstream pass/fail outcome rewards enforce functional correctness via executing unit tests, but the resulting sparsity limits potential performance gains. While recent work has explored external Reward Models (RM) to generate richer, continuous rewards, the learned RMs suffer from reward misalignment and prohibitive computational cost. In this paper, we introduce \\textbf{VeRPO} (\\textbf{V}erifiable D\\textbf{e}nse \\textbf{R}eward \\textbf{P}olicy \\textbf{O}ptimization), a novel RL framework for code generation that synthesizes \\textit{robust and dense rewards fully grounded in verifiable execution feedback}. The core idea of VeRPO is constructing dense rewards from weighted partial success: by dynamically estimating the difficulty weight of each unit test based on the execution statistics during training, a dense reward is derived from the sum of weights of the passed unit tests. To solidify the consistency between partial success and end-to-end functional correctness, VeRPO further integrates the dense signal with global execution outcomes, establishing a robust and dense reward paradigm relying solely on verifiable execution feedback. Extensive experiments across diverse benchmarks and settings demonstrate that VeRPO consistently outperforms outcome-driven and RM-based baselines, achieving up to +8.83\\% gain in pass@1 with negligible time cost (< 0.02\\%) and zero GPU memory overhead.",
      "authors": [
        "Longwen Wang",
        "Xuan'er Wu",
        "Xiaohui Hu",
        "Yirui Liu",
        "Yuankai Fan",
        "Kaidong Yu",
        "Qizhen Weng",
        "Wei Xi",
        "Xuelong Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-07 02:29:49+00:00",
      "link": "https://arxiv.org/pdf/2601.03525v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03520v1",
      "title": "A Reinforcement Learning-Based Model for Mapping and Goal-Directed Navigation Using Multiscale Place Fields",
      "abstract": "Autonomous navigation in complex and partially observable environments remains a central challenge in robotics. Several bio-inspired models of mapping and navigation based on place cells in the mammalian hippocampus have been proposed. This paper introduces a new robust model that employs parallel layers of place fields at multiple spatial scales, a replay-based reward mechanism, and dynamic scale fusion. Simulations show that the model improves path efficiency and accelerates learning compared to single-scale baselines, highlighting the value of multiscale spatial representations for adaptive robot navigation.",
      "authors": [
        "Bekarys Dukenbaev",
        "Andrew Gerstenslager",
        "Alexander Johnson",
        "Ali A. Minai"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.RO"
      ],
      "published": "2026-01-07 02:10:52+00:00",
      "link": "https://arxiv.org/pdf/2601.03520v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03515v1",
      "title": "Mem-Gallery: Benchmarking Multimodal Long-Term Conversational Memory for MLLM Agents",
      "abstract": "Long-term memory is a critical capability for multimodal large language model (MLLM) agents, particularly in conversational settings where information accumulates and evolves over time. However, existing benchmarks either evaluate multi-session memory in text-only conversations or assess multimodal understanding within localized contexts, failing to evaluate how multimodal memory is preserved, organized, and evolved across long-term conversational trajectories. Thus, we introduce Mem-Gallery, a new benchmark for evaluating multimodal long-term conversational memory in MLLM agents. Mem-Gallery features high-quality multi-session conversations grounded in both visual and textual information, with long interaction horizons and rich multimodal dependencies. Building on this dataset, we propose a systematic evaluation framework that assesses key memory capabilities along three functional dimensions: memory extraction and test-time adaptation, memory reasoning, and memory knowledge management. Extensive benchmarking across thirteen memory systems reveals several key findings, highlighting the necessity of explicit multimodal information retention and memory organization, the persistent limitations in memory reasoning and knowledge management, as well as the efficiency bottleneck of current models.",
      "authors": [
        "Yuanchen Bei",
        "Tianxin Wei",
        "Xuying Ning",
        "Yanjun Zhao",
        "Zhining Liu",
        "Xiao Lin",
        "Yada Zhu",
        "Hendrik Hamann",
        "Jingrui He",
        "Hanghang Tong"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 02:03:13+00:00",
      "link": "https://arxiv.org/pdf/2601.03515v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03511v1",
      "title": "IntroLM: Introspective Language Models via Prefilling-Time Self-Evaluation",
      "abstract": "A major challenge for the operation of large language models (LLMs) is how to predict whether a specific LLM will produce sufficiently high-quality output for a given query. Existing approaches rely on external classifiers, most commonly BERT based models, which suffer from limited context windows, constrained representational capacity, and additional computational overhead. We propose IntroLM, a method that enables causal language models to predict their own output quality during the prefilling phase without affecting generation using introspective tokens. By introducing token conditional LoRA that activates only for the introspective token, the model learns to predict the output quality for a given query while preserving the original backbone behavior and avoiding external evaluators. On question answering benchmarks, IntroLM applied to Qwen3 8B achieves a ROC AUC of 90 precent for success prediction, outperforming a DeBERTa classifier by 14 precent. When integrated into multi model routing systems, IntroLM achieves superior cost performance tradeoffs, reducing latency by up to 33 precent and large model usage by up to 50 precent at matched reliability.",
      "authors": [
        "Hossein Hosseini Kasnavieh",
        "Gholamreza Haffari",
        "Chris Leckie",
        "Adel N. Toosi"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-01-07 01:48:17+00:00",
      "link": "https://arxiv.org/pdf/2601.03511v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.03509v1",
      "title": "Evolving Programmatic Skill Networks",
      "abstract": "We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional network that evolves through experience. PSN defines three core mechanisms instantiated via large language models: (1)REFLECT for structured fault localization over skill compositions, (2) progressive optimization with maturity-aware update gating that stabilizes reliable skills while maintaining plasticity for uncertain ones, and (3) canonical structural refactoring under rollback validation that maintains network compactness. We further show that PSN's learning dynamics exhibit structural parallels to neural network training. Experiments on MineDojo and Crafter demonstrate robust skill reuse, rapid adaptation, and strong generalization across open-ended task distributions.\\footnote{We plan to open-source the code.",
      "authors": [
        "Haochen Shi",
        "Xingdi Yuan",
        "Bang Liu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "published": "2026-01-07 01:43:25+00:00",
      "link": "https://arxiv.org/pdf/2601.03509v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03505v1",
      "title": "Beyond Perplexity: A Lightweight Benchmark for Knowledge Retention in Supervised Fine-Tuning",
      "abstract": "Supervised Fine-Tuning (SFT) is a standard approach for injecting domain knowledge into Large Language Models (LLMs). However, relying on validation perplexity to monitor training is often insufficient, as it confounds stylistic mimicry with genuine factual internalization. To address this, we introduce the Knowledge Retention (KR) Test , a lightweight, corpus-grounded evaluation framework designed to distinguish factual learning from linguistics. KR-Test utilizes automatically generated contrastive examples to measure likelihood preferences for correct versus incorrect continuations, requiring no instruction tuning or generative decoding. We validate the framework's integrity through a \"blind vs. oracle\" baseline analysis. Furthermore, we demonstrate the diagnostic capabilities of KR-Test by analyzing the training dynamics of Low-Rank Adaptation (LoRA). By exposing the fine-grained dissociation between linguistic convergence and knowledge retention, KR-Test enhances the interpretability of fine-tuning dynamics.",
      "authors": [
        "Soheil Zibakhsh Shabgahi",
        "Pedram Aghazadeh",
        "Farinaz Koushanfar"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-01-07 01:34:28+00:00",
      "link": "https://arxiv.org/pdf/2601.03505v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03500v1",
      "title": "SDCD: Structure-Disrupted Contrastive Decoding for Mitigating Hallucinations in Large Vision-Language Models",
      "abstract": "Large Vision-Language Models (LVLMs) demonstrate significant progress in multimodal understanding and reasoning, yet object hallucination remains a critical challenge. While existing research focuses on mitigating language priors or high-level statistical biases, they often overlook the internal complexities of the visual encoding process. We identify that visual statistical bias, arising from the inherent Bag-of-Patches behavior of Vision Encoders under weak structural supervision, acts as a contributing factor of object hallucinations. Under this bias, models prioritize local texture features within individual patches over holistic geometric structures. This tendency may induce spurious visual confidence and result in hallucinations. To address this, we introduce a training-free algorithm called Structure-Disrupted Contrastive Decoding (SDCD), which performs contrastive calibration of the output distribution by introducing a shuffled structure-disrupted view. By penalizing tokens that maintain high confidence under this structure-less view, SDCD effectively suppresses the texture-driven bias. Experimental results demonstrate that SDCD significantly mitigates hallucinations across multiple benchmarks and enhances the overall multimodal capabilities of LVLMs.",
      "authors": [
        "Yuxuan Xia",
        "Siheng Wang",
        "Peng Li"
      ],
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "published": "2026-01-07 01:27:58+00:00",
      "link": "https://arxiv.org/pdf/2601.03500v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03496v1",
      "title": "STELLA: Self-Reflective Terminology-Aware Framework for Building an Aerospace Information Retrieval Benchmark",
      "abstract": "Tasks in the aerospace industry heavily rely on searching and reusing large volumes of technical documents, yet there is no public information retrieval (IR) benchmark that reflects the terminology- and query-intent characteristics of this domain. To address this gap, this paper proposes the STELLA (Self-Reflective TErminoLogy-Aware Framework for BuiLding an Aerospace Information Retrieval Benchmark) framework. Using this framework, we introduce the STELLA benchmark, an aerospace-specific IR evaluation set constructed from NASA Technical Reports Server (NTRS) documents via a systematic pipeline that comprises document layout detection, passage chunking, terminology dictionary construction, synthetic query generation, and cross-lingual extension. The framework generates two types of queries: the Terminology Concordant Query (TCQ), which includes the terminology verbatim to evaluate lexical matching, and the Terminology Agnostic Query (TAQ), which utilizes the terminology's description to assess semantic matching. This enables a disentangled evaluation of the lexical and semantic matching capabilities of embedding models. In addition, we combine Chain-of-Density (CoD) and the Self-Reflection method with query generation to improve quality and implement a hybrid cross-lingual extension that reflects real user querying practices. Evaluation of seven embedding models on the STELLA benchmark shows that large decoder-based embedding models exhibit the strongest semantic understanding, while lexical matching methods such as BM25 remain highly competitive in domains where exact lexical matching technical term is crucial. The STELLA benchmark provides a reproducible foundation for reliable performance evaluation and improvement of embedding models in aerospace-domain IR tasks. The STELLA benchmark can be found in https://huggingface.co/datasets/telepix/STELLA.",
      "authors": [
        "Bongmin Kim"
      ],
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.CL"
      ],
      "published": "2026-01-07 01:23:44+00:00",
      "link": "https://arxiv.org/pdf/2601.03496v1",
      "tags": [
        "query:sr-bench",
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04496v1",
      "title": "Adaptive Multi-Grade Deep Learning for Highly Oscillatory Fredholm Integral Equations of the Second Kind",
      "abstract": "This paper studies the use of Multi-Grade Deep Learning (MGDL) for solving highly oscillatory Fredholm integral equations of the second kind. We provide rigorous error analyses of continuous and discrete MGDL models, showing that the discrete model retains the convergence and stability of its continuous counterpart under sufficiently small quadrature error. We identify the DNN training error as the primary source of approximation error, motivating a novel adaptive MGDL algorithm that selects the network grade based on training performance. Numerical experiments with highly oscillatory (including wavenumber 500) and singular solutions confirm the accuracy, effectiveness and robustness of the proposed approach.",
      "authors": [
        "Jie Jiang",
        "Yuesheng Xu"
      ],
      "primary_category": "math.NA",
      "categories": [
        "math.NA"
      ],
      "published": "2026-01-08 02:00:06+00:00",
      "link": "https://arxiv.org/pdf/2601.04496v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03906v1",
      "title": "Exact Continuous Reformulations of Logic Constraints in Nonlinear Optimization and Optimal Control Problems",
      "abstract": "Many nonlinear optimal control and optimization problems involve constraints that combine continuous dynamics with discrete logic conditions. Standard approaches typically rely on mixed-integer programming, which introduces scalability challenges and requires specialized solvers. This paper presents an exact reformulation of broad classes of logical constraints as binary-variable-free expressions whose differentiability properties coincide with those of the underlying predicates, enabling their direct integration into nonlinear programming models. Our approach rewrites arbitrary logical propositions into conjunctive normal form, converts them into equivalent max--min constraints, and applies a smoothing procedure that preserves the exact feasible set. The method is evaluated on two benchmark problems, a quadrotor trajectory optimization with obstacle avoidance and a hybrid two-tank system with temporal logic constraints, and is shown to obtain optimal solutions more consistently and efficiently than existing binary variable elimination techniques.",
      "authors": [
        "Jad Wehbeh",
        "Eric C. Kerrigan"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY",
        "math.OC"
      ],
      "published": "2026-01-07 13:16:33+00:00",
      "link": "https://arxiv.org/pdf/2601.03906v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03759v1",
      "title": "Connecting Max-entropy With Computational Geometry, LP And SDP",
      "abstract": "We consider the well-known max-(relative) entropy problem $Θ$(y) = infQ$\\ll$P DKL(Q P ) with Kullback-Leibler divergence on a domain $Ω$ $\\subset$ R d , and with ''moment'' constraints h dQ = y, y $\\in$ R m . We show that when m $\\le$ d, $Θ$ is the Cram{é}r transform of a function v that solves a simply related computational geometry problem. Also, and remarkably, to the canonical LP: min x$\\ge$0 {c T x\\,: A x = y}, with A $\\in$ R mxd , one may associate a max-entropy problem with a suitably chosen reference measure P on R d + and linear mapping h(x) = Ax, such that its associated perspective function $ε$ $Θ$(y/$ε$) is the optimal value of the log-barrier formulation (with parameter $ε$) of the dual LP (and so it converges to the LP optimal value as $ε$ $\\rightarrow$ 0). An analogous result also holds for the canonical SDP: min X 0 { C, X\\,: A(X) = y }.",
      "authors": [
        "Jean B Lasserre"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-07 09:48:10+00:00",
      "link": "https://arxiv.org/pdf/2601.03759v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.04913v1",
      "title": "Bayesian Additive Regression Tree Copula Processes for Scalable Distributional Prediction",
      "abstract": "We show how to construct the implied copula process of response values from a Bayesian additive regression tree (BART) model with prior on the leaf node variances. This copula process, defined on the covariate space, can be paired with any marginal distribution for the dependent variable to construct a flexible distributional BART model. Bayesian inference is performed via Markov chain Monte Carlo on an augmented posterior, where we show that key sampling steps can be realized as those of Chipman et al. (2010), preserving scalability and computational efficiency even though the copula process is high dimensional. The posterior predictive distribution from the copula process model is derived in closed form as the push-forward of the posterior predictive distribution of the underlying BART model with an optimal transport map. Under suitable conditions, we establish posterior consistency for the regression function and posterior means and prove convergence in distribution of the predictive process and conditional expectation. Simulation studies demonstrate improved accuracy of distributional predictions compared to the original BART model and leading benchmarks. Applications to five real datasets with 506 to 515,345 observations and 8 to 90 covariates further highlight the efficacy and scalability of our proposed BART copula process model.",
      "authors": [
        "Jan Martin Wenkel",
        "Michael Stanley Smith",
        "Nadja Klein"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-08 13:11:37+00:00",
      "link": "https://arxiv.org/pdf/2601.04913v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04138v1",
      "title": "On the Distributed Estimation for Scalar-on-Function Regression Models",
      "abstract": "This paper proposes distributed estimation procedures for three scalar-on-function regression models: the functional linear model (FLM), the functional non-parametric model (FNPM), and the functional partial linear model (FPLM). The framework addresses two key challenges in functional data analysis, namely the high computational cost of large samples and limitations on sharing raw data across institutions. Monte Carlo simulations show that the distributed estimators substantially reduce computation time while preserving high estimation and prediction accuracy for all three models. When block sizes become too small, the FPLM exhibits overfitting, leading to narrower prediction intervals and reduced empirical coverage probability. An example of an empirical study using the \\textit{tecator} dataset further supports these findings.",
      "authors": [
        "Peilun He",
        "Han Lin Shang",
        "Nan Zou"
      ],
      "primary_category": "stat.CO",
      "categories": [
        "stat.CO"
      ],
      "published": "2026-01-07 17:51:46+00:00",
      "link": "https://arxiv.org/pdf/2601.04138v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03994v1",
      "title": "pintervals: an R package for model-agnostic prediction intervals",
      "abstract": "The \\pkg{pintervals} package aims to provide a unified framework for constructing prediction intervals and calibrating predictions in a model-agnostic setting using set-aside calibration data. It comprises routines to construct conformal as well as parametric and bootstrapped prediction intervals from any model that outputs point predictions. Several R packages and functions already exist for constructing prediction intervals, but they often focus on specific modeling frameworks or types of predictions, or require manual customization for different models or applications. By providing a consistent interface for a variety of prediction interval construction approaches (all model-agnostic), \\pkg{pintervals} allows researchers to apply and compare them across different modeling frameworks and applications.",
      "authors": [
        "David Randahl",
        "Anders Hjort",
        "Jonathan P. Williams"
      ],
      "primary_category": "stat.AP",
      "categories": [
        "stat.AP",
        "stat.CO",
        "stat.ME"
      ],
      "published": "2026-01-07 15:04:51+00:00",
      "link": "https://arxiv.org/pdf/2601.03994v1",
      "tags": [
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03674v1",
      "title": "Multi-transport Distributional Regression",
      "abstract": "We study distribution-on-distribution regression problems in which a response distribution depends on multiple distributional predictors. Such settings arise naturally in applications where the outcome distribution is driven by several heterogeneous distributional sources, yet remain challenging due to the nonlinear geometry of the Wasserstein space. We propose an intrinsic regression framework that aggregates predictor-specific transported distributions through a weighted Fréchet mean in the Wasserstein space. The resulting model admits multiple distributional predictors, assigns interpretable weights quantifying their relative contributions, and defines a flexible regression operator that is invariant to auxiliary construction choices, such as the selection of a reference distribution. From a theoretical perspective, we establish identifiability of the induced regression operator and derive asymptotic guarantees for its estimation under a predictive Wasserstein semi-norm, which directly characterizes convergence of the composite prediction map. Extensive simulation studies and a real data application demonstrate the improved predictive performance and interpretability of the proposed approach compared with existing Wasserstein regression methods.",
      "authors": [
        "Yuanying Chen",
        "Tongyu Li",
        "Yang Bai",
        "Zhenhua Lin"
      ],
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME"
      ],
      "published": "2026-01-07 07:54:20+00:00",
      "link": "https://arxiv.org/pdf/2601.03674v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.04914v1",
      "title": "Analytic Regularity and Approximation Limits of Coefficient-Constrained Shallow Networks",
      "abstract": "We study approximation limits of single-hidden-layer neural networks with analytic activation functions under global coefficient constraints. Under uniform $\\ell^1$ bounds, or more generally sub-exponential growth of the coefficients, we show that such networks generate model classes with strong quantitative regularity, leading to uniform analyticity of the realized functions. As a consequence, up to an exponentially small residual term, the error of best network approximation on generic target functions is bounded from below by the error of best polynomial approximation. In particular, networks with analytic activation functions with controlled coefficients cannot outperform classical polynomial approximation rates on non-analytic targets. The underlying rigidity phenomenon extends to smoother, non-analytic activations satisfying Gevrey-type regularity assumptions, yielding sub-exponential variants of the approximation barrier. The analysis is entirely deterministic and relies on a comparison argument combined with classical Bernstein-type estimates; extensions to higher dimensions are also discussed.",
      "authors": [
        "Jean-Gabriel Attali"
      ],
      "primary_category": "q-fin.MF",
      "categories": [
        "q-fin.MF"
      ],
      "published": "2026-01-08 13:13:14+00:00",
      "link": "https://arxiv.org/pdf/2601.04914v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.05087v1",
      "title": "Online Bayesian Learning of Agent Behavior in Differential Games",
      "abstract": "This work introduces an online Bayesian game-theoretic method for behavior identification in multi-agent dynamical systems. By casting Hamilton-Jacobi-Bellman optimality conditions as linear-in-parameter residuals, the method enables fast sequential Bayesian updates, uncertainty-aware inference, and robust prediction from limited, noisy data-without history stacks. The approach accommodates nonlinear dynamics and nonquadratic value functions through basis expansions, providing flexible models. Experiments, including linear-quadratic and nonlinear shared-control scenarios, demonstrate accurate prediction with quantified uncertainty, highlighting the method's relevance for adaptive interaction and real-time decision making.",
      "authors": [
        "Francesco Bianchin",
        "Robert Lefringhausen",
        "Sandra Hirche"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-01-08 16:35:43+00:00",
      "link": "https://arxiv.org/pdf/2601.05087v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.04775v1",
      "title": "Towards a Unified Theoretical Framework for Self-Supervised MRI Reconstruction",
      "abstract": "The demand for high-resolution, non-invasive imaging continues to drive innovation in magnetic resonance imaging (MRI), yet prolonged acquisition times hinder accessibility and real-time applications. While deep learning-based reconstruction methods have accelerated MRI, their predominant supervised paradigm depends on fully-sampled reference data that are challenging to acquire. Recently, self-supervised learning (SSL) approaches have emerged as promising alternatives, but most are empirically designed and fragmented. Therefore, we introduce UNITS (Unified Theory for Self-supervision), a general framework for self-supervised MRI reconstruction. UNITS unifies prior SSL strategies within a common formalism, enabling consistent interpretation and systematic benchmarking. We prove that SSL can achieve the same expected performance as supervised learning. Under this theoretical guarantee, we introduce sampling stochasticity and flexible data utilization, which improve network generalization under out-of-domain distributions and stabilize training. Together, these contributions establish UNITS as a theoretical foundation and a practical paradigm for interpretable, generalizable, and clinically applicable self-supervised MRI reconstruction.",
      "authors": [
        "Siying Xu",
        "Kerstin Hammernik",
        "Daniel Rueckert",
        "Sergios Gatidis",
        "Thomas Küstner"
      ],
      "primary_category": "eess.IV",
      "categories": [
        "eess.IV"
      ],
      "published": "2026-01-08 09:57:39+00:00",
      "link": "https://arxiv.org/pdf/2601.04775v1",
      "tags": [
        "keyword:resnet",
        "keyword:符号回归（示例）"
      ]
    },
    {
      "id": "2601.03767v1",
      "title": "Output Consensus on Periodic References for Constrained Multi-agent Systems Under a Switching Network",
      "abstract": "This work addresses the output consensus problem of constrained heterogeneous multi-agent systems under a switching network with potential communication delay, where outputs are periodic and characterized by a linear exosystem. Since periodic references have more complex dynamics, it is more challenging to track periodic references and achieve consensus on them. In this paper, a model predictive control method incorporating an artificial reference and a modified cost is proposed to track periodic references, which maintains recursive feasibility even when reference switches. Moreover, consensus protocols are proposed to achieve consensus on periodic references in different scenarios, in which global information such as the set of globally admissible references and the global time index are not involved. Theoretical analysis proves that constrained output consensus is asymptotically achieved with the proposed algorithm as the references of each agent converge and agents track their references while maintaining constraint satisfaction. Finally, numerical examples are provided to verify the effectiveness of the proposed algorithm.",
      "authors": [
        "Shibo Han",
        "Bonan Hou",
        "Chong Jin Ong"
      ],
      "primary_category": "eess.SY",
      "categories": [
        "eess.SY"
      ],
      "published": "2026-01-07 10:00:55+00:00",
      "link": "https://arxiv.org/pdf/2601.03767v1",
      "tags": [
        "keyword:RL"
      ]
    },
    {
      "id": "2601.03750v1",
      "title": "Multivariate kernel regression in vector and product metric spaces",
      "abstract": "This paper derives limit properties of nonparametric kernel regression estimators without requiring existence of density for regressors in $\\mathbb{R}^{q}.$ In functional regression limit properties are established for multivariate functional regression. The rate and asymptotic normality for the Nadaraya-Watson (NW) estimator is established for distributions of regressors in $\\mathbb{R}^{q}$ that allow for mass points, factor structure, multicollinearity and nonlinear dependence, as well as fractal distribution; when bounded density exists we provide statistical guarantees for the standard rate and the asymptotic normality without requiring smoothness. We demonstrate faster convergence associated with dimension reducing types of singularity, such as a fractal distribution or a factor structure in the regressors. The paper extends asymptotic normality of kernel functional regression to multivariate regression over a product of any number of metric spaces. Finite sample evidence confirms rate improvement due to singularity in regression over $\\mathbb{R}^{q}.$ For functional regression the simulations underline the importance of accounting for multiple functional regressors. We demonstrate the applicability and advantages of the NW estimator in our empirical study, which reexamines the job training program evaluation based on the LaLonde data.",
      "authors": [
        "Marcia Schafgans",
        "Victoria Zinde-Walsh"
      ],
      "primary_category": "econ.EM",
      "categories": [
        "econ.EM"
      ],
      "published": "2026-01-07 09:40:54+00:00",
      "link": "https://arxiv.org/pdf/2601.03750v1",
      "tags": [
        "keyword:符号回归（示例）",
        "query:sr-bench"
      ]
    },
    {
      "id": "2601.03558v1",
      "title": "Artificial Intelligence and Skills: Evidence from Contrastive Learning in Online Job Vacancies",
      "abstract": "We investigate the impact of artificial intelligence (AI) adoption on skill requirements using 14 million online job vacancies from Chinese listed firms (2018-2022). Employing a novel Extreme Multi-Label Classification (XMLC) algorithm trained via contrastive learning and LLM-driven data augmentation, we map vacancy requirements to the ESCO framework. By benchmarking occupation-skill relationships against 2018 O*NET-ESCO mappings, we document a robust causal relationship between AI adoption and the expansion of skill portfolios. Our analysis identifies two distinct mechanisms. First, AI reduces information asymmetry in the labor market, enabling firms to specify current occupation-specific requirements with greater precision. Second, AI empowers firms to anticipate evolving labor market dynamics. We find that AI adoption significantly increases the demand for \"forward-looking\" skills--those absent from 2018 standards but subsequently codified in 2022 updates. This suggests that AI allows firms to lead, rather than follow, the formal evolution of occupational standards. Our findings highlight AI's dual role as both a stabilizer of current recruitment information and a catalyst for proactive adaptation to future skill shifts.",
      "authors": [
        "Hangyu Chen",
        "Yongming Sun",
        "Yiming Yuan"
      ],
      "primary_category": "econ.GN",
      "categories": [
        "econ.GN"
      ],
      "published": "2026-01-07 03:55:57+00:00",
      "link": "https://arxiv.org/pdf/2601.03558v1",
      "tags": [
        "query:大厂llm"
      ]
    },
    {
      "id": "2601.04172v1",
      "title": "Stochastic Path Compression for Spectral Tensor Networks on Cyclic Graphs",
      "abstract": "We develop a new approach to compress cyclic tensor networks called stochastic path compression (SPC) that uses an iterative importance sampling procedure to target edges with large bond-dimensions. Closed random walks in SPC form compression pathways that spatially localize large bond-dimensions in the tensor network. Analogous to the phase separation of two immiscible liquids, SPC separates the graph of bond-dimensions into spatially distinct high and low density regions. When combined with our integral decimation algorithm, SPC facilitates the accurate compression of cyclic tensor networks with continuous degrees of freedom. To benchmark and illustrate the methods, we compute the absolute thermodynamics of $q$-state clock models on two-dimensional square lattices and an XY model on a Watts-Strogatz graph, which is a small-world network with random connectivity between spins.",
      "authors": [
        "Ryan T. Grimm",
        "Joel D. Eaves"
      ],
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech",
        "physics.comp-ph"
      ],
      "published": "2026-01-07 18:39:49+00:00",
      "link": "https://arxiv.org/pdf/2601.04172v1",
      "tags": [
        "keyword:resnet"
      ]
    },
    {
      "id": "2601.03613v1",
      "title": "PhysicsFormer: An Efficient and Fast Attention-Based Physics Informed Neural Network for Solving Incompressible Navier Stokes Equations",
      "abstract": "Traditional experimental and numerical approaches for fluid dynamics problems often suffer from high computational cost, mesh sensitivity, and limited capability in capturing complex physical behaviors. Moreover, conventional physics-informed neural networks (PINNs) frequently struggle in chaotic and highly unsteady flow regimes. In this work, we propose \\textit{PhysicsFormer}, a fast and efficient transformer-based physics-informed framework that incorporates multi-head encoder-decoder cross-attention. Unlike multilayer perceptron-based PINNs, PhysicsFormer operates on sequential representations constructed from spatio-temporal data, enabling effective learning of long-range temporal dependencies and improved propagation of initial condition information. A data-embedding strategy is employed to convert spatio-temporal points into pseudo-sequences, while a dynamics-weighted loss function replaces the standard PINNs formulation. Owing to its parallel learning structure, PhysicsFormer demonstrates superior computational efficiency compared to existing transformer-based approaches. The framework is validated on Burgers' equation and flow reconstruction governed by the Navier-Stokes equations, achieving mean squared errors on the order of $10^{-6}$. In addition, an inverse problem involving parameter identification in the two-dimensional incompressible Navier-Stokes equations is investigated. For clean data, PhysicsFormer achieves zero identification error for both $λ_1$ and $λ_2$; under $1\\%$ Gaussian noise, the errors are $0.07\\%$ for $λ_1$ and $0\\%$ for $λ_2$. These results demonstrate that PhysicsFormer provides a reliable and computationally efficient surrogate modeling framework for time-dependent fluid flow problems.",
      "authors": [
        "Biswanath Barman",
        "Debdeep Chatterjee",
        "Rajendra K. Ray"
      ],
      "primary_category": "physics.flu-dyn",
      "categories": [
        "physics.flu-dyn"
      ],
      "published": "2026-01-07 05:41:50+00:00",
      "link": "https://arxiv.org/pdf/2601.03613v1",
      "tags": [
        "keyword:符号回归（示例）"
      ]
    }
  ],
  "queries": [
    {
      "type": "keyword",
      "tag": "符号回归（示例）",
      "paper_tag": "keyword:符号回归（示例）",
      "query_text": "Find research papers describing recent advancements in symbolic regression techniques that utilize deep learning and genetic programming to discover interpretable mathematical expressions and governing physical laws from complex datasets.",
      "sim_scores": {
        "2601.04051v1": {
          "score": 0.8052353262901306,
          "rank": 1
        },
        "2601.04799v1": {
          "score": 0.799704372882843,
          "rank": 2
        },
        "2601.05227v1": {
          "score": 0.7971362471580505,
          "rank": 3
        },
        "2601.03910v1": {
          "score": 0.7935246229171753,
          "rank": 4
        },
        "2601.05051v1": {
          "score": 0.7867955565452576,
          "rank": 5
        },
        "2601.03682v1": {
          "score": 0.7851604223251343,
          "rank": 6
        },
        "2601.04496v1": {
          "score": 0.7814065217971802,
          "rank": 7
        },
        "2601.04270v1": {
          "score": 0.777492880821228,
          "rank": 8
        },
        "2601.03839v1": {
          "score": 0.7754310369491577,
          "rank": 9
        },
        "2601.05052v1": {
          "score": 0.7746360301971436,
          "rank": 10
        },
        "2601.04509v1": {
          "score": 0.773944616317749,
          "rank": 11
        },
        "2601.03988v1": {
          "score": 0.7739417552947998,
          "rank": 12
        },
        "2601.04447v1": {
          "score": 0.7724284529685974,
          "rank": 13
        },
        "2601.04941v1": {
          "score": 0.7716256380081177,
          "rank": 14
        },
        "2601.04577v1": {
          "score": 0.7712769508361816,
          "rank": 15
        },
        "2601.03919v2": {
          "score": 0.7689322233200073,
          "rank": 16
        },
        "2601.04932v1": {
          "score": 0.7682561278343201,
          "rank": 17
        },
        "2601.04670v1": {
          "score": 0.76581871509552,
          "rank": 18
        },
        "2601.04473v1": {
          "score": 0.7657922506332397,
          "rank": 19
        },
        "2601.04568v1": {
          "score": 0.7653771042823792,
          "rank": 20
        },
        "2601.04833v1": {
          "score": 0.7652376890182495,
          "rank": 21
        },
        "2601.03847v1": {
          "score": 0.7652095556259155,
          "rank": 22
        },
        "2601.03743v1": {
          "score": 0.7652021050453186,
          "rank": 23
        },
        "2601.04918v1": {
          "score": 0.764859676361084,
          "rank": 24
        },
        "2601.03674v1": {
          "score": 0.7646472454071045,
          "rank": 25
        },
        "2601.04176v1": {
          "score": 0.7644590139389038,
          "rank": 26
        },
        "2601.03845v1": {
          "score": 0.7632390260696411,
          "rank": 27
        },
        "2601.03750v1": {
          "score": 0.7623445391654968,
          "rank": 28
        },
        "2601.05053v1": {
          "score": 0.7619196176528931,
          "rank": 29
        },
        "2601.03654v1": {
          "score": 0.7617344856262207,
          "rank": 30
        },
        "2601.04731v1": {
          "score": 0.7613131403923035,
          "rank": 31
        },
        "2601.03595v1": {
          "score": 0.7612946033477783,
          "rank": 32
        },
        "2601.04264v1": {
          "score": 0.7611827850341797,
          "rank": 33
        },
        "2601.03634v1": {
          "score": 0.7608774900436401,
          "rank": 34
        },
        "2601.03683v1": {
          "score": 0.7608582377433777,
          "rank": 35
        },
        "2601.04263v1": {
          "score": 0.7601598501205444,
          "rank": 36
        },
        "2601.03657v1": {
          "score": 0.7590499520301819,
          "rank": 37
        },
        "2601.04483v1": {
          "score": 0.7589444518089294,
          "rank": 38
        },
        "2601.04878v1": {
          "score": 0.7588186264038086,
          "rank": 39
        },
        "2601.03812v1": {
          "score": 0.7584301233291626,
          "rank": 40
        },
        "2601.04752v1": {
          "score": 0.7582893371582031,
          "rank": 41
        },
        "2601.04058v1": {
          "score": 0.7582278847694397,
          "rank": 42
        },
        "2601.04279v1": {
          "score": 0.7579149603843689,
          "rank": 43
        },
        "2601.03665v1": {
          "score": 0.7579064965248108,
          "rank": 44
        },
        "2601.03540v1": {
          "score": 0.7578016519546509,
          "rank": 45
        },
        "2601.04651v1": {
          "score": 0.7570393085479736,
          "rank": 46
        },
        "2601.04992v1": {
          "score": 0.7570348381996155,
          "rank": 47
        },
        "2601.03776v1": {
          "score": 0.7565752863883972,
          "rank": 48
        },
        "2601.05200v1": {
          "score": 0.7564188241958618,
          "rank": 49
        },
        "2601.04700v1": {
          "score": 0.7561607360839844,
          "rank": 50
        },
        "2601.04801v1": {
          "score": 0.755833089351654,
          "rank": 51
        },
        "2601.04378v1": {
          "score": 0.7557954788208008,
          "rank": 52
        },
        "2601.03606v1": {
          "score": 0.7557426691055298,
          "rank": 53
        },
        "2601.03561v2": {
          "score": 0.7554033398628235,
          "rank": 54
        },
        "2601.03559v1": {
          "score": 0.7553967237472534,
          "rank": 55
        },
        "2601.03858v1": {
          "score": 0.7553806304931641,
          "rank": 56
        },
        "2601.03882v1": {
          "score": 0.7553209066390991,
          "rank": 57
        },
        "2601.04301v1": {
          "score": 0.7551431655883789,
          "rank": 58
        },
        "2601.04727v1": {
          "score": 0.7547228932380676,
          "rank": 59
        },
        "2601.03769v2": {
          "score": 0.7546563148498535,
          "rank": 60
        },
        "2601.04675v1": {
          "score": 0.7544418573379517,
          "rank": 61
        },
        "2601.04587v1": {
          "score": 0.7540072202682495,
          "rank": 62
        },
        "2601.03621v1": {
          "score": 0.7539152503013611,
          "rank": 63
        },
        "2601.03764v1": {
          "score": 0.7538026571273804,
          "rank": 64
        },
        "2601.04390v1": {
          "score": 0.7537953853607178,
          "rank": 65
        },
        "2601.05049v1": {
          "score": 0.7537808418273926,
          "rank": 66
        },
        "2601.04766v1": {
          "score": 0.753735363483429,
          "rank": 67
        },
        "2601.04278v1": {
          "score": 0.7536075115203857,
          "rank": 68
        },
        "2601.04458v1": {
          "score": 0.7529986500740051,
          "rank": 69
        },
        "2601.04365v1": {
          "score": 0.7526698708534241,
          "rank": 70
        },
        "2601.04789v1": {
          "score": 0.7525745630264282,
          "rank": 71
        },
        "2601.03808v1": {
          "score": 0.7524529695510864,
          "rank": 72
        },
        "2601.04361v1": {
          "score": 0.7524297833442688,
          "rank": 73
        },
        "2601.03673v1": {
          "score": 0.751996636390686,
          "rank": 74
        },
        "2601.05099v1": {
          "score": 0.75190269947052,
          "rank": 75
        },
        "2601.04919v1": {
          "score": 0.7518433332443237,
          "rank": 76
        },
        "2601.03550v1": {
          "score": 0.751811146736145,
          "rank": 77
        },
        "2601.03723v1": {
          "score": 0.7517436742782593,
          "rank": 78
        },
        "2601.04582v1": {
          "score": 0.7515525221824646,
          "rank": 79
        },
        "2601.03908v1": {
          "score": 0.7514093518257141,
          "rank": 80
        },
        "2601.03885v1": {
          "score": 0.7512528300285339,
          "rank": 81
        },
        "2601.04973v1": {
          "score": 0.7512460947036743,
          "rank": 82
        },
        "2601.04914v1": {
          "score": 0.7507818341255188,
          "rank": 83
        },
        "2601.04696v1": {
          "score": 0.7507200837135315,
          "rank": 84
        },
        "2601.03584v1": {
          "score": 0.750329852104187,
          "rank": 85
        },
        "2601.04728v1": {
          "score": 0.7503020763397217,
          "rank": 86
        },
        "2601.04854v1": {
          "score": 0.7502692937850952,
          "rank": 87
        },
        "2601.03605v1": {
          "score": 0.7502416968345642,
          "rank": 88
        },
        "2601.03613v1": {
          "score": 0.7500795125961304,
          "rank": 89
        },
        "2601.03566v1": {
          "score": 0.749966025352478,
          "rank": 90
        },
        "2601.03725v1": {
          "score": 0.7498149275779724,
          "rank": 91
        },
        "2601.03511v1": {
          "score": 0.749799370765686,
          "rank": 92
        },
        "2601.03577v1": {
          "score": 0.7497504353523254,
          "rank": 93
        },
        "2601.04891v1": {
          "score": 0.7497167587280273,
          "rank": 94
        },
        "2601.05027v1": {
          "score": 0.7496297359466553,
          "rank": 95
        },
        "2601.04775v1": {
          "score": 0.7495449781417847,
          "rank": 96
        },
        "2601.04537v1": {
          "score": 0.7494216561317444,
          "rank": 97
        },
        "2601.03759v1": {
          "score": 0.7492943406105042,
          "rank": 98
        },
        "2601.05205v1": {
          "score": 0.7491912841796875,
          "rank": 99
        },
        "2601.04121v1": {
          "score": 0.7491785883903503,
          "rank": 100
        }
      }
    },
    {
      "type": "keyword",
      "tag": "RL",
      "paper_tag": "keyword:RL",
      "query_text": "Find research papers describing recent advancements in deep reinforcement learning algorithms for autonomous decision-making in complex multi-agent environments and their applications in real-world robotics.",
      "sim_scores": {
        "2601.04511v1": {
          "score": 0.8532214164733887,
          "rank": 1
        },
        "2601.03686v1": {
          "score": 0.8392747640609741,
          "rank": 2
        },
        "2601.04668v1": {
          "score": 0.8351707458496094,
          "rank": 3
        },
        "2601.04767v1": {
          "score": 0.833448052406311,
          "rank": 4
        },
        "2601.03976v1": {
          "score": 0.8322915434837341,
          "rank": 5
        },
        "2601.05087v1": {
          "score": 0.8278829455375671,
          "rank": 6
        },
        "2601.03520v1": {
          "score": 0.8259923458099365,
          "rank": 7
        },
        "2601.04842v1": {
          "score": 0.8257135152816772,
          "rank": 8
        },
        "2601.04365v1": {
          "score": 0.8256718516349792,
          "rank": 9
        },
        "2601.04694v1": {
          "score": 0.8241795301437378,
          "rank": 10
        },
        "2601.03743v1": {
          "score": 0.8226964473724365,
          "rank": 11
        },
        "2601.04748v1": {
          "score": 0.8226450681686401,
          "rank": 12
        },
        "2601.04191v1": {
          "score": 0.8197587132453918,
          "rank": 13
        },
        "2601.05205v1": {
          "score": 0.8188828825950623,
          "rank": 14
        },
        "2601.04695v1": {
          "score": 0.8185611963272095,
          "rank": 15
        },
        "2601.04441v1": {
          "score": 0.8181119561195374,
          "rank": 16
        },
        "2601.04703v1": {
          "score": 0.8167994022369385,
          "rank": 17
        },
        "2601.04170v1": {
          "score": 0.8140288591384888,
          "rank": 18
        },
        "2601.03956v1": {
          "score": 0.8124692440032959,
          "rank": 19
        },
        "2601.03715v1": {
          "score": 0.8123778104782104,
          "rank": 20
        },
        "2601.04287v1": {
          "score": 0.8117107152938843,
          "rank": 21
        },
        "2601.03641v2": {
          "score": 0.8109310865402222,
          "rank": 22
        },
        "2601.05053v1": {
          "score": 0.8107888698577881,
          "rank": 23
        },
        "2601.04861v1": {
          "score": 0.8103606104850769,
          "rank": 24
        },
        "2601.04411v1": {
          "score": 0.808090329170227,
          "rank": 25
        },
        "2601.03723v1": {
          "score": 0.8074109554290771,
          "rank": 26
        },
        "2601.04177v1": {
          "score": 0.8069204688072205,
          "rank": 27
        },
        "2601.03872v1": {
          "score": 0.8060629367828369,
          "rank": 28
        },
        "2601.05230v1": {
          "score": 0.8059760928153992,
          "rank": 29
        },
        "2601.03703v1": {
          "score": 0.8058799505233765,
          "rank": 30
        },
        "2601.05152v1": {
          "score": 0.8058196306228638,
          "rank": 31
        },
        "2601.04786v1": {
          "score": 0.8056095838546753,
          "rank": 32
        },
        "2601.05242v1": {
          "score": 0.8040595054626465,
          "rank": 33
        },
        "2601.04401v1": {
          "score": 0.803681492805481,
          "rank": 34
        },
        "2601.04699v1": {
          "score": 0.8034849166870117,
          "rank": 35
        },
        "2601.03661v1": {
          "score": 0.8024610877037048,
          "rank": 36
        },
        "2601.04714v1": {
          "score": 0.8013390898704529,
          "rank": 37
        },
        "2601.03905v2": {
          "score": 0.8000243902206421,
          "rank": 38
        },
        "2601.04126v2": {
          "score": 0.7983957529067993,
          "rank": 39
        },
        "2601.04537v1": {
          "score": 0.7982219457626343,
          "rank": 40
        },
        "2601.03555v1": {
          "score": 0.7973589897155762,
          "rank": 41
        },
        "2601.04120v1": {
          "score": 0.7968335747718811,
          "rank": 42
        },
        "2601.04809v1": {
          "score": 0.7966788411140442,
          "rank": 43
        },
        "2601.03822v1": {
          "score": 0.7962085008621216,
          "rank": 44
        },
        "2601.04083v2": {
          "score": 0.7960585355758667,
          "rank": 45
        },
        "2601.04392v1": {
          "score": 0.7958894968032837,
          "rank": 46
        },
        "2601.03823v1": {
          "score": 0.7952338457107544,
          "rank": 47
        },
        "2601.05111v1": {
          "score": 0.7950673699378967,
          "rank": 48
        },
        "2601.05002v1": {
          "score": 0.7950332164764404,
          "rank": 49
        },
        "2601.04577v1": {
          "score": 0.7949235439300537,
          "rank": 50
        },
        "2601.05248v1": {
          "score": 0.7944077253341675,
          "rank": 51
        },
        "2601.03895v1": {
          "score": 0.7937932014465332,
          "rank": 52
        },
        "2601.03807v1": {
          "score": 0.7936031818389893,
          "rank": 53
        },
        "2601.04805v1": {
          "score": 0.7917371392250061,
          "rank": 54
        },
        "2601.03846v1": {
          "score": 0.7912973165512085,
          "rank": 55
        },
        "2601.03595v1": {
          "score": 0.7908898591995239,
          "rank": 56
        },
        "2601.03767v1": {
          "score": 0.789901614189148,
          "rank": 57
        },
        "2601.03509v1": {
          "score": 0.789571225643158,
          "rank": 58
        },
        "2601.03969v1": {
          "score": 0.7894169688224792,
          "rank": 59
        },
        "2601.04973v1": {
          "score": 0.7892774343490601,
          "rank": 60
        },
        "2601.05241v1": {
          "score": 0.7891020178794861,
          "rank": 61
        },
        "2601.05187v1": {
          "score": 0.7889796495437622,
          "rank": 62
        },
        "2601.04954v1": {
          "score": 0.7885474562644958,
          "rank": 63
        },
        "2601.04052v1": {
          "score": 0.7884534001350403,
          "rank": 64
        },
        "2601.04060v1": {
          "score": 0.7881407141685486,
          "rank": 65
        },
        "2601.04611v1": {
          "score": 0.7880215644836426,
          "rank": 66
        },
        "2601.04288v1": {
          "score": 0.7879623174667358,
          "rank": 67
        },
        "2601.03906v1": {
          "score": 0.7877363562583923,
          "rank": 68
        },
        "2601.05227v1": {
          "score": 0.7873064279556274,
          "rank": 69
        },
        "2601.03624v1": {
          "score": 0.7865297794342041,
          "rank": 70
        },
        "2601.05014v1": {
          "score": 0.786455512046814,
          "rank": 71
        },
        "2601.04266v1": {
          "score": 0.7857167720794678,
          "rank": 72
        },
        "2601.04799v1": {
          "score": 0.7857038378715515,
          "rank": 73
        },
        "2601.05107v1": {
          "score": 0.785365104675293,
          "rank": 74
        },
        "2601.04153v1": {
          "score": 0.7853087782859802,
          "rank": 75
        },
        "2601.04270v1": {
          "score": 0.7851511240005493,
          "rank": 76
        },
        "2601.04474v1": {
          "score": 0.7850974202156067,
          "rank": 77
        },
        "2601.04887v1": {
          "score": 0.7849997878074646,
          "rank": 78
        },
        "2601.04544v1": {
          "score": 0.7848331928253174,
          "rank": 79
        },
        "2601.04509v1": {
          "score": 0.7844428420066833,
          "rank": 80
        },
        "2601.04731v1": {
          "score": 0.7842922806739807,
          "rank": 81
        },
        "2601.04137v1": {
          "score": 0.7841260433197021,
          "rank": 82
        },
        "2601.04726v1": {
          "score": 0.7838192582130432,
          "rank": 83
        },
        "2601.04035v1": {
          "score": 0.7835964560508728,
          "rank": 84
        },
        "2601.04698v1": {
          "score": 0.7830815315246582,
          "rank": 85
        },
        "2601.03646v2": {
          "score": 0.7824491262435913,
          "rank": 86
        },
        "2601.03525v1": {
          "score": 0.7822948694229126,
          "rank": 87
        },
        "2601.04334v1": {
          "score": 0.7818354964256287,
          "rank": 88
        },
        "2601.04616v1": {
          "score": 0.7817894220352173,
          "rank": 89
        },
        "2601.04670v1": {
          "score": 0.7813583612442017,
          "rank": 90
        },
        "2601.03540v1": {
          "score": 0.7809211611747742,
          "rank": 91
        },
        "2601.03693v1": {
          "score": 0.7807109355926514,
          "rank": 92
        },
        "2601.04171v1": {
          "score": 0.7806878685951233,
          "rank": 93
        },
        "2601.04404v1": {
          "score": 0.780394971370697,
          "rank": 94
        },
        "2601.04996v1": {
          "score": 0.7799668908119202,
          "rank": 95
        },
        "2601.03607v1": {
          "score": 0.7797979116439819,
          "rank": 96
        },
        "2601.05016v1": {
          "score": 0.7793220281600952,
          "rank": 97
        },
        "2601.04525v1": {
          "score": 0.7792606949806213,
          "rank": 98
        },
        "2601.04516v1": {
          "score": 0.7791850566864014,
          "rank": 99
        },
        "2601.05191v1": {
          "score": 0.7787784337997437,
          "rank": 100
        }
      }
    },
    {
      "type": "keyword",
      "tag": "resnet",
      "paper_tag": "keyword:resnet",
      "query_text": "Find research papers describing the architectural evolution and performance benchmarks of deep residual networks in computer vision, specifically focusing on the implementation of skip connections to address the vanishing gradient problem in high-depth neural network training.",
      "sim_scores": {
        "2601.03889v1": {
          "score": 0.8208051919937134,
          "rank": 1
        },
        "2601.03658v1": {
          "score": 0.8159435391426086,
          "rank": 2
        },
        "2601.04270v1": {
          "score": 0.8147698640823364,
          "rank": 3
        },
        "2601.03660v1": {
          "score": 0.8128989934921265,
          "rank": 4
        },
        "2601.04707v1": {
          "score": 0.8090885877609253,
          "rank": 5
        },
        "2601.05052v1": {
          "score": 0.8078578114509583,
          "rank": 6
        },
        "2601.03924v1": {
          "score": 0.8072136640548706,
          "rank": 7
        },
        "2601.04914v1": {
          "score": 0.8068971633911133,
          "rank": 8
        },
        "2601.03839v1": {
          "score": 0.8055046796798706,
          "rank": 9
        },
        "2601.03955v1": {
          "score": 0.8042507171630859,
          "rank": 10
        },
        "2601.04727v1": {
          "score": 0.8029224872589111,
          "rank": 11
        },
        "2601.04855v1": {
          "score": 0.8022602796554565,
          "rank": 12
        },
        "2601.05246v1": {
          "score": 0.8012350797653198,
          "rank": 13
        },
        "2601.05251v1": {
          "score": 0.8006920218467712,
          "rank": 14
        },
        "2601.03686v1": {
          "score": 0.7996137142181396,
          "rank": 15
        },
        "2601.05227v1": {
          "score": 0.7995257377624512,
          "rank": 16
        },
        "2601.04734v1": {
          "score": 0.7983275055885315,
          "rank": 17
        },
        "2601.03665v1": {
          "score": 0.7962501049041748,
          "rank": 18
        },
        "2601.03781v1": {
          "score": 0.7960281372070312,
          "rank": 19
        },
        "2601.04348v1": {
          "score": 0.7953019142150879,
          "rank": 20
        },
        "2601.04153v1": {
          "score": 0.7946419715881348,
          "rank": 21
        },
        "2601.04264v1": {
          "score": 0.7945780754089355,
          "rank": 22
        },
        "2601.04263v1": {
          "score": 0.7945056557655334,
          "rank": 23
        },
        "2601.04342v1": {
          "score": 0.793363630771637,
          "rank": 24
        },
        "2601.05125v1": {
          "score": 0.7931427955627441,
          "rank": 25
        },
        "2601.04792v1": {
          "score": 0.7930439710617065,
          "rank": 26
        },
        "2601.04090v1": {
          "score": 0.7930347919464111,
          "rank": 27
        },
        "2601.04509v1": {
          "score": 0.792510449886322,
          "rank": 28
        },
        "2601.03992v1": {
          "score": 0.7924382090568542,
          "rank": 29
        },
        "2601.03885v1": {
          "score": 0.7913649082183838,
          "rank": 30
        },
        "2601.04352v1": {
          "score": 0.7908148169517517,
          "rank": 31
        },
        "2601.03869v1": {
          "score": 0.7903115153312683,
          "rank": 32
        },
        "2601.04397v1": {
          "score": 0.7895934581756592,
          "rank": 33
        },
        "2601.04807v1": {
          "score": 0.789306640625,
          "rank": 34
        },
        "2601.04775v1": {
          "score": 0.7890891432762146,
          "rank": 35
        },
        "2601.04359v1": {
          "score": 0.78859543800354,
          "rank": 36
        },
        "2601.04890v1": {
          "score": 0.7880295515060425,
          "rank": 37
        },
        "2601.05049v1": {
          "score": 0.7871679663658142,
          "rank": 38
        },
        "2601.05116v1": {
          "score": 0.7868409752845764,
          "rank": 39
        },
        "2601.04494v1": {
          "score": 0.7866911888122559,
          "rank": 40
        },
        "2601.04496v1": {
          "score": 0.7864392995834351,
          "rank": 41
        },
        "2601.03500v1": {
          "score": 0.7854139804840088,
          "rank": 42
        },
        "2601.04005v1": {
          "score": 0.7852869033813477,
          "rank": 43
        },
        "2601.04378v1": {
          "score": 0.7851467728614807,
          "rank": 44
        },
        "2601.04719v1": {
          "score": 0.7850865125656128,
          "rank": 45
        },
        "2601.05138v1": {
          "score": 0.7845096588134766,
          "rank": 46
        },
        "2601.04476v1": {
          "score": 0.7841135263442993,
          "rank": 47
        },
        "2601.04754v1": {
          "score": 0.7835986614227295,
          "rank": 48
        },
        "2601.04825v1": {
          "score": 0.7835439443588257,
          "rank": 49
        },
        "2601.04278v1": {
          "score": 0.7834998369216919,
          "rank": 50
        },
        "2601.04791v1": {
          "score": 0.7834125757217407,
          "rank": 51
        },
        "2601.04068v2": {
          "score": 0.782970130443573,
          "rank": 52
        },
        "2601.04120v1": {
          "score": 0.7829670310020447,
          "rank": 53
        },
        "2601.04785v1": {
          "score": 0.7826099991798401,
          "rank": 54
        },
        "2601.04518v1": {
          "score": 0.7818440198898315,
          "rank": 55
        },
        "2601.04891v1": {
          "score": 0.7816761136054993,
          "rank": 56
        },
        "2601.05174v1": {
          "score": 0.7815588116645813,
          "rank": 57
        },
        "2601.03875v1": {
          "score": 0.7811076045036316,
          "rank": 58
        },
        "2601.04984v1": {
          "score": 0.7809116244316101,
          "rank": 59
        },
        "2601.03714v2": {
          "score": 0.7809070348739624,
          "rank": 60
        },
        "2601.04052v1": {
          "score": 0.780754029750824,
          "rank": 61
        },
        "2601.04442v1": {
          "score": 0.7806493043899536,
          "rank": 62
        },
        "2601.04572v1": {
          "score": 0.7800506949424744,
          "rank": 63
        },
        "2601.04056v1": {
          "score": 0.7798811197280884,
          "rank": 64
        },
        "2601.05017v1": {
          "score": 0.779876708984375,
          "rank": 65
        },
        "2601.05249v1": {
          "score": 0.7797084450721741,
          "rank": 66
        },
        "2601.05200v1": {
          "score": 0.7795652151107788,
          "rank": 67
        },
        "2601.03617v1": {
          "score": 0.7793291807174683,
          "rank": 68
        },
        "2601.04275v1": {
          "score": 0.7792707085609436,
          "rank": 69
        },
        "2601.04912v1": {
          "score": 0.7792260646820068,
          "rank": 70
        },
        "2601.04061v1": {
          "score": 0.7792060971260071,
          "rank": 71
        },
        "2601.03566v1": {
          "score": 0.7790466547012329,
          "rank": 72
        },
        "2601.03919v2": {
          "score": 0.7789724469184875,
          "rank": 73
        },
        "2601.03728v1": {
          "score": 0.7786658406257629,
          "rank": 74
        },
        "2601.04361v1": {
          "score": 0.778350830078125,
          "rank": 75
        },
        "2601.04682v1": {
          "score": 0.7781173586845398,
          "rank": 76
        },
        "2601.04651v1": {
          "score": 0.7780045866966248,
          "rank": 77
        },
        "2601.03976v1": {
          "score": 0.7779839634895325,
          "rank": 78
        },
        "2601.03683v1": {
          "score": 0.7777135968208313,
          "rank": 79
        },
        "2601.03743v1": {
          "score": 0.7772862911224365,
          "rank": 80
        },
        "2601.04539v1": {
          "score": 0.7772287130355835,
          "rank": 81
        },
        "2601.04646v1": {
          "score": 0.7771490216255188,
          "rank": 82
        },
        "2601.04302v1": {
          "score": 0.7768779993057251,
          "rank": 83
        },
        "2601.05237v1": {
          "score": 0.7764729261398315,
          "rank": 84
        },
        "2601.03858v1": {
          "score": 0.7763898372650146,
          "rank": 85
        },
        "2601.04824v1": {
          "score": 0.7763887047767639,
          "rank": 86
        },
        "2601.04172v1": {
          "score": 0.7762518525123596,
          "rank": 87
        },
        "2601.03577v1": {
          "score": 0.7762197256088257,
          "rank": 88
        },
        "2601.05127v1": {
          "score": 0.7761896848678589,
          "rank": 89
        },
        "2601.03528v1": {
          "score": 0.7761756181716919,
          "rank": 90
        },
        "2601.04537v1": {
          "score": 0.7761622071266174,
          "rank": 91
        },
        "2601.03629v1": {
          "score": 0.7761496305465698,
          "rank": 92
        },
        "2601.04582v1": {
          "score": 0.7760175466537476,
          "rank": 93
        },
        "2601.03596v1": {
          "score": 0.775921106338501,
          "rank": 94
        },
        "2601.04752v1": {
          "score": 0.7757474184036255,
          "rank": 95
        },
        "2601.04777v1": {
          "score": 0.7752881050109863,
          "rank": 96
        },
        "2601.04864v1": {
          "score": 0.7752838730812073,
          "rank": 97
        },
        "2601.03540v1": {
          "score": 0.7751222848892212,
          "rank": 98
        },
        "2601.04778v1": {
          "score": 0.7750607132911682,
          "rank": 99
        },
        "2601.04054v1": {
          "score": 0.774882435798645,
          "rank": 100
        }
      }
    },
    {
      "type": "llm_query",
      "tag": "sr-bench",
      "paper_tag": "query:sr-bench",
      "query_text": "Find research papers describing standardized benchmarks, datasets, and evaluation frameworks for symbolic regression to facilitate comparative performance analysis.",
      "sim_scores": {
        "2601.04051v1": {
          "score": 0.7753354907035828,
          "rank": 1
        },
        "2601.05103v1": {
          "score": 0.7743275165557861,
          "rank": 2
        },
        "2601.05099v1": {
          "score": 0.7735110521316528,
          "rank": 3
        },
        "2601.03988v1": {
          "score": 0.766573429107666,
          "rank": 4
        },
        "2601.05051v1": {
          "score": 0.7646307945251465,
          "rank": 5
        },
        "2601.03496v1": {
          "score": 0.7622601389884949,
          "rank": 6
        },
        "2601.04764v1": {
          "score": 0.7596703171730042,
          "rank": 7
        },
        "2601.04568v1": {
          "score": 0.7566126585006714,
          "rank": 8
        },
        "2601.03750v1": {
          "score": 0.7558351159095764,
          "rank": 9
        },
        "2601.03748v1": {
          "score": 0.7551361322402954,
          "rank": 10
        },
        "2601.03986v1": {
          "score": 0.7533584833145142,
          "rank": 11
        },
        "2601.04932v1": {
          "score": 0.7531380653381348,
          "rank": 12
        },
        "2601.04574v1": {
          "score": 0.7529528737068176,
          "rank": 13
        },
        "2601.05200v1": {
          "score": 0.7525243163108826,
          "rank": 14
        },
        "2601.03794v1": {
          "score": 0.7523426413536072,
          "rank": 15
        },
        "2601.03908v1": {
          "score": 0.7510481476783752,
          "rank": 16
        },
        "2601.05027v1": {
          "score": 0.7508887052536011,
          "rank": 17
        },
        "2601.03621v1": {
          "score": 0.7480133175849915,
          "rank": 18
        },
        "2601.04618v1": {
          "score": 0.7463968396186829,
          "rank": 19
        },
        "2601.03540v1": {
          "score": 0.7458453178405762,
          "rank": 20
        },
        "2601.04646v1": {
          "score": 0.7456868886947632,
          "rank": 21
        },
        "2601.04945v1": {
          "score": 0.744904637336731,
          "rank": 22
        },
        "2601.04833v1": {
          "score": 0.7423791885375977,
          "rank": 23
        },
        "2601.05082v1": {
          "score": 0.7410823702812195,
          "rank": 24
        },
        "2601.03618v1": {
          "score": 0.7405706644058228,
          "rank": 25
        },
        "2601.03606v1": {
          "score": 0.739815354347229,
          "rank": 26
        },
        "2601.04582v1": {
          "score": 0.7397937774658203,
          "rank": 27
        },
        "2601.05125v1": {
          "score": 0.7395361661911011,
          "rank": 28
        },
        "2601.04110v1": {
          "score": 0.739496111869812,
          "rank": 29
        },
        "2601.04447v1": {
          "score": 0.7394533157348633,
          "rank": 30
        },
        "2601.04577v1": {
          "score": 0.7391477823257446,
          "rank": 31
        },
        "2601.04918v1": {
          "score": 0.7381179332733154,
          "rank": 32
        },
        "2601.03812v1": {
          "score": 0.737990140914917,
          "rank": 33
        },
        "2601.04888v1": {
          "score": 0.7372545599937439,
          "rank": 34
        },
        "2601.04720v1": {
          "score": 0.7372164726257324,
          "rank": 35
        },
        "2601.04770v1": {
          "score": 0.7369735240936279,
          "rank": 36
        },
        "2601.04458v1": {
          "score": 0.7368350028991699,
          "rank": 37
        },
        "2601.04138v1": {
          "score": 0.7363725900650024,
          "rank": 38
        },
        "2601.04879v1": {
          "score": 0.7363351583480835,
          "rank": 39
        },
        "2601.04100v1": {
          "score": 0.7356231212615967,
          "rank": 40
        },
        "2601.04455v1": {
          "score": 0.7353509664535522,
          "rank": 41
        },
        "2601.03940v1": {
          "score": 0.7349995374679565,
          "rank": 42
        },
        "2601.04390v1": {
          "score": 0.7349967956542969,
          "rank": 43
        },
        "2601.03511v1": {
          "score": 0.7346742749214172,
          "rank": 44
        },
        "2601.04859v1": {
          "score": 0.7343786954879761,
          "rank": 45
        },
        "2601.04919v1": {
          "score": 0.7343382835388184,
          "rank": 46
        },
        "2601.04483v1": {
          "score": 0.7334868907928467,
          "rank": 47
        },
        "2601.03994v1": {
          "score": 0.7334229946136475,
          "rank": 48
        },
        "2601.03743v1": {
          "score": 0.7330451011657715,
          "rank": 49
        },
        "2601.04757v1": {
          "score": 0.7329248189926147,
          "rank": 50
        },
        "2601.05038v1": {
          "score": 0.7328906655311584,
          "rank": 51
        },
        "2601.03676v1": {
          "score": 0.732722818851471,
          "rank": 52
        },
        "2601.04853v1": {
          "score": 0.7325865030288696,
          "rank": 53
        },
        "2601.04941v1": {
          "score": 0.7321956753730774,
          "rank": 54
        },
        "2601.05184v1": {
          "score": 0.7319697141647339,
          "rank": 55
        },
        "2601.04278v1": {
          "score": 0.7318203449249268,
          "rank": 56
        },
        "2601.03882v1": {
          "score": 0.7315282225608826,
          "rank": 57
        },
        "2601.04423v1": {
          "score": 0.7313590049743652,
          "rank": 58
        },
        "2601.04301v1": {
          "score": 0.7307250499725342,
          "rank": 59
        },
        "2601.04350v1": {
          "score": 0.7305046916007996,
          "rank": 60
        },
        "2601.03605v1": {
          "score": 0.7299743890762329,
          "rank": 61
        },
        "2601.04424v1": {
          "score": 0.72989821434021,
          "rank": 62
        },
        "2601.05219v1": {
          "score": 0.7295722961425781,
          "rank": 63
        },
        "2601.04768v1": {
          "score": 0.7293374538421631,
          "rank": 64
        },
        "2601.05227v1": {
          "score": 0.7291918992996216,
          "rank": 65
        },
        "2601.04913v1": {
          "score": 0.7285228967666626,
          "rank": 66
        },
        "2601.04377v1": {
          "score": 0.7278456687927246,
          "rank": 67
        },
        "2601.04643v1": {
          "score": 0.7276092767715454,
          "rank": 68
        },
        "2601.03674v1": {
          "score": 0.7274667620658875,
          "rank": 69
        },
        "2601.04799v1": {
          "score": 0.7274366617202759,
          "rank": 70
        },
        "2601.04801v1": {
          "score": 0.7274318933486938,
          "rank": 71
        },
        "2601.04395v1": {
          "score": 0.7274038791656494,
          "rank": 72
        },
        "2601.03682v1": {
          "score": 0.7272725105285645,
          "rank": 73
        },
        "2601.04651v1": {
          "score": 0.7267820239067078,
          "rank": 74
        },
        "2601.04060v1": {
          "score": 0.7266676425933838,
          "rank": 75
        },
        "2601.03584v1": {
          "score": 0.7257616519927979,
          "rank": 76
        },
        "2601.04524v1": {
          "score": 0.725727915763855,
          "rank": 77
        },
        "2601.05049v1": {
          "score": 0.7255997657775879,
          "rank": 78
        },
        "2601.04361v1": {
          "score": 0.7254862189292908,
          "rank": 79
        },
        "2601.03786v1": {
          "score": 0.7253741025924683,
          "rank": 80
        },
        "2601.04632v1": {
          "score": 0.7253701686859131,
          "rank": 81
        },
        "2601.03505v1": {
          "score": 0.724955677986145,
          "rank": 82
        },
        "2601.03559v1": {
          "score": 0.7249155044555664,
          "rank": 83
        },
        "2601.04891v1": {
          "score": 0.7248550057411194,
          "rank": 84
        },
        "2601.04670v1": {
          "score": 0.7248122096061707,
          "rank": 85
        },
        "2601.05163v1": {
          "score": 0.7245351076126099,
          "rank": 86
        },
        "2601.04085v1": {
          "score": 0.7242481708526611,
          "rank": 87
        },
        "2601.03669v1": {
          "score": 0.7242119908332825,
          "rank": 88
        },
        "2601.04121v1": {
          "score": 0.7241107225418091,
          "rank": 89
        },
        "2601.04885v1": {
          "score": 0.7237656116485596,
          "rank": 90
        },
        "2601.04992v1": {
          "score": 0.7234099507331848,
          "rank": 91
        },
        "2601.04895v1": {
          "score": 0.723365068435669,
          "rank": 92
        },
        "2601.04587v1": {
          "score": 0.7230955958366394,
          "rank": 93
        },
        "2601.03808v1": {
          "score": 0.7229576706886292,
          "rank": 94
        },
        "2601.03728v1": {
          "score": 0.7229475378990173,
          "rank": 95
        },
        "2601.04722v1": {
          "score": 0.7227728366851807,
          "rank": 96
        },
        "2601.03731v1": {
          "score": 0.7226325273513794,
          "rank": 97
        },
        "2601.04157v1": {
          "score": 0.7223372459411621,
          "rank": 98
        },
        "2601.03910v1": {
          "score": 0.7222329378128052,
          "rank": 99
        },
        "2601.03769v2": {
          "score": 0.7221691608428955,
          "rank": 100
        }
      }
    },
    {
      "type": "llm_query",
      "tag": "大厂llm",
      "paper_tag": "query:大厂llm",
      "query_text": "Find research papers describing the technical architectures, training methodologies, and evaluation benchmarks of large language models as detailed in technical reports from major industry leaders like OpenAI, Google, and Meta.",
      "sim_scores": {
        "2601.03540v1": {
          "score": 0.7783826589584351,
          "rank": 1
        },
        "2601.03743v1": {
          "score": 0.7736314535140991,
          "rank": 2
        },
        "2601.03986v1": {
          "score": 0.7729078531265259,
          "rank": 3
        },
        "2601.04879v1": {
          "score": 0.7713035345077515,
          "rank": 4
        },
        "2601.03496v1": {
          "score": 0.7710988521575928,
          "rank": 5
        },
        "2601.05163v1": {
          "score": 0.7702187299728394,
          "rank": 6
        },
        "2601.03748v1": {
          "score": 0.7689083814620972,
          "rank": 7
        },
        "2601.04891v1": {
          "score": 0.7672973871231079,
          "rank": 8
        },
        "2601.04632v1": {
          "score": 0.7668547034263611,
          "rank": 9
        },
        "2601.03618v1": {
          "score": 0.7647042870521545,
          "rank": 10
        },
        "2601.04932v1": {
          "score": 0.7640893459320068,
          "rank": 11
        },
        "2601.03908v1": {
          "score": 0.7638229131698608,
          "rank": 12
        },
        "2601.04696v1": {
          "score": 0.7638076543807983,
          "rank": 13
        },
        "2601.03511v1": {
          "score": 0.7627953290939331,
          "rank": 14
        },
        "2601.04888v1": {
          "score": 0.7617818117141724,
          "rank": 15
        },
        "2601.03812v1": {
          "score": 0.7606911659240723,
          "rank": 16
        },
        "2601.05103v1": {
          "score": 0.7595980167388916,
          "rank": 17
        },
        "2601.04764v1": {
          "score": 0.7584493160247803,
          "rank": 18
        },
        "2601.04377v1": {
          "score": 0.7582505941390991,
          "rank": 19
        },
        "2601.05125v1": {
          "score": 0.7580000758171082,
          "rank": 20
        },
        "2601.05051v1": {
          "score": 0.7564728260040283,
          "rank": 21
        },
        "2601.03794v1": {
          "score": 0.7562715411186218,
          "rank": 22
        },
        "2601.05099v1": {
          "score": 0.7559927701950073,
          "rank": 23
        },
        "2601.04823v1": {
          "score": 0.7559687495231628,
          "rank": 24
        },
        "2601.04859v1": {
          "score": 0.7559125423431396,
          "rank": 25
        },
        "2601.03676v1": {
          "score": 0.755710244178772,
          "rank": 26
        },
        "2601.04597v1": {
          "score": 0.7557075023651123,
          "rank": 27
        },
        "2601.05047v1": {
          "score": 0.7546433210372925,
          "rank": 28
        },
        "2601.04568v1": {
          "score": 0.7544409036636353,
          "rank": 29
        },
        "2601.04945v1": {
          "score": 0.7542140483856201,
          "rank": 30
        },
        "2601.04526v1": {
          "score": 0.7530401945114136,
          "rank": 31
        },
        "2601.04577v1": {
          "score": 0.752936601638794,
          "rank": 32
        },
        "2601.04919v1": {
          "score": 0.751502275466919,
          "rank": 33
        },
        "2601.04646v1": {
          "score": 0.7505776882171631,
          "rank": 34
        },
        "2601.04424v1": {
          "score": 0.7504401206970215,
          "rank": 35
        },
        "2601.04036v1": {
          "score": 0.749508261680603,
          "rank": 36
        },
        "2601.03752v1": {
          "score": 0.7490310668945312,
          "rank": 37
        },
        "2601.04060v1": {
          "score": 0.7488702535629272,
          "rank": 38
        },
        "2601.04498v1": {
          "score": 0.7487714290618896,
          "rank": 39
        },
        "2601.05191v1": {
          "score": 0.7487378120422363,
          "rank": 40
        },
        "2601.04768v1": {
          "score": 0.7483259439468384,
          "rank": 41
        },
        "2601.05170v1": {
          "score": 0.7472474575042725,
          "rank": 42
        },
        "2601.03988v1": {
          "score": 0.7468150854110718,
          "rank": 43
        },
        "2601.03725v1": {
          "score": 0.7466210126876831,
          "rank": 44
        },
        "2601.05192v1": {
          "score": 0.7465238571166992,
          "rank": 45
        },
        "2601.04458v1": {
          "score": 0.7463256120681763,
          "rank": 46
        },
        "2601.03624v1": {
          "score": 0.7462921142578125,
          "rank": 47
        },
        "2601.04700v1": {
          "score": 0.7461065649986267,
          "rank": 48
        },
        "2601.03926v1": {
          "score": 0.7460695505142212,
          "rank": 49
        },
        "2601.04651v1": {
          "score": 0.7460651993751526,
          "rank": 50
        },
        "2601.05101v1": {
          "score": 0.7460476756095886,
          "rank": 51
        },
        "2601.04582v1": {
          "score": 0.7459840774536133,
          "rank": 52
        },
        "2601.05184v1": {
          "score": 0.7458816766738892,
          "rank": 53
        },
        "2601.04742v1": {
          "score": 0.7454283237457275,
          "rank": 54
        },
        "2601.03606v1": {
          "score": 0.7449700832366943,
          "rank": 55
        },
        "2601.05106v1": {
          "score": 0.7447441220283508,
          "rank": 56
        },
        "2601.04571v1": {
          "score": 0.7446545362472534,
          "rank": 57
        },
        "2601.03746v1": {
          "score": 0.7442448735237122,
          "rank": 58
        },
        "2601.04703v1": {
          "score": 0.7440152764320374,
          "rank": 59
        },
        "2601.04618v1": {
          "score": 0.7437623739242554,
          "rank": 60
        },
        "2601.04633v1": {
          "score": 0.743546724319458,
          "rank": 61
        },
        "2601.04819v1": {
          "score": 0.7429178953170776,
          "rank": 62
        },
        "2601.04395v1": {
          "score": 0.7426818013191223,
          "rank": 63
        },
        "2601.03597v1": {
          "score": 0.7424194812774658,
          "rank": 64
        },
        "2601.04750v1": {
          "score": 0.7422598600387573,
          "rank": 65
        },
        "2601.05009v1": {
          "score": 0.7420927286148071,
          "rank": 66
        },
        "2601.04889v1": {
          "score": 0.7417516112327576,
          "rank": 67
        },
        "2601.04853v1": {
          "score": 0.7413814067840576,
          "rank": 68
        },
        "2601.05091v1": {
          "score": 0.741226077079773,
          "rank": 69
        },
        "2601.05039v1": {
          "score": 0.7410985231399536,
          "rank": 70
        },
        "2601.04131v1": {
          "score": 0.7406868934631348,
          "rank": 71
        },
        "2601.04574v1": {
          "score": 0.7405391335487366,
          "rank": 72
        },
        "2601.03515v1": {
          "score": 0.7402230501174927,
          "rank": 73
        },
        "2601.04094v1": {
          "score": 0.7401608228683472,
          "rank": 74
        },
        "2601.04569v1": {
          "score": 0.7399345636367798,
          "rank": 75
        },
        "2601.04349v1": {
          "score": 0.7397173643112183,
          "rank": 76
        },
        "2601.03872v1": {
          "score": 0.7395703196525574,
          "rank": 77
        },
        "2601.03698v1": {
          "score": 0.7394415140151978,
          "rank": 78
        },
        "2601.03648v1": {
          "score": 0.7391561269760132,
          "rank": 79
        },
        "2601.05027v1": {
          "score": 0.7391443848609924,
          "rank": 80
        },
        "2601.04734v1": {
          "score": 0.7383998036384583,
          "rank": 81
        },
        "2601.05038v1": {
          "score": 0.738386332988739,
          "rank": 82
        },
        "2601.03699v1": {
          "score": 0.7379134893417358,
          "rank": 83
        },
        "2601.04720v1": {
          "score": 0.7377450466156006,
          "rank": 84
        },
        "2601.04801v1": {
          "score": 0.737719714641571,
          "rank": 85
        },
        "2601.04336v1": {
          "score": 0.7376198172569275,
          "rank": 86
        },
        "2601.04726v1": {
          "score": 0.7375714778900146,
          "rank": 87
        },
        "2601.04019v1": {
          "score": 0.7371687889099121,
          "rank": 88
        },
        "2601.03878v1": {
          "score": 0.7370768189430237,
          "rank": 89
        },
        "2601.03558v1": {
          "score": 0.7368980646133423,
          "rank": 90
        },
        "2601.04260v1": {
          "score": 0.7366098165512085,
          "rank": 91
        },
        "2601.04390v1": {
          "score": 0.7365672588348389,
          "rank": 92
        },
        "2601.04861v1": {
          "score": 0.7364248037338257,
          "rank": 93
        },
        "2601.04707v1": {
          "score": 0.7362047433853149,
          "rank": 94
        },
        "2601.05187v1": {
          "score": 0.736090898513794,
          "rank": 95
        },
        "2601.04157v1": {
          "score": 0.7358376383781433,
          "rank": 96
        },
        "2601.04885v1": {
          "score": 0.7357035279273987,
          "rank": 97
        },
        "2601.03940v1": {
          "score": 0.7355941534042358,
          "rank": 98
        },
        "2601.05200v1": {
          "score": 0.7354556322097778,
          "rank": 99
        },
        "2601.03605v1": {
          "score": 0.7354505062103271,
          "rank": 100
        }
      }
    }
  ]
}