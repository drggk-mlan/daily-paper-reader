{
  "mode": "standard",
  "generated_at": "2026-01-27T04:04:19.023408+00:00",
  "stats": {
    "mode": "standard",
    "tag_count": 3,
    "deep_divecandidates": 2,
    "deep_cap": 8,
    "deep_selected": 2,
    "quick_candidates": 10,
    "quick_skim_target": 13,
    "quick_selected": 10
  },
  "deep_dive": [
    {
      "id": "2601.17899v1",
      "title": "Evolving Interdependent Operators with Large Language Models for Multi-Objective Combinatorial Optimization",
      "abstract": "Neighborhood search operators are critical to the performance of Multi-Objective Evolutionary Algorithms (MOEAs) and rely heavily on expert design. Although recent LLM-based Automated Heuristic Design (AHD) methods have made notable progress, they primarily optimize individual heuristics or components independently, lacking explicit exploration and exploitation of dynamic coupling relationships between multiple operators. In this paper, multi-operator optimization in MOEAs is formulated as a Markov decision process, enabling the improvement of interdependent operators through sequential decision-making. To address this, we propose the Evolution of Operator Combination (E2OC) framework for MOEAs, which achieves the co-evolution of design strategies and executable codes. E2OC employs Monte Carlo Tree Search to progressively search combinations of operator design strategies and adopts an operator rotation mechanism to identify effective operator configurations while supporting the integration of mainstream AHD methods as the underlying designer. Experimental results across AHD tasks with varying objectives and problem scales show that E2OC consistently outperforms state-of-the-art AHD and other multi-heuristic co-design frameworks, demonstrating strong generalization and sustained optimization capability.",
      "authors": [
        "Junhao Qiu",
        "Xin Chen",
        "Liang Ge",
        "Liyong Lin",
        "Zhichao Lu",
        "Qingfu Zhang"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-01-25 16:31:07+00:00",
      "link": "https://arxiv.org/pdf/2601.17899v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 10.0,
      "llm_evidence_en": "LLM-based automated heuristic design and evolution of operators",
      "llm_evidence_cn": "基于大语言模型的自动化启发式设计与算子演化",
      "llm_evidence": "基于大语言模型的自动化启发式设计与算子演化",
      "llm_tldr_en": "Proposes E2OC framework using LLMs to evolve interdependent neighborhood search operators for multi-objective optimization.",
      "llm_tldr_cn": "提出E2OC框架，利用大模型演化多目标优化中的相互依赖邻域搜索算子。",
      "llm_tldr": "提出E2OC框架，利用大模型演化多目标优化中的相互依赖邻域搜索算子。",
      "llm_tags": [
        "keyword:LNS",
        "keyword:EOH",
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.18446v1",
      "title": "Scaling Behaviors of Evolutionary Algorithms on GPUs: When Does Parallelism Pay Off?",
      "abstract": "Evolutionary algorithms (EAs) are increasingly implemented on graphics processing units (GPUs) to leverage parallel processing capabilities for enhanced efficiency. However, existing studies largely emphasize the raw speedup obtained by porting individual algorithms from CPUs to GPUs. Consequently, these studies offer limited insight into when and why GPU parallelism fundamentally benefits EAs. To address this gap, we investigate how GPU parallelism alters the behavior of EAs beyond simple acceleration metrics. We conduct a systematic empirical study of 16 representative EAs on 30 benchmark problems. Specifically, we compare CPU and GPU executions across a wide range of problem dimensionalities and population sizes. Our results reveal that the impact of GPU acceleration is highly heterogeneous and depends strongly on algorithmic structure. We further demonstrate that conventional fixed-budget evaluation based on the number of function evaluations (FEs) is inadequate for GPU execution. In contrast, fixed-time evaluation uncovers performance characteristics that are unobservable under small or practically constrained FE budgets, particularly for adaptive and exploration-oriented algorithms. Moreover, we identify distinct scaling regimes in which GPU parallelism is beneficial, saturates, or degrades as problem dimensionality and population size increase. Crucially, we show that large populations enabled by GPUs not only improve hardware utilization but also reveal algorithm-specific convergence and diversity dynamics that are difficult to observe under CPU-constrained settings. Consequently, our findings indicate that GPU parallelism is not strictly an implementation detail, but a pivotal factor that influences how EAs should be evaluated, compared, and designed for modern computing platforms.",
      "authors": [
        "Xinmeng Yu",
        "Tao Jiang",
        "Ran Cheng",
        "Yaochu Jin",
        "Kay Chen Tan"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-01-26 12:55:21+00:00",
      "link": "https://arxiv.org/pdf/2601.18446v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 8.0,
      "llm_evidence_en": "systematic study of evolutionary algorithms on GPUs",
      "llm_evidence_cn": "GPU上进化算法的系统性研究",
      "llm_evidence": "GPU上进化算法的系统性研究",
      "llm_tldr_en": "Investigates how GPU parallelism fundamentally alters the behavior and efficiency of evolutionary algorithms.",
      "llm_tldr_cn": "研究GPU并行化如何从根本上改变进化算法的行为与效率。",
      "llm_tldr": "研究GPU并行化如何从根本上改变进化算法的行为与效率。",
      "llm_tags": [
        "keyword:EOH"
      ]
    }
  ],
  "quick_skim": [
    {
      "id": "2601.17428v1",
      "title": "Scaling Rough Terrain Locomotion with Automatic Curriculum Reinforcement Learning",
      "abstract": "Curriculum learning has demonstrated substantial effectiveness in robot learning. However, it still faces limitations when scaling to complex, wide-ranging task spaces. Such task spaces often lack a well-defined difficulty structure, making the difficulty ordering required by previous methods challenging to define. We propose a Learning Progress-based Automatic Curriculum Reinforcement Learning (LP-ACRL) framework, which estimates the agent's learning progress online and adaptively adjusts the task-sampling distribution, thereby enabling automatic curriculum generation without prior knowledge of the difficulty distribution over the task space. Policies trained with LP-ACRL enable the ANYmal D quadruped to achieve and maintain stable, high-speed locomotion at 2.5 m/s linear velocity and 3.0 rad/s angular velocity across diverse terrains, including stairs, slopes, gravel, and low-friction flat surfaces--whereas previous methods have generally been limited to high speeds on flat terrain or low speeds on complex terrain. Experimental results demonstrate that LP-ACRL exhibits strong scalability and real-world applicability, providing a robust baseline for future research on curriculum generation in complex, wide-ranging robotic learning task spaces.",
      "authors": [
        "Ziming Li",
        "Chenhao Li",
        "Marco Hutter"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-01-24 11:54:16+00:00",
      "link": "https://arxiv.org/pdf/2601.17428v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Automatic curriculum generation for reinforcement learning",
      "llm_evidence_cn": "强化学习的自动课程生成",
      "llm_evidence": "强化学习的自动课程生成",
      "llm_tldr_en": "Proposes LP-ACRL for automatic curriculum generation in complex robotic locomotion tasks.",
      "llm_tldr_cn": "提出LP-ACRL框架，在复杂的机器人运动任务中实现自动课程生成。",
      "llm_tldr": "提出LP-ACRL框架，在复杂的机器人运动任务中实现自动课程生成。",
      "llm_tags": [
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.17483v1",
      "title": "Automatic Stability and Recovery for Neural Network Training",
      "abstract": "Training modern neural networks is increasingly fragile, with rare but severe destabilizing updates often causing irreversible divergence or silent performance degradation. Existing optimization methods primarily rely on preventive mechanisms embedded within the optimizer, offering limited ability to detect and recover from instability once it occurs. We introduce a supervisory runtime stability framework that treats optimization as a controlled stochastic process. By isolating an innovation signal derived from secondary measurements, such as validation probes, the framework enables automatic detection and recovery from destabilizing updates without modifying the underlying optimizer. We provide theoretical runtime safety guarantees that formalize bounded degradation and recovery. Our implementation incurs minimal overhead and is compatible with memory-constrained training settings.",
      "authors": [
        "Barak Or"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-24 15:14:54+00:00",
      "link": "https://arxiv.org/pdf/2601.17483v1",
      "tags": [
        "keyword:EAA"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "automatic stability and recovery in training",
      "llm_evidence_cn": "训练中的自动稳定性与恢复",
      "llm_evidence": "训练中的自动稳定性与恢复",
      "llm_tldr_en": "An automatic framework to detect and recover from instability during neural network training.",
      "llm_tldr_cn": "一种用于在神经网络训练过程中自动检测并恢复不稳定状态的框架。",
      "llm_tldr": "一种用于在神经网络训练过程中自动检测并恢复不稳定状态的框架。",
      "llm_tags": [
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.17513v1",
      "title": "Constrained Multi-Objective Genetic Algorithm Variants for Design and Optimization of Tri-Band Microstrip Patch Antenna loaded CSRR for IoT Applications: A Comparative Case Study",
      "abstract": "This paper presents an automated antenna design and optimization framework employing multi-objective genetic algorithms (MOGAs) to investigate various evolutionary optimization approaches, with a primary emphasis on multi-band frequency optimization. Five MOGA variants were implemented and compared: the Pareto genetic algorithm (PGA), non-dominated sorting genetic algorithm with niching (NSGA-I), non-dominated sorting genetic algorithm with elitism (NSGA-II), non-dominated sorting genetic algorithm using reference points (NSGA-III), and strength Pareto evolutionary algorithm (SPEA). These algorithms are employed to design and optimize microstrip patch antennas loaded with complementary split-ring resonators (CSRRs). A weighted-sum scalarization approach was adopted within a single-objective genetic algorithm framework enhanced with domain-specific constraint handling mechanisms. The optimization addresses the conflicting objectives of minimizing the return loss ($S_{11} < -10$~dB) and achieving multi-band resonance at 2.4~GHz, 3.6~GHz, and 5.2~GHz. The proposed method delivers a superior overall performance by aggregating these objectives into a unified fitness function encompassing $S_{11}$(2.4~GHz), $S_{11}$(3.6~GHz), and $S_{11}$(5.2~GHz). This approach effectively balances all three frequency bands simultaneously, rather than exploring trade-off solutions typical of traditional multi-objective approaches. The antenna was printed on a Rogers RT5880 substrate with a dielectric constant of 2.2 , loss tangent of 0.0009 , and thickness of 1.57~mm . Scalarization approach achieved return loss values of $-21.56$~dB, $-16.60$~dB, and $-27.69$~dB, with corresponding gains of 1.96~dBi, 2.6~dB, and 3.99~dBi at 2.4~GHz, 3.6~GHz, and 5.2~GHz, respectively.",
      "authors": [
        "Moahmed Hamza Boulaich",
        "Said Ohamouddou",
        "Mohammed Ali Ennasar",
        "Abdelatif El Afia"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.NI"
      ],
      "published": "2026-01-24 16:25:28+00:00",
      "link": "https://arxiv.org/pdf/2601.17513v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "automated antenna design using evolutionary optimization",
      "llm_evidence_cn": "使用进化优化进行自动化天线设计",
      "llm_evidence": "使用进化优化进行自动化天线设计",
      "llm_tldr_en": "Compares five multi-objective genetic algorithm variants for automated antenna design and optimization.",
      "llm_tldr_cn": "比较了五种多目标遗传算法变体在自动化天线设计与优化中的应用。",
      "llm_tldr": "比较了五种多目标遗传算法变体在自动化天线设计与优化中的应用。",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.17554v1",
      "title": "Full event interpretation with machine-learning-based particle-flow reconstruction in the CMS detector",
      "abstract": "The particle-flow (PF) algorithm constructs a global description of each particle collision by producing a comprehensive list of final-state particles, and is central to event reconstruction in the CMS experiment at the CERN LHC. The existing PF implementation relies on physics-motivated heuristics and assumptions that can be replaced by machine-learning (ML) models trained directly on simulated data and naturally suited to modern graphics processing units (GPUs). A state-of-the-art ML-based PF (MLPF) reconstruction algorithm, implemented within the CMS software framework, is presented. The MLPF algorithm performs a learnable full-event reconstruction on GPUs, generalizes across detector conditions and collision energies, and replaces multiple modular reconstruction steps with a single unified model. Physics performance comparable to standard PF reconstruction is achieved in both simulation and data, with improved jet energy resolution and inference time. In simulated top quark-antiquark events under LHC Run-3 (2023$-$2024) conditions, the jet energy resolution improves by 10$-$20% for jets with transverse momentum between 30$-$100 GeV. Inference time is evaluated using simulated multijet events, with a median of 20 ms per event on an Nvidia L4 GPU, compared to approximately 110 ms for the standard CMS PF reconstruction.",
      "authors": [
        "CMS Collaboration"
      ],
      "primary_category": "physics.ins-det",
      "categories": [
        "physics.ins-det",
        "hep-ex"
      ],
      "published": "2026-01-24 18:49:22+00:00",
      "link": "https://arxiv.org/pdf/2601.17554v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "replaces physics-motivated heuristics with learnable models",
      "llm_evidence_cn": "用可学习模型取代基于物理的启发式算法",
      "llm_evidence": "用可学习模型取代基于物理的启发式算法",
      "llm_tldr_en": "Replaces manual heuristics in particle-flow reconstruction with a learnable ML model for GPU efficiency.",
      "llm_tldr_cn": "在粒子流重建中用可学习的机器学习模型取代手动启发式算法，提高GPU效率。",
      "llm_tldr": "在粒子流重建中用可学习的机器学习模型取代手动启发式算法，提高GPU效率。",
      "llm_tags": [
        "keyword:EOH"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.17596v1",
      "title": "Learning to Ideate for Machine Learning Engineering Agents",
      "abstract": "Existing machine learning engineering (MLE) agents struggle to iteratively optimize their implemented algorithms for effectiveness. To address this, we introduce MLE-Ideator, a dual-agent framework that separates ideation from implementation. In our system, an implementation agent can request strategic help from a dedicated Ideator. We show this approach is effective in two ways. First, in a training-free setup, our framework significantly outperforms implementation-only agent baselines on MLE-Bench. Second, we demonstrate that the Ideator can be trained with reinforcement learning (RL) to generate more effective ideas. With only 1K training samples from 10 MLE tasks, our RL-trained Qwen3-8B Ideator achieves an 11.5% relative improvement compared to its untrained counterpart and surpasses Claude Sonnet 3.5. These results highlights a promising path toward training strategic AI systems for scientific discovery.",
      "authors": [
        "Yunxiang Zhang",
        "Kang Zhou",
        "Zhichao Xu",
        "Kiran Ramnath",
        "Yun Zhou",
        "Sangmin Woo",
        "Haibo Ding",
        "Lin Lee Cheong"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-24 21:20:33+00:00",
      "link": "https://arxiv.org/pdf/2601.17596v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Automated optimization of algorithms and iterative ideation for engineering agents",
      "llm_evidence_cn": "算法的自动优化和工程代理的迭代构思",
      "llm_evidence": "算法的自动优化和工程代理的迭代构思",
      "llm_tldr_en": "Introduces MLE-Ideator to iteratively optimize machine learning algorithms using reinforcement learning.",
      "llm_tldr_cn": "引入 MLE-Ideator 框架，利用强化学习迭代优化机器学习算法。",
      "llm_tldr": "引入 MLE-Ideator 框架，利用强化学习迭代优化机器学习算法。",
      "llm_tags": [
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.17808v1",
      "title": "Motif Diversity in Human Liver ChIP-seq Data Using MAP-Elites",
      "abstract": "Motif discovery is a core problem in computational biology, traditionally formulated as a likelihood optimization task that returns a single dominant motif from a DNA sequence dataset. However, regulatory sequence data admit multiple plausible motif explanations, reflecting underlying biological heterogeneity. In this work, we frame motif discovery as a quality-diversity problem and apply the MAP-Elites algorithm to evolve position weight matrix motifs under a likelihood-based fitness objective while explicitly preserving diversity across biologically meaningful dimensions. We evaluate MAP-Elites using three complementary behavioral characterizations that capture trade-offs between motif specificity, compositional structure, coverage, and robustness. Experiments on human CTCF liver ChIP-seq data aligned to the human reference genome compare MAP-Elites against a standard motif discovery tool, MEME, under matched evaluation criteria across stratified dataset subsets. Results show that MAP-Elites recovers multiple high-quality motif variants with fitness comparable to MEME's strongest solutions while revealing structured diversity obscured by single-solution approaches.",
      "authors": [
        "Alejandro Medina",
        "Mary Lauren Benton"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "q-bio.GN"
      ],
      "published": "2026-01-25 11:57:54+00:00",
      "link": "https://arxiv.org/pdf/2601.17808v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Evolutionary algorithm for motif discovery",
      "llm_evidence_cn": "用于基序发现的进化算法",
      "llm_evidence": "用于基序发现的进化算法",
      "llm_tldr_en": "Applies MAP-Elites to evolve diverse DNA motifs, aligning with interests in evolutionary heuristics.",
      "llm_tldr_cn": "应用 MAP-Elites 算法演化多样化的 DNA 基序，符合进化启发式算法的研究兴趣。",
      "llm_tldr": "应用 MAP-Elites 算法演化多样化的 DNA 基序，符合进化启发式算法的研究兴趣。",
      "llm_tags": [
        "keyword:EOH"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.18067v1",
      "title": "EvolVE: Evolutionary Search for LLM-based Verilog Generation and Optimization",
      "abstract": "Verilog's design cycle is inherently labor-intensive and necessitates extensive domain expertise. Although Large Language Models (LLMs) offer a promising pathway toward automation, their limited training data and intrinsic sequential reasoning fail to capture the strict formal logic and concurrency inherent in hardware systems. To overcome these barriers, we present EvolVE, the first framework to analyze multiple evolution strategies on chip design tasks, revealing that Monte Carlo Tree Search (MCTS) excels at maximizing functional correctness, while Idea-Guided Refinement (IGR) proves superior for optimization. We further leverage Structured Testbench Generation (STG) to accelerate the evolutionary process. To address the lack of complex optimization benchmarks, we introduce IC-RTL, targeting industry-scale problems derived from the National Integrated Circuit Contest. Evaluations establish EvolVE as the new state-of-the-art, achieving 98.1% on VerilogEval v2 and 92% on RTLLM v2. Furthermore, on the industry-scale IC-RTL suite, our framework surpasses reference implementations authored by contest participants, reducing the Power, Performance, Area (PPA) product by up to 66% in Huffman Coding and 17% in the geometric mean across all problems. The source code of the IC-RTL benchmark is available at https://github.com/weiber2002/ICRTL.",
      "authors": [
        "Wei-Po Hsin",
        "Ren-Hao Deng",
        "Yao-Ting Hsieh",
        "En-Ming Huang",
        "Shih-Hao Hung"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.NE",
        "cs.PL"
      ],
      "published": "2026-01-26 01:53:54+00:00",
      "link": "https://arxiv.org/pdf/2601.18067v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Evolutionary search strategies for optimization",
      "llm_evidence_cn": "用于优化的进化搜索策略",
      "llm_evidence": "用于优化的进化搜索策略",
      "llm_tldr_en": "Explores evolutionary strategies like MCTS and IGR to optimize LLM-based Verilog generation.",
      "llm_tldr_cn": "探索MCTS和IGR等进化策略，以优化基于大模型的Verilog生成。",
      "llm_tldr": "探索MCTS和IGR等进化策略，以优化基于大模型的Verilog生成。",
      "llm_tags": [
        "keyword:EOH"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.18130v1",
      "title": "RouteMoA: Dynamic Routing without Pre-Inference Boosts Efficient Mixture-of-Agents",
      "abstract": "Mixture-of-Agents (MoA) improves LLM performance through layered collaboration, but its dense topology raises costs and latency. Existing methods employ LLM judges to filter responses, yet still require all models to perform inference before judging, failing to cut costs effectively. They also lack model selection criteria and struggle with large model pools, where full inference is costly and can exceed context limits. To address this, we propose RouteMoA, an efficient mixture-of-agents framework with dynamic routing. It employs a lightweight scorer to perform initial screening by predicting coarse-grained performance from the query, narrowing candidates to a high-potential subset without inference. A mixture of judges then refines these scores through lightweight self- and cross-assessment based on existing model outputs, providing posterior correction without additional inference. Finally, a model ranking mechanism selects models by balancing performance, cost, and latency. RouteMoA outperforms MoA across varying tasks and model pool sizes, reducing cost by 89.8% and latency by 63.6% in the large-scale model pool.",
      "authors": [
        "Jize Wang",
        "Han Wu",
        "Zhiyuan You",
        "Yiming Song",
        "Yijun Wang",
        "Zifei Shan",
        "Yining Li",
        "Songyang Zhang",
        "Xinyi Le",
        "Cailian Chen",
        "Xinping Guan",
        "Dacheng Tao"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-26 04:22:22+00:00",
      "link": "https://arxiv.org/pdf/2601.18130v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "efficient mixture-of-agents and dynamic routing",
      "llm_evidence_cn": "高效代理混合与动态路由",
      "llm_evidence": "高效代理混合与动态路由",
      "llm_tldr_en": "Proposes an efficient mixture-of-agents framework using dynamic routing to reduce inference costs.",
      "llm_tldr_cn": "提出一种高效的代理混合框架，通过动态路由降低推理成本。",
      "llm_tldr": "提出一种高效的代理混合框架，通过动态路由降低推理成本。",
      "llm_tags": [
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.18226v1",
      "title": "Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks",
      "abstract": "Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.",
      "authors": [
        "Haotian Li",
        "Shijun Yang",
        "Weizhen Qi",
        "Silei Zhao",
        "Rui Hua",
        "Mingzhu Song",
        "Xiaojian Yang",
        "Chao Peng"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-26 07:27:47+00:00",
      "link": "https://arxiv.org/pdf/2601.18226v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "Self-evolving agent system for open-ended tasks",
      "llm_evidence_cn": "面向开放任务的自进化智能体系统",
      "llm_evidence": "面向开放任务的自进化智能体系统",
      "llm_tldr_en": "Proposes an in-situ self-evolving paradigm for agents to expand capabilities through tool evolution.",
      "llm_tldr_cn": "提出一种原位自进化范式，通过工具演化使智能体在开放任务中持续扩展能力。",
      "llm_tldr": "提出一种原位自进化范式，通过工具演化使智能体在开放任务中持续扩展能力。",
      "llm_tags": [
        "keyword:EOH"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.18542v1",
      "title": "XFit: Global Optimization and Degeneracy Mapping in X-ray Spectral Modeling",
      "abstract": "The standard approach to modeling X-ray spectral data relies on local optimization methods, such as the Levenberg-Marquardt algorithm. While effective for simple models and speedy spectral fitting, these local optimizers are prone to becoming trapped in local minima, particularly in high-dimensional or degenerate parameter spaces, and typically require extensive user intervention. In this work, we introduce XFit, a global optimization method for fitting X-ray data, which makes extensive use of the Ferret evolutionary algorithm. XFit enables automated exploration of complex parameter spaces, efficient mapping of confidence intervals, and identification of degenerate solutions that may be overlooked by local methods. We demonstrate the performance of XFit using two representative X-ray sources: the Central Compact Object in Cassiopeia A and the supernova remnant G41.1-0.3. These examples span both low- and high-dimensional models, allowing us to illustrate the advantages of global optimization. In both cases, XFit produces solutions that are consistent with or improve upon those found with traditional methods, while also revealing alternative fits or degenerate solutions within statistically acceptable confidence levels. The automated mapping of parameter space offered by XFit makes it a powerful complement to existing spectral fitting tools, particularly as models and data quality become increasingly complex. Future work will expand the application of XFit to broader datasets and more physically motivated models.",
      "authors": [
        "Austin MacMaster",
        "Adam Rogers",
        "Jason Fiege",
        "Rebecca Man",
        "Samar Safi-Harb"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE",
        "astro-ph.IM"
      ],
      "published": "2026-01-26 14:48:08+00:00",
      "link": "https://arxiv.org/pdf/2601.18542v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ],
      "llm_score": 6.0,
      "llm_evidence_en": "automated exploration using evolutionary algorithms",
      "llm_evidence_cn": "使用演化算法进行自动化探索",
      "llm_evidence": "使用演化算法进行自动化探索",
      "llm_tldr_en": "Introduces XFit, a global optimization method using the Ferret evolutionary algorithm for automated spectral fitting.",
      "llm_tldr_cn": "引入XFit，一种利用Ferret演化算法进行自动化光谱拟合的全局优化方法。",
      "llm_tldr": "引入XFit，一种利用Ferret演化算法进行自动化光谱拟合的全局优化方法。",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "6"
    }
  ]
}