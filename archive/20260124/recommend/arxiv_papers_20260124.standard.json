{
  "mode": "standard",
  "generated_at": "2026-01-24T10:49:39.631806+00:00",
  "stats": {
    "mode": "standard",
    "tag_count": 3,
    "deep_divecandidates": 5,
    "deep_cap": 8,
    "deep_selected": 5,
    "quick_candidates": 8,
    "quick_skim_target": 13,
    "quick_selected": 8
  },
  "deep_dive": [
    {
      "id": "2601.15738v1",
      "title": "LLM-Assisted Automatic Dispatching Rule Design for Dynamic Flexible Assembly Flow Shop Scheduling",
      "abstract": "Dynamic multi-product delivery environments demand rapid coordination of part completion and product-level kitting within hybrid processing and assembly systems to satisfy strict hierarchical supply constraints. The flexible assembly flow shop scheduling problem formally defines dependencies for multi-stage kitting, yet dynamic variants make designing integrated scheduling rules under multi-level time coupling highly challenging. Existing automated heuristic design methods, particularly genetic programming constrained to fixed terminal symbol sets, struggle to capture and leverage dynamic uncertainties and hierarchical dependency information under transient decision states. This study develops an LLM-assisted Dynamic Rule Design framework (LLM4DRD) that automatically evolves integrated online scheduling rules adapted to scheduling features. Firstly, multi-stage processing and assembly supply decisions are transformed into feasible directed edge orderings based on heterogeneous graph. Then, an elite knowledge guided initialization embeds advanced design expertise into initial rules to enhance initial quality. Additionally, a dual-expert mechanism is introduced in which LLM-A evolutionary code to generate candidate rules and LLM-S conducts scheduling evaluation, while dynamic feature-fitting rule evolution combined with hybrid evaluation enables continuous improvement and extracts adaptive rules with strong generalization capability. A series of experiments are conducted to validate the effectiveness of the method. The average tardiness of LLM4DRD is 3.17-12.39% higher than state-of-the-art methods in 20 practical instances used for training and testing, respectively. In 24 scenarios with different resource configurations, order loads, and disturbance levels totaling 480 instances, it achieves 11.10% higher performance than the second best competitor, exhibiting excellent robustness.",
      "authors": [
        "Junhao Qiu",
        "Haoyang Zhuang",
        "Fei Liu",
        "Jianjun Liu",
        "Qingfu Zhang"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-01-22 08:06:40+00:00",
      "link": "https://arxiv.org/pdf/2601.15738v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 10.0,
      "llm_evidence": "LLM-assisted automatic design of heuristics for scheduling problems",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15717v1",
      "title": "Investigation of the Generalisation Ability of Genetic Programming-evolved Scheduling Rules in Dynamic Flexible Job Shop Scheduling",
      "abstract": "Dynamic Flexible Job Shop Scheduling (DFJSS) is a complex combinatorial optimisation problem that requires simultaneous machine assignment and operation sequencing decisions in dynamic production environments. Genetic Programming (GP) has been widely applied to automatically evolve scheduling rules for DFJSS. However, existing studies typically train and test GP-evolved rules on DFJSS instances of the same type, which differ only by random seeds rather than by structural characteristics, leaving their cross-type generalisation ability largely unexplored. To address this gap, this paper systematically investigates the generalisation ability of GP-evolved scheduling rules under diverse DFJSS conditions. A series of experiments are conducted across multiple dimensions, including problem scale (i.e., the number of machines and jobs), key job shop parameters (e.g., utilisation level), and data distributions, to analyse how these factors influence GP performance on unseen instance types. The results show that good generalisation occurs when the training instances contain more jobs than the test instances while keeping the number of machines fixed, and when both training and test instances have similar scales or job shop parameters. Further analysis reveals that the number and distribution of decision points in DFJSS instances play a crucial role in explaining these performance differences. Similar decision point distributions lead to better generalisation, whereas significant discrepancies result in a marked degradation of performance. Overall, this study provides new insights into the generalisation ability of GP in DFJSS and highlights the necessity of evolving more generalisable GP rules capable of handling heterogeneous DFJSS instances effectively.",
      "authors": [
        "Luyao Zhu",
        "Fangfang Zhang",
        "Yi Mei",
        "Mengjie Zhang"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 07:38:27+00:00",
      "link": "https://arxiv.org/pdf/2601.15717v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 9.0,
      "llm_evidence": "automatically evolving scheduling rules using genetic programming for combinatorial optimization",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15212v1",
      "title": "ZENITH: Automated Gradient Norm Informed Stochastic Optimization",
      "abstract": "Training deep computer vision models requires manual oversight or hyperparameter tuning of the learning rate (LR) schedule. While existing adaptive optimizers schedule the LR automatically, they suffer from computational and memory overhead, incompatibility with regularization, and suboptimal LR choices. In this work, we introduce the ZENITH (Zero-overhead Evolution using Norm-Informed Training History) optimizer, which adapts the LR using the temporal evolution of the gradient norm. Image classification experiments spanning 6 CNN architectures and 6 benchmarks demonstrate that ZENITH achieves higher test accuracy in lower wall-clock time than baselines. It also yielded superior mAP in object detection, keypoint detection, and instance segmentation on MS COCO using the R-CNN family of models. Furthermore, its compatibility with regularization enables even better generalization.",
      "authors": [
        "Dhrubo Saha"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "published": "2026-01-21 17:36:12+00:00",
      "link": "https://arxiv.org/pdf/2601.15212v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ],
      "llm_score": 8.0,
      "llm_evidence": "automated evolution of learning rate using training history aligns with evolution of heuristics and automatic algorithms",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.15561v1",
      "title": "Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial Optimization Problems",
      "abstract": "This article critically investigates the limitations of the simulated annealing algorithm using probabilistic bits (pSA) in solving large-scale combinatorial optimization problems. The study begins with an in-depth analysis of the pSA process, focusing on the issues resulting from unexpected oscillations among p-bits. These oscillations hinder the energy reduction of the Ising model and thus obstruct the successful execution of pSA in complex tasks. Through detailed simulations, we unravel the root cause of this energy stagnation, identifying the feedback mechanism inherent to the pSA operation as the primary contributor to these disruptive oscillations. To address this challenge, we propose two novel algorithms, time average pSA (TApSA) and stalled pSA (SpSA). These algorithms are designed based on partial deactivation of p-bits and are thoroughly tested using Python simulations on maximum cut benchmarks that are typical combinatorial optimization problems. On the 16 benchmarks from 800 to 5,000 nodes, the proposed methods improve the normalized cut value from 0.8% to 98.4% on average in comparison with the conventional pSA.",
      "authors": [
        "Naoya Onizawa",
        "Takahiro Hanyu"
      ],
      "primary_category": "cs.ET",
      "categories": [
        "cs.ET",
        "cs.LG"
      ],
      "published": "2026-01-22 01:01:35+00:00",
      "link": "https://arxiv.org/pdf/2601.15561v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 8.0,
      "llm_evidence": "improving simulated annealing for large-scale optimization relates to neighborhood search and heuristic evolution",
      "llm_tags": [
        "keyword:LNS",
        "keyword:EOH",
        "keyword:EAA"
      ]
    },
    {
      "id": "2601.16175v1",
      "title": "Learning to Discover at Test Time",
      "abstract": "How can we use AI to discover a new state of the art for a scientific problem? Prior work in test-time scaling, such as AlphaEvolve, performs search by prompting a frozen LLM. We perform reinforcement learning at test time, so the LLM can continue to train, but now with experience specific to the test problem. This form of continual learning is quite special, because its goal is to produce one great solution rather than many good ones on average, and to solve this very problem rather than generalize to other problems. Therefore, our learning objective and search subroutine are designed to prioritize the most promising solutions. We call this method Test-Time Training to Discover (TTT-Discover). Following prior work, we focus on problems with continuous rewards. We report results for every problem we attempted, across mathematics, GPU kernel engineering, algorithm design, and biology. TTT-Discover sets the new state of the art in almost all of them: (i) Erd≈ës' minimum overlap problem and an autocorrelation inequality; (ii) a GPUMode kernel competition (up to $2\\times$ faster than prior art); (iii) past AtCoder algorithm competitions; and (iv) denoising problem in single-cell analysis. Our solutions are reviewed by experts or the organizers. All our results are achieved with an open model, OpenAI gpt-oss-120b, and can be reproduced with our publicly available code, in contrast to previous best results that required closed frontier models. Our test-time training runs are performed using Tinker, an API by Thinking Machines, with a cost of only a few hundred dollars per problem.",
      "authors": [
        "Mert Yuksekgonul",
        "Daniel Koceja",
        "Xinhao Li",
        "Federico Bianchi",
        "Jed McCaleb",
        "Xiaolong Wang",
        "Jan Kautz",
        "Yejin Choi",
        "James Zou",
        "Carlos Guestrin",
        "Yu Sun"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-22 18:24:00+00:00",
      "link": "https://arxiv.org/pdf/2601.16175v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 8.0,
      "llm_evidence": "Focuses on automated discovery of state-of-the-art solutions using LLM-based search and evolution",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ]
    }
  ],
  "quick_skim": [
    {
      "id": "2601.15127v1",
      "title": "DeepFedNAS: A Unified Framework for Principled, Hardware-Aware, and Predictor-Free Federated Neural Architecture Search",
      "abstract": "Federated Neural Architecture Search (FedNAS) aims to automate model design for privacy-preserving Federated Learning (FL) but currently faces two critical bottlenecks: unguided supernet training that yields suboptimal models, and costly multi-hour pipelines for post-training subnet discovery. We introduce DeepFedNAS, a novel, two-phase framework underpinned by a principled, multi-objective fitness function that synthesizes mathematical network design with architectural heuristics. Enabled by a re-engineered supernet, DeepFedNAS introduces Federated Pareto Optimal Supernet Training, which leverages a pre-computed Pareto-optimal cache of high-fitness architectures as an intelligent curriculum to optimize shared supernet weights. Subsequently, its Predictor-Free Search Method eliminates the need for costly accuracy surrogates by utilizing this fitness function as a direct, zero-cost proxy for accuracy, enabling on-demand subnet discovery in mere seconds. DeepFedNAS achieves state-of-the-art accuracy (e.g., up to 1.21% absolute improvement on CIFAR-100), superior parameter and communication efficiency, and a substantial ~61x speedup in total post-training search pipeline time. By reducing the pipeline from over 20 hours to approximately 20 minutes (including initial cache generation) and enabling 20-second individual subnet searches, DeepFedNAS makes hardware-aware FL deployments instantaneous and practical. The complete source code and experimental scripts are available at: https://github.com/bostankhan6/DeepFedNAS",
      "authors": [
        "Bostan Khan",
        "Masoud Daneshtalab"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CV",
        "cs.DC"
      ],
      "published": "2026-01-21 16:03:25+00:00",
      "link": "https://arxiv.org/pdf/2601.15127v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 7.0,
      "llm_evidence": "Automated model design using architectural heuristics and multi-objective optimization",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2601.15038v1",
      "title": "A Curriculum-Based Deep Reinforcement Learning Framework for the Electric Vehicle Routing Problem",
      "abstract": "The electric vehicle routing problem with time windows (EVRPTW) is a complex optimization problem in sustainable logistics, where routing decisions must minimize total travel distance, fleet size, and battery usage while satisfying strict customer time constraints. Although deep reinforcement learning (DRL) has shown great potential as an alternative to classical heuristics and exact solvers, existing DRL models often struggle to maintain training stability-failing to converge or generalize when constraints are dense. In this study, we propose a curriculum-based deep reinforcement learning (CB-DRL) framework designed to resolve this instability. The framework utilizes a structured three-phase curriculum that gradually increases problem complexity: the agent first learns distance and fleet optimization (Phase A), then battery management (Phase B), and finally the full EVRPTW (Phase C). To ensure stable learning across phases, the framework employs a modified proximal policy optimization algorithm with phase-specific hyperparameters, value and advantage clipping, and adaptive learning-rate scheduling. The policy network is built upon a heterogeneous graph attention encoder enhanced by global-local attention and feature-wise linear modulation. This specialized architecture explicitly captures the distinct properties of depots, customers, and charging stations. Trained exclusively on small instances with N=10 customers, the model demonstrates robust generalization to unseen instances ranging from N=5 to N=100, significantly outperforming standard baselines on medium-scale problems. Experimental results confirm that this curriculum-guided approach achieves high feasibility rates and competitive solution quality on out-of-distribution instances where standard DRL baselines fail, effectively bridging the gap between neural speed and operational reliability.",
      "authors": [
        "Mertcan Daysalilar",
        "Fuat Uyguroglu",
        "Gabriel Nicolosi",
        "Adam Meyers"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-21 14:42:33+00:00",
      "link": "https://arxiv.org/pdf/2601.15038v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence": "reinforcement learning framework as alternative to classical heuristics for routing",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.15727v1",
      "title": "Towards Automated Kernel Generation in the Era of LLMs",
      "abstract": "The performance of modern AI systems is fundamentally constrained by the quality of their underlying kernels, which translate high-level algorithmic semantics into low-level hardware operations. Achieving near-optimal kernels requires expert-level understanding of hardware architectures and programming models, making kernel engineering a critical but notoriously time-consuming and non-scalable process. Recent advances in large language models (LLMs) and LLM-based agents have opened new possibilities for automating kernel generation and optimization. LLMs are well-suited to compress expert-level kernel knowledge that is difficult to formalize, while agentic systems further enable scalable optimization by casting kernel development as an iterative, feedback-driven loop. Rapid progress has been made in this area. However, the field remains fragmented, lacking a systematic perspective for LLM-driven kernel generation. This survey addresses this gap by providing a structured overview of existing approaches, spanning LLM-based approaches and agentic optimization workflows, and systematically compiling the datasets and benchmarks that underpin learning and evaluation in this domain. Moreover, key open challenges and future research directions are further outlined, aiming to establish a comprehensive reference for the next generation of automated kernel optimization. To keep track of this field, we maintain an open-source GitHub repository at https://github.com/flagos-ai/awesome-LLM-driven-kernel-generation.",
      "authors": [
        "Yang Yu",
        "Peiyu Zang",
        "Chi Hsu Tsai",
        "Haiming Wu",
        "Yixin Shen",
        "Jialing Zhang",
        "Haoyu Wang",
        "Zhiyou Xiao",
        "Jingze Shi",
        "Yuyu Luo",
        "Wentao Zhang",
        "Chunlei Men",
        "Guang Liu",
        "Yonghua Lin"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "published": "2026-01-22 07:53:52+00:00",
      "link": "https://arxiv.org/pdf/2601.15727v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 7.0,
      "llm_evidence": "Automates kernel generation and optimization using iterative feedback-driven agentic loops",
      "llm_tags": [
        "keyword:EAA"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2601.15252v1",
      "title": "Automating Idealness Proofs for Binary Programs with Application to Rectangle Packing",
      "abstract": "An integer program is called ideal if its continuous relaxation coincides with its convex hull allowing the problem to be solved as a continuous program and offering substantial computational advantages. Proving idealness analytically can be extraordinarily tedious -- even for small formulations -- such proofs often span many pages of intricate case analysis which motivates the development of automated verification methods. We develop a general-purpose framework for certifying idealness in Mixed Binary Linear Programs (MBLPs), formulating the verification problem as a linear program when the data is fixed and as a nonconvex quadratic program when the data is parametric. We apply this framework to study several formulations of the rectangle packing problem that are conjectured to be pairwise-ideal, obtaining computational proofs where analytic proofs were previously unknown or impractical. As our second contribution, we introduce and model a novel generalization of the rectangle packing problem that enforces edge clearances between selected rectangles. We present both existing and novel MBLP formulations which arise from different encodings of the underlying disjunctive constraints. We perform some computational experiments on these formulations under a strip-packing objective to determine the importance of pairwise-idealness in practice.",
      "authors": [
        "Jamie Fravel",
        "Robert Hildebrand"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-21 18:35:20+00:00",
      "link": "https://arxiv.org/pdf/2601.15252v1",
      "tags": [
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence": "automated verification and computational advantages for packing problems",
      "llm_tags": [
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.15876v1",
      "title": "EvoCUA: Evolving Computer Use Agents via Learning from Scalable Synthetic Experience",
      "abstract": "The development of native computer-use agents (CUA) represents a significant leap in multimodal AI. However, their potential is currently bottlenecked by the constraints of static data scaling. Existing paradigms relying primarily on passive imitation of static datasets struggle to capture the intricate causal dynamics inherent in long-horizon computer tasks. In this work, we introduce EvoCUA, a native computer use agentic model. Unlike static imitation, EvoCUA integrates data generation and policy optimization into a self-sustaining evolutionary cycle. To mitigate data scarcity, we develop a verifiable synthesis engine that autonomously generates diverse tasks coupled with executable validators. To enable large-scale experience acquisition, we design a scalable infrastructure orchestrating tens of thousands of asynchronous sandbox rollouts. Building on these massive trajectories, we propose an iterative evolving learning strategy to efficiently internalize this experience. This mechanism dynamically regulates policy updates by identifying capability boundaries -- reinforcing successful routines while transforming failure trajectories into rich supervision through error analysis and self-correction. Empirical evaluations on the OSWorld benchmark demonstrate that EvoCUA achieves a success rate of 56.7%, establishing a new open-source state-of-the-art. Notably, EvoCUA significantly outperforms the previous best open-source model, OpenCUA-72B (45.0%), and surpasses leading closed-weights models such as UI-TARS-2 (53.1%). Crucially, our results underscore the generalizability of this approach: the evolving paradigm driven by learning from experience yields consistent performance gains across foundation models of varying scales, establishing a robust and scalable path for advancing native agent capabilities.",
      "authors": [
        "Taofeng Xue",
        "Chong Peng",
        "Mianqiu Huang",
        "Linsen Guo",
        "Tiancheng Han",
        "Haozhe Wang",
        "Jianing Wang",
        "Xiaocheng Zhang",
        "Xin Yang",
        "Dengchang Zhao",
        "Jinrui Ding",
        "Xiandi Ma",
        "Yuchen Xie",
        "Peng Pei",
        "Xunliang Cai",
        "Xipeng Qiu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 11:36:43+00:00",
      "link": "https://arxiv.org/pdf/2601.15876v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 7.0,
      "llm_evidence": "Integrates policy optimization into a self-sustaining evolutionary cycle for agent development",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2601.15482v1",
      "title": "Martingale Foresight Sampling: A Principled Approach to Inference-Time LLM Decoding",
      "abstract": "Standard autoregressive decoding in large language models (LLMs) is inherently short-sighted, often failing to find globally optimal reasoning paths due to its token-by-token generation process. While inference-time strategies like foresight sampling attempt to mitigate this by simulating future steps, they typically rely on ad-hoc heuristics for valuing paths and pruning the search space. This paper introduces Martingale Foresight Sampling (MFS), a principled framework that reformulates LLM decoding as a problem of identifying an optimal stochastic process. By modeling the quality of a reasoning path as a stochastic process, we leverage Martingale theory to design a theoretically-grounded algorithm. Our approach replaces heuristic mechanisms with principles from probability theory: step valuation is derived from the Doob Decomposition Theorem to measure a path's predictable advantage, path selection uses Optional Stopping Theory for principled pruning of suboptimal candidates, and an adaptive stopping rule based on the Martingale Convergence Theorem terminates exploration once a path's quality has provably converged. Experiments on six reasoning benchmarks demonstrate that MFS surpasses state-of-the-art methods in accuracy while significantly improving computational efficiency. Code will be released at https://github.com/miraclehetech/EACL2026-Martingale-Foresight-Sampling.",
      "authors": [
        "Huayu Li",
        "ZhengXiao He",
        "Siyuan Tian",
        "Jinghao Wen",
        "Ao Li"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-21 21:34:29+00:00",
      "link": "https://arxiv.org/pdf/2601.15482v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence": "principled approach to search space pruning and path valuation",
      "llm_tags": [
        "keyword:LNS",
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.16056v1",
      "title": "Designing faster mixed integer linear programming algorithm via learning the optimal path",
      "abstract": "Designing faster algorithms for solving Mixed-Integer Linear Programming (MILP) problems is highly desired across numerous practical domains, as a vast array of complex real-world challenges can be effectively modeled as MILP formulations. Solving these problems typically employs the branch-and-bound algorithm, the core of which can be conceived as searching for a path of nodes (or sub-problems) that contains the optimal solution to the original MILP problem. Traditional approaches to finding this path rely heavily on hand-crafted, intuition-based heuristic strategies, which often suffer from unstable and unpredictable performance across different MILP problem instances. To address this limitation, we introduce DeepBound, a deep learning-based node selection algorithm that automates the learning of such human intuition from data. The core of DeepBound lies in learning to prioritize nodes containing the optimal solution, thereby improving solving efficiency. DeepBound introduces a multi-level feature fusion network to capture the node representations. To tackle the inherent node imbalance in branch-and-bound trees, DeepBound employs a pairwise training paradigm that enhances the model's ability to discriminate between nodes. Extensive experiments on three NP-hard MILP benchmarks demonstrate that DeepBound achieves superior solving efficiency over conventional heuristic rules and existing learning-based approaches, obtaining optimal feasible solutions with significantly reduced computation time. Moreover, DeepBound demonstrates strong generalization capability on large and complex instances. The analysis of its learned features reveals that the method can automatically discover more flexible and robust feature selection, which may effectively improve and potentially replace human-designed heuristic rules.",
      "authors": [
        "Ruizhi Liu",
        "Liming Xu",
        "Xulin Huang",
        "Jingyan Sui",
        "Shizhe Ding",
        "Boyang Xia",
        "Chungong Yu",
        "Dongbo Bu"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-22 15:41:22+00:00",
      "link": "https://arxiv.org/pdf/2601.16056v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 7.0,
      "llm_evidence": "improving MILP heuristics via learning aligns with evolution of heuristics and efficient algorithms",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2601.16156v1",
      "title": "All ascents exponential from valued constraint graphs of pathwidth three",
      "abstract": "Many combinatorial optimization problems can be formulated as finding as assignment that maximized some pseudo-Boolean function (that we call the fitness function). Strict local search starts with some assignment and follows some update rule to proceed to an adjacent assignment of strictly higher fitness. This means that strict local search algorithms follow ascents in the fitness landscape of the pseudo-Boolean function. The complexity of the pseudo-Boolean function (and the fitness landscapes that it represents) can be parameterized by properties of the valued constraint satisfaction problem (VCSP) that encodes the pseudo-Boolean function. We focus on properties of the constraint graphs of the VCSP, with the intuition that spare graphs are less complex than dense ones. Specifically, we argue that pathwidth is the natural sparsity parameter for understanding limits on the power of strict local search. We show that prior constructions of sparse VCSPs where all ascents are exponentially long had pathwidth greater than or equal to four. We improve this this with our controlled doubling construction: a valued constraint satisfaction problem of pathwidth three where all ascents are exponentially long from a designated initial assignment. From this, we conclude that all strict local search algorithms can be forced to take an exponential number of steps even on simple valued constraint graphs of pathwidth three.",
      "authors": [
        "Artem Kaznatcheev",
        "Willemijn Volgering"
      ],
      "primary_category": "cs.DM",
      "categories": [
        "cs.DM",
        "cs.DS"
      ],
      "published": "2026-01-22 17:57:54+00:00",
      "link": "https://arxiv.org/pdf/2601.16156v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence": "local search and fitness landscapes in combinatorial optimization",
      "llm_tags": [
        "keyword:LNS"
      ],
      "quick_tier": "6"
    }
  ]
}