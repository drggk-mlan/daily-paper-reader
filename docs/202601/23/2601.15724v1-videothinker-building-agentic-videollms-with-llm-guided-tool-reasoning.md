# VideoThinker: Building Agentic VideoLLMs with LLM-Guided Tool Reasoning
# VideoThinker：通过 LLM 引导的工具推理构建智能体化视频大语言模型

**Authors**: Chenglin Li, Qianglong Chen, Feng Han, Yikun Wang, Xingxi Yin, Yan Gong, Ruilin Li, Yin Zhang, Jiaqi Wang
**Date**: 2026-01-22
**PDF**: https://arxiv.org/pdf/2601.15724v1
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-pink">query:大厂llm</span>
**Score**: 6.0
**Evidence**: describes building agentic VideoLLMs using LLM-guided reasoning and synthetic trajectories

---

## Abstract
Long-form video understanding remains a fundamental challenge for current Video Large Language Models. Most existing models rely on static reasoning over uniformly sampled frames, which weakens temporal localization and leads to substantial information loss in long videos. Agentic tools such as temporal retrieval, spatial zoom, and temporal zoom offer a natural way to overcome these limitations by enabling adaptive exploration of key moments. However, constructing agentic video understanding data requires models that already possess strong long-form video comprehension, creating a circular dependency. We address this challenge with VideoThinker, an agentic Video Large Language Model trained entirely on synthetic tool interaction trajectories. Our key idea is to convert videos into rich captions and employ a powerful agentic language model to generate multi-step tool use sequences in caption space. These trajectories are subsequently grounded back to video by replacing captions with the corresponding frames, yielding a large-scale interleaved video and tool reasoning dataset without requiring any long-form understanding from the underlying model. Training on this synthetic agentic dataset equips VideoThinker with dynamic reasoning capabilities, adaptive temporal exploration, and multi-step tool use. Remarkably, VideoThinker significantly outperforms both caption-only language model agents and strong video model baselines across long-video benchmarks, demonstrating the effectiveness of tool augmented synthetic data and adaptive retrieval and zoom reasoning for long-form video understanding.

## 摘要
长视频理解仍然

---

## 速览摘要（自动生成）

**问题**：现有VideoLLM处理长视频时因静态采样导致信息丢失且