# Structured Hints for Sample-Efficient Lean Theorem Proving
# 结构化提示助力样本高效的 Lean 定理证明

**Authors**: Zachary Burton
**Date**: 2026-01-22
**PDF**: https://arxiv.org/pdf/2601.16172v1
**Tags**: <span class="tag-label tag-blue">精读区</span> <span class="tag-label tag-pink">keyword:RL</span> <span class="tag-label tag-pink">keyword:ppo</span> <span class="tag-label tag-pink">query:大厂llm</span>
**Score**: 8.0
**Evidence**: Discusses DeepSeek-Prover-V1.5 which is an industry LLM using RL and PPO-style training

---

## Abstract
State-of-the-art neural theorem provers like DeepSeek-Prover-V1.5 combine large language models with reinforcement learning, achieving impressive results through sophisticated training. We ask: do these highly-trained models still benefit from simple structural guidance at inference time? We evaluate a lightweight intervention -- a fixed prompt schedule over 15 common tactic skeletons -- on the miniF2F benchmark. This simple approach yields 21.7% pass@16 compared to 15.2% for standard sampling from the same model, a 43% relative improvement using the same number of samples (k=16) and same maximum generation length (1024 tokens). Our results suggest that even capable RL-trained provers underutilize structural priors available in the tactic language, and that simple inference-time guidance remains a cheap, complementary boost.

## 摘要
像 DeepSeek-Prover-V1.5 这样最先进的神经定理证明器结合了大语言模型与强化学习，通过复杂的训练取得了令人瞩目的成果。我们提出一个问题：这些经过高度训练的模型在推理阶段是否仍能从简单的结构化引导中获益？我们在 miniF2

---

## 论文详细总结（自动生成）

这篇论文《Structured Hints for Sample-Efficient Lean Theorem Proving》探讨了如何通过简单的推理时干预，提升强化学习（RL）训练后的神经定理证明器的性能。以下是该论文的结构化总结：

### 1. 核心问题与整体含义
*   **研究动机**：尽管当前的神经定理证明器（如 DeepSeek-Prover-V1.5）通过大规模强化学习取得了显著进步，但它们在推理时依然表现出“脆弱性”，经常犯低级结构性错误（如语法错误、标识符幻觉），而非缺乏数学洞察力。
*   **核心问题**：在资源受限（低采样预算）的情况下，这些高度训练的模型是否仍能从简单的、预定义的结构化引导（策略骨架）中获益？
*   **背景**：现有的提升方法通常依赖昂贵的随机搜索或海量采样（如 $k=1024$），而本文关注的是轻量级的推理时优化。

### 2. 论文提出的方法论
*   **核心思想**：引入一种**结构化中间表示（Structured IR）**，通过固定的“提示调度表”（Prompt Schedule）强制模型在生成证明前遵循特定的策略骨架。
*   **关键技术细节**：
    *   **结构化查询**：将查询定义为元组 $q = (x, s)$，其中 $x$ 是定理陈述，$s$ 是策略骨架（Tactic Skeleton）。
    *   **固定提示调度**：不依赖纯随机采样，而是预设 15 种常见的 Lean 策略骨架（如 `simp`, `intro`, `induction`, `constructor`, `linarith` 等）。
    *   **推理流程**：对于每个定理，模型按顺序尝试这 15 个骨架（加上一个带提示的空骨架，共 $k=16$ 次尝试）。这种方法强制模型探索不同的证明路径，防止采样分布塌陷到单一的错误模式。

### 3. 实验设计
*   **数据集/场景**：使用 **miniF2F-test** 基准测试集（Lean 4 版本，包含 244 个定理）。
*   **对比方法**：
    *   **Baseline**：使用相同的模型（DeepSeek-Prover-V1.5-RL）进行标准随机采样（$k=16$）。
    *   **Structured IR (本文方法)**：按固定调度表进行骨架引导采样（$k=16$）。
*   **约束条件**：严格限制推理预算，最大生成长度为 1024 tokens，每个尝试限时 60 秒。

### 4. 资源与算力
*   **模型**：使用了开源的 `deepseek-ai/DeepSeek-Prover-V1.5-RL`。
*   **算力说明**：文中**未明确说明**具体的 GPU 型号、数量或总推理时长。由于该研究侧重于推理时的轻量级干预，不涉及模型训练，因此算力消耗主要集中在对 244 个定理进行 $k=16$ 的推理采样上。
*   **环境**：Lean 4 v4.27.0-rc1，配合 Mathlib 库。

### 5. 实验数量与充分性
*   **实验规模**：针对 244 个定理进行了对比实验，总计进行了数千次证明尝试。
*   **分析维度**：
    *   **配对分析**：通过 Venn 图展示了两种方法解决问题的交集，并使用 McNemar 检验验证了统计显著性（$p < 0.001$）。
    *   **失败模式分析**：对失败尝试的错误类型（如未解决目标、语法错误、未知标识符等）进行了分类统计。
*   **充分性评价**：实验设计较为客观、公平（控制了相同的采样数和 token 限制），但实验仅限于 miniF2F 一个基准集，缺乏在更大型数据集（如 ProofNet 或真实 Mathlib 库）上的验证。

### 6. 主要结论与发现
*   **性能大幅提升**：在相同的推理预算下，结构化引导将 pass@16 从 15.16% 提升至 **21.72%**，相对提升了 **43.2%**。
*   **非对称优势**：本文方法解决了 19 个基线失败的定理，而基线仅解决了 3 个本文方法失败的定理，证明了结构化引导的稳健性。
*   **错误分布相似**：失败模式分析显示，两种方法的错误类型分布几乎一致。这表明结构化引导的成功并非因为避免了特定错误，而是通过提供“热启动”提高了正确路径的命中率。
*   **RL 模型的局限**：结果暗示即使是经过 RL 训练的模型，也未能充分利用策略语言中的结构先验。

### 7. 优点
*   **简单高效**：无需重新训练模型，仅通过推理时的 Prompt 工程即可获得显著增益。
*   **资源友好**：在低采样预算（$k=16$）下表现优异，适合计算资源有限的场景。
*   **互补性强**：这种方法可以作为 RL 训练和树搜索算法的补充手段。

### 8. 不足与局限
*   **计算预算限制**：为了严谨对比，实验限制在 1024 tokens，这可能导致一些需要长证明的复杂定理被截断，无法反映模型在长文本下的真实上限。
*   **骨架固定**：目前使用的是固定的 15 个骨架，缺乏动态性。如果定理类型与预设骨架不匹配，引导可能失效。
*   **泛化验证不足**：尚未在更广泛的定理证明任务或不同规模的基础模型上进行大规模测试。
*   **随机性风险**：仅报告了单次运行的结果，未进行多次随机种子的重复实验以评估方差。