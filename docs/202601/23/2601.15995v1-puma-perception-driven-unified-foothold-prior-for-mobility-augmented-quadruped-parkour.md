# PUMA: Perception-driven Unified Foothold Prior for Mobility Augmented Quadruped Parkour
# PUMA：感知驱动的统一落脚点先验，助力移动增强的四足机器人跑酷

**Authors**: Liang Wang, Kanzhong Yao, Yang Liu, Weikai Qin, Jun Wu, Zhe Sun, Qiuguo Zhu
**Date**: 2026-01-22
**PDF**: https://arxiv.org/pdf/2601.15995v1
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-pink">keyword:RL</span>
**Score**: 6.0
**Evidence**: end-to-end reinforcement learning framework for quadruped locomotion

---

## Abstract
Parkour tasks for quadrupeds have emerged as a promising benchmark for agile locomotion. While human athletes can effectively perceive environmental characteristics to select appropriate footholds for obstacle traversal, endowing legged robots with similar perceptual reasoning remains a significant challenge. Existing methods often rely on hierarchical controllers that follow pre-computed footholds, thereby constraining the robot's real-time adaptability and the exploratory potential of reinforcement learning. To overcome these challenges, we present PUMA, an end-to-end learning framework that integrates visual perception and foothold priors into a single-stage training process. This approach leverages terrain features to estimate egocentric polar foothold priors, composed of relative distance and heading, guiding the robot in active posture adaptation for parkour tasks. Extensive experiments conducted in simulation and real-world environments across various discrete complex terrains, demonstrate PUMA's exceptional agility and robustness in challenging scenarios.

## 摘要
四足

---

## 速览摘要（自动生成）

**问题**：现有四足机器人跑酷方法缺乏实时感知推理能力，落脚点选择灵活性差，难以应对复杂地形。

**方法**：提出 PUMA 框架，将视觉感知与基于极坐标的落脚点先验（距离和航向）集成到端到端单阶段训练中。

**结论**：显著提升了机器人在离散复杂地形下的敏捷性与鲁