# HumanLLM: Towards Personalized Understanding and Simulation of Human Nature
# HumanLLM：迈向人性的个性化理解与模拟

**Authors**: Yuxuan Lei, Tianfu Wang, Jianxun Lian, Zhengyu Hu, Defu Lian, Xing Xie
**Date**: 2026-01-22
**PDF**: https://arxiv.org/pdf/2601.15793v1
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-pink">query:大厂llm</span>
**Score**: 6.0
**Evidence**: Discusses LLM pretraining and simulation capabilities relevant to large language model technical reports

---

## Abstract
Motivated by the remarkable progress of large language models (LLMs) in objective tasks like mathematics and coding, there is growing interest in their potential to simulate human behavior--a capability with profound implications for transforming social science research and customer-centric business insights. However, LLMs often lack a nuanced understanding of human cognition and behavior, limiting their effectiveness in social simulation and personalized applications. We posit that this limitation stems from a fundamental misalignment: standard LLM pretraining on vast, uncontextualized web data does not capture the continuous, situated context of an individual's decisions, thoughts, and behaviors over time. To bridge this gap, we introduce HumanLLM, a foundation model designed for personalized understanding and simulation of individuals. We first construct the Cognitive Genome Dataset, a large-scale corpus curated from real-world user data on platforms like Reddit, Twitter, Blogger, and Amazon. Through a rigorous, multi-stage pipeline involving data filtering, synthesis, and quality control, we automatically extract over 5.5 million user logs to distill rich profiles, behaviors, and thinking patterns. We then formulate diverse learning tasks and perform supervised fine-tuning to empower the model to predict a wide range of individualized human behaviors, thoughts, and experiences. Comprehensive evaluations demonstrate that HumanLLM achieves superior performance in predicting user actions and inner thoughts, more accurately mimics user writing styles and preferences, and generates more authentic user profiles compared to base models. Furthermore, HumanLLM shows significant gains on out-of-domain social intelligence benchmarks, indicating enhanced generalization.

## 摘要
受大语言模型（LLMs）在数学和编程等客观任务中取得的显著进展启发，学术界对其模拟人类行为的潜力产生了日益浓厚的兴趣——这一能力对于变革社会科学研究和获取以客户为中心的商业洞察具有深远意义。然而，LLMs往往缺乏对人类认知和行为的细致理解，限制了其在社会模拟和个性化应用中的有效性。我们认为，这种局限性源于一种根本性的失配：标准LLM在海量、缺乏语境的网络数据上进行的预训练，未能捕捉到个体随时间推移在决策、思想和行为中表现出的持续且情境化的背景。为了弥补这一差距，我们推出了 HumanLLM，这是一个旨在实现

---

## 速览摘要（自动生成）

120 limit).
    *   Structure: Problem, Method, Conclusion.

    *