Title: Towards Reliable Medical LLMs: Benchmarking and Enhancing Confidence Estimation of Large Language Models in Medical Consultation

URL Source: https://arxiv.org/pdf/2601.15645v1

Published Time: Fri, 23 Jan 2026 01:26:57 GMT

Number of Pages: 33

Markdown Content:
# Towards Reliable Medical LLMs: Benchmarking and Enhancing Confidence Estimation of Large Language Models in Medical Consultation 

Zhiyao Ren 1, Yibing Zhan 2, Siyuan Liang 1, Guozheng Ma 1, Baosheng Yu 1,Dacheng Tao 1* 

> 1

Nanyang Technological University, Singapore, Singapore. 

> 2

Wuhan University, Wuhan, China. *Corresponding author(s). E-mail(s): dacheng.tao@gmail.com; Contributing authors: zhiyao001@e.ntu.edu.sg; zybjy@mail.ustc.edu.cn; siyuan.liang@ntu.edu.sg; guozheng001@e.ntu.edu.sg; baosheng.yu@ntu.edu.sg; 

Abstract 

Large-scale language models (LLMs) often offer clinical judgments based on incomplete information, increasing the risk of misdiagnosis. Existing studies have primarily evaluated confidence in single-turn, static settings, overlooking the coupling between confidence and correctness as clinical evidence accu-mulates during real consultations, which limits their support for reliable decision-making. We propose the first benchmark for assessing confidence in multi-turn interaction during realistic medical consul-tations. Our benchmark unifies three types of medical data for open-ended diagnostic generation and introduces an information sufficiency gradient to characterize the confidence‚Äìcorrectness dynamics as evidence increases. We implement and compare 27 representative methods on this benchmark; two key insights emerge: (1) medical data amplifies the inherent limitations of token-level and consistency-level confidence methods, and (2) medical reasoning must be evaluated for both diagnostic accuracy and information completeness. Based on these insights, we present MedConf, an evidence-grounded linguistic self-assessment framework that constructs symptom profiles via retrieval-augmented genera-tion, aligns patient information with supporting, missing, and contradictory relations, and aggregates them into an interpretable confidence estimate through weighted integration. Across two LLMs and three medical datasets, MedConf consistently outperforms state-of-the-art methods on both AUROC and Pearson correlation coefficient metrics, maintaining stable performance under conditions of infor-mation insufficiency and multimorbidity. These results demonstrate that information adequacy is a key determinant of credible medical confidence modeling, providing a new pathway toward building more reliable and interpretable large medical models. 

Keywords: Large Language Models, confidence estimation, medical data 

## 1 Introduction 

LLMs should evaluate their confidence levels in diagnostic conclusions based on the available patient information, similar to how clinicians assess their own confidence during the decision-making process [1‚Äì3]. Such a self-assessment mechanism enables the model to actively acquire 1

> arXiv:2601.15645v1 [cs.CL] 22 Jan 2026 1

I

> I‚Äôve been having stomach pain, feeling nauseous, and I have a slight fever.

IIt‚Äôs a signs of appendicitis. Let‚Äôs get you to surgery right away. 

(a) Unreliable Confidence 

> Wait, doctor. I should mention I've been having watery diarrhea about 5 times a day.

I

> Oh... appendicitis doesn't cause diarrhea. It should be Urinary tract infection.

II‚Äôve been having stomach pain, feeling nauseous, and I have a slight fever 

IHave you had any diarrhea? 

> Yes, actually. Watery diarrhea about 5 times since yesterday.

IHas anyone else been sick too? 

> My wife and daughter both got sick after we all had lunch at the same restaurant yesterday.
> This is clearly acute gastroenteritis.

I

(b) Reliable Confidence 

> Conf:
> 60
> Conf:
> 30
> Conf:
> 90
> Conf:
> 98
> Conf:
> 95

Fig. 1 : Examples of medical consultation with reliable and unreliable confidence guidance. more information at low confidence levels and provide diagnostic conclusions at high confidence levels, thereby enhancing the safety of the system in clinical applications. However, the current confidence estimation of LLMs still faces significant challenges: uncal-ibrated confidence scores may lead to erroneous decisions (Fig. 1(a)), whereas ideally, confidence should be dynamically adjusted during the inter-action process (Fig. 1(b)). While studies have begun to investigate the confidence performance of LLMs in the medical domain [4‚Äì11], there are still three limitations: (1) Single-round static assess-ment. Most of the work [4‚Äì7] measures confidence only in a single-round, static scenario, and fails to take into account the dynamic coupling of confi-dence and diagnostic correctness with the gradual accumulation of clinical evidence. (2) The task is oversimplified. Gu et al. [8] and Omar et al. [9] are based on multiple-choice or closed-ended question-and-answer tasks, which are difficult to reflect the context-dependent and complex inter-actions in real medical consultations; (3) Limited method coverage. Gao et al. [10] and Chen et al. [11] have only examined some of the confidence estimation strategies and have not yet systemat-ically compared the applicability of token-level, consistency-level, and self-verbalized methods in medical scenarios. In this paper, we introduce the first benchmark for assessing the confidence of multi-round inter-actions in real medical consultations. The bench-mark integrates three types of medical data for open-ended diagnostic generation and introduces information sufficiency gradients (1%, 20%, 40%, 60%, 80%, 100%) to characterize the dynamic relationship between confidence and accuracy. We used Pearson and Spearman correlation coeffi-cients [12] to assess consistency and measured discriminative power using AUROC [13] and AUPRC [14] on the DDXPlus [15], MediTOD [16], and MedQA [17] datasets to compare the perfor-mance of the 27 methods. The evaluation results show that the uncer-tainty of existing confidence estimation methods on medical data exhibits significant instability and randomness. Some self-verbalized methods achieve better results on DDXPlus and Medi-TOD but are markedly weaker than token-level and consistency-level methods on MedQA. This inconsistency mainly stems from two reasons. (1) Limitations at the methodological level. The highly specialized terminology and imbalanced label distribution of medical data make token-level methods susceptible to interference, while the lat-ter undermines the stability of consistency-level methods, thereby amplifying their inherent flaws. (2) Domain-specific challenges. Medical diagnosis is inherently uncertain, and the same symptom may correspond to multiple diseases; thus, even if a diagnosis aligns with patient information, it does not necessarily indicate that the information is sufficient or the judgment is reliable. Based on these findings, we propose two takeaways for the design of confidence estimation methods in med-ical scenarios: (1) confidence estimation methods that rely solely on model output features (e.g., token layer or consistency layer) are highly sen-sitive to the characteristics of medical data and should be enhanced by incorporating other types of strategies; and (2) confidence assessment in medical tasks should account for both diagnos-tic accuracy and information completeness rather than only assessing the correctness of answers. Based on these two insights, we propose Med-Conf. On one hand, it replaces the reliance on 2token or consistency signals with self-verbalized evaluation to mitigate its sensitivity to data char-acteristics at the source. On the other hand, it evaluates information integrity using evidence-based metrics. As shown in Fig. 6, the model first generates a preliminary diagnosis based on the available information; then, MedConf retrieves authoritative knowledge related to the diagnosis through retrieval-augmented generation (RAG) [18] and summarizes it to form a symp-tom spectrum with symptom descriptions and significance; and finally, the LLM identifies the supportive, missing, and contradictory relation-ships between the information provided by the patient and the symptom spectrum. It weights and aggregates these relationships as interpretable evi-dence to derive a confidence score for the current diagnosis. Experimental results demonstrate that Med-Conf achieves state-of-the-art performance across all datasets and models, exhibiting excellent cor-relation with accuracy and superior discrimina-tive capability. For example, compared to the 27 baseline methods in our study on DDX-Plus with Llama-3.1, MedConf demonstrates aver-age improvements of 0.410 and 0.476 for Pear-son and Spearman coefficients, while achieving improvements of 0.129 and 0.124 in AUROC and AUPRC metrics. Furthermore, MedConf demon-strates superior robustness against noisy or irrel-evant information and achieves higher accuracy with efficiency when integrated with medical agents. Ablation studies reveal the contribution of different designs in MedConf. Our main contri-butions are :

‚Ä¢ We propose the first medical LLMs confidence estimation benchmark that assesses confidence under a multi-turn interaction setting for real-istic medical scenarios. Our benchmark utilizes more realistic tasks, comprehensively collects 27 confidence estimation methods, and evaluates their correlation with accuracy and discrimi-native ability under different levels of patient information. 

‚Ä¢ Benchmark results reveal that medical data may amplify the limitations of token-level and consistency-level methods that rely on model output features, and medical tasks need to con-sider uncertainty arising from incomplete input information. To solve this, we propose Med-Conf, an evidence-based self-verbalized method that considers the supportive, missing, and con-tradictory relationships between existing infor-mation and diagnosis results as evidence to infer a confidence score. 

‚Ä¢ Experimental results show that MedConf achieves state-of-the-art results across all benchmark configurations. Furthermore, Med-Conf demonstrates robustness to irrelevant information and achieves high diagnostic accu-racy and interaction efficiency when integrated into healthcare agents. 

## 2 Related Works 

2.1 LLMs Confidence Estimation 

As illustrated in Fig. 2, current confidence esti-mation methods for LLMs can be categorized into three types: token-level methods, consistency-level methods, and self-verbalized methods. In this paper, we collect 27 confidence estimation meth-ods and evaluate them on our proposed medical confidence estimation benchmark. 

Token-level methods calculate the confi-dence of LLMs based on the probability distribu-tion of the generation. These techniques rely on token probability from a single model prediction. Jiang et al. [19] first propose measuring the confi-dence score using the predicted probability of the response tokens. Huang et al. [20] and Manakul et al. [21] propose using the negative log-likelihood or entropy of the average or maximum of the response tokens to estimate confidence. Moreover, alternatives such as perplexity [22], mutual infor-mation [23], R¬¥ enyi divergences, and Fisher-Rao distance [24] are widely used to calculate confi-dence. Using a different approach, Claim Condi-tional Probability (CCP) [25] decomposes LLM outputs into a set of claims and computes token-level uncertainty from the tokens constituting each claim. Recently, Duan et al. [26] demonstrate that not all tokens contribute equally to the meaning. They propose the tokenSAR method, which re-weights the computation results by evaluating the importance of each token. 

Consistency-level methods sample multi-ple responses to the same query, then utilize the consistency to estimate the confidence score. Man-akul et al. [21] propose using the percentage of 3Input  Confidence     

> Prompt
> Answer
> LLM Confidence
> Score
> LLM
> Input Answer
> White Box
> LLM
> Tokens Prob
> ùëÉùëÉ (ùëßùëß |ùë•ùë• )
> Probability
> Calculation
> Confidence
> Score
> Input LLM Repeat k times
> Answer 1
> Answer 2
> Answer k
> ‚Ä¶
> Similarity
> Calculation
> Confidence
> Score
> (a) Token-Level Method
> (b) Consistency-Level Method
> (c) Self-Verbalized Method

Fig. 2 : Illustration of the token-level, consistency-level, and self-verbalized method of LLMs confi-dence estimation. the most consistent samples to evaluate the confi-dence. Lin et al. [27] introduce the use of different linear algebra techniques, such as Degree Matrix, Sum of Eigenvalues of the Graph Laplacian, and Eccentricity, to measure confidence. Furthermore, lexical similarity [21] and semantic similarity [28] can also be regarded as essential metrics for con-sistency assessment. Taking a different approach, some studies integrate token probability into the calculation of consistency measures. Monte Carlo Sequence Entropy [29] generates several sequences via random sampling and computes the result-ing entropy. Semantic Entropy [29] clusters the semantically similar generations and then calcu-lates the entropy. Finally, SAR [26] amplifies the probability of sentences that are more relevant and convincing than others. 

Self-verbalized methods query the LLM itself about the confidence of its generation. Lin et al. [30] first demonstrate the LLM‚Äôs capabilities to provide reasonable confidence. Subsequently, Tian et al. [31] introduce a two-step process, top-k sampling, and chain-of-thought techniques to improve confidence score. P(true) [32] introduce a different approach by asking the model to validate its answer as true or false and then assigning the confidence score on the probability of true. 

2.2 LLMs Confidence Estimation in Medical Domain 

Confidence estimation effectively improves the reliability and reduces risks of an artificial intel-ligence system in the medical domain. Exist-ing research has applied confidence estimation to machine learning models [33‚Äì35], vision mod-els [36‚Äì39], and small language models [40‚Äì42]. However, due to the large-scale parameter char-acteristics of LLMs, these methods are difficult to transfer to LLM evaluation. Recent studies have applied existing LLM confidence estimation methods to various medical datasets to investi-gate their effectiveness on medical data. Savage et al. [6] and Atf et al. [7] evaluate these methods on Medical QA tasks, while Gu et al. [8], Omar et al. [9], and Savage et al. [6] focus on medical multiple-choice questions. Gao et al. [10] and Chen et al. [11] examine their effectiveness on electronic health records (EHR)-based clinical prediction. However, these benchmarks evaluate confidence only under complete information and overlook how confidence scores evolve as additional relevant information becomes available. Beyond bench-marking, Hu et al. [43] introduce confidence scores to enhance inquiry effectiveness, whereas Wu et al. [44] and Qin et al. [45] calibrate medical LLM con-fidence through Chain-of-Verification and atypical presentations, respectively. In this paper, we pro-pose an evidence-based self-verbalized method that improves confidence estimation for medical datasets. 

## 3 Medical Confidence Benchmark 

3.1 Motivation 

Existing medical LLMs confidence estimation benchmarks [6‚Äì11] have three fundamental limi-tations in their setup. First, current studies only evaluate confidence in a single-round and static scenario, and fail to take into account the dynamic coupling of confidence and diagnostic correct-ness as the information increases. Second, exist-ing benchmarks only evaluate on simple medical tasks. Savage et al. [6] and Atf et al. [7] assess confidence performance on simple question-answer task and Gu et al. [8] and Omar et al. [9] eval-uate on multiple-choice questions task. However, 4Table 1 : Confidence estimation methods implemented in our benchmark. Category Confidence Estimation Method Type Token-level Average Sequence Probability (ASP) [20] White-box Maximum Sequence Probability (MSP) [20] White-box Perplexity [22] White-box Entropy [21] White-box Pointwise Mutual Information (PMI) [23] White-box Conditional PMI [46] White-box TokenSAR [26] White-box R¬¥ enyi Divergence [24] White-box Fisher-Rao Distance [24] White-box Claim Conditional Probability (CCP) [25] White-box Consistency-level Percentage of Consistency (PoC) [21] Black-box Lexical Similarity (LexSim) [21] Black-box Semantic Similarity (SemSim) (BERT) [28] Black-box Semantic Similarity (SemSim) (MedBERT) [28] Black-box Number of Semantic Sets (NumSet) [27] Black-box Sum of Eigenvalues of the Graph Laplacian (EigV) [27] Black-box Degree Matrix (Deg) [27] Black-box Eccentricity (Ecc) [27] Black-box Monte Carlo Sequence Entropy (MC-SE) [29] White-box Monte Carlo Norm. Seq. Entropy (MC-NSE) [47] White-box Semantic Entropy [29] White-box SentenceSAR [26] White-box SAR [26] White-box Self-verbalized Confidence Elicitation (CE) [31] Black-box CoT CE [31] Black-box Top-k CE [31] Black-box P(True) [32] White-box open-ended decision-making based on dialogues or reports is more aligned with real-world med-ical consultations. Finally, existing benchmarks demonstrate insufficient methodological compre-hensiveness. Omar et al. [9] evaluate only the token probability confidence performance. In con-trast, Gu et al. [8] and Atf et al. [7] focus on partial token-level and self-verbalized methods. Meanwhile, Savage et al. [6] includes all three cate-gories of methods but evaluates only 2-3 relatively outdated approaches. In this section, we introduce a new evaluation benchmark. To conduct testing in scenarios more aligned with real medical practice, we restructure the data format into doctor-patient dialogues or patient reports and transform tasks into open-ended diagnostic generation (In Sec. 3.2). To test the trends of confidence changes as patient infor-mation increases, we propose a patient informa-tion dividing method and new evaluation metrics (In Sec. 3.3). Additionally, we collect and evalu-ate 27 confidence estimation methods, enhancing the comprehensiveness of benchmark evaluation (In Sec. 3.4). 

3.2 Data Preparation 

We evaluate the existing confidence estimation methods on three medical datasets: DDXPlus [15], MediTOD [16], and MedQA [17]. DDXPlus is a large-scale synthetic dataset containing pathology information, symptoms, and patient antecedents. MediTOD comprises real-world doctor-patient dialogues with annotated complex relationships between dialogue content and corresponding 5attributes. MedQA is a professional-level multiple-choice question (MCQ) dataset derived from med-ical licensing examinations ( e.g., USMLE) that requires complex medical reasoning and domain knowledge. To achieve closer alignment with clinical prac-tice, we preprocess all datasets by transforming them into doctor-patient conversation formats or medical report formats and restructuring them as open-ended diagnosis generation tasks. Specifi-cally, for the DDXPlus dataset, we convert struc-tured data into doctor-patient dialogue format using GPT-4.1 [48], transforming symptoms into doctor inquiries and converting binary or numeri-cal results into natural language patient responses. For MediTOD, since the data is already in dia-logue format, we retain the original structure while filtering to include only effective dialogues based on the purpose and contribution of each conversational turn as labeled in the dataset. For MedQA, we retain its report format and trans-form the MCQ task into a generation task by removing multiple-choice options and requiring open-ended responses. More details are provided in the supplementary material and Fig. A1. To ensure adequate patient information for the following confidence estimation, we apply fil-tering criteria selecting DDXPlus and MediTOD dialogues with more than 10 conversational turns and MedQA cases with more than 10 sentences. The final evaluation dataset comprises 171 DDX-Plus instances, 231 MediTOD instances, and 181 MedQA instances. 

3.3 Evaluation Pipeline and Metrics 

In our evaluation, we systematically partition patient information into progressive levels: 1% (containing only single-turn conversation or one-sentence report), 20%, 40%, 60%, 80%, and 100% of the complete case information. We then gener-ate diagnostic predictions using LLMs based on each information level and compute confidence scores for these predictions using different confi-dence estimation methods. Finally, we assess the accuracy of each generated diagnosis and analyze its relationship with the corresponding confidence scores. We evaluate confidence estimation perfor-mance from two perspectives: 1) Correlation assessment: We employ Pearson and Spearman correlation coefficients to measure the align-ment between diagnostic accuracy and confi-dence scores, determining whether confidence esti-mates appropriately increase alongside accuracy improvements. 2) Discriminative assessment: We utilize AUROC and AUPRC metrics to evaluate the capability of confidence scores to effectively distinguish between correct and incorrect diagnos-tic predictions. 

3.4 Evaluated Methods 

As listed in Tab. 1, we implement and evaluate 27 widely-used confidence estimation methods, com-prising 10 token-level methods, 13 consistency-level methods, and four self-verbalized methods. Accessibility requirements categorize these meth-ods: 11 are black-box methods that rely solely on model generation outputs and apply to both closed-source and open-source models, while 16 are white-box methods that require access to internal model states, such as logits or hidden layer outputs, and are therefore limited to open-source models. For mathematical notations used in this section, please refer to Tab. A1 in the supplementary material. 

Token-level methods: The token-level methods analyze the probability distribution over individ-ual tokens P (yl | y<l , x), where x is the input sequence and y<l is previous generated tokens. A universal formula of token-level methods can be represented as: 

C = œÜ

> L

M

> l=1

wl ‚äô œà (P (yl | y<l , x)) 

!

(1) where œà(¬∑) is the token-level transformation func-tion, LLl=1 is the aggregation operation, œÜ(¬∑) is the final transformation function, wl is the token weights, and L is the generated sequence length. For example, Average Sequence Probability (ASP) [20] applies identity transformation func-tion ( œà(P ) = P and œÜ(x) = x) and aggregates tokens probabilities via average ( wl = 1 

> L

and 

LLl=1 = PLl=1 ), while Maximum Sequence Proba-bility (MSP) [20] similarly uses identity transfor-mations but aggregates by selecting the maximum token probability ( LLl=1 = max l=1 ,...,L ). Perplex-ity [22] transforms token probabilities via negative 6logarithm ( œà(P ) = ‚àí log P ) and applies expo-nential final transformation ( œÜ(x) = exp( x)) with uniform averaging. Moreover, TokenSAR [26] pro-poses that the contributions of different tokens are unequal and utilizes a relevance-based func-tion to change the weight for each token ( wl =ÀúRT (yl, y, x)). We provide a more detailed dis-cussion on the specifics of these methods and other token-level methods in the supplementary material. 

Consistency-level methods: The consistency-level methods evaluate confidence by assessing the consistency of responses under the same input. This approach involves two steps: 1) Given input x, the LLM generates aresponse set Y = {y1, y2, . . . , yK } containing K

outputs. 2) Estimate confidence by quantifying the con-sistency within the set Y.Consistency-based methods primarily focus on designing different metrics to evaluate consistency. For instance, PoC [21] calculates the propor-tion of the most frequent response, while Sem-Sim [28] measures confidence by computing the average cosine similarity between the embedding of response pairs. On the other hand, several approaches inte-grate token probability data into consistency measures. Monte Carlo Sequence Entropy (MC-SE) [29] calculates entropy at the sequence level by averaging the negative log-probabilities across multiple generated sequences: 

CMC-SE = ‚àí 1

K

> K

X

> k=1

log P (y(k)|x) (2) where P (y(k)|x) = QLk 

> l=1

P (y(k) 

> l

|y(k) 

> <l

, x) rep-resents the probability of the k-th generated sequence. Based on this, Semantic Entropy (SE) [29] first clusters the responses into similar groups and then calculates the entropy over these semantic clusters. We provide a more detailed discussion of consistency-based methods in the supplementary material. 

Self-verbalized Methods: The Confidence Elic-itation (CE) methods utilize the LLM‚Äôs reason-ing ability to express confidence in natural lan-guage [31]. Given input x and LLM output y, the model provides a confidence score from 0 to 100 using a specific prompt: 

CCE = f (Prompt , x, y) (3) where f (¬∑) represents the LLM model. The prompt follows different strategies such as vanilla prompt-ing, Chain-of-Thought reasoning, or Top-k selec-tion, with details provided in the supplementary material and Fig. A2-A4. Alternatively, the P(True) [32] method queries the model to validate its answer as true or false. The confidence is computed as the proportion of true responses across K evaluations: 

CPTrue = 1

K

> K

X

> i=1

I(y(i) = ‚ÄúTrue‚Äù) (4) 

## 4 Benchmark Results 

In this section, we conduct experiments with two large language models: an open-source model Llama-3.1 [49], and a closed-source model GPT-4.1 [48]. We first report the performance of dif-ferent methods across various models and dataset combinations, then analyze the shortcomings of existing methods based on experimental results. Finally, we propose insights for designing con-fidence estimation methods that meet medical requirements. 

4.1 Information-Accuracy Correlation 

In this part, we examine how diagnostic accuracy varies for Llama-3.1 and GPT-4.1 as patient infor-mation is progressively accumulated across differ-ent medical datasets. This evaluation establishes the fundamental relationship between information availability and diagnostic performance, providing critical context for understanding the importance of confidence-guided decision making in medical AI systems. As shown in the results in Fig. 3, both mod-els exhibit a consistent and approximately linear increase in diagnostic accuracy with the sequential addition of relevant clinical information. This lin-ear relationship underscores a fundamental princi-ple: making diagnoses based on insufficient patient 7(a) Llama-3.1 (b) GPT-4.1 

Fig. 3 : Model performance on medical datasets DDXPlus, MediTOD, and MedQA across information levels for (a) Llama-3.1 and (b) GPT-4.1. information inevitably leads to suboptimal out-comes, while comprehensive information gathering significantly enhances diagnostic reliability. 

4.2 Confidence-Accuracy Correlation 

In this part, we evaluate the correlation between confidence and diagnostic accuracy as patient information increases. The results in Tab. 2 reveal performance variability across different datasets and models. Token-level methods and consistency-level methods exhibit significant sensitivity to datasets and models. For instance, for Llama-3.1, token-level methods Perplexity and TokenSAR demonstrate strong accuracy-confidence align-ment on MedQA (Pearson coefficients > 0.961, Spearman coefficients = 1.0), yet show markedly poor consistency on DDXPlus and MediTOD datasets (Pearson coefficients < 0.515, Spearman coefficients < 0.486). Consistency-level methods Eig, Deg, and Ecc methods achieve excellent con-sistency on MediTOD and MedQA datasets on GPT-4.1, but fail to maintain this performance on DDXPlus with GPT-4.1 or on any datasets with Llama-3.1. In contrast, self-verbalized methods demon-strate superior robustness across most models and datasets. The CE and CoT CE methods consistently produce confidence scores with sta-tistically significant accuracy correlations across both Llama-3.1 and GPT-4.1 on all datasets. How-ever, exceptions still exist. For example, when applying the CoT CE method to the MediTOD dataset with the Llama-3.1 model, the align-ment effect remains limited (Pearson correlation = 0.596, Spearman correlation = 0.086). 

4.3 Discriminative Ability 

In this part, we examine the ability of the confidence score to discriminate between correct and incorrect diagnosis. Based on the results shown in Fig. 4, existing confidence estima-tion methods exhibit two key characteristics in their discriminative ability. First, different meth-ods exhibit varying applicability across datasets. Self-verbalized methods outperform both token-level and consistency-based methods on DDX-Plus and MediTOD datasets, while on MedQA, self-verbalized methods demonstrate poor per-formance and consistency-based methods achieve optimal results. Second, performance variations exist among methods within the same category. For instance, on DDXPlus using Llama-3.1, the ASP method achieves excellent discriminative ability, whereas the MSP and Entropy methods, despite belonging to the same token-level category, perform substantially worse. 

4.4 Discussion 

Existing methods show certain consistency with accuracy and discriminative ability for correct answers, indicating the potential for applying con-fidence estimation in the medical domain. How-ever, experimental results reveal that existing methods exhibit sensitivity to both models and datasets. These methods may perform well under specific conditions but substantially underperform 8Table 2 : Pearson and Spearman correlation coefficients between accuracy and confidence scores across different confidence estimation methods, models, and datasets. Results show correlation values with p-values in parentheses. Statistically significant results (p ‚â§0.05) are bolded. Token-level methods are colored blue, consistency-level methods are colored green, and self-verbalized methods are colored orange. 

(a) Llama-3.1 

Method DDXPlus MediTOD MedQA Pearson Spearman Pearson Spearman Pearson Spearman ASP 0.794 (0.059) 0.429 (0.397) 0.306 (0.556) 0.257 (0.623) 0.994 ( ‚â§0.05) 0.943 ( ‚â§0.05) 

MSP 0.786 (0.064) 1.000 ( ‚â§0.05) 0.807 (0.137) 0.486 (0.329) 0.913 ( ‚â§0.05) 0.943 ( ‚â§0.05) 

Perplexity 0.508 (0.303) 0.486 (0.329) 0.431 (0.596) 0.086 (0.872) 0.978 ( ‚â§0.05) 1.000 ( ‚â§0.05) 

Entropy 0.14 (0.792) 0.029 (0.957) 0.18 (0.733) 0.143 (0.787) 0.905 ( ‚â§0.05) 0.829 ( ‚â§0.05) 

PMI 0.781 (0.067) 0.943 ( ‚â§0.05) 0.526 (0.283) 0.714 (0.111) 0.746 (0.089) 0.886 ( ‚â§0.05) 

Conditional PMI 0.829 ( ‚â§0.05) 0.042 (0.397) 0.734 (0.097) 0.829 ( ‚â§0.05) 0.973 ( ‚â§0.05) 0.943 ( ‚â§0.05) 

TokenSAR 0.515 (0.296) 0.486 (0.329) 0.382 (0.226) 0.257 (0.623) 0.981 ( ‚â§0.05) 1.000 ( ‚â§0.05) 

R¬¥ enyi Divergence 0.041 (0.939) 0.029 (0.957) 0.662 (0.160) 0.257 (0.623) 0.961 ( ‚â§0.05) 0.771 (0.072) Fisher-Rao Distance 0.049 (0.927) 0.086 (0.871) 0.608 (0.200) 0.257 (0.623) 0.961 ( ‚â§0.05) 0.943 ( ‚â§0.05) 

CCP 0.848 ( ‚â§0.05) 0.943 ( ‚â§ 0.05) 0.585 (0.223) 0.771 (0.072) 0.958 ( ‚â§0.05) 0.943 ( ‚â§0.05) 

PoC 0.555 (0.253) 0.2 (0.704) 0.285 (0.815) 0.086 (0.872) 0.865 ( ‚â§0.05) 0.886 ( ‚â§0.05) 

Lexical Similarity 0.320 (0.537) 0.657 (0.156) 0.335 (0.516) 0.657 (0.156) 0.917 ( ‚â§0.05) 0.829 ( ‚â§0.05) 

Semantic Similarity (BERT) 0.733 (0.098) 0.429 (0.397) 0.491 (0.523) 0.571 (0.156) 0.865 ( ‚â§0.05) 0.886 ( ‚â§0.05) 

Semantic Similarity (MedBERT) 0.437 (0.386) 0.2 (0.704) 0.331 (0.522) 0.429 (0.397) 0.265 (0.612) 0.200 (0.704) NumSet 0.443 (0.379) 0.657 (0.156) 0.443 (0.379) 0.657 (0.156) 0.594 (0.214) 0.143 (0.787) EigV 0.567 (0.24) 0.029 (0.623) 0.195 (0.711) 0.371 (0.468) 0.894 ( ‚â§0.05) 0.600 (0.208) Deg 0.655 (0.158) 0.6 (0.208) 0.059 (0.911) 0.600 (0.208) 0.698 (0.125) 0.257 (0.623) Ecc 0.668 (0.147) 0.429 (0.397) 0.668 (0.147) 0.429 (0.397) 0.708 (0.116) 0.429 (0.397) MC-SE 0.578 (0.229) 0.371 (0.468) 0.579 (0.229) 0.371 (0.468) 0.897 ( ‚â§0.05) 0.886 ( ‚â§0.05) 

MC-NSE 0.473 (0.343) 0.6 (0.208) 0.473 (0.344) 0.486 (0.329) 0.988 ( ‚â§0.05) 1.000 ( ‚â§0.05) 

Semantic Entropy 0.722 (0.105) 1.000 ( ‚â§0.05) 0.510 (0.302) 0.486 (0.329) 0.897 ( ‚â§0.05) 1.000 ( ‚â§0.05) 

SentenceSAR 0.326 (0.529) 0.257 (0.623) 0.372 (0.467) 0.257 (0.623) 0.981 ( ‚â§0.05) 1.000 ( ‚â§0.05) 

SAR 0.347 (0.502) 0.086 (0.871) 0.533 (0.280) 0.486 (0.329) 0.897 ( ‚â§0.05) 0.771 (0.072) CE 0.870 ( ‚â§0.05) 0.771 (0.072) 0.895 ( ‚â§0.05) 1.000 ( ‚â§0.05) 0.972 ( ‚â§0.05) 1.000 ( ‚â§0.05) 

CoT CE 0.907 ( ‚â§0.05) 0.943 ( ‚â§0.05) 0.596 (0.470) 0.086 (0.623) 0.935 ( ‚â§0.05) 0.943 ( ‚â§0.05) 

Top-k CE 0.814 ( ‚â§0.05) 0.829 ( ‚â§0.05) 0.690 (0.130) 0.714 (0.111) 0.704 (0.119) 0.771 (0.072) P(True) 0.364 (0.478) 0.086 (0.871) 0.232 (0.558) 0.143 (0.787) 0.585 (0.223) 0.771 (0.072) 

(b) GPT-4.1 

Method DDXPlus MediTOD MedQA Pearson Spearman Pearson Spearman Pearson Spearman PoC 0.105 (0.861) 0.257 (0.623) 0.356 (0.489) 0.600 (0.208) 0.834 ( ‚â§0.05) 0.657 (0.156) Lexical Similarity 0.069 (0.897) 0.371 (0.468) 0.451 (0.369) 0.714 (0.111) 0.958 ( ‚â§0.05) 1.000 ( ‚â§0.05) 

Semantic Similarity (BERT) 0.785 (0.064) 0.829 ( ‚â§0.05) 0.828 ( ‚â§0.05) 0.771 (0.072) 0.903 ( ‚â§0.05) 0.829 ( ‚â§0.05) 

Semantic Similarity (MedBERT) 0.120 (0.821) 0.257 (0.623) 0.109 (0.836) 0.086 (0.872) 0.847 ( ‚â§0.05) 0.771 (0.072) NumSet 0.047 (0.930) 0.086 (0.872) 0.000 (1.000) 0.086 (0.872) 0.804 (0.054) 0.714 (0.111) EigV 0.660 (0.154) 0.429 (0.397) 0.871 ( ‚â§0.05) 0.943 ( ‚â§0.05) 0.945 ( ‚â§0.05) 1.000 ( ‚â§0.05) 

Deg 0.576 (0.231) 0.657 (0.156) 0.873 ( ‚â§0.05) 0.943 ( ‚â§0.05) 0.900 ( ‚â§0.05) 0.829 ( ‚â§0.05) 

Ecc 0.575 (0.233) 0.600 (0.208) 0.873 ( ‚â§0.05) 0.943 ( ‚â§0.05) 0.906 ( ‚â§0.05) 0.886 ( ‚â§0.05) 

CE 0.989 ( ‚â§0.05) 1.000 ( ‚â§0.05) 0.981 ( ‚â§0.05) 1.000 ( ‚â§0.05) 0.989 ( ‚â§0.05) 1.000 ( ‚â§0.05) 

CoT CE 0.861 ( ‚â§0.05) 0.943 ( ‚â§0.05) 0.981 ( ‚â§0.05) 1.000 ( ‚â§0.05) 0.987 ( ‚â§0.05) 1.000 ( ‚â§0.05) 

Top-k CE 0.269 (0.591) 0.429 (0.397) 0.587 (0.220) 0.943 ( ‚â§0.05) 0.552 (0.256) 0.486 (0.329) 

when applied to different models or datasets. For example, on Llama-3.1, the Entropy method achieves excellent consistency (Pearson coeffi-cient = 0.905 and Spearman coefficient = 0.829) and discriminative ability (AUROC = 0.766 and AUPRC = 0.694) on the MedQA dataset. In contrast, the same method demonstrates severely limited consistency (Pearson coefficient = 0.14 and Spearman coefficient = 0.029) and discrimi-native ability (AUROC = 0.501 and AUPRC = 0.555) on the DDXPlus dataset. These findings underscore the insufficient reli-ability of current methods when confronted with diverse medical data, thereby hindering their prac-tical deployment in clinical applications. The challenges of current methods in the medical domain are primarily concentrated in two key 9(a) Llama-3.1 

> (b) GPT-4.1

Fig. 4 : Discriminative performance comparison of confidence estimation methods across models and datasets using AUROC and AUPRC metrics. (a) Results for Llama-3.1 model and (b) Results for GPT-4.1 model. Methods are color-coded by category: token-level methods (blue), consistency-level methods (green), and self-verbalized methods (yellow). areas: 1) methodological limitations, where the unique characteristics of medical data amplify the inherent limitations of existing approaches; 2) domain-specific challenges, where the medical field imposes additional requirements for confidence evaluation. 

4.4.1 Methodological limitations 

Token-level methods exhibit fundamental limita-tions that they rely heavily on the probability of individual tokens. However, the token logit only captures the model‚Äôs uncertainty regarding the next token rather than providing an assessment of the reliability of a specific claim [50]. In medical contexts, the complex and lengthy domain-specific terminology magnifies this limitation. As illus-trated in Fig. 5(a), which presents an incorrect diagnosis, the ‚ÄúAnticholinergic Toxicity‚Äù is tok-enized into 5 tokens: ‚ÄúAnt‚Äù,‚Äúich‚Äù,‚Äúolin‚Äù,‚Äúergic‚Äù ,and ‚Äútoxicity‚Äù . Although the model exhibits high uncertainty for the initial token ‚ÄúAnt‚Äù , once this token is generated, subsequent tokens have very high probabilities. Consequently, when consider-ing the average probability of generating this diagnosis, this erroneous prediction receives a high confidence score of 0.754. For consistency-level methods, they suffer from a different fundamental issue: consistency reflects only the relative likelihood of an LLM response compared to alternative responses generated by the same model, rather than its likelihood in the real world [29]. In the medical domain, the coexistence of common and rare diseases creates uneven data distributions that amplify the dis-crepancy between model-generated likelihood and actual clinical likelihood. As the example shown in Fig. 5(b), when patient information contains only non-specific symptoms like fever, conditions such as flu, cold, and pneumonia should theoretically exhibit similar generation probabilities, resulting in appropriately low consistency scores. However, due to the model overfitting toward more frequent conditions like flu, the model generates highly 10 Anticholinergic Toxicity  [Ant, ich, olin, ergic, toxicity] tokenize           

> Ant ich olin ergic toxicity
> Average Probability:
> 0.754
> Prob (a) Token-level methods limitation Patient Information: Fever
> Flu Cold Pneumonia Flu Cold Pneumonia
> Overfit
> Low Consistency
> High Consistency
> (b) Consistency-level methods limitation Symptoms Diseases
> Stomach Pain
> Fever
> Diarrhea
> Clustering Case
> Food Poisoning
> Appendicitis
> Urinary Infection
> Support
> Missing
> (c) Medical domain challenge

Fig. 5: Example of methodological limitation of (a) token-level methods, (b) consistency-level methods, and (c) medical domain challenge. consistent results even for such ambiguous pre-sentations, rendering consistency scores unable to accurately reflect true diagnostic uncertainty. 

4.4.2 Domain-specific Challenge 

Existing confidence estimation methods were orig-inally designed for arithmetic, logic, and symbolic reasoning tasks, which are characterized by com-prehensive problem descriptions and unique cor-rect answers [4, 5]. However, medical diagnostic tasks present fundamentally different challenges: patient-provided information is often incomplete or insufficient, and the relationships between symptoms and diseases are inherently complex and multifaceted. As illustrated in Fig. 5(c), when a patient provides information about stomach pain and fever, the model makes a diagnosis of food poisoning. According to previous task evalu-ation standards, the current diagnosis contains no errors and should receive high confidence support. However, due to the complex nature of medi-cal conditions, the currently provided information could also correspond to other diseases, such as appendicitis or urinary tract infection, revealing the uncertainty of the current diagnosis. There-fore, in medical contexts, confidence evaluation needs to assess not only whether the conclusion is correct, but also whether the input information is sufficient to support the diagnostic conclusion. However, current methods all lack the ability to evaluate input completeness. 

4.4.3 Medical Confidence Estimation Insights 

Based on existing analysis, we propose two insights for designing medical confidence estima-tion methods suitable for healthcare applications: 

‚ù∂ Based on our analysis of methodological limita-tions, methods that rely on model output features (token-level methods and consistency-based meth-ods) are highly sensitive to the characteristics of medical data. To achieve stable performance, alternative strategies that are less affected by medical data should be considered, such as self-verbalized methods based on model reasoning to evaluate confidence scores; ‚ù∑ Based on our analy-sis of domain-specific challenges that medical data requires assessing patient information sufficiency, confidence assessment in medical tasks should account for both diagnostic accuracy and informa-tion completeness rather than only assessing the correctness of answers. 

## 5 MedConf 

Following Insight ‚ù∂, MedConf does not rely on model output probabilities or distributions, but instead leverages the model‚Äôs reasoning capabili-ties through a self-verbalized approach, mitigat-ing its sensitivity to medical data characteristics. According to Insight ‚ù∑, MedConf treats the com-prehensiveness of patient information as a crucial criterion for confidence assessment. Based on these two insights, we propose MedConf, a diagnostic confidence estimation method based on evidence-driven self-verbalization. The goal of MedConf is to estimate a confidence score C ‚àà [0 , 100] that 11 Patient Information  

> I have been having stomach pain, feeling nauseous, and I have a slight fever.
> Diagnostic Result
> It‚Äôs appendicitis
> Medical RAG
> Symptom Profile
> {‚ÄúId‚Äù: 0,
> ‚ÄúDescription‚Äù: Fever,
> ‚ÄúImportance‚Äù: Moderate}
> Low-grade fever that may rise as the condition progresses
> Keyword
> Compare
> Confidence Estimation
> {‚ÄúId‚Äù: 0,
> ‚ÄúDescription‚Äù: Fever,
> ‚ÄúImportance‚Äù: Moderate,
> ‚ÄúSupport‚Äù: Supported,
> ‚ÄúEvidence‚Äù: I have a sight fever.
> ‚Ä¶
> }
> Confidence: 30
> 1
> 2
> 2
> 33

Fig. 6 : The main proposed MedConf framework. This framework consists three steps: ‚ë† diagnostic generation, ‚ë° symptoms generation, and ‚ë¢ confidence generation. reflects the reliability of a diagnosis d generated by an LLM, based on the comprehensiveness and sup-port of available patient evidence. As illustrated in Fig. 6, MedConf comprises three sequential steps: diagnostic generation, symptom generation, and confidence generation. We also provide all prompts used in MedConf in the Fig. A5-A7 and a case study for MenConf in the supplementary material and Fig. A9-A13. 

5.1 Diagnostic Generation 

The diagnostic generation step is responsible for producing diagnostic results. Given patient infor-mation I and LLM f , the model utilizes the diagnosis prompt Prompt d to generate diagnostic assessments d:

d = f (Prompt d, I ) (5) For instance, the patient information I in Fig. 6 is ‚ÄúI have been having stomach pain, feeling nauseous, and I have a slight fever ‚Äù, and the generated diagnosis d is ‚Äú It‚Äôs appendicitis ‚Äù. 

5.2 Symptom Generation 

The symptom generation step operates through a two-phase process to create a comprehensive symptom profile for the predicted diagnosis. 

Knowledge Retrieval Phase: The process first utilizes a RAG system to identify and retrieve the relevant medical passages R associated with the generated diagnosis d:

R = RAG( d, D) (6) The RAG system enables the LLMs to search rel-evant literature to integrate domain knowledge in their response. It operates through a three-stage process: First, given the diagnosis d, the LLM extracts the primary diagnostic keyword. In the example shown in Fig. 6, the keyword is ‚Äú appendicitis ‚Äù. Second, the medical corpus D,comprising PubMed, StatPearls, Textbooks, and Wikipedia, is preprocessed by splitting documents into manageable chunks [51]. Third, we employ BM25 [52], a lexical search algorithm, as the retriever to identify the most semantically relevant passages based on keyword matching and term frequency analysis. The number of retrieved pas-sages is determined through empirical validation to balance information comprehensiveness with computational efficiency. In our setting, we choose the 15 most relevant passages as the RAG results. As shown in the example in Fig. 6, a passage ‚ÄúLow-grade fever that may rise as the condition progresses ‚Äù is retrieved from the corpus. 

Symptom Profile Generation Phase: Fol-lowing the RAG step, the LLM generates struc-tured symptom profiles S to summarize the retrieved medical knowledge: 

S = f (Prompt s, R, d ) (7) where Prompt s is the symptom profile genera-tion prompt. To ensure the generated content is suitable for subsequent processing, the symptom generation prompt instructs the model to con-vert retrieved passages into a standardized JSON format with the following schema: 12 [{"id": index number, "description": symptom description, "importance": Strong|Moderate|Weak }, ... ]

Each symptom entry includes a unique index num-ber, a concise symptom description, and an impor-tance classification that reflects the symptom‚Äôs diagnostic significance for the given condition. For example, the retrieved passage about fever is converted into ‚Äú {‚Äúid‚Äù: 0, ‚Äúdescription‚Äù: ‚ÄúFever‚Äù, ‚Äúimportance‚Äù: ‚ÄúModerate‚Äù }‚Äù. 

5.3 Confidence Generation 

The confidence generation process operates through systematic evidence analysis in two dis-tinct phases: 

Evidence Mapping Phase: For each symp-tom si ‚àà S, the model evaluates its relationship with patient information I using three relationship categories: 1. Supported: Patient information explicitly men-tions the symptom or closely related clinical manifestations. 2. Missing: The symptom is absent from patient information despite being expected for the diagnosis, indicating incomplete information. 3. Contradictory: Patient information explicitly contradicts the expected symptom presenta-tion. For supported and contradictory cases, relevant statements are extracted from patient informa-tion as evidence. This analysis is also generated in a structured format to align with the symptom profiles, ensuring systematic evaluation of each symptom. Continuing with our running example from Fig. 6, the symptom ‚Äú fever ‚Äù is compared against the patient statement ‚Äú I have a slight fever‚Äù . Since this represents explicit symptom mention, it is categorized as Supported with the evidence text. 

Score Aggregation Phase: The model sum-marizes evidence from all symptoms to produce the final confidence score. The model is guided to consider both the proportion of supported, missing, and contradictory symptoms and their relative importance weights, with higher confi-dence assigned when critical symptoms are well-supported and fewer missing or contradictions are present. The overall confidence generation process is formulated as: 

CMedConf = f (Prompt c, S, I, d ) (8) where Prompt c is the prompt for confidence score generation. For our example in Fig. 6, although the symptom fever is supported by evidence, there are still other decisive symptoms that are not supported and are missing. Therefore, the model inference is that the final confidence score is 30. 

## 6 Experimental Results 

In this section, we conduct comprehensive evalu-ations of MedConf. First, we compare MedConf against existing confidence estimation methods to assess its performance across various model-dataset combinations. Second, we validate Med-Conf‚Äôs robustness against irrelevant information interference, which is a critical requirement for reliable deployment in clinical settings where extraneous information may be present. Third, we evaluate the effectiveness of integrating Med-Conf with healthcare agents to assess its practical utility in interactive diagnostic scenarios. Finally, we conduct ablation studies to quantify the con-tribution of each key design component within MedConf. 

6.1 Comparison with Existing Methods 

We systematically evaluate MedConf against the best-performing baseline methods of token-level, consistency-level, and self-verbalized categories across all model-dataset combinations. As demon-strated in Tab. 3, MedConf exhibits consistent and substantial superiority across every evaluated con-figuration, establishing its robustness across dif-ferent model architectures and medical datasets. 

Confidence-Accuracy Correlation: For confidence-accuracy correlation, MedConf demon-strates exceptional performance with Pearson cor-relation coefficients ranging from 0.936 to 0.989. It achieves either the highest correlation or per-forms comparably to the best baseline across all 13 conditions. This superior alignment indicates that MedConf‚Äôs confidence scores are more calibrated and trustworthy indicators of prediction accuracy. 

Discriminative Ability: MedConf achieves notable improvements in discriminative capability, with an average AUROC enhancement of 0.056 compared to the best-performing baseline meth-ods across all configurations. Specifically, Med-Conf attains AUROC scores ranging from 0.672 to 0.796, consistently outperforming competing approaches by margins of 0.030 to 0.126 depend-ing on the model-dataset combination. These improvements demonstrate MedConf‚Äôs superior ability to distinguish between correct and incor-rect predictions, establishing it as a more reli-able confidence estimation method for medical AI applications. 

Generalizability: The consistent perfor-mance improvements across three distinct medical datasets (DDXPlus , MediTOD, and MedQA) and two different model architectures (Llama-3.1 and GPT-4.1) demonstrate MedConf‚Äôs broad applica-bility and reliability within the medical domain. These results collectively establish that MedConf generates more reliable and well-calibrated con-fidence scores, providing enhanced stability and trustworthiness compared to existing confidence estimation methods in medical LLMs applications. 

6.2 Robustness to Irrelevant Information 

We conduct a robustness analysis comparing MedConf against representative baseline methods from different confidence estimation categories: ASP (token-level), PoC (consistency-level), and CE (self-verbalized). This evaluation is performed using Llama-3.1 on the DDXPlus dataset to assess each method‚Äôs resistance to irrelevant information interference, a critical factor for reliable clinical deployment. 

Experimental Setup: To simulate realis-tic clinical scenarios where additional but non-diagnostic information may be present, we ran-domly select 1-2 conversational turns from doctor-patient dialogues and employ GPT-4.1 to generate semantically equivalent paraphrased content with varied linguistic expressions. This paraphrased content is appended to the model input, creating controlled conditions where the added informa-tion provides no additional diagnostic value while potentially introducing linguistic variations that could affect confidence estimation stability. We evaluate confidence scores across three distinct irrelevant information conditions using identical random seeds to ensure fair compari-son. Robustness is quantified using the Coefficient of Variation (CV), where CV group measures variability among mean confidence scores across the three experimental groups, and CV sample calculates the average CV across individual sam-ple instances. Lower CV values indicate greater robustness and stability. 

Results and Analysis: As demonstrated in Tab. 4, baseline methods exhibit substantial vul-nerability to irrelevant information interference. The CE method shows particularly poor stability with CV values of 11.655 (group-level) and 47.575 (sample-level), likely attributable to the inher-ent sensitivity of self-verbalized approaches to prompt variations and linguistic nuances. In con-trast, MedConf demonstrates exceptional robust-ness with significantly lower variability scores (CV group: 2.343, CV sample: 12.401). This represents substantial improvements of 0.237 and 2.857 over ASP, 2.515 and 11.924 over PoC, and remarkable improvements of 9.312 and 35.174 over the CE method. MedConf‚Äôs superior robustness stems from its fundamental design principle: MedConf is based on structured patient information analysis rather than surface-level linguistic features. Since semantically equivalent but linguistically varied content does not alter the underlying patient information, MedConf maintains stable confidence scores regardless of presentation variations. These results establish MedConf‚Äôs superior predictabil-ity and robustness across varying input scenar-ios‚Äîessential characteristics for reliable deploy-ment in medical AI applications where consistency and stability are important for supporting critical clinical decision-making processes. 

6.3 Integration with Healthcare Agent 

We integrate MedConf and three representa-tive baseline methods (ASP, PoC, and CE) into healthcare agents to evaluate their effec-tiveness in improving diagnostic performance within interactive clinical scenarios. This evalua-tion assesses how different confidence estimation 14 Table 3 : Performance comparison of MedConf against the best-performing token-level, consistency-level, and self-verbalized methods across Llama-3.1 and GPT-4.1 on DDXPlus, MediTOD, and MedQA. 

(a) Llama-3.1 and DDXPlus                

> Method Type AUROC Pearson MedConf Self-Verbalized 0.722 0.968
> PMI Token-Level 0.593 0.829 SemSim (BERT) Consistency-Level 0.652 0.733 CE Self-Verbalized 0.670 0.870

(b) Llama-3.1 and MediTOD                

> Method Type AUROC Pearson MedConf Self-Verbalized 0.687 0.943
> Conditional PMI Token-Level 0.560 0.734 SemSim (BERT) Consistency-Level 0.628 0.491 CE Self-Verbalized 0.636 0.895

(c) Llama-3.1 and MedQA                

> Method Type AUROC Pearson MedConf Self-Verbalized 0.796 0.979 Entropy Token-Level 0.766 0.905 MC-NSE Consistency-Level 0.685 0.988
> CoT CE Self-verbalized 0.641 0.935

(d) GPT-4.1 and DDXPlus             

> Method Type AUROC Pearson MedConf Self-Verbalized 0.795 0.936 SemSim (BERT) Consistency-Level 0.622 0.785 CE Self-Verbalized 0.682 0.989

(e) GPT-4.1 and MediTOD             

> Method Type AUROC Pearson MedConf Self-Verbalized 0.672 0.981
> SemSim (BERT) Consistency-Level 0.593 0.829 CE Self-Verbalized 0.628 0.981

(f) GPT-4.1 and MedQA             

> Method Type AUROC Pearson MedConf Self-Verbalized 0.690 0.989
> Ecc Consistency-Level 0.667 0.906 CoT CE Self-Verbalized 0.642 0.987

Table 4 : Robustness evaluation of confidence estimation methods to irrelevant information. Coefficient of variation (CV) measures perfor-mance stability of mean and sample level. 

Method Type CV group CV sample MedConf Self-Verbalized 2.343 12.401 ASP Token-Level 2.580 15.258 PoC Consistency-Level 4.858 24.325 CE Self-Verbalized 11.655 47.575 

Table 5: Performance of confidence estimation methods integrated into healthcare agents. # Utter-ances represents the average utterances in a consul-tation, and accuracy indicates diagnostic accuracy. 

Method Type # Utterances Accuracy (%) MedConf Self-Verbalized 17.84 36 ASP Token-Level 5.20 24 PoC Consistency-Level 18.00 30 CE Self-Verbalized 25.04 36 

methods impact both diagnostic accuracy and interaction efficiency in practical healthcare appli-cations. 

Experimental Setup: Following the setup of Ren et al. [53], we implement healthcare agents that employ confidence score-based decision mak-ing rather than model planning approaches. The agent determines the next action as either patient inquiry or diagnosis based on confidence score thresholds: the agent continues patient inquiry when confidence scores fall below a predeter-mined threshold and proceeds to diagnosis when scores exceed this threshold. We deploy these agents in simulated clinical consultations with virtual patients, systematically evaluating each confidence estimation method‚Äôs impact on diag-nostic performance. The effectiveness is measured through two key metrics: diagnostic accuracy (per-centage of correct diagnoses) and average dia-logue length (measured in utterances per consulta-tion), which together capture the critical trade-off between diagnostic quality and resource efficiency in clinical settings. 

Results and Analysis: As shown in Tab. 5, the confidence estimation methods exhibit dis-tinct behavioral patterns that directly impact both diagnostic accuracy and interaction effi-ciency. The ASP method demonstrates a tendency to generate inappropriately high confidence scores during early interaction stages, resulting in pre-mature diagnostic decisions with only 5.20 average utterances per consultation. This aggressive early termination leads to suboptimal diagnostic accu-racy of 24%, indicating insufficient information gathering for reliable diagnosis. Conversely, the CE method produces high confidence scores only when substantial patient information becomes available, leading to extended dialogues aver-aging 25.04 utterances per consultation. While this conservative approach enables CE to achieve higher diagnostic accuracy (36%) compared to ASP, it requires significantly more computational resources and consultation time due to prolonged interactions, potentially limiting practical applica-bility in resource-constrained clinical settings. The PoC method demonstrates intermediate behavior with 18.00 average utterances and 30% accu-racy, showing moderate performance across both 15 Table 6 : The results of ablation studies. Method AUROC AUPRC Pearson Spearman MedConf 0.772 0.708 0.968 0.943 w/o Symptom Profile 0.657 0.645 0.786 0.657 w/o RAG 0.670 0.588 0.939 0.771 w/o Structure Format 0.688 0.692 0.907 0.943 w/o Importance Level 0.639 0.601 0.959 0.943 efficiency and accuracy metrics but failing to optimize either dimension effectively. MedConf achieves superior performance by striking an optimal balance between diagnostic accuracy and interaction efficiency. With 17.84 average utterances per consultation, MedConf maintains computational efficiency comparable to PoC while achieving the highest diagnostic accuracy of 36%‚Äîmatching CE‚Äôs performance with significantly reduced resource requirements. These results demonstrate that MedConf‚Äôs well-calibrated confidence scores enable more informed decision-making in healthcare agents, leading to appropriately timed diagnostic decisions that maximize accuracy while minimizing unnecessary prolonged interactions. 

6.4 Ablation Studies 

In this section, we conduct systematic ablation experiments to investigate the contribution of key design components within MedConf. These exper-iments isolate individual components to quantify their specific impact on confidence estimation per-formance. The experimental results are presented in Tab. 6, evaluated using Llama-3.1 on the DDX-Plus dataset across multiple performance metrics, including AUROC, AUPRC, Pearson correlation, and Spearman correlation. 

Two-Step Reasoning Process: We first evaluate the impact of MedConf‚Äôs symptom-confidence two-step reasoning framework by removing the intermediate symptom profile gen-eration step. In this ablation variant (w/o Symp-tom Profile), we directly generate confidence scores using RAG-retrieved results, bypassing the symptom profile generation phase. The results demonstrate substantial performance degradation across all metrics, with AUROC declining from 0.772 to 0.657, AUPRC dropping from 0.708 to 0.645, and correlation coefficients decreasing sig-nificantly (Pearson: 0.968 to 0.786, Spearman: 0.943 to 0.657). These findings reveal that mod-els struggle to effectively utilize raw RAG retrieval results as the direct foundation for confidence reasoning. The intermediate symptom profile gen-eration step addresses this limitation by trans-forming fragmented retrieval information into coherent, structured representations that are more amenable to model interpretation, thereby sub-stantially enhancing the reasoning capability for accurate confidence score generation. 

RAG Integration: Secondly, we evaluate MedConf‚Äôs performance without external knowl-edge retrieval (w/o RAG) to assess the neces-sity of incorporating medical knowledge bases. Removing RAG causes substantial performance degradation, with AUROC declining from 0.772 to 0.670, AUPRC decreasing from 0.708 to 0.588, Pearson correlation dropping from 0.968 to 0.939, and Spearman correlation decreasing from 0.943 to 0.771. These findings indicate that external knowledge retrieval is crucial for achieving optimal discriminative capability in medical confidence estimation, as it provides essential domain-specific context that enhances the model‚Äôs ability to assess prediction reliability accurately. 

Structured Format and Importance-Level Annotations: Finally, we examine the contribution of structured formatting and importance-level annotations during symptom profile generation through two separate ablations. Removing structured format (w/o Structure For-mat) results in moderate performance decline (AUROC from 0.772 to 0.688, AUPRC from 0.708 to 0.692), while eliminating importance level annotations (w/o Importance Level) causes more substantial degradation in discriminative perfor-mance (AUROC from 0.772 to 0.639, AUPRC from 0.708 to 0.601). The experimental results 16 indicate that the structured format improves the interpretability and recognition capability of symptom profiles, preventing information loss during subsequent reasoning processes. More critically, importance level annotations provide essential weighting information that enables the model to appropriately consider each symptom‚Äôs differential impact on confidence estimation based on clinical significance. 

## 7 Conclusion and Future Work 

Reliable confidence estimation is essential for med-ical LLMs to prevent misdiagnosis caused by premature conclusions. In this work, we intro-duce the first comprehensive benchmark that eval-uates 27 confidence estimation methods across three medical datasets under varying levels of information, assessing both their correlation with accuracy and their discriminative capability. Our results show that existing methods suffer from instability in medical tasks, driven by method-ological limitations and the unique requirement to assess not only diagnostic accuracy but also the completeness of patient information. To address these gaps, we propose MedConf, a diagnostic evidence‚Äìbased self-verbalized method that lever-ages retrieval-augmented generation to analyze the relationships between patient information and symptom profiles. MedConf achieves state-of-the-art performance, demonstrating superior accuracy correlation, discriminative power, and robustness, while preserving accuracy and efficiency when deployed within healthcare agents. 

Limitation and Future Work: While the benchmark and method presented in this paper are promising, several limitations remain to be addressed in future work. First, our evaluation focuses solely on diagnostic tasks. Confidence esti-mation, however, is also important for other medi-cal applications such as medical report generation and clinical note summarization, which introduce different challenges. These tasks are beyond the current scope, but we plan to extend the bench-mark to cover a broader range of medical appli-cations. Second, although our MedConf method achieves state-of-the-art performance, its multi-step reasoning process introduces additional com-putational overhead and latency compared to sim-pler token-level approaches. This may limit real-time deployment in some resource-constrained clinical settings. To address this, we plan to inves-tigate efficiency optimization techniques, includ-ing caching frequently accessed medical knowledge and developing lightweight symptom profile gen-eration models, to reduce inference time while maintaining performance. Finally, all experiments in this paper are conducted in simulated environ-ments using benchmark datasets rather than in real clinical settings. While these datasets reflect real-world data and provide a practical alterna-tive to clinical testing at this stage‚Äîhelping to reduce the burden on medical professionals and patients as well as the time required‚Äîthey cannot fully capture the complexities of real-world clini-cal practice. As future work, we aim to conduct prospective clinical trials where healthcare profes-sionals interact directly with confidence-aware AI systems to assess their practical utility and the interpretability of confidence scores. 

## Author contribution 

Z.R., Y.Z., B.Y., and G.M. conceived and designed this study. Z.R. developed code and conducted experiments. Z.R., Y.Z., B.Y., S.L., and D.T. con-tributed to write the manuscript. Y.Z., B.Y, S.L., and D.T. supervised this paper. All authors have read and approved the manuscript. 

## Acknowledgements 

This study received no funding. 

## Funding 

This study received no funding. 

## Competing interests 

The authors declare no competing interests. 

## Data availability 

The DDXPlus, MediTOD, and MedQA datasets are publicly available. 17 Code availability 

The underlying code for this study is not publicly available but may be made available to quali-fied researchers on reasonable request from the corresponding author. 

## References 

[1] Meyer, A.N., Payne, V.L., Meeks, D.W., Rao, R., Singh, H.: Physicians‚Äô diagnostic accuracy, confidence, and resource requests: a vignette study. JAMA internal medicine 

173 (21), 1952‚Äì1958 (2013) [2] Ng, C., Palmer, C.: Analysis of diagnostic confidence and diagnostic accuracy: a unified framework. The British journal of radiology 

80 (951), 152‚Äì160 (2007) [3] Bhise, V., Rajan, S.S., Sittig, D.F., Mor-gan, R.O., Chaudhary, P., Singh, H.: Defin-ing and measuring diagnostic uncertainty in medicine: a systematic review. Journal of gen-eral internal medicine 33 (1), 103‚Äì115 (2018) [4] Shorinwa, O., Mei, Z., Lidard, J., Ren, A.Z., Majumdar, A.: A survey on uncertainty quantification of large language models: Tax-onomy, open research challenges, and future directions. ACM Computing Surveys (2025) [5] Liu, X., Chen, T., Da, L., Chen, C., Lin, Z., Wei, H.: Uncertainty quantification and con-fidence calibration in large language models: A survey. In: Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discov-ery and Data Mining V. 2, pp. 6107‚Äì6117 (2025) [6] Savage, T., Wang, J., Gallo, R., Boukil, A., Patel, V., Safavi-Naini, S.A.A., Soroush, A., Chen, J.H.: Large language model uncer-tainty proxies: discrimination and calibration for medical diagnosis and treatment. Journal of the American Medical Informatics Associ-ation 32 (1), 139‚Äì149 (2025) [7] Atf, Z., Safavi-Naini, S.A.A., Lewis, P.R., Mahjoubfar, A., Naderi, N., Savage, T.R., Soroush, A.: The challenge of uncertainty quantification of large language models in medicine. arXiv preprint arXiv:2504.05278 (2025) [8] Gu, B., Desai, R.J., Lin, K.J., Yang, J.: Probabilistic medical predictions of large lan-guage models. npj Digital Medicine 7(1), 367 (2024) [9] Omar, M., Agbareia, R., Glicksberg, B.S., Nadkarni, G.N., Klang, E.: Benchmarking the confidence of large language models in clinical questions. MedRxiv, 2024‚Äì08 (2024) [10] Gao, Y., Myers, S., Chen, S., Dligach, D., Miller, T., Bitterman, D.S., Chen, G., Mayampurath, A., Churpek, M.M., Afshar, M.: Uncertainty estimation in diagnosis gen-eration from large language models: next-word probability is not pre-test probability. JAMIA open 8(1), 154 (2025) [11] Chen, Z., Li, P., Dong, X., Hong, P.: Uncer-tainty quantification for clinical outcome pre-dictions with (large) language models. arXiv preprint arXiv:2411.03497 (2024) [12] Mukaka, M.M.: A guide to appropriate use of correlation coefficient in medical research. Malawi medical journal 24 (3), 69‚Äì71 (2012) [13] Hanley, J.A., McNeil, B.J.: The meaning and use of the area under a receiver operating characteristic (roc) curve. Radiology 143 (1), 29‚Äì36 (1982) [14] Davis, J., Goadrich, M.: The relationship between precision-recall and roc curves. In: Proceedings of the 23rd International Con-ference on Machine Learning, pp. 233‚Äì240 (2006) [15] Fansi Tchango, A., Goel, R., Wen, Z., Mar-tel, J., Ghosn, J.: Ddxplus: A new dataset for automatic medical diagnosis. Advances in neural information processing systems 35 ,31306‚Äì31318 (2022) [16] Saley, V., Saha, G., Das, R., Raghu, D., 

et al. : Meditod: An english dialogue dataset for medical history taking with comprehen-sive annotations. In: Proceedings of the 2024 18 Conference on Empirical Methods in Nat-ural Language Processing, pp. 16843‚Äì16877 (2024) [17] Jin, D., Pan, E., Oufattole, N., Weng, W.-H., Fang, H., Szolovits, P.: What disease does this patient have? a large-scale open domain ques-tion answering dataset from medical exams. Applied Sciences 11 (14), 6421 (2021) [18] Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., K¬® uttler, H., Lewis, M., Yih, W.-t., Rockt¬® aschel, T., 

et al. : Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in neural information processing systems 33 ,9459‚Äì9474 (2020) [19] Jiang, Z., Araki, J., Ding, H., Neubig, G.: How can we know when language models know? on the calibration of language models for question answering. Transactions of the Association for Computational Linguistics 9,962‚Äì977 (2021) [20] Huang, Y., Song, J., Wang, Z., Zhao, S., Chen, H., Juefei-Xu, F., Ma, L.: Look before you leap: An exploratory study of uncertainty analysis for large language models. IEEE Transactions on Software Engineering (2025) [21] Manakul, P., Liusie, A., Gales, M.: Selfcheck-gpt: Zero-resource black-box hallucination detection for generative large language mod-els. In: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pp. 9004‚Äì9017 (2023) [22] Ren, J., Luo, J., Zhao, Y., Krishna, K., Saleh, M., Lakshminarayanan, B., Liu, P.J.: Out-of-distribution detection and selective gen-eration for conditional language models. In: The Eleventh International Conference on Learning Representations (2023) [23] Takayama, J., Arase, Y.: Relevant and infor-mative response generation using pointwise mutual information. In: Proceedings of the First Workshop on NLP for Conversational AI, pp. 133‚Äì138 (2019) [24] Darrin, M., Piantanida, P., Colombo, P.: Rainproof: An umbrella to shield text gen-erators from out-of-distribution data. arXiv preprint arXiv:2212.09171 (2022) [25] Fadeeva, E., Rubashevskii, A., Shelmanov, A., Petrakov, S., Li, H., Mubarak, H., Tsym-balov, E., Kuzmin, G., Panchenko, A., Bald-win, T., et al.: Fact-checking the output of large language models via token-level uncertainty quantification. arXiv preprint arXiv:2403.04696 (2024) [26] Duan, J., Cheng, H., Wang, S., Zavalny, A., Wang, C., Xu, R., Kailkhura, B., Xu, K.: Shifting attention to relevance: Towards the predictive uncertainty quantification of free-form large language models. In: Proceedings of the 62nd Annual Meeting of the Associa-tion for Computational Linguistics (Volume 1: Long Papers), pp. 5050‚Äì5063 (2024) [27] Lin, Z., Trivedi, S., Sun, J.: Generating with confidence: Uncertainty quantification for black-box large language models. Transac-tions on Machine Learning Research (2023) [28] Chen, J., Mueller, J.: Quantifying uncer-tainty in answers from any language model and enhancing their trustworthiness. In: Ku, L.-W., Martins, A., Srikumar, V. (eds.) Pro-ceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (2024) [29] Kuhn, L., Gal, Y., Farquhar, S.: Semantic uncertainty: Linguistic invariances for uncer-tainty estimation in natural language genera-tion. arXiv preprint arXiv:2302.09664 (2023) [30] Lin, S., Hilton, J., Evans, O.: Teaching mod-els to express their uncertainty in words. arXiv preprint arXiv:2205.14334 (2022) [31] Tian, K., Mitchell, E., Zhou, A., Sharma, A., Rafailov, R., Yao, H., Finn, C., Man-ning, C.: Just ask for calibration: Strategies for eliciting calibrated confidence scores from language models fine-tuned with human feed-back. In: Bouamor, H., Pino, J., Bali, K. (eds.) Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (2023) 19 [32] Kadavath, S., Conerly, T., Askell, A., Henighan, T., Drain, D., Perez, E., Schiefer, N., Hatfield-Dodds, Z., DasSarma, N., Tran-Johnson, E., et al.: Language models (mostly) know what they know. arXiv preprint arXiv:2207.05221 (2022) [33] Kompa, B., Snoek, J., Beam, A.L.: Second opinion needed: communicating uncertainty in medical machine learning. NPJ Digital Medicine 4(1), 4 (2021) [34] Kang, D.Y., DeYoung, P.N., Tantiongloc, J., Coleman, T.P., Owens, R.L.: Statistical uncertainty quantification to augment clini-cal decision support: a first implementation in sleep medicine. NPJ digital medicine 4(1), 142 (2021) [35] Park, S., Pettigrew, M.F., Cha, Y.J., Kim, I.-H., Kim, M., Banerjee, I., Barnfather, I., Clemenceau, J.R., Jang, I., Kim, H., et al. : Deep gaussian process with uncertainty estimation for microsatellite instability and immunotherapy response prediction from his-tology. npj Digital Medicine 8(1), 294 (2025) [36] Mehrtash, A., Wells, W.M., Tempany, C.M., Abolmaesumi, P., Kapur, T.: Confidence calibration and predictive uncertainty esti-mation for deep medical image segmenta-tion. IEEE transactions on medical imaging 

39 (12), 3868‚Äì3878 (2020) [37] Zou, K., Chen, Z., Yuan, X., Shen, X., Wang, M., Fu, H.: A review of uncertainty estima-tion and its application in medical imaging. Meta-Radiology 1(1), 100003 (2023) [38] L¬® ohr, T., Ingrisch, M., H¬® ullermeier, E.: Towards aleatoric and epistemic uncertainty in medical image classification. In: Interna-tional Conference on Artificial Intelligence in Medicine, pp. 145‚Äì155 (2024). Springer [39] Abboud, Z., Lombaert, H., Kadoury, S.: Sparse bayesian networks: Efficient uncer-tainty quantification in medical image analy-sis. In: International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 675‚Äì684 (2024). Springer [40] Isenegger, K., Dong, Y., Shang, M., Furst, J., Stan-Raicu, D.: Characterizing and quan-tifying diagnostic (un) certainty in medical reports through natural language processing. In: 2019 International Conference on Com-putational Science and Computational Intel-ligence (CSCI), pp. 914‚Äì919 (2019). IEEE [41] Peluso, A., Danciu, I., Yoon, H.-J., Yusof, J.M., Bhattacharya, T., Spannaus, A., Scha-efferkoetter, N., Durbin, E.B., Wu, X.-C., Stroup, A., et al. : Deep learning uncer-tainty quantification for clinical text clas-sification. Journal of biomedical informatics 

149 , 104576 (2024) [42] Khandokar, I., Farghaly, O., Kothari, A.N., Deshpande, P.: Towards precision diagnosis: Integrating lexical analysis and deep learn-ing for uncertainty detection and quantifi-cation in clinical reports. In: 2024 IEEE 37th International Symposium on Computer-Based Medical Systems (CBMS), pp. 267‚Äì272 (2024). IEEE [43] Hu, Z., Liu, C., Feng, X., Zhao, Y., Ng, S.-K., Luu, A.T., He, J., Koh, P.W.W., Hooi, B.: Uncertainty of thoughts: Uncertainty-aware planning enhances information seeking in llms. Advances in Neural Information Pro-cessing Systems 37 , 24181‚Äì24215 (2024) [44] Wu, J., Yu, Y., Zhou, H.-Y.: Uncertainty estimation of large language models in medical question answering. arXiv preprint arXiv:2407.08662 (2024) [45] Qin, J., Liu, B., Nguyen, Q.D.: Enhanc-ing healthcare llm trust with atypical presentations recalibration. arXiv preprint arXiv:2409.03225 (2024) [46] Van Der Poel, L., Cotterell, R., Meister, C.: Mutual information alleviates hallucinations in abstractive summarization. In: Proceed-ings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 5956‚Äì5965 (2022) [47] Malinin, A., Gales, M.: Uncertainty estima-tion in autoregressive structured prediction. In: International Conference on Learning 20 Representations (2021) [48] OpenAI: Introducing GPT-4.1 in the API. https://openai.com/index/ gpt-4-1/[accessed: 2025-08-25] (2025) [49] Grattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A., Let-man, A., Mathur, A., Schelten, A., Vaughan, A., et al.: The llama 3 herd of models. arXiv preprint arXiv:2407.21783 (2024) [50] Xiong, M., Hu, Z., Lu, X., LI, Y., Fu, J., He, J., Hooi, B.: Can llms express their uncertainty? an empirical evaluation of con-fidence elicitation in llms. In: The Twelfth International Conference on Learning Repre-sentations (2024) [51] Xiong, G., Jin, Q., Lu, Z., Zhang, A.: Bench-marking retrieval-augmented generation for medicine. In: Findings of the Association for Computational Linguistics ACL 2024, pp. 6233‚Äì6251 (2024) [52] Robertson, S., Zaragoza, H., et al. : The probabilistic relevance framework: Bm25 and beyond. Foundations and Trends ¬Æ in Infor-mation Retrieval 3(4), 333‚Äì389 (2009) [53] Ren, Z., Zhan, Y., Yu, B., Ding, L., Xu, P., Tao, D.: Healthcare agent: eliciting the power of large language models for medical con-sultation. npj Artificial Intelligence 1(1), 24 (2025) 21 Appendix A Common notations 

We list common notations in Tab. A1 for mathematical definitions. 

Table A1 : Common notations and descriptions. 

Notion Description x Input sequence (patient information) 

y Output sequence (generated diagnosis/response) 

yl Token at position l in the output sequence 

y<l All tokens before position lL Length of generated sequence 

K Number of sampled responses 

P (yl|y<l , x ) Probability of token yl given previous tokens and input 

f (¬∑) Large language model 

C Confidence score 

œà(¬∑) Token-level transformation function 

œï(¬∑) Final transformation function 

wl Weight for token at position l

LLl=1 Aggregation operation over tokens 

H(yl|y<l , x ) Entropy at token position lN Vocabulary size 

q Uniform distribution over vocabulary 

Œ± Hyperparameter for R¬¥ enyi divergence 

RT (yl, y, x) Token relevance function ÀúRT (yl, y, x) Normalized token relevance 

Y = {y1, y 2, . . . , y K } Set of K generated responses 

y(k) The k-th sampled response 

yc Most frequent/consistent response 

e(¬∑) Embedding function Cos( ¬∑, ¬∑) Cosine similarity function 

Cn Semantic cluster n

ÀúPn(x) Average probability of cluster n

S Similarity matrix 

L Graph Laplacian matrix 

D Diagonal degree matrix 

Œªk k-th eigenvalue 

uk k-th eigenvector 

vj Embedding vector for response jLk Length of sequence y(k)

RS (y(j), x ) Sentence relevance function 

I Patient information 

d Generated diagnosis 

D Medical corpus (PubMed, StatPearls, etc.) 

R Retrieved medical passages from RAG 

S Symptom profile (set of symptoms) Prompt Prompt template RAG( d, D) Retrieval-augmented generation function 

22 Appendix B More Details of Benchmark 

B.1 Details of Data Processing 

To better align with real-world medical consultation scenarios, we process the datasets by converting the model input format into doctor-patient dialogues or medical reports, and restructure the tasks as open-end decision making. DDXPlus is a large-scale contains different diagnosis with ground truth pathology, symptoms and antecedents. It collect data in a structured format and provide categorical and multi-choice symp-toms symptoms and antecedents for more detailed description. In our processing procedure, we convert structured format information into doctor-patient dialogue format. Using GPT-4.1, we convert symp-tom information in the dataset into doctor inquiries, while the symptoms are transformed into patient responses, converting binary and numerical information into patients‚Äô natural language expressions. The specific prompts are shown in Fig. A1. The model will generate diagnostic results based on the generated dialogue. Prompt for input conversion of DDXPlus 

Prompt for doctor inquiry: 

You are playing the role of a doctor. Refer to the question {question }, ask the patient the question in a doctor‚Äôs specialized form. Please do not change the original intent and do not include additional information and your response should contain only the question. Question: 

Prompt for patient answer: 

You are playing the role of a patient. Refer to the question {question } and the result result, answer the question in a patient‚Äôs colloquial manner. Please do not include add any information that isn‚Äôt mentioned and your response should contain only the answer. Answer: 

Fig. A1 : Prompt for input conversion of DDXPlus. MediTOD comprises real-world doctor-patient dialogues with annotated complex relationships between dialogue content and corresponding clinical attributes. To select the effective dialogues, we retain the dialogue with intents of ‚ÄúInform‚Äù, ‚ÄúInquire‚Äù, and ‚ÄúDiagnose‚Äù, while ignore dialogue for ‚ÄúChit-chat‚Äù and ‚Äúsalutations‚Äù. MedQA contains profession multiple-choice question. The question background of MedQA is a comprehensive medical report and we remove the option in the question to convert the task from multiple choice question to open-end decision making task. 

B.2 Details of Evaluated Methods 

B.2.1 Token-level Methods 

Average Sequence Probability (ASP) [20] computes the arithmetic mean of token probabilities across the generated sequence: 

CASP = 1

L

> L

X

> l=1

P (yl | y<l , x) (A1) 23 Maximum Sequence Probability (MSP) [20] estimates the sequence-level confidence by selecting the highest token probability within the generated sequence: 

CMSP = max  

> l=1 ,...,L

P (yl | y<l , x) (A2) Additional metrics analyze the probability distribution characteristics. Perplexity [22] measures the exponential of the average negative log-probability: 

CPerp = exp 

(

‚àí 1

L

> L

X

> l=1

log P (yl|y<l , x)

)

(A3) The Entropy [21] computes the average entropy across all token positions in the generated sequence: 

CH = 1

L

> L

X

> l=1

H(yl|y<l , x) (A4) where H(yl|y<l , x) represents the entropy of the token distribution at position l.Takayama and Arase [23] propose utilize Pointwise Mutual Information (PMI) between conditioned and unconditioned input to measure confidence: 

CPMI = 1

L

> L

X

> l=1

log P (yl|y<l )

P (yl|y<l , x) (A5) Van Der Poel et al. [46] propose a modification called Conditional Pointwise Mutual Information (CPMI) to only evaluate those token have entropy above a threshold: 

CCPMI = 1

L

> L

X

> l=1

log P (yl|y<l , x) (A6) + ŒªL

X

> l:H(yl|y<l ,x)‚â•œÑ

log P (yl|y<l ) (A7) where Œª is a changeable parameter. Darrin et al. [24] propose to use R¬¥ enyi Divergence and Fisher-Rao distance to calculate the divergence between the distribution of each token and the uniform distribution. For N is the number of tokens in vocabulary and q is a uniform distribution over the vocabulary, the Renyi divergences is: 

CRD = 1

L

> L

X

> l=1

1

Œ± ‚àí 1 log 

> N

X

> i=1

P (yl|y<l , x)Œ±

qŒ±‚àí1

> i

(A8) while the Fisher-Rao is: 

CFRD = 1

L

> L

X

> l=1

2

œÄ arccos 

> N

X

> i=1

pP (yl|y<l , x) ¬∑ qi (A9) TokenSAR [26] first proposes that the contribution of different tokens are unequal. It utilize a token relevance function to calculate the importance of each token: 

RT (yl, y, x) = 1 ‚àí g(x ‚à™ y, x ‚à™ y \ { yl}) (A10) 24 where g(¬∑, ¬∑) measures the semantic similarity between two sequences. The reweighted entropy is then computed as: 

CTokenSAR = ‚àí

> L

X

> l=1

ÀúRT (yl, y, x) log P (yl|y<l , x) (A11) where ÀúRT (yl, y, x) = RT (yl,y,x)   

> PLi=1 RT(yi,y,x)

represents the normalized token relevance weights. Claim Conditioned Probability (CCP) [25] quantifies uncertainty by assessing how token substitutions affect semantic consistency. For each token position j, the method replaces token yj with alternative candidates ykj sampled from the top-k predictions of the model‚Äôs output distribution. A Natural Language Inference (NLI) model then evaluates the semantic relationship between the original sequence and each perturbed variant. The CCP score is computed as: 

CCCP =

P   

> k:NLI( ykj,y j)=‚Äòentail‚Äô

P (ykj |y<j , x)

P   

> k:NLI( ykj,y j)‚àà{ ‚Äòentail‚Äô ,‚Äòcontra‚Äô }

P (ykj |y<j , x) (A12) where NLI( ykj , y j ) = ‚Äòentail‚Äô denotes the NLI model predicts an entailment relation and NLI( ykj , y j ) = ‚Äòcontra‚Äô denotes that the NLI model classifies relationships as contradiction. 

B.2.2 Consistency-level Methods 

Percentage of Consistency (PoC) [21] evaluates confidence by calculating the proportion of responses that match the most frequent response: 

CPoC =

PKi=1 I(yi = yc)

K (A13) where yc = arg max y‚ààY 

PKj=1 I(yj = y). Semantic Similarity (SemSim) [28] measures confidence by computing the average cosine similarity between embeddings of all response pairs. It can be represented as: 

CSemSim = 1

K(K ‚àí 1) 

> K

X

> i=1

X 

> jÃ∏=i

Cos( e(yi), e (yj )) (A14) where Cos( ¬∑, ¬∑) denotes the cosine similarity function and e(¬∑) represents the embedding process that maps sequences to vector representations. Lexical Similarity [21] measures confidence through lexical overlap between K sampled responses using n-gram metric ( e.g., ROUGE and BLEU): 

CLexSim = 1

K(K ‚àí 1) 

> K

X

> i=1

X 

> jÃ∏=i

LexicalSim( y(i), y (j)) (A15) where LexicalSim computes n-gram overlap between responses y(i) and y(j). In our setting, we utilize ROUGE-L as the lexical similarity metric. Number of Semantic Sets (NumSet) [27] clusters semantically similar responses into non-overlapping groups using NLI-based entailment relations. The confidence calculate the number of cluster in the response: 

CNumSet = 1 ‚àí NumClusters 

K (A16) where responses y(i) and y(i) are clustered together if ÀÜpentail (y(i), y (j)) > ÀÜpcontra (y(i), y (j)) and ÀÜpentail (y(j), y (i)) > ÀÜpcontra (y(j), y (i)). 25 Sum of Eigenvalues of the Graph Laplacian (EigV) [27] constructs a similarity graph from K responses and analyzes eigenvalues of the normalized Laplacian matrix to quantify semantic diversity. For a similarity matrix S, the Laplacian for S is formula as: 

L = I ‚àí D‚àí 12 SD ‚àí 12 (A17) where D is a diagonal matrix and Œªk are the eigenvalues of matrix L. The confidence of EigV can be represented as: 

CEigV = 1 ‚àí

> K

X

> k=1

max(0 , 1 ‚àí Œªk) (A18) Furthermore, Degree Matrix (Deg) [27] extract confidence from the previous metioned diagonal matrix 

D and the confidence score is estimated by: 

CDeg = trace( D)

K2 (A19) Eccentricity (Ecc) [27] quantifies confidence by measuring distance from the centroid in embedding space derived from the similarity graph. This method leverages the eigenvectors u1, ¬∑ ¬∑ ¬∑ , uk corre-sponding to the k smallest eigenvalues of the graph Laplacian to construct informative embeddings 

vj = [ u1,j , . . . , uk,j ] for each response yj . The uncertainty score is calculated as the average distance from the centroid in this embedding space: 

CEcc = 1 ‚àí ‚à• [Àú vT 

> 1

, . . . , ÀúvTK ]‚à•2 (A20) where Àú vj = vj ‚àí 1

> K

PK‚Ñì=1 v‚Ñì.On the other method, several approaches integrate token probability data into consistency measures. Monte Carlo Sequence Entropy (MC-SE) [29] calculates entropy at the sequence level by averaging the negative log-probabilities across multiple generated sequences: 

CMC-SE = ‚àí 1

K

> K

X

> k=1

log P (y(k)|x) (A21) where P (y(k)|x) = QLk 

> l=1

P (y(k) 

> l

|y(k) 

> <l

, x) represents the probability of the k-th generated sequence. To obtain a more reliable uncertainty measure, the sequence probabilities can be length-normalized [47]: ÀÜCMC-SE = ‚àí 1

K

> K

X

> k=1

1

Lk

log P (y(k)|x) (A22) where Lk is the length of sequence y(k).Semantic Entropy (SE) [29] specifically targets the influence of semantically equivalent expressions on entropy calculations. It clusters generated responses into semantically similar groups Cn, n = 1 , 2, . . . , N 

and averages the sequence probabilities within each cluster. The entropy calculated over these semantic clusters is formulated as: 

CSE = ‚àí

> N

X

> n=1

|Cn|

K log ÀúPn(x) (A23) where ÀúPn(x) = P 

> y‚ààC n

P (y|x) represents the average probability of cluster n.26 For SentenceSAR [26], it reweigh the importance of each sentence. Through the sentence relevance function: 

RS (y(j), x) = X 

> kÃ∏=j

g(y(j), y (k))P (y(k)|x) (A24) it increase the probability of sentences that are more relevant than others: 

USentSAR (x) = 1

K

> K

X

> k=1



log P (y(k)|x) + 1

t RS (y(k), x)



(A25) where t is the hyperparameter. By changing the probability P (y | x) with TokenSAR in Eq. A11, we can obtain SAR method that combine both TokenSAR and SentenceSAR. 

B.2.3 Self-verbalized Methods 

We utilize three prompt strategies for Confidence Elicitation method, including vanilla prompt, chain-of-through prompt, and Tok-k prompt. The prompt details are shown in Fig. A2, Fig. A3, and Fig. A4, respectively. Prompt for vanilla CE Your task is to rate the confidence of the proposed answer on a score from 0 to 100, where 0 represents definitely not confidence and 100 represents definitely confidence. Note: The confidence indicates how likely you think your answer is true. Please, only answer with your score in between square brackets (ex. [50]). =========== Scenario: dialogue Answer: answer 

Fig. A2 : Prompt for vanilla CE. Prompt for CoT CE Your task is to rate the confidence of the proposed answer on a score from 0 to 100, where 0 represents definitely not confidence and 100 represents definitely confidence. Note: The confidence indicates how likely you think your answer is true. Provide your explanation first and show your confidence in between square brackets (ex. [50]). The answer format is: Explanation: Confidence: =========== Scenario: dialogue Answer: answer 

Fig. A3 : Prompt for CoT CE. 27 Prompt for Top-k CE 

Your task is to rate the uncertainty of the proposed answer on a score from 0 to 100, where 0 represents definitely uncertain and 100 represents definitely certain. Note: The confidence indicates how likely you think your answer is true. Provide your 5 best guess of the confidence and answer with your score in between square brackets (ex. [50]). For example: G1: ... G5: =========== Scenario: dialogue Answer: answer Now, please provide your confidence. 

Fig. A4 : Prompt for Top-k CE. 

## Appendix C Details of MedConf 

In the diagnostic generation step, given patient information, the model generate diagnosis with diagnosis prompt Prompt d. The details of Prompt d are shown in Fig. A5. Details of diagnosis prompt Read the medical information below and determine the final diagnosis. Provide a specific diagnosis for the case and label your Answer in square brackets. =========== Medical information: {inquiry }

Fig. A5 : Details of diagnosis prompt. Following this, RAG system identify and retrieve the relevant medical passages in database associated with the generated diagnosis. The retrieve results are summarize to a JSON structured symptom profile with symptom profile generation prompt Prompt s. The details of Prompt s are shown in Fig. A6.   

> Details of symptom profile generation prompt
> You are a helpful medical expert, and your task is to generate structured diagnostic criteria for the following condition using the relevant documents. Each criterion should include a description and importance level and output in JSON format. Condition: {diagnosis }
> Relevant documents: {content }
> Now, Please output the diagnostic criteria in JSON format as follow:
> {
> ‚Äúid‚Äù: Criterion ID, e.g., 1, ‚Äúdescription‚Äù: ‚ÄùSpecific diagnostic criterion description‚Äù, ‚Äúimportance‚Äù: ‚Äùstrong/moderate/weak‚Äù
> }
> Importance definitions: - strong: Core diagnostic criteria, absence severely impacts diagnosis - moderate: Important supportive criteria, helps confirm diagnosis - weak: Auxiliary criteria, increases diagnostic confidence but not essential

Fig. A6 : Details of symptom profile generation prompt. 28 Finally, the confidence generation step utilize the confidence generation prompt Prompt c to first analyze the supportive, missing, and contradictory relationship between patient information and symptom profile and then estimate confidence score. The details of Prompt c are shown in Fig. A7. 

Details of confidence generation prompt 

You are a specialist with extensive medical knowledge. Your task is evaluate how well each diagnostic criterion is met based on the following patient-doctor conversation and then provide the confidence score. The confidence score is from 0 to 100, where 0 represents definitely not confidence and 100 represents definitely confidence. Note: The confidence indicates how likely you think your answer is true. Diagnostic Criteria: {criteria }

Patient Information: {inform }

First, you need to analyze each criterion and generate evaluation results in the following JSON format: 

{

‚Äúcriteria evaluation‚Äù: [ 

{

‚Äúid‚Äù: Criterion ID, ‚Äúdescription‚Äù: Criterion description, ‚Äúimportance‚Äù: strong/moderate/weak, ‚Äúsupport level‚Äù: supported/contradicted/missing, ‚Äúevidence‚Äù: Quoted supporting/contradicting evidence from conversation, or null if none 

}

], ‚Äúsummary‚Äù: {

‚Äúsupported criteria‚Äù: {

‚Äúsupported strong‚Äù: [List all supported strong-level criteria], ‚Äúsupported moderate‚Äù: [List all supported moderate-level criteria], ‚Äúsupported weak‚Äù: [List all supported weak-level criteria] 

},‚Äúmissing criteria‚Äù: { ‚Äúmissing strong‚Äù: [List all missing strong-level criteria], ‚Äúmissing moderate‚Äù: [List all missing moderate-level criteria], ‚Äúmissing weak‚Äù: [List all missing weak-level criteria] 

}

‚Äúcontradicted criteria‚Äù: {

‚Äúcontradicted strong‚Äù: [List all contradicted strong-level criteria], ‚Äúcontradicted moderate‚Äù: [List all contradicted moderate-level criteria], ‚Äúcontradicted weak‚Äù: [List all contradicted weak-level criteria] 

},‚Äúconfidence‚Äù: {

reasoning: Provide your reasons for the confidence score. confidence score: Please provide the confidence score between double angle brackets 

} } } 

Fig. A7 : Details of confidence generation prompt. 29 Appendix D Case Study 

D.1 Case Study of Existing Methods 

In this section, we provide case study for token-level methods, consistency-level methods, and self-verbalized methods. In our example, the model input is ‚Äú I have been having stomach pain, feeling nauseous, and I have a slight fever.‚Äù .In this example, the model prediction is ‚Äú appendicitis‚Äù and the probability for each token are 

‚Äúappend = 0 .3204 , icit = 0 .9722 , is = 0 .9999‚Äù. So, for token-level method ASP that calculate the mean of the generated token, the confidence result is 76.42. Furthermore, when the generate temperature is 0.5 and we generate 15 answers, there are 10 answers are appendicitis, 3 answers are acute gastroenteritis, and 2 answers are viral gastroenteritis. When we apply consistency-level methods PoC that calculate the proportion of the most frequent response, the confidence is 66.67. Finally, when we utilize self-verbalized method CoT CE to obtain the result, the model output are shown in Fig. A8. The model provide an anlysis first and then evaluate the confidence score as 60. Details of CoT CE in case study Appendicitis is a condition where the appendix, a small organ attached to the large intestine, becomes inflamed. The symptoms of appendicitis can vary, but common ones include abdominal pain, nausea, vomiting, and fever. Given the symptoms you described, such as stomach pain, feeling nauseous, and a slight fever, it is possible that you may have appendicitis. Given the information provided, it is difficult to make a definitive diagnosis without further evaluation. However, based on the symptoms described, I would rate the uncertainty of the proposed answer as 60. 

Fig. A8 : Details of CoT CE in case study. 

D.2 Case Study of MedConf 

D.2.1 Diagnostic Generation 

In this example, the patient describes their symptoms to the doctor to seek a diagnosis. Their patient information I is shown in Fig. A9. Due to the patient‚Äôs limited capabilities, they often can only provide incomplete and brief descriptions. Details of patient information in case study I have been having stomach pain, feeling nauseous, and I have a slight fever. 

Fig. A9 : Details of patient information in case study. Subsequently, patient information I is used to generate diagnostic assessment d through the guidance of the diagnosis prompt Prompt d. The generated result d is shown in Fig. A10. 

D.2.2 Symptom Generation 

In this process, LLMs generate a symptom profile for the diagnostic results, which serves as the support knowledge for subsequent confidence evaluation. In this example, we utilize RAG to obtain the most 30 Details of diagnostic result in case study 

I have been having stomach pain, feeling nauseous, and I have a slight fever. 

Fig. A10 : Details of diagnostic result in case study. relevant passages in the medical corpus D of the keyword ‚Äú appendicitis‚Äù . An example of RAG results R

is shown in Fig. A11. 

Examples of RAG result in case study 

Document *0* (Title: Appendicitis) Epidemiology Appendicitis is most common between the ages of 5 and 40. In 2013, it resulted in 72,000 deaths globally, down from 88,000 in 1990. In the United States, there were nearly 293,000 hospitalizations involving appendicitis in 2010. Appendicitis is one of the most frequent diagnoses for emergency department visits resulting in hospitalization among children ages 5‚Äì17 years in the United States. See also Deaths from appendicitis Evan O‚ÄôNeill Kane Leonid Rogozov References External links CT of the abdomen showing acute appendicitis Appendicitis, history, diagnosis and treatment by Surgeons Net Education Appendicitis: Acute Abdomen and Surgical Gastroenterology from the Merck Manual Professional (content last modified September 2007) Appendicitis ‚Äì Symptoms Causes and Treatment at Health N Surgery 

Fig. A11 : Examples of RAG result in case study. Following the RAG step, the LLM generates symptom profile S based on the RAG result R, the diagnostic result d, and the symptom profile generation prompt Prompt s. The symptom profile for this example is shown in Fig. A12. 

D.2.3 Confidence Generation 

In this process, the LLMs evaluate the relationship between patient information I and symptom profile 

S and then utilize it as evidence to inference the confidence score of current generated diagnosis. The response of the final confidence is shown in Fig. A13. 31 Details of symptom profile in case study 

[

{

‚Äúid‚Äù: 1, ‚Äúdescription‚Äù: ‚ÄúPresence of right lower quadrant abdominal pain, which is often the first symptom of appendicitis.‚Äù, ‚Äúimportance‚Äù: ‚Äústrong‚Äù 

},

{

‚Äúid‚Äù: 2, ‚Äúdescription‚Äù: ‚ÄúNausea and vomiting following the onset of abdominal pain, which is commonly reported by patients with appendicitis.‚Äù, ‚Äúimportance‚Äù: ‚Äústrong‚Äù 

},

{

‚Äúid‚Äù: 3, ‚Äúdescription‚Äù: ‚ÄúFever, typically low-grade, which may accompany the other symptoms of appendicitis.‚Äù, ‚Äúimportance‚Äù: ‚Äúmoderate‚Äù 

},

{

‚Äúid‚Äù: 4, ‚Äúdescription‚Äù: ‚ÄúRebound tenderness or guarding in the right lower quadrant during physical examination, indicating irritation of the peri-toneum.‚Äù, ‚Äúimportance‚Äù: ‚Äústrong‚Äù 

},

{

‚Äúid‚Äù: 5, ‚Äúdescription‚Äù: ‚ÄúElevated white blood cell count (leukocytosis), which is a common laboratory finding in patients with appendicitis.‚Äù, ‚Äúimportance‚Äù: ‚Äúmoderate‚Äù 

},

{

‚Äúid‚Äù: 6, ‚Äúdescription‚Äù: ‚ÄúUse of imaging studies such as ultrasound or CT scan to visualize the appendix and confirm the diagnosis of appendicitis.‚Äù, ‚Äúimportance‚Äù: ‚Äúmoderate‚Äù 

},

{

‚Äúid‚Äù: 7, ‚Äúdescription‚Äù: ‚ÄúHistory of previous episodes of abdominal pain or gastrointestinal issues, which may suggest a recurrent appendicitis.‚Äù, ‚Äúimportance‚Äù: ‚Äúweak‚Äù 

},

{

‚Äúid‚Äù: 8, ‚Äúdescription‚Äù: ‚ÄúApplication of scoring systems like the Alvarado score or Appendicitis Inflammatory Response (AIR) score to assist in diag-nosis.‚Äù, ‚Äúimportance‚Äù: ‚Äúweak‚Äù 

}

]

Fig. A12 : Details of symptom profile in case study. 32 Details of confidence generation in case study 

{

‚Äúcriteria evaluation‚Äù: [ 

{

‚Äúid‚Äù: 1, ‚Äúdescription‚Äù: ‚ÄúPresence of right lower quadrant abdominal pain, which is often the first symptom of appendicitis.‚Äù, ‚Äúimportance‚Äù: ‚Äústrong‚Äù, ‚Äúsupport level‚Äù:‚Äú‚Äùmissing‚Äù, ‚Äúevidence‚Äù: null 

},

{

‚Äúid‚Äù: 2, ‚Äúdescription‚Äù: ‚ÄúNausea and vomiting following the onset of abdominal pain, which is commonly reported by patients with appendicitis.‚Äù, ‚Äúimportance‚Äù: ‚Äústrong‚Äù, ‚Äúsupport level‚Äù: ‚Äúsupported‚Äù, ‚Äúevidence‚Äù: ‚ÄúI have been feeling nauseous‚Äù 

},

{

‚Äúid‚Äù: 3, ‚Äúdescription‚Äù: ‚ÄúFever, typically low-grade, which may accompany the other symptoms of appendicitis.‚Äù, ‚Äúimportance‚Äù: ‚Äúmoderate‚Äù, ‚Äúsupport level‚Äù: ‚Äúsupported‚Äù, ‚Äúevidence‚Äù: ‚ÄúI have a slight fever‚Äù 

},

{

‚Äúid‚Äù: 4, ‚Äúdescription‚Äù: ‚ÄúRebound tenderness or guarding in the right lower quadrant during physical examination, indicating irritation of the peri-toneum.‚Äù, ‚Äúimportance‚Äù: ‚Äústrong‚Äù, ‚Äúsupport level‚Äù: ‚Äúmissing‚Äù, ‚Äúevidence‚Äù: null 

},

{

‚Äúid‚Äù: 5, ‚Äúdescription‚Äù: ‚ÄúElevated white blood cell count (leukocytosis), which is a common laboratory finding in patients with appendicitis.‚Äù, ‚Äúimportance‚Äù: ‚Äúmoderate‚Äù, ‚Äúsupport level‚Äù: ‚Äúmissing‚Äù, ‚Äúevidence‚Äù: null 

},

{

‚Äúid‚Äù: 6, ‚Äúdescription‚Äù: ‚ÄúUse of imaging studies such as ultrasound or CT scan to visualize the appendix and confirm the diagnosis of appendicitis.‚Äù, ‚Äúimportance‚Äù: ‚Äúmoderate‚Äù, ‚Äúsupport level‚Äù: ‚Äúmissing‚Äù, ‚Äúevidence‚Äù: null 

},

{

‚Äúid‚Äù: 7, ‚Äúdescription‚Äù: ‚ÄúHistory of previous episodes of abdominal pain or gastrointestinal issues, which may suggest a recurrent appendicitis.‚Äù, ‚Äúimportance‚Äù: ‚Äúweak‚Äù, ‚Äúsupport level‚Äù: ‚Äúmissing‚Äù, ‚Äúevidence‚Äù: null 

},

{

‚Äúid‚Äù: 8, ‚Äúdescription‚Äù: ‚ÄúApplication of scoring systems like the Alvarado score or Appendicitis Inflammatory Response (AIR) score to assist in diag-nosis.‚Äù, ‚Äúimportance‚Äù: ‚Äúweak‚Äù, ‚Äúsupport level‚Äù: ‚Äúmissing‚Äù, ‚Äúevidence‚Äù: null 

}

], ‚Äúsummary‚Äù: {

‚Äúsupported criteria‚Äù: {

‚Äúsupported strong‚Äù: [2], ‚Äúsupported moderate‚Äù: [3], ‚Äúsupported weak‚Äù: [] 

},‚Äúmissing criteria‚Äù: {

‚Äúmissing strong‚Äù: [1, 4], ‚Äúmissing moderate‚Äù: [5, 6], ‚Äúmissing weak‚Äù: [7, 8] 

},‚Äúcontradicted criteria‚Äù: {

‚Äúcontradicted strong‚Äù: [], ‚Äúcontradicted moderate‚Äù: [], ‚Äúcontradicted weak‚Äù: [] 

},‚Äúconfidence‚Äù: {

‚Äúreasoning‚Äù: ‚ÄúThe patient has reported nausea and a slight fever, which supports two of the moderate and strong criteria. However, the absence of specific evidence for right lower quadrant pain and other criteria leads to a lower confidence score.‚Äù, ‚Äúconfidence score‚Äù: ‚Äú <<30> >‚Äù

}}} 

Fig. A13 : Details of confidence generation in case study. 33