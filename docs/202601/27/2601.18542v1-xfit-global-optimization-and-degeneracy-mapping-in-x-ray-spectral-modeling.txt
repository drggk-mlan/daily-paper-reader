Title: XFit: Global Optimization and Degeneracy Mapping in X-ray Spectral Modeling

URL Source: https://arxiv.org/pdf/2601.18542v1

Published Time: Tue, 27 Jan 2026 03:11:00 GMT

Number of Pages: 23

Markdown Content:
> Draft version January 27, 2026
> Typeset using L ATEX twocolumn style in AASTeX7

XFit : Global Optimization and Degeneracy Mapping in X-ray Spectral Modeling 

MacMaster A. ,1 Rogers A. ,2 Fiege J., 1 Man R., 1 and Safi-Harb S. 1

> 1Department of Physics and Astronomy, University of Manitoba, Winnipeg, MB R3T 2N2, Canada
> 2Department of Physics and Astronomy, Brandon University, Brandon, MB R7A 6A9, Canada

ABSTRACT The standard approach to modeling X-ray spectral data relies on local optimization methods, such as the Levenberg-Marquardt algorithm. While effective for simple models and speedy spectral fitting, these local optimizers are prone to becoming trapped in local minima, particularly in high-dimensional or degenerate parameter spaces, and typically require extensive user intervention. In this work, we introduce XFit , a global optimization method for fitting X-ray data, which makes extensive use of the 

Ferret evolutionary algorithm. XFit enables automated exploration of complex parameter spaces, effi-cient mapping of confidence intervals, and identification of degenerate solutions that may be overlooked by local methods. We demonstrate the performance of XFit using two representative X-ray sources: the Central Compact Object in Cassiopeia A and the supernova remnant G41.1–0.3. These examples span both low- and high-dimensional models, allowing us to illustrate the advantages of global opti-mization. In both cases, XFit produces solutions that are consistent with or improve upon those found with traditional methods, while also revealing alternative fits or degenerate solutions within statisti-cally acceptable confidence levels. The automated mapping of parameter space offered by XFit makes it a powerful complement to existing spectral fitting tools, particularly as models and data quality become increasingly complex. Future work will expand the application of XFit to broader datasets and more physically motivated models. 

Keywords: High Energy astrophysics (739) — Computational astronomy (293) — Supernovae (1668) — Stellar remnants (1627) — Astronomy data analysis (1858) 

1. INTRODUCTION Astrophysical phenomena are ideal laboratories for studying the myriad high-energy emission processes ca-pable of producing X-ray radiation. Such processes in-clude the synchrotron emission emanating from compact objects, pulsar wind nebulae, and shocked plasma in supernova remnants (SNRs; S. P. Reynolds 2008); the bremsstrahlung, collisional excitation, and recombina-tion radiation in hot, optically thin plasmas of stellar coronae, clusters of galaxies, and SNRs (K. Heuer et al. 2021); electron scattering in the accretion disks of neu-tron stars (NSs) and black holes (BHs); and photoion-ization in X-ray binaries and active galactic nuclei (O. Kargaltsev & G. G. Pavlov 2008; K. Mukai et al. 2003). Additionally, X-rays can penetrate deeply into gas and dust surrounding regions of star formation (A. C. Raga et al. 2002). In cosmology, X-rays are used to study the 

> Email: austin.macmaster@gmail.com

photons emitted by the cosmic microwave background as they are scattered by relativistic electrons (A. Celotti et al. 2001), and large-scale distance estimates can be calculated using elemental abundances inferred from the absorption of X-rays in the interstellar medium (ISM J. Silk & S. D. M. White 1978). Plasma interactions in clusters of galaxies can reach temperatures upwards of 10-100 MK (mega-Kelvin), producing thermal X-rays used to estimate baryonic matter densities in cosmolog-ical models (D. H. Weinberg et al. 2013). Recent stud-ies of the multi-messenger event GW170817 (B. P. Ab-bott et al. 2017a,b) are also demonstrating the relevance of X-rays as an electromagnetic counterpart to gravita-tional wave astronomy in investigating the evolution of merging NS-NS, NS-BH, and BH-BH binary systems in the short gamma-ray burst and kilonova remnant phases (M. Nynka et al. 2018; S. Safi-Harb et al. 2019; E. Troja et al. 2020; J. Ren & Z. G. Dai 2022; A. Hajela et al. 2022). The 1962 launch of a Geiger counter demonstrated the feasibility of detecting X-rays outside Earth’s atmo-

> arXiv:2601.18542v1 [astro-ph.HE] 26 Jan 2026

2sphere, and christened a new era of X-ray astronomy (R. Giacconi et al. 1962). Subsequently, improvements in spectroscopic observing techniques in the field of X-ray astronomy — such as CCD detector technology (N. S. Brickhouse 2000) 3,4 and microcalorimeter arrays (Hit-omi Collaboration et al. 2018) 3 — have led to major improvements in detector sensitivity, reductions in back-ground count rates, as well as the spatial and spectral resolution of energy distributions of photons. As data sets increase in size, detail, and complexity, so too do the models predicting the physical properties inferred by the observed spectra, introducing an ever-increasing demand on the reliability and consistency of the opti-mization schemes used to fit models to data. A common approach to model fitting begins with the selection of an objective or ‘fitness’ function that sta-tistically determines how well a given model ˆM (xk; p)predicts the probability of detecting an observed event 

M (xk; p) across an observation’s k spectral energy bins for a given set of independent variables xk and their measurement error σ(M (xk)) = σMk . Nonlinearities in the parameters p of a chosen model pose challenges for local linear least-squares fitting methods, which be-come unreliable or inefficient. Furthermore, gradient-based methods require that the objective function be smooth and continuous, and if any of the partial deriva-tives of the objective function are nonlinear with respect to the model parameters, the space of solutions must be searched for a minimum by iteratively adjusting param-eter values based on the topology of the surrounding parameter space until a minimum fit value is obtained. The choice of objective function is problem specific and can depend on multiple factors, such as the total number of counts present in a spectrum. For example, low count rates are typical in X-ray astronomy, where distributions of counts may best be described by Poisson statistics. A commonly used fit statistic in the low-count regime is the Cash statistic (W. Cash 1979) and its variants. For high numbers of counts, the Poisson distribution is well-approximated by a Gaussian distribution, and a minimization of the sum of the weighted squares of the errors between ˆM (xk; p) and M (xk; p) is performed over n energy bins as shown in the objective function χ2 of Equation 1.    

> 3https://cxc.harvard.edu/proposer/POG/html/chap8.html
> 4https://www.cosmos.esa.int/web/xmm-newton
> 3https://www.isas.jaxa.jp/en/missions/spacecraft/past/ hitomi.html

χ2(p) = 

> n

X

> k=1

 M (xk) − ˆM (xk; p)

σMk

2

= MT WM − 2MT W ˆM + ˆMT

W ˆM, (1) where M and ˆM are the matrix forms of the observed events and model, respectively, and W is the inverse of the error covariance matrix. The XSPEC 4 (K. A. Arnaud 1996) fitting package contains multiple minimization methods for fitting mod-els with non-linear parameters. XSPEC’s default op-timizer, the modified Levenberg-Marquardt (LM; K. LEVENBERG 1944) algorithm based on the CURFIT routine from Bevington (P. R. Bevington & D. K. Robin-son 2003), is a commonly used approach to model fitting in high-energy astrophysics. The LM algorithm (LMA) is designed to minimize the objective function by up-dating the model parameters by a perturbation h that is scaled by a damping coefficient λ, as shown in Equa-tion 2. 

h

JT WJ + λI

i

h = JT W(M − ˆM) (2) where J is the Jacobian matrix. The LMA approaches the optimization differently de-pending on the local geometry of the parameter space surrounding the current search point. The LMA starts with an initial guess for the parameters p0 and λi=0 >> 

1. Far from the putative minimum, λ is large and the LM algorithm behaves like a gradient-based optimizer, simultaneously adjusting the step size of the first deriva-tives of each parameter and orienting the search in the direction of steepest descent. As the search approaches a minimum, gradients tend toward zero as the topol-ogy of the parameter space becomes flattened. Small step sizes in this region come at the cost of computa-tional efficiency, while large step sizes result in a loss of precision and increased risk of moving further from the solution by stepping over the minimum. The LMA circumvents this issue by iteratively updating λ to find perturbations in the model parameters that contribute to an overall decrease in the objective function at suc-cessive steps. If a step leads to improvement in the fit, 

χ2(p + h) < χ 2(p) and the objective function is then evaluated at a trial next-step using a reduced λi+1 < λ i.If χ2(λi+1 ) ≈ χ2(λi), the quadratic approximation is considered valid and λ is decreased. Otherwise λ is in-creased. As λ → 0, Equation 2 reduces to the Gauss-Newton method of minimization, where χ2 is Taylor ex- 

> 4https://heasarc.gsfc.nasa.gov/xanadu/xspec/

3panded to second-order and approximated as a parabolic surface. The LMA is an example of a local, single-search-agent, gradient-based optimizer. Such optimizers evaluate very quickly, perform well on simple, low-dimensional prob-lems, and return a fitness value arbitrarily close to the minimum in the convex parameter region. However, one can imagine many hypersurfaces for which gradient-based optimization methods would get stuck in local minima, missing other potentially better or degenerate solutions wherein different sets of parameters evaluate to fitness values within 3 σ of the global-best solution. Models that are fully or partially based on data ta-bles may not be smooth or continuous in the model pa-rameters or their derivatives, and noise may look like many small local minima for an optimizer, resulting in poorly defined gradients. Additionally, a steepest-descent gradient-based algorithm is incapable of explor-ing other regions a of a parameter space once a local min-imum is found, since a step size in any direction results in a poorer objective function value. For these reasons, it is common practice for researchers to use informa-tion collected through simulations or from the literature for similar astrophysical scenarios to make an educated ‘best initial guess’ of a reasonable starting point for the search. For complicated problems, the final result may be sensitive to this initial condition in practice, since lo-cal optimizers are prone to become trapped in local min-ima. Other practices, such as reducing the hypervolume of the search space by holding particular model param-eters constant and performing a local search within a subspace, are also common. However, not all problems can be solved by sequentially optimizing arbitrarily cho-sen subspaces, which are still prone to becoming trapped in local minima or potentially introducing bias into the results of the fit. A single-agent gradient-based optimization algo-rithm’s reliance on differentiable objective functions and arbitrary user-input imposes limits on researchers’ abil-ity to fit models to data containing both systematic uncertainty and noise. This motivates the question as to whether novel approaches such as global optimiza-tion methods represent suitable alternatives that can improve the consistency with which physically interest-ing solutions are found, while also reducing potential biases introduced by the aforementioned conventional approaches to model fitting. Global Bayesian samplers interfaced with XSPEC provide a powerful alternative to local optimization for fitting models to X-ray spec-tra. The Bayesian X-ray Analysis (BXA) software (J. Buchner et al. 2014; J. Buchner 2021) is a Bayesian-inference front-end that connects XSPEC models to the “UltraNest” nested sampling engine (J. Buchner 2021) (originally MultiNest, F. Feroz et al. 2009) that demon-strates improvements over a number of limitations typ-ically associated with the use of standard Markov chain Monte Carlo (MCMC) methods in complicated likeli-hood landscapes. MultiNest uses multi-ellipsoid clus-tering to track and apply weights to separate local max-ima in a fully Bayesian manner, while UltraNest adds region-based metrics in the evidence and posterior, en-abling Bayesian inference in multi-modal problems. The computational cost required to compute evidence and posterior estimates using nested sampling scales linearly with the number of live points and at least quadratically with dimension (J. Buchner 2023). In ap-plications where the target is to map the profile likeli-hood rather than compute Bayesian evidences, differen-tial evolution–based scanners have been found to out-perform MultiNest and several variants of MCMC in terms of computational cost for models with ≳ 10 free parameters (G. D. Martinez et al. 2017). Furthermore, optimizers that utilize evolutionary strategies are partic-ularly effective at identifying and mapping multi-modal structures of high-likelihood regions in parameter space for high-dimensional problems where evidence computa-tion would be prohibitively expensive for large data sets. Section 2 will provide a broad overview of the global evo-lutionary optimization methods used to fit spectroscopic models to the two sources in Section 3, and Section 4 describes the analytical methodology used in comparing the results of the optimizations.  

> 2.

XFIT: GLOBAL OPTIMIZATION High-dimensional objective functions containing noise, uncertainty, and multiple local optima pose significant challenges to optimization. Problems of this type also represent rich testbeds for determining which characteristics in a given model present difficulties to an optimization algorithm, the exploration of alternative optimization schemes that may perform better on some or all of these characteristics, and identifying robust indicators for the efficiency and efficacy of said optimizers. Genetic Algorithms were first described by J. H. Holland (1975) and operate in analogy to the principle of biological evolution (D. E. Goldberg 1989). Examples include the PIKAIA algorithm (P. Charbonneau 1995), which was offered as an option in previous versions of XSPEC (v.11.3; K. A. Arnaud 1996). PIKAIA implements two basic genetic operations acting on a population of strings encoded using a decimal alphabet: a uniform one-point crossover operator and uniform one-point mutation operator. However, this simple genetic algorithm was found to be inefficient at 4optimizing spectral model parameters. As mentioned in the XSPEC v11.3 manual, “tests with 3 free parameters show that thousands of generations are required to converge on the correct fit”. This is evidence that the fitting problem is difficult for a simple GA with limited operators and precision. The “genetic” option in XSPEC was later removed in successive versions as it was a seldom-used fitting method in that package. In this paper, we introduce XFit , an X-ray spectral fitting package written in MATLAB (The MathWorks Inc. 2023) which uses the Qubist Global Optimization Toolbox (J. D. Fiege 2025) to fit spectral models to X-ray data. The Qubist package includes the Ferret Evolutionary Optimizer which is specially designed to explore the structure of the parameter space by making use of advanced mapping capabilities and the ability to output degenerate solutions where different sets of parameters map to objective function values within 3 σ

(99.7% confidence) of the global best solution. While traditional GAs use a binary representation of the objective function parameters (J. H. Holland 1975), evolutionary optimizers (EOs), such as Ferret, use real-valued parameters that are acted upon by the algo-rithm’s various operators. EOs use a stochastic search approach to explore the parameter space in a random, yet directed manner, and like GAs, borrow from the principles of natural selection to search for a global min-imum while also maintaining diversity in a population of parameter sets each mapping to a fitness value. This diversity gives the EO the ability to search for degen-erate solutions while simultaneously mapping regions of the parameter space satisfying a user-specified statistical fitness criterion. Each set of parameter values is encoded in an array that represents a ‘member’ of a population that is transformed at each time-step or ‘generation’ of the algorithm by operators such as the crossover, muta-tion, and selection operators. A tournament-based selection operator assigns copies to each member of the population to pass on to the next generation. The number of copies assigned to each member is calculated based on the value of the individ-ual’s objective function. To ensure the fitness mono-tonically decreases, a user-defined fraction of the most-fit solutions or ‘elites’ are guaranteed to pass directly to the next generation without modification. Crossover operators select members to swap a single parameter or combinations of parameters as ‘building blocks’, and a secondary geometric crossover operator mixes sets of parameters by treating the two sets of parameters as coordinates in a vector space and taking the stochastic average between them to generate new parameter sets known as ‘offspring’. The array elements of each indi-vidual are acted upon by a mutation operator, which perturbs the element by a value chosen from an empir-ical distribution that co-evolves with the population to maximize success probability. The mutation operator is also highly directed, making use of the semi-local distri-bution of the population and their fitness values. The probability of an element being selected for mutation as well as the standard deviation of perturbation in both mutation and geometric crossover operations can be set by the user and even optimized by the algorithm as the search progresses. With the iteration of these three ba-sic processes, the population moves toward individuals of superior fitness, exploring the parameter space, and converging on the global minimum. Techniques such as ‘niching’ promote diversity in the population by penalizing solutions that are too similar to each other. This diversity drives the thorough explo-ration of a parameter space around isolated solutions, allowing the algorithm to potentially discover and map distinct islands of solutions, a process that is crucial for multi-objective objective functions. Niching is also useful for mapping confidence intervals as an XFit run proceeds and helps avoid premature convergence. An-other of Ferret’s useful features is its ‘linkage learning’ algorithm, which attempts to monitor nonlinearities in the problem. If nonlinearities are found, Ferret will at-tempt to reduce the parameter space into separate sub-spaces (when possible), which can then be optimized quasi-independently. 

XFit makes use of a MATLAB MEX interface to in-terface with the existing library of spectral models that are distributed with the XSPEC code, written in C and FORTRAN. The flexibility of this approach allows us to include new models that are frequently written and up-dated by the XSPEC user base. Moreover, fitting with the Qubist toolbox is an automatic procedure that does not require extensive user interaction common to local opti-mizers, such as guessing a best initial starting point or freezing parameters and fitting over the resulting lower-dimensional subspace. The global nature of evolutionary optimizers allows the process to proceed with minimal external influence, reducing the chances of introducing bias into the fitting procedure. Global optimization methods such as Ferret often re-quire a greater number of calls to the objective function per evaluation step than the local LMA, although Fer-ret’s computations are easily parallelized to make use of multi-core computers or clusters. Despite the some-times large number of evaluations required to converge to a solution, the advantages of global approaches be-come obvious in mapping degeneracies and thoroughly exploring the parameter space of complex models. XFit 5provides a new method that is capable of finding mul-tiple degenerate solutions with model fit statistics that predict the observed data better than the standard ap-proach while automatically mapping confidence inter-vals during a run. Although convergence to an optimal solution with the EO may be slower than with the LM method, it is more likely to find solutions that are diffi-cult to find with the usual manual search of parameter subspaces as models increase in size and complexity. 

XFit is an exploration tool that produces a robust set of optimal solutions even when exploring high-dimensional parameter spaces, and illustrates subtle, nontrivial behaviors of models over large regions of pa-rameter space, saving valuable human time and effort in exchange for computing cycles. We see XFit as a valuable tool that augments the traditional approach, overcomes many limitations inherent in local optimiz-ers, and usually finds better solutions. As a proof of concept, we apply XFit to two represen-tative X-ray datasets. The CCO in Cassiopeia A and the western lobe of the SNR G41.1 −0.3. These examples were selected to demonstrate the application of XFit to a low-dimensional blackbody spectral model in compact objects, and a high-dimensional spectral model describ-ing thermal emission from an ejecta dominated SNR, respectively. The present study focuses on these two sources for illustrative purposes, and future work will extend the application of XFit to larger source samples and more physically motivated models.  

> 3.

SPECTRAL FITTING SNRs come in a variety of morphologies made up of some combination of compact object, wind nebula, and shell of shocked and heated material ejected into the in-terstellar medium. SNRs emit radiation through a myr-iad of processes with dependencies on elemental com-position; electron temperature; ionization and recom-bination timescales; turbulent velocity flows; and non-thermal particle distributions. Accurate measurements of X-ray emission lines are important for estimating plasma temperatures and the abundances of nucleosyn-thesis products in SNR ejecta. A spectral line is typi-cally characterized by its amplitude, width, and centroid energy. In spectroscopy, line amplitudes or emissivities are used to determine elemental abundances contained within a source. Lines are attributed a natural width due to quantum mechanical uncertainty, but deviations from this natural line width can also be used to mea-sure the thermal motion of the plasma. Additionally, Doppler shifting of line centroids are often used to de-termine the distributions of velocities within a plasma. Furthermore, several studies (e.g., H. Yamaguchi et al. 2014; C. Braun et al. 2023) demonstrate a strong cor-relation between progenitor type, explosion mechanism, and the strong optically-thin emission lines of ejecta (in-cluding the Fe-K line centroid) in thermal X-ray spectra of SNRs. Depending on the energy resolution of the ob-servation, multiple species as well as ions of the same species, may contribute to the intensity of a line, imply-ing the possibility of degeneracy in the parameter space of solutions. Theoretical models aim to predict the count rates ob-served by a detector as a function of photon energy. The process of spectral fitting can be described by per-forming a simultaneous regression between the observed and predicted count rates over a range of energy bins. An X-ray telescope’s pulse height amplitude (PHA) en-codes the photon energy as the integrated charge per pixel of the “event”, and a background subtraction re-gion can be used to improve the signal-to-noise of the spectrum. An ancillary response file containing informa-tion on the energy- and time-dependence of the detec-tor area’s quantum efficiency is multiplied by the model photon spectrum, producing a spectrum that would be seen by a detector with perfect spectral resolution. This spectrum is then multiplied by a response matrix file, which maps from energy space into pulse height, effec-tively spreading the counts by the detector’s energy res-olution and producing the final spectrum. The XSPEC data analysis software utilizes custom made and pre-loaded models to fit to data. The ‘Tuebingen-Boulder ISM absorption’ (TBabs) model is used to account for X-ray absorption due to hydrogen, where the observed intensity Iobs (xk) of the X-ray spec-trum of a source with emitted intensity Isource is given by Equation 3. 

Iobs (xk) = e−σISM (xk )NH Isource (xk), (3) Where N H is the total hydrogen column density in units of cm −2. J. Wilms et al. (2000) provide updated ISM abundance values and ionization cross-sections to TBabs by assuming a default value for molecular hydro-gen of 20%. Photoelectric cross-sections obtained by M. Balucinska-Church & D. McCammon (1992) are used with the TBabs model in the following analysis of the CCO in Cassiopeia A (see 3.1). To enable direct com-parison with earlier work, we fit G41.1–0.3 (3.1) using a photoelectric absorption model based on the Wiscon-sin cross-sections (R. Morrison & D. McCammon 1983), that predicts a model spectrum given by Equation 4. 

M (xk; p) = e−NH σ(xx), (4) 6where σ(xk) is the photo-electric cross-section neglect-ing Thomson scattering and the relative abundances are obtained by E. Anders & N. Grevesse (1989). 3.1. The CCO in Cassiopeia A 

Cassiopeia A (Cas A) hosts one of the most widely known CCOs, CXOU J232327.9+584842, which was first seen by the Chandra “first light” observation in 1999 (H. Tananbaum 1999; G. G. Pavlov et al. 2000). Spectral and timing analysis by J. S. Heyl et al. (2001) revealed that the point source in Cas A shows no signs of pulsations and different spectral properties than other young pulsars such as the Crab pulsar. CCOs commonly reside near the geometric centre of young (0 .3 − 7 kyr) SNRs, producing thermal X-ray emission with no ra-dio or optical counterparts. Their spectra are typically well fit to that of a hot blackbody model of temperature 

∼ 2 − 6 × 10 6 MK (A. De Luca 2017) or to a power law spectrum with a steep photon index (G. G. Pavlov et al. 2004, 2001). Although young NSs are typically expected to produce pulsations, only 3 CCOs have been detected so far as pulsars (E. V. Gotthelf et al. 2013). Possible explanations for the lack of pulsations in most CCOs include weak magnetic fields ( < 10 8 G), uniform surface temperature, or a viewing angle from Earth that pre-vents us from seeing any pulsations. When the emitting radius is derived from these models, the result is typi-cally on the order of ∼ 1 km, much smaller than the ∼

10 km canonical size of a NS (P. Ozel & P. Freire 2016) implying the existence of hotspots on the NS surface that are usually associated with large magnetic fields. G. G. Pavlov & G. J. M. Luna (2009) reanalyzed the spectrum of the Cas A CCO and conclude it is likely a NS with non-uniform surface temperature and low mag-netic field. Cas A was observed by the Chandra Space telescope on May 05, 2012 for a total exposure time of 63.39 ks (ACIS-S; PI: Pavlov; doi: 10.25574/cdc.484). A broad-band spectrum grouped to a minimum of 15 counts per bin over the energy range 0.3-6.5 keV is used for this study. The spectrum of the CCO in Cas A is fit by a simple five-parameter absorbed blackbody for modeling the soft emission with an additional absorbed power-law component to model the hard emission generated by the putative hotspot. Due to the simplicity of the model used to fit its spectrum, Cas A is a representa-tive example useful for demonstrating the consistency between optimization algorithms since both local and global methods find the same best-fit solution over iden-tical weakly-constrained search boundaries. The best fit parameters and their corresponding fit statistics found by XSPEC and XFit are shown in Table 1 along with the 10 -3               

> 10 -2
> 123456
> -4 -2 024
> Figure 1. Top panel: The spectral data and uncertainties of the CCO in Cassiopeia A is plotted logarithmically in dark blue crosses. The best-fit XSPEC model is plotted as a solid cyan line and the best-fit XFit model is plotted as a solid magenta line. Bottom panel: the residuals between the data and model for each optimizer. Residuals for each solution are plotted side-by-side at each energy bin to make nearly-identical pairs of data points both comparable and distinguishable .

minimum and maximum search boundaries used for the search. Both weakly-constrained and unconstrained searches are useful in problems where one knows nothing about the expected range of parameter values containing the best-fit solution a priori. They are also useful when one wishes to map the topology of the parameter space in or-der to inform future searches, as well as in searching for degeneracies in best-fit solutions. Due to the simplicity of the model used in fitting CXOU J232327.9+584842, both the LMA and EO converge to the same minimum in the weakly-constrained search. The best fit model and residuals for the LMA (cyan) and EO (magenta) are plotted in Figure 1 showing strong agreement be-tween the solutions found by each optimizer. 3.2. G41.1–0.3 

The Galactic SNR 3C 397 (G41.1–0.3) is among the brightest of the Galactic radio SNRs due to its filled central X-ray emission, and is selected as a high-dimensional, representative example given that it is a uniquely bright and ejecta-dominated SNR whose super-nova progenitor is being debated (H. Yamaguchi et al. 2014). A broadband study performed by S. Safi-Harb et al. (2000) used combined ROSAT, ASCA, and RXTE spectra to fit a two-component non-equilibrium ioniza-tion model to the soft- and hard-emission associated with 3C 397, finding a heavily absorbed spectrum domi-7

Table 1. CXOU J232327.9+584842 Best-fit Model Parameters Parameter Min. bound Max. bound XSPEC XFit 

NH 10 22 a 0.01 10 3.24 +0 .89  

> −0.64

3.24 +0 .55 

> −0.44

kT b 0.001 100 0.41 +0 .01  

> −0.02

0.42 +0 .02 

> −0.02

NBB c 10 −16 10 20 1.65 +0 .86  

> −0.24

× 10 −5 1.65 +0 .52  

> −0.26

× 10 −5

Γ 0.01 10 5.56 +2 .07  

> −1.00

5.56 +1 .3

> −0.73

NP d 10 −16 10 20 5.97 +18 .96  

> −4.17

× 10 −3 5.97 +8 .3 

> −3.1

× 10 −3

χ2 159.57 159.57 DoF 164 164 # PHA bins 169 169  

> a

cm −2 

> b

keV  

> c

photons keV −1 cm −2 s−1 

> d

photons keV −1 cm −2 s−1 at 1 keV 

Note —A comparison of the best-fit model solutions found by XSPEC and XFit for the CCO in Cassiopeia A. The minimum and maximum search limits are given, as well as the parameters and associated fit statistic. The model is an absorbed blackbody and power-law. The column density of the absorption model is NH , the temperature of the black-body component is given by kT with normalization NBB 

and the power-law exponent is given by the photon index Γ with normalization 

NP . The fit statistic is χ2, number of degrees of freedom (DoF) over the stated number of pulse height PHA bins (pulse height amplitude: integrated charge per pixel from an event recorded in the detector). 

nated by thermal emission containing Mg, Si, S, Ar, and Fe emission lines. These findings were later confirmed by a spatially resolved Chandra observation (S. Safi-Harb et al. 2005). This composite SNR features a shell type remnant in the radio (D. A. Green 2004) and an X-ray bright central region. In this work we use broadband Chandra observations from the ACIS-S detector (66 ks exposure time taken on September 6, 2001; PI:Holt; doi: 10.25574/cdc.484) with the spectrum grouped to a min-imum of 20 counts per bin over the energy range 0.5-7.5 keV. The continuum and line emission of the western lobe of G41.1–0.3 is fit to a 29-parameter absorbed two-component Bremsstrahlung model with eight Gaussian peaks. This high-dimensional model provides a useful test of a more complicated model for the optimizers. Due to its high-dimensionality, the search-space hyper-volume is constrained to a smaller range compared to those used to fit the Cas A CCO, including constrain-ing the Bremsstrahlung model components into high-and low-temperature components. The search bound-aries and best-fit parameter values found by both XFit 

and XSPEC for the western lobe model can be found in Table 2. The data and best-fit models found by both optimizers are shown in Figures 2 and 3 with a close-up of the fit to the Ca emission line shown in the rightmost panels of Figure 2. 

4. RESULTS Due to their differing approaches to optimization, comparisons between local and global optimization algo-rithms must be performed using measurable quantities that are common to both types of algorithm, such as the number of evaluation calls to the objective function. This quantity is used to determine the performance of the search at each step and inform the direction of fu-ture steps, with a ‘step’, referring to a change in the co-ordinate of a search-agent in the parameter space. De-pending on both the optimization algorithm, and the function being optimized, numerous objective function evaluations may be required to determine the next-best coordinate for a search-agent as the optimization contin-ues. Thus, the number of objective function evaluations is always equal to, or greater than the number of steps in an optimization. As discussed in Section 1, local optimizers such as the LMA use a single-agent gradient-based search approach that stores information about the position, gradient, and fitness value only at the current and immediately neigh-boring time steps, and disposes of any information ob-tained at previous steps. In contrast, EOs collect and store any information that contributes to a decrease in the objective function throughout the entire optimiza-tion and exchanges this information usefully among its 8

Table 2. Western Lobe of G41.1–0.3 Best-fit Model Parameters Parameter Min. bound Max. bound XSPEC Solution 1 XFit Solution 1 XFit Solution 2 

NH a 4 8 4.39 +0 .84  

> −0.13

4.635 +0 .061  

> −0.057

5.27 +0 .18 

> −0.11

kT 1 b 0.01 1 0.17 +0 .01  

> −0.03

0.155 +0 .004  

> −0.002

0.135 +0 .005 

> −0.007

NBR 1 c 10 −4 10 5 3.40 +52 .2 

> −1.4

× 10 2 7.4+1 .6 

> −1.9

× 10 2 5+5  

> −1.8

× 10 3

kT 2 b 1.1 5 3.3533 +0 .0001  

> −0.82

1.96 +0 .21  

> −0.17

3.24 +1 .2

> −0.53

NBR 2 c 10 −4 10 5 1.1+0 .64 × 10 −3 3.04 +0 .64  

> −0.55

× 10 −3 1.25 +0 .35  

> −0.41

× 10 −3

E1 b 0.01 1.1 0.705 +0 .002  

> −0.15

0.693 +0 .028  

> −0.14

0.522 +0 .086 

> −0.034

σ1 b 10 −4 1 0.12 +0 .02 0.121 +0 .025  

> −0.006

0.142 +0 .007 

> −0.014

NG1 d 10 −6 10 4 59 +2324  

> −21

1.46 +6 .2 

> −0.4

× 10 2 9.52 +0 .48  

> −6.2

× 10 3

E2 b 1.2 1.4 1.3351 +0 .003  

> −0.0002

1.336 +0 .008  

> −0.004

1.335 +0 .001 

> −0.003

σ2 b 10 −4 1 3.3+20  

> −2

× 10 −4 2.81 +11  

> −2.7

× 10 −3 0.0232 +1 .4 

> −0.013

× 10 −2

NG2 d 10 −6 10 4 8.5+15  

> −0.8

× 10 −3 1.163 +0 .1 

> −0.1

× 10 −2 2.6+0 .67  

> −0.31

× 10 −2

E3 b 1.8 1.95 1.830 +0 .0005  

> −0.002

1.830 +0 .002  

> −0.002

1.829 +0 .002 

> −0.004

σ3 b 10 −4 1 2.8+0 .5 

> −0.8

× 10 −2 2.70 +0 .38  

> −0.43

× 10 −2 3.33 +0 .49  

> −0.32

× 10 −2

NG3 d 10 −6 10 4 9.9+7 .6 

> −1.3

× 10 −4 1.122 +0 .043  

> −0.069

× 10 −3 1.71 +0 .25  

> −0.14

× 10 −3

E4 b 2.2 2.35 2.27 +0 .03  

> −0.09

2.268 +0 .019  

> −0.011

2.181 +0 .02 

> −0.077

σ4 b 10 −4 1 0.209 +0 .06  

> −0.007

0.217 +0 .017  

> −0.018

0.267 +0 .061 

> −0.03

NG4 d 10 −6 10 4 5.2+5 .4 

> −0.8

× 10 −4 5.16 +0 .48  

> −0.65

× 10 −4 1.05 +0 .38  

> −0.14

× 10 −3

E5 b 2.35 2.95 2.4303 +0 .0005  

> −0.0003

2.430 +0 .004  

> −0.001

2.430 +0 .004 

> −0.001

σ5 b 10 −4 1 1.1+5 .4 

> −0.9

× 10 −3 0.09156 +1 .4 

> −0.082

× 10 −2 0.0145 +1 .4 

> −0.0045

× 10 −2

NG5 d 10 −6 10 4 1.8+0 .4 

> −0.1

× 10 −4 1.961 +0 .091  

> −0.16

× 10 −4 2.32 +0 .24  

> −0.11

× 10 −4

E6 b 2.35 3.11 2.9515 +0 .06  

> −0.0001

2.977 +0 .024  

> −0.018

2.979 +0 .044 

> −0.045

σ6 b 10 −4 1 0.23 −0.05 0.191 +0 .019  

> −0.022

0.217 +0 .036 

> −0.029

NG6 d 10 −6 10 4 1.623 +0 .004  

> −0.4

× 10 −4 1.083 +0 .088  

> −0.14

× 10 −4 1.67 +0 .41  

> −0.28

× 10 −4

E7 b 3.75 3.95 3.8062 −0.01 3.846 +0 .023  

> −0.015

3.793 +0 .039 

> −0.039

σ7 b 10 −4 1 0.17 +0 .01  

> −0.01

8.07 +39  

> −8

× 10 −3 0.181 +0 .039 

> −0.034

NG7 d 10 −6 10 4 2.5+0 .4 

> −0.3

× 10 −5 9.9+1 .7 

> −1.5

× 10 −6 2.87 +0 .77  

> −0.42

× 10 −5

E8 b 6.53 6.56 6.546 +0 .004  

> −0.007

6.547 +0 .013  

> −0.013

6.546 +0 .012 

> −0.013

σ8 b 10 −4 1 6.35 +0 .02  

> −0.3

× 10 −2 7.1+1  

> −1.9

× 10 −2 6.3+1 .3 

> −1.5

× 10 −2

NG8 d 10 −6 10 4 4.10 +0 .1 

> −0.01

× 10 −5 4.32 +0 .46  

> −0.48

× 10 −5 4.14 +0 .37  

> −0.4

× 10 −5

χ2 323.48 326.81 323 .51 # DoF 264 264 264 # PHA bins 293 293 293  

> a

cm −2 

> b

keV  

> c

photons keV −1 cm −2 s−1 

> d

photons keV −1 cm −2 s−1 at 1 keV 

Note —A comparison of XSPEC and XFit best-fit model solutions for the western lobe of G41.1–0.3. The minimum and maximum search limits are given as well as the parameters and associated fit statistic. The model is a two-component bremsstrahlung model with eight Gaussian lines. The column density of the absorption model is NH , the temperature of each bremsstrahlung component is given by kT n with normalization NBRn with n denoting the component index. The centroid energy of each Gaussian line component is given by En, and the line width and normalization are given by σn and NGn respectively. The fit statistic is χ2, number of degrees of freedom (DoF) over the stated number of PHA bins. 910 -3               

> 10 -2
> 10 -1
> 10 0
> 1234567
> -5 -3 -1 1350.01
> 3.4 3.6 3.8 44.2 4.4
> -4 -2 024

Figure 2. Left : Best-fit models and residuals fit to the spectrum of the western lobe of G41.1–0.3 are plotted logarithmically for Solution 1 ( χ2 

> r

= 1 .238). Observed count rates and their uncertainties are plotted as dark blue crosses. The best-fit XSPEC model is plotted as a solid cyan line and the best-fit XFit model is plotted as a solid magenta line. Right : a zoomed-in view across a narrower range of energies highlighting degeneracies in spectral features of the best-fit Ca (He α) amplitudes, line centroids and widths found by XSPEC and XFit . Residuals for each solution are plotted side-by-side at each energy bin to make nearly-identical pairs of data points both comparable and distinguishable .10 10 -3               

> 10 -2
> 10 -1
> 10 0
> 1234567
> -5 -3 -1 135
> Figure 3. Best-fit models and residuals fit to the spectrum of the western lobe of G41.1–0.3 are plotted logarithmically for Solution 2 ( χ2
> r= 1 .225). Observed count rates and their uncertainties are plotted as dark blue crosses. The best-fit
> XSPEC model is plotted as a solid cyan line and the best-fit
> XFit model is plotted as a solid magenta line. Residuals for each solution are plotted side-by-side at each energy bin to make nearly-identical pairs of data points both comparable and distinguishable .

search agents. For these reasons, we are interested in comparisons between the number of degenerate minima found by each optimizer, and the frequency at which such solutions are found for a given number of objec-tive function evaluations. Following this argument, the EO and LM algorithms are allotted an equal number of calls to the objective function for evaluation. The initial population of parameter sets used in the EO search is randomly sampled from a distribution with user-defined limits for each parameter, and boundary values that are given in Tables 1 and 2. XFit then performs a search, converges on one or more solutions, and returns the total number of objective function evaluations N in a run. An initial starting point for the LM search is then randomly sampled from a uniform distribution with the same boundaries as was used by XFit .The single-step stopping criterion for the LMA works by signaling a stop as soon as the improvement in the fit-ness falls below a user-defined absolute threshold value termed the ‘critical delta’, ∆ crit . The value for the crit-ical delta ∆ crit = 0 .001 was selected to be of the same order as the absolute difference in the best objective function values found by XFit at the penultimate and ultimate generations of its optimization, ensuring that both optimizers are capable of distinguishing between solutions at the same level of precision in the convex basin. An additional stopping criterion for the LMA is employed called the ‘fit delta’ ∆ fit , used to prevent wasting evaluations in regions where parameter values aren’t changing significantly even if ∆ crit has not yet been triggered. ∆ fit is related to the relative difference in a parameter’s value between successive steps. When this relative difference falls below a user-defined thresh-old for all model parameters, ∆ fit is triggered. If either of these stopping criteria are triggered, the LMA is sig-naled to halt, and the current solution is returned. Tra-jectories taken by the LMA through the parameter space are deterministic, since for identical initial values for the damping parameter λ, step size h, ∆ crit , and ∆ fit at the start of the search, any solution found that triggers stop-ping solely depends on the initial starting point of the search. We use a default value of ∆ fit = 0 .001. The pa-rameter deltas used for calculating the finite-difference derivatives of the Jacobian matrix are set to their de-fault values. Once the stopping criterion for an LMA search is reached, statistics about the run are collected, including a tally of the number of objective function evaluations called during the run. If the total number of objective function evaluations called at the end of the current LMA run is less than the N calls made by the EO, another LMA search is initiated with a newly sam-pled starting point and this process is continued until N total objective function evaluations have been called by the LMA. The uncertainties in the best-fit model pa-rameters found by each optimizer listed in Tables 1 and 2 are determined using the entire set of solutions found within the 90% confidence interval of the minimum χ2

> r

solution. All experiments were performed on a workstation equipped with an AMD Ryzen Threadripper PRO 5995WX CPU (64 cores, 2.7 GHz base/4.5 GHz boost) and 256 GB of RAM (PassMark Software 2025), using MATLAB with the Parallel Computing Toolbox and 64 workers for parallel evaluation of the population. We benchmarked the scaling of XFit ’s runtime with the number of free parameters N by varying N from 1 to the full Nmax = 29. Over this range, the mean wall-clock time per fitness evaluation remains in the ∼ 1-2 ms regime and is well described by an approximately linear model with a fixed overhead of ∼ 0.7 ms due to the MEX API loading time, and an additional ∼ 30 μsper free parameter. For the full 29-parameter model, a complete optimization run with our standard settings requires a total wall-clock time of ∼ 7 hours on this system. 4.1. CXOU J232327.9+584842 

In fitting the spectrum of CXOU J232327.9+584842, 

XFit was given four populations of 100 search agents, finding the global best solution and uncertainties (90% confidence) shown in Table 1 after N CasA = 582592 ob-11 jective function evaluations. The LMA completed 5365 independent local runs before reaching the maximum number of fitness calls returned by XFit , finding a global best solution that is in strong agreement with the so-lution found by XFit . Figure 4 displays a parameter space map of solutions discovered by the LMA across N evaluation. To ensure the map only contains solution ar-rived at by the LMA using gradient information, the ini-tial starting points of each search are excluded. Highly colour-saturated bins coincide with local minima, the fi-nal coordinate of an LMA trajectory at the moment the stopping criterion was triggered. Each coordinate bin is colour-coded based on the best χ2 value attained within that bin. The clustering of solutions around local min-ima observed in the maps in Figure 4 illustrates the local optimizer’s sensitivity to the initial starting conditions of the run. We find very few regions corresponding to the final positions of the search indicating that this is a simple problem with few local minima. This simplicity is further confirmed by the matching solutions found by both local and global optimizers. If one knows very little about a given model or would like to avoid introducing bias into the results of a run, these maps can provide in-sights into suitable search boundaries for an optimizer, resulting in a potential reduction in required resources and computation time. Uncertainties in model parameters are obtained using the set of all solutions found by each optimizer with a fit statistic χ2 within the 3 σ (99.7%) confidence inter-val, which we refer to as the “optimal set”. In general, the optimal set can possess complicated morphologies or even be spread out over multiple, disconnected regions of parameter space. Confidence maps are important for determining the precision with which we can say our so-lution best reflects the true values of the physical proper-ties of the source as well as for mapping the behaviour of an optimizer in the fitness landscape surrounding local minima. In problems where multiple degenerate solu-tions exist, confidence mapping also allows one to dis-tinguish between solutions with fitness values within the 3σ range of the global best. Mapping confidence regions in XSPEC is typically achieved by creating an M-dimensional grid of linearly spaced values around a previously found solution for the number of “interesting” parameters requiring confidence estimates. The parameters of interest are held at con-stant values corresponding to their position in the grid and the remaining “uninteresting”, free parameters are given initial values corresponding to the latest best fit solution. A local fit is then performed at each point in the grid by varying the “uninteresting” parameters until a new best-fit solution is achieved and an interpo-lation over all points generates contours at the 1 σ, 2 σ

and 3 σ levels above the best-fit solution. Due to its re-liance on local optimization, this procedure inevitably runs into the same caveats discussed in Section 1. For a parameter space with many local minima, the question also arises as to how reliably the contours generated us-ing this method map the space around solutions. XFit 

simply maps confidence regions by returning all individ-ual solutions that are members of the optimal set found during a run. This contrasts with XSPEC s approach de-scribed above, which aims only to return a single best-known solution. Thus, XFit thoroughly and automati-cally discovers and maps the structure of the 1 σ, 2 σ and 3σ confidence interval projections while simultaneously searching for the best fit. This also allows XFit to map degenerate solutions and evaluate the uncertainties in their parameter values simultaneously. Figure 5 shows the confidence interval maps generated by XFit for the CCO in Cas A with the 1 σ, 2 σ, and 3 σ

intervals represented by red bins of varying darkness. Confidence contours surrounding the LMA’s best-fit so-lution were then generated using XSPEC ’s conventional interpolation method and are plotted as solid blue and purple contour lines. The LMA and EO predict identical uncertainties in their parameters for the majority of the confidences and combinations of parameters when using this conventional approach, demonstrating that both op-timizers observe the same solution and surrounding pa-rameter space for CXOU J232327.9+584842. However, there is a notable disagreement between the optimizers for both confidence maps containing the power law in-dex Γ. The 3 σ contour (dark-blue) generated by the local optimizer encounters difficulty in tracing the con-tours generated by the EO. A possible explanation for this discrepancy is the LMA becoming stuck in a local minimum or continuing the search along a narrow and steeply descending region in the parameter space, taking the search outside the allowed range of values defined in the grid. When performing many local searches in the manner described at the beginning of this section, it is not pos-sible to predict the number of objective function evalu-ations that will be required to determine parameter un-certainties for the best-fit solution found by the LMA. Additionally, since XSPEC ’s interpolation method is not a built-in feature of the LMA, it is only used to confirm consistency between optimization methods for this sim-ple model as shown in Figure 5, and is excluded from the remaining analysis. Instead, the uncertainties listed in Table 1 are determined using the set of solutions found by each optimizers after N objective function evalua-tions. 12 0 2 4 6 8 10                

> 020 40 60 80 100
> 0.97 1.27 1.58 1.73 1.88 0246810
> 0246810
> 0.97 1.12 1.28 1.43 29.99
> Figure 4. Parameter space projections of the column density NH, blackbody temperature kT , and photon index Γ for the absorbed thermal model used to fit the spectrum of CXOU J232327.9+584842, visualizing the entire space of points covered by the 5365 independent searches conducted by the LMA. The data is spatially binned to include only the best-fit χ2
> rsolution found in each bin. Coordinates with high color saturation coincide with local minima in the parameter space at which the LMA converged. The small proportion of local minima found by the local optimizer is representative of the ‘simplicity’ of the model.
> XFit ’s best found solution is marked with a magenta star and XSPEC ’s best found solution is marked with a red star which is covered by XFit ’s solution since both optimizers converge to the same global best value. A trailing red line shows the path taken by the local optimizer in its search to find the best solution starting from the initial optimization step, and illustrates the strong tendency of the LMA to move along narrow ‘canyons’ with large negative gradients.

4.2. G41.1–0.3 

The 29-parameter model used to fit the spectrum of G41.1–0.3 presents a more challenging case for both op-timizers even with more narrowly constrained search limits. To allow for comparisons with previously pub-lished values (S. Safi-Harb et al. 2005), we here select the western lobe of this SNR. XFit performed its op-timization using 6 populations of 250 individuals each, over a total of N EO = 20285430 objective function calls, and finds two unique solutions, indicating degeneracy in the parameter space of the model. The LMA completed 45297 independent local runs given the same number of objective function evaluations as XFit , and finds a best-fit solution of min χ2 

> r

= 1 .225; a column density NH of 4.39 cm −2; temperatures of 0.17 keV and 3.4 keV for the first and second Bremsstrahlung components kT 1

and kT 2, respectively; values of 3.8 keV and 0.17 keV for centroid energy E 7 and line width σ7 components of the seventh Gaussian line respectively, corresponding to the Ca He α emission line; and 0.24 keV for line width component of the sixth Gaussian line, corresponding to the Ar He α emission line. XFit also finds this solution (χ2 

> r

= 1 .225), plus an additional, degenerate solution (χ2 

> r

= 1 .238) within the 3 σ uncertainty of min χ2 

> r

, with values of 4.635 cm −2, 0.155 keV, 1.96 keV, 3.846 keV, 8.07 × 10 −3 keV, and 0.191 keV for these parameters, respectively. XFit also finds degeneracy in the emission line normalizations for all but the Fe line component 

NG8. These findings have implications in SNR progen-itor diagnostics, owing to their use in calculating emis-sion line flux (H. Mart´ ınez-Rodr´ ıguez et al. 2020). The lack of degeneracy in the Fe K α line is likely influenced by its high signal-to-noise in the spectrum, owing to its high abundance among the high-Z elements and its sen-sitivity to the hottest and most energetic astrophysical processes. Its insensitivity to foreground extinction also makes Fe ions among the strongest emitters in X-rays (N. Hell et al. 2020). This inverse correlation between the S/N of a model component and the expected de-gree of degeneracy in the solution space reinforces the role of Fe as a robust diagnostic element, particularly in the era of ultra-high-resolution X-ray microcalorimeter spectroscopy. The top panel of Figure 6 shows the best fitness value at each local optimization step for every search attempt made by the LMA. Searh trajectories are monotonically colour-coded based on the best-fit value found at the fi-nal step in the search. This plot demonstrates local and global optimizer behaviour that is in alignment with the ideas explored in Section 1. The LMA appears to tend towards a larger number of steps for large (worse) final fit statistics. Such searches represent the majority of the solutions found by the LMA and are likely becom-ing trapped in regions that span large volumes of the parameter space at high χ2 

> r

values, and subsequently de-clining rapidly towards unreliable fits, while also failing to trigger the stopping criterion close to the local min-imum. For the small number of solutions found by the LMA that tend toward good χ2 values, the more quickly the run converges, the better the final fit statistic is, im-plying that success with the LMA depends strongly on choosing a fortuitous starting point and highlighting the 13                 

> Figure 5. A selection of parameter-space projections between the column density NH, blackbody temperature kT, and photon index Γ for the absorbed thermal model used to fit the spectrum of CXOU J232327.9+584842. The solutions discovered by XFit
> are plotted as 1 σ(black), 2 σ(dark red) and 3 σ(red) areas. 480864 solutions are plotted and spatially binned and the best-fit solution found by XFit is marked by a white cross. The contours generated by XSPEC are plotted as 1 σ(light blue), 2 σ(blue) and 3 σ(dark blue) lines. For this relatively simple model, the results of the two fitting methods coincide across the majority of parameters. However, the local optimizer appears to run into some difficulty mapping the space for the NH— Γ cross-section.

risk of introducing bias into the final solution based on how this starting point is selected. An EO encodes information about the features of the parameter space that lead to improvements in the objec-tive function and shares this encoded information use-fully among individuals in a population at each genera-tion, which is then passed on to offspring that populate future generations in the search. The various evolution-ary operators discussed in Section 2 make it difficult to identify unique trajectories corresponding to an “indi-vidual” search agent’s progress towards a final solution in the same way that can be done for the LMA’s inde-pendent searches. Although such an analysis is currently outside the scope of the current work, it is instructive to consider representations that are common to both lo-cal and global optimizations. For example, distributions of the densities of solutions found by an optimizer each time p is updated to a new coordinate in the param-eter space, represented by a “step” and “generation” in the LMA and EO respectively, and can be used for more direct comparisons. The middle panel of Figure 6 shows the distributions of χ2 

> r

values found by the LMA at each optimization step for fitness values χ2 

> r

≤ 20. A histogram is then used to color-code the distribution at each step as the fractional frequency of the total number of solutions found within a χ2 

> r

bin at that step. Since this visualization makes no use of tracing the line connecting any two subsequent steps made by a search agent, it can also be used to identically represent the search-space as seen by the EO, shown in the bottom panel of Figure 6. The EO uses significantly less computations in re-gions of high χ2 

> r

when compared with the LMA, as the trajectories taken by the EO show more compactness across values of χ2 

> r

than the LMA, illustrated by the six trajectories in the bottom panel of Figure 6. The EO trajectories show a strong amount overlap at early and late times in the run, marking epochs of ‘exploita-tion’, wherein the optimizer favours fast convergence to small objective function values. Epochs of ‘exploration’ are marked by the diverging of population trajectories, 14 10 1 10 2 10 3 10 4       

> 1.225 10 20
> -4.59 -3.00 -2.00 -1.00 0.00 log(Frequency) 10 110 210 310 4
> 1.225 10 20
> -3.18 -2.00 -1.00 -0.18 log(Frequency)

Figure 6. Top panel : χ2 

> r

trajectories per optimization step of the 45297 LMA attempts performed by the local optimizer. Each path is monotonically color-coded based on the best local minimum fitness value found for each attempt. There is an inverse correlation between the number of steps taken by the optimizer and the best χ2 

> r

found for a given run, indicating the LMAs strong preference for steeply decreasing regions of the parameter space. The dark red line illustrates the path taken by the best solution found by the LMA. Middle and Bottom Panels: χ2 

> r

densities at each step in the LMA and EO optimizations respectively. Each coordinate in the grid is color-coded based on the frequency of binned χ2 

> r

values found within the step bin. 

where the EO spreads itself across distinct regions of the parameter space in favour of collecting useful informa-tion about its topology to aid in future convergence, and can be seen to occur between roughly 30 and 1000 gen-erations. Various points in this step range are marked by sudden, discontinuous drops in χ2 

> r

across populations. Discontinuities leading to convergence with another pop-ulation is likely due to XFit ’s built-in ‘immigration’ op-erator, that probabilistically selects individuals from one population to join another. Other discontinuous trajec-tories are preceded by sharp spikes in χ2 

> r

values repre-sented in a population. This behaviour is due to XFit ’s ‘supermutation’ operator, which introduces brief epochs of higher than usual mutation in a population. The typical width of a population at each generation is in-fluenced by XFit ’s ‘fuzzy’ relative tolerance threshold that identifies individuals within some tolerance of the population’s best solution as ‘optimals’, and are given a higher probability of selection. In contrast, the LMA trajectories are spread across a significantly wide range of χ2 

> r

values at any given step, indicating that there are many possible unique paths leading to local minima when relying on gradient information to inform updates. Assuming consistent starting values of h, λ, ∆ crit , and ∆fit between runs, each LMA fit is deterministic, with trajectories depending only on the initial starting point of the search. Therefore, a small number of LMA trajec-tories that do end up leading to a good solution implies a relatively small volume of promising initial search points in the parameter space in comparison to those that con-verge to poor fits, illustrating the LMA’s sensitivity to the boundaries of the distribution used to sample the starting point. The range of optimization steps spanned by a given 

χ2 

> r

also offers clues about the topology of the parame-ter space. The maximum number of steps taken by the LMA at values of χ2 

> r

≈ 20 is approximately 50 steps. Search agents spend significantly less time in this region 15 when compared to 2 < χ 2 

> r

< 15, where the total num-ber of steps in an optimization can span over 4 orders of magnitude. The gradient-based nature of the LMA suggests that level regions of χ2 

> r

in the parameter space containing a sparse number of steep gradients are asso-ciated with smaller numbers of optimization steps. This is also demonstrated by the trajectory that results in the best solution found by the LMA, shown as a solid dark-red line in the top panel of Figure 6. The majority of the paths leading to the best χ2 

> r

solutions show a sudden de-crease between 40-400 steps before the optimizer quickly converges to its final solution. The LMA’s χ2 

> r

densities also become less uniformly distributed across each step as the step number in the optimization increases, and comparisons between the top and middle panels of Fig-ure 6 indicate strong correlations between trajectories that result in both small and large χ2 

> r

up to a maxi-mum step size (e.g. at steps 40-200, 6 < χ 2 

> r

< 10 and 2.5 < χ 2 

> r

< 3), at which point the trajectories suddenly diverge. The χ2 

> r

densities spanning multiple orders of magnitude between 2 .2 ≤ χ2 

> r

≤ 15 imply that for certain ranges of χ2 

> r

values, there exist hyper-dimensional, level-plateaus in the fitness landscape where the objective function exhibits a decreased sensitivity to changes in the parameters, with one or more relatively small “fun-nels” to lower χ2 

> r

regions. LMA performance in these re-gions is significantly impacted by a correlation between one’s choice in convergence criteria and the topology of the fitness landscape, features which generally can-not be known a priori. In a level plateau containing a funnel, smaller values of ∆ crit may prove helpful for finding small, sharply declining funnels, by preventing early convergence in the flattened regions surrounding them. However, this invariably comes at the cost of a larger number of fitness function evaluations. On the other hand, the LMA would benefit from a larger ∆ crit 

in level plateaus that do not contain a monotonically decreasing path to a smaller χ2 

> r

, as this would lead to earlier convergence and reserve resources for a greater number of optimization attempts. By studying correlations between topological features in the model fitness-landscape and optimizer conver-gence, we gain a better understanding of the strengths and weaknesses of local and global approaches. Figures 10, 11, and 12 depict projections of model parameters across χ2 

> r

values and optimizer step (generation), as seen by the LMA (EO) for the parameters kT 1, kT 2, and σ7,respectively. This visualization strategy is identical to those described in Figure 6. The trajectories carved out by the EO in panel ( iii ) appear to correlate most strongly with the highest density LMA trajectories of panel ( ii ). This is also seen when comparing panels and (iv ) and ( v ), suggesting that although the EO does not explicitly use gradient information to inform its search, it is nonetheless able to identify and encode these re-gions when it is beneficial to the optimization process, discarding of this information in favor of encoding other, potentially non-linear, or non-gradient topological fea-tures when gradient features are no longer useful. A 2-dimensional projection map of parameter values found by each search attempt made by the LMA for this 29-parameter model is shown in Figure 7. Each parameter space map illustrates that the two solutions found for the width of the Ca line component σ7 are de-generate with respect to the second temperature com-ponent kT 2 but not kT 1. Such maps also help visual-ize why certain model components pose significant chal-lenges to the local optimizer. Solution 1 is tucked away in the bottom left corner of the possible range of values for both kT 2 and σ7 making it statistically much more likely that randomly sampled initial starting point for the search will start out closer to the second solution. Solution 2 is also surrounded by a long narrow valley of smaller χ2 values that effectively corrals the LMA towards it, shielding the first solution from the local op-timizer’s view. Since XFit does not rely on gradient information to update its search, it is less susceptible to this trapping behaviour. In the top panel of Figure 10, we see that unless the LMA starts its search near 

kT 1(χ2 

> r

= 1 .225) = 0 .17 keV, it tends towards worse χ2

> r

values when it finds itself in the convex basin containing 

kT 1(χ2 

> r

= 1 .225) at large χ2 

> r

. The explanation for this is illustrated in the left panel of Figure 7. This projection shows a large number of local minima separating solu-tion χ2 

> r

= 1 .225 from the high-χ2 

> r

(dark blue) regions of 0 .3 < kT 1 < 1. Near kT 1(χ2 

> r

= 1 .225), there also exist a number of narrow vertical canyons spanning the range σ7(χ2 

> r

= 1 .225) < σ 7 < 1, showing that the LMA is more likely to find paths to the 3 σ convex basin if it arrives at this χ2 

> r

≈ 1.8 (orange) canyon. Contrastly, we see no such vertical narrow canyons leading towards the 3σ convex basin for kT 2 in the right panel of Figure 7, a feature that is also reflected in the lack of correlation between LMA trajectories for χ2 

> r

< 2 in panels ( i) and (ii ) of Figure 11. Such features indicate that if the LMA is starting far away from kT 2, there is very narrow range of values for σ7 that lead to the 3 σ convex basin, fur-ther demonstrating the potential pitfalls of performing consecutive local searches within a subspace of the pa-rameters, where although convergence in one parameter may lead to improved fits early on, this may also run the risk of cutting off regions containing better solutions. Two metrics are defined to allow for comparisons be-tween EO and LMA performance. An exploration met-16 ric Eore emphasizes optimizer effectiveness in mapping regions around solutions in the parameter space over a total number of objective function evaluations NLMA 

and NEO for the local and global optimizers, respec-tively. Equation 5 describes Eore as the ratio between the total number of distinct solutions q(χ2 

> r, 3σ

) found by both optimizers within the convex basin of the 3 σ con-fidence interval surrounding solutions 1 and 2. 

Eore (n) = qLMA (χ2 

> r, 3σ

)

NLMA 

NEO 

qEO (χ2 

> r, 3σ

) (5) A value of Eore ≈ 1 indicates comparable effective-ness in exploratory capability between the optimizers, and Eore << 1 favors the EO. A solution is only con-sidered distinct and added to q(χ2 

> r, 3σ

) if a subsequent step from that solution to any other found by the op-timizer would not trigger the stopping criterion set by ∆crit and ∆ fit for the LMA and outlined at the begin-ning of this section. This condition balances the gran-ularity of the parameter space between the optimizers, excluding solutions found by the EO that are too sim-ilar to be distinguished by the LMA and avoids over-counting EO solutions. For a total NEO objective func-tion calls, the EO finds qEO (χ2 

> r, 3σ

= 1 .238) = 15290 and qEO (χ2 

> r, 3σ

= 1 .225) = 843002 unique solutions in the 3 σ convex basin surrounding Solutions 1 and 2, re-spectively. In comparison, the LMA finds qLMA (χ2 

> r, 3σ

=1.238) = 39 and qLMA (χ2 

> r, 3σ

= 1 .225) = 2713 solutions across NLM A = 220740499 objective function evalua-tions. Values of Eore (χ2 

> r, 3σ

= 1 .238) = 2 .34 × 10 −4 and 

Eore (χ2 

> r, 3σ

= 1 .225) = 2 .96 ×10 −4 show strong preference for the EO in terms of its exploratory power. An exploitation metric Eoit emphasizes optimizer ef-ficiency and measures the smallest number of fitness function evaluations required by each optimizer to con-verge to χ2 

> r, 3σ

for each solution. The EO converges to Solutions 1 and 2 in NEO (χ2 

> r, 3σ

= 1 .238) = 12355392 and NEO (χ2 

> r, 3σ

= 1.225) = 4349990 objective func-tion evaluations, respectively. 10 5 Monte Carlo simu-lations were performed for the LMA across a total of 

NLM A (χ2 

> r, 3σ

) = 220739152 objective function evalua-tions for each simulation. To generate the probabil-ity distribution shown in Figure 8, statistics from each LMA attempt were collected only up to and including the step that converged to the χ2 

> r, 3σ

basin. The num-ber of LMA attempts that successfully converged within the χ2 

> r, 3σ

basin are given by m( χ2 

> r, 3σ

= 1 .238) = 3 and m( χ2 

> r, 3σ

= 1 .225) = 73 for solutions 1 and 2, respec-tively. The relative probability of the LMA converging to χ2 

> r, 3σ

within the allotted NEO (χ2 

> r, 3σ

) for each solution is given by Equation 6. 

Eoit (χ2 

> r, 3σ

) = mLM A (χ2 

> r, 3σ

)

NLM A (χ2 

> r, 3σ

) NEO (χ2 

> r, 3σ

) (6) The probability of the LMA finding Solution 1 is 

Eoit (χ2 

> r, 3σ

= 1 .238) = 0 .17 when compared to the EO for an equal number of objective function evaluations, show-ing strong preference for the EO in terms of exploitative efficiency. In contrast, Eoit (χ2 

> r, 3σ

= 1 .225) = 1 .44 indi-cates that the local and global optimizers are compara-ble in this metric for solution 2. Figure 9 shows two distinct solutions as islands of 3 σ

confidence whose values are used to calculate the uncer-tainties given in Table 2. Had this problem been solved by conventional means, one of these solutions may have been missed entirely. Compared with Solution 2, Solu-tion 1 is clearly more challenging for both optimizers to find based on the number of fitness function evaluations required to converge to the χ2 

> r, 3σ

= 1 .238 convex basin, and the number of distinct solutions mapped for each re-gion. This is partially explained by the difference in the parameter space volume filled by the 3 σ convex basin surrounding each solution. Solution 2 (blue) is associ-ated with a higher degree of uncertainty in its parame-ters, representing a much larger target for an optimizer. In the case of the LMA, a larger target is more likely to contain a greater number of trajectories, and conse-quently, a greater number of initial starting points, that lead to it. The 3 σ confidence volume of Solution 2 in-fluences the performance of the EO as well, since there are a greater number of representations available to it within the objective function’s fuzzy tolerance. This suggests that the greater the precision in the parame-ter values predicted by a model’s solution, the harder the solution is to find, particularly when it resides in a parameter space containing other, degenerate solutions with a greater degree of uncertainty. Despite being unable to find the second degenerate so-lution within the allotted number of objective function evaluations, the LMA demonstrates a particular utility in mapping potentially problematic regions of the pa-rameter space when compared with the EO, emphasiz-ing a promising synergy when utilizing local and global optimization methods together in identifying useful met-rics for optimizer performance, with the goal of improv-ing the robustness of local and global optimization algo-rithms alike.  

> 5.

CONCLUSIONS We have developed and extensively tested XFit , an X-ray spectral fitting code written in MATLAB, that makes use of the Ferret EO, which is part of the 17 0.2 0.4 0.6 0.8 1       

> 00.2 0.4 0.6 0.8 1
> 1.225 1.670 2.115 2.560 19.961 1.5 22.5 33.5 44.5 5
> 00.2 0.4 0.6 0.8 1
> 1.225 1.671 2.116 2.749 19.983

Figure 7. Parameter space projections of the first and second bremsstrahlung components kT 1 and kT 2, and the width of the Ca He α line for the absorbed thermal model used to fit the spectrum of G41.1–0.3. The data is spatially binned to include only the best-fit χ2 

> r

solution found in each bin and bins of high opacity represent the local minima found across 45297 independent LMA searches. The LMA shows similar trapping behavior when attempting to fit this model as was seen when fitting the five-parameter model of CXOU J232327.9+584842 in Figure 4. In fitting the 29-parameter model, the LMA is corralled down a narrow canyon of solutions shielding Solution 1 ( χ2 

> r

= 1 .238) from large regions of the parameter space and effectively reducing the number of possible paths capable of reaching it. The solid red line traces the path taken by LMA in finding the Solution 2 (χ2 

> r

= 1 .225). 

Figure 8. A Monte Carlo simulated probability distribu-tion sampled from 2 .1 × 10 5 independent LMA runs (total-ing ≈ 2.2 × 10 8 objective function evaluations). The dis-tribution was generated using 10 5 simulations and finds a 

Eoit (χ2 

> r

= 1 .238) = 0 .17 and Eoit (χ2 

> r

= 1 .225) = 1 .44 relative probability for the LMA to converge to degenerate Solutions 1 and 2 respectively given N G41 = 20285430 objective func-tion evaluations (equal to that of the EO). 

Qubist Optimization Toolbox. The Qubist package pro-vides a variety of local optimization tools in addition to the global Ferret EO. These tools allow for auto-mated search and exploration of spectral model param-eter spaces, requiring minimal input from the user to locate best-fit solutions. In this work we analysed a simple, five-parameter ab-sorbed thermal model applied to the CCO in Cassiopeia A (CXOU J232327.9+584842), and a more complicated, 29-parameter Gaussian line model applied to the SNR G41.1–0.3, as representative examples to demonstrate cases of spectral fitting where global optimization meth-ods are needed. Our fully automated and parallel search method illuminates the parameter space structure of the individual fits, providing insight into the efficacy of op-timization techniques used to explore solutions in fitness landscapes. This is made possible by the mapping fea-tures and advanced exploration capabilities of the Ferret Evolutionary Optimizer, which return families of opti-mal solutions that occupy the 1 σ, 2 σ and 3 σ confidence intervals during a run (Figures 5 and 9). This is in con-trast with the local, single-search-agent, gradient-based LMA, that is designed to return a single best-fit solu-tion. XFit s optimal solutions are robust and repeat-able between individual runs of the XFit code. This global approach is extremely valuable for analyzing the behavior of model parameters when fitting data, and is especially useful for the thorough exploration and map-ping of high-dimensional model parameter spaces (Fig-ures 4 and 7). Multiple performance metrics: Eore and 

Eoit are defined, which compare the exploratory effec-tiveness and exploitative efficiency of both optimizers, respectively. Comparisons between the local LMA and global EO methods are found to favour global methods as models increase in number of parameters and search-space hypervolume, due to their strong discrimination of large-χ2 

> r

regions, and their ability to encode complex features in the parameter space, which are shared use-fully among individuals in a population. Novel visual-izations are introduced in Figure 6, and Figures 10, 11, and 12 in the appendix, as a means of making com-parisons between the convergence behaviour of different optimization methods. Although a single LMA search tends to require a smaller number of objective function evaluations than 18         

> Figure 9. The 1 σ, 2 σ, and 3 σconfidence regions automatically mapped by XFit during optimization. The parameter uncer-tainties of Solution 1 (red) occupy a smaller volume in the temperature components kT 1and kT 2relative to Solution 2 (blue), suggesting that solutions associated with a greater degree of uncertainty in their parameters represent larger targets for the optimizer with a higher probability of being found.

the EO to converge to a local minimum, it is unable to consistently find and map solutions when these ap-proaches are compared using the above performance metrics. Our results suggest that in addition to con-sidering the number of objective function evaluations required for updating the search coordinates of an opti-mization, other metrics should also be considered when deciding between local and global approaches for model fitting. We also show that LMA performance is more sensitive to the initial starting point of the search when compared with the EO, as XFit demonstrates more ro-bustness against trapping by local minima. Local op-timization techniques typically require researchers to make progress on a fitting problem by holding certain parameters constant and sequentially performing fits over subspaces of parameter values. Based on our re-sults, it is not clear that such an approach is sufficiently robust for large model parameter spaces, and can in-crease the likelihood of introducing bias into the result-ing best-fit solutions that are used to infer properties associated with astrophysical processes. In such cases, 

XFit reduces the need for human intervention in opti-mization and decreases the risk of introducing bias into the resulting fit parameters. In summary, we present XFit , a new spectral fitting tool that is particularly robust for high-dimensional problems and capable of uncovering solutions that the Levenberg–Marquardt algorithm may miss. We demonstrate and emphasize that XFit is designed as a complimentary approach to the XSPEC software, rather than a replacement, and makes use of XSPEC ’s library of spectral models. This development is especially timely given the surge of high-resolution X-ray spectroscopy data from XRISM and the upcoming NewAthena mis-sion, and future work will explore XFit ’s performance on larger parameter spaces and broader datasets. The authors plan to release a publicly available version of 

XFit in the near future. Researchers interested in using 19 

XFit should contact the primary author. This research is primarily supported by the Natural Sciences and Engineering Research Council of Canada (NSERC) through the Discovery Grants and Canada Research Chairs Programs (S.S.H.). This research made use of NASA’s Astrophysics Data System and the HEASARC database. 

## Software: Qubist (J. D. Fiege 2025), MATLAB ( The MathWorks Inc. 2023), XSPEC (K. A. Arnaud 1996), Plot and compare histograms; pretty by default (L. J. C. 2025), 200 colormap ( Zhaoxu Liu / slandarer 2025) APPENDIX REFERENCES 

Abbott, B. P., Abbott, R., Abbott, T. D., et al. 2017a, PhRvL, 119, 161101, doi: 10.1103/PhysRevLett.119.161101 Abbott, B. P., Abbott, R., Abbott, T. D., et al. 2017b, ApJL, 848, L12, doi: 10.3847/2041-8213/aa91c9 Anders, E., & Grevesse, N. 1989, GeoCoA, 53, 197, doi: 10.1016/0016-7037(89)90286-X Arnaud, K. A. 1996, in Astronomical Society of the Pacific Conference Series, Vol. 101, Astronomical Data Analysis Software and Systems V, ed. G. H. Jacoby & J. Barnes, 17 Balucinska-Church, M., & McCammon, D. 1992, ApJ, 400, 699, doi: 10.1086/172032 Bevington, P. R., & Robinson, D. K. 2003, Data reduction and error analysis for the physical sciences (McGraw-Hill) Braun, C., Safi-Harb, S., Fryer, C. L., & Zhou, P. 2023, MNRAS, 525, 6257, doi: 10.1093/mnras/stad2592 Brickhouse, N. S. 2000, in IAU Joint Discussion, Vol. 24, IAU Joint Discussion, 19 Buchner, J. 2021, The Journal of Open Source Software, 6, 3001, doi: 10.21105/joss.03001 Buchner, J. 2023, Statistics Surveys, 17, 169, doi: 10.1214/23-SS144 Buchner, J., Georgakakis, A., Nandra, K., et al. 2014, A&A, 564, A125, doi: 10.1051/0004-6361/201322971 C., L. J. 2025, Plot and compare histograms; pretty by default, MATLAB Central File Exchange. https://www. mathworks.com/matlabcentral/fileexchange/27388-plot-and-compare-histograms-pretty-by-default Cash, W. 1979, ApJ, 228, 939, doi: 10.1086/156922 Celotti, A., Ghisellini, G., & Chiaberge, M. 2001, MNRAS, 321, L1, doi: 10.1046/j.1365-8711.2001.04160.x Charbonneau, P. 1995, ApJS, 101, 309, doi: 10.1086/192242 De Luca, A. 2017, Journal of Physics: Conference Series, 932, 012006, doi: 10.1088/1742-6596/932/1/012006 Feroz, F., Hobson, M. P., & Bridges, M. 2009, MNRAS, 398, 1601, doi: 10.1111/j.1365-2966.2009.14548.x Fiege, J. D. 2025, (Winnipeg Canada: nQube Technical Computing) Giacconi, R., et al. 1962, PhRvL, 9, 439, doi: 10.1103/PhysRevLett.9.439 Goldberg, D. E. 1989, Genetic algorithms in search, optimization and machine learning (Addison-Wesley Publishing Company, Inc.) Gotthelf, E. V., Halpern, J. P., & Alford, J. 2013, ApJ, 765, 58, doi: 10.1088/0004-637X/765/1/58 Green, D. A. 2004, Mullard Radio Astronomy Observatory, Cavendish Laboratory, Cambridge, United Kingdom (available at ”http://www.mrao.cam.ac.uk/surveys/snrs/”) Hajela, A., Margutti, R., Bright, J. S., et al. 2022, ApJL, 927, L17, doi: 10.3847/2041-8213/ac504a Hell, N., Beiersdorfer, P., Brown, G. V., et al. 2020, X-ray Spectrometry, 49, 218, doi: 10.1002/xrs.3107 Heuer, K., Foster, A. R., & Smith, R. 2021, ApJ, 908, 3, doi: 10.3847/1538-4357/abcaff Heyl, J. S., et al. 2001, The Astrophyscial Journal, 546, 800, doi: 10.1086/318994 Hitomi Collaboration, et al. 2018, PASJ, 70, 12, doi: 10.1093/pasj/psx156 Holland, J. H. 1975, Adaptation in natural and artificial systems. an introductory analysis with applications to biology, control and artificial intelligence (The MIT Press) Kargaltsev, O., & Pavlov, G. G. 2008, in American Institute of Physics Conference Series, Vol. 983, 40 Years of Pulsars: Millisecond Pulsars, Magnetars and More, ed. C. Bassa, Z. Wang, A. Cumming, & V. M. Kaspi (AIP), 171–185, doi: 10.1063/1.2900138 LEVENBERG, K. 1944, Quarterly of Applied Mathematics, 2, 164. http://www.jstor.org/stable/43633451 20 1.225 10 20                   

> 0.2 0.4 0.6 0.8 1
> -3.53 -2.36 -1.18 0.00 log(Frequency) 1.225 10 20
> 0.2 0.4 0.6 0.8 1
> -3.65 -2.44 -1.23 -0.01 log(Frequency) 10 010 110 210 310 4
> 0.2 0.4 0.6 0.8 1
> -3.46 -2.30 -1.15 0.00 log(Frequency) 10 010 110 210 310 4
> 0.2 0.4 0.6 0.8 1
> -3.18 -2.40 -1.63 -0.86 -0.09 log(Frequency)

Figure 10. Parameter space projections for the temperature of the first bremsstrahlung component kT 1. In descending order from the topmost figure: (i) LMA trajectories through the parameter space for each independent optimization attempt as a function of the monotonically decreasing objective function value using the same color-coding as the top Panel of Figure 6. (ii) 

LMA χ2 

> r

density map as a function of parameter value and color-coded identically to that of the middle panel of Figure 6. (iii) 

EO χ2 

> r

density map as a function of parameter value and color-coded identically to that of the bottom panel of Figure 6. (iv) 

Same as (ii) but projected as a function of optimizer step. (v) Same as (iii) but projected as a function of optimizer generation. 21 1.225 10 20 

2345

> -3.53 -2.36 -1.18 0.00 log(Frequency)

1.225 10 20 

2345

> -2.99 -1.55 -0.11 log(Frequency)

10 0 10 1 10 2 10 3 10 4

2345

> -3.38 -2.25 -1.13 0.00 log(Frequency)

10 0 10 1 10 2 10 3 10 4

2345

> -3.18 -2.53 -1.89 -1.25 -0.61 log(Frequency)

Figure 11. Parameter space projections for the temperature of the second bremsstrahlung component kT 2. See Figure 10 for descriptions of each panel. 22 1.225 10 20 

0.2 0.4 0.6 0.8 1

> -3.53 -2.36 -1.18 0.00 log(Frequency)

1.225 10 20 

00.2 0.4 0.6 0.8 1

> -2.95 -1.50 -0.05 log(Frequency)

10 0 10 1 10 2 10 3 10 4

0.2 0.4 0.6 0.8 1

> -3.45 -2.30 -1.15 0.00 log(Frequency)

10 0 10 1 10 2 10 3 10 4

00.2 0.4 0.6 0.8 1

> -3.18 -2.48 -1.78 -1.09 -0.39 log(Frequency)

Figure 12. Parameter space projections for the line width of the seventh Gaussian line component σ7. See Figure 10 for descriptions of each panel. 23 

Martinez, G. D., McKay, J., Farmer, B., et al. 2017, European Physical Journal C, 77, 761, doi: 10.1140/epjc/s10052-017-5274-y Mart´ ınez-Rodr´ ıguez, H., Lopez, L. A., Auchettl, K., et al. 2020, arXiv e-prints, arXiv:2006.08681, doi: 10.48550/arXiv.2006.08681 Morrison, R., & McCammon, D. 1983, ApJ, 270, 119, doi: 10.1086/161102 Mukai, K., Kinkhabwala, A., Peterson, J. R., Kahn, S. M., & Paerels, F. 2003, ApJL, 586, L77, doi: 10.1086/374583 Nynka, M., Ruan, J. J., Haggard, D., & Evans, P. A. 2018, ApJL, 862, L19, doi: 10.3847/2041-8213/aad32d Ozel, P., & Freire, P. 2016, Annual Review of Astronomy and Astrophysics, 54, 401, doi: 10.1146/annurev-astro-081915-023322 PassMark Software. 2025, CPU Benchmarks: AMD Ryzen Threadripper PRO 5995WX,, https://www.cpubenchmark.net/cpu.php?cpu=AMD+ Ryzen+Threadripper+PRO+5995WX Pavlov, G. G., & Luna, G. J. M. 2009, The Astrophysical Journal, 703, 910, doi: 10.1088/0004-637X/703/1/910 Pavlov, G. G., Sanwal, D., Kiziltan, B., & Garmire, G. P. 2001, The Astrophyscial Journal, 559, L131, doi: 10.1086/323975 Pavlov, G. G., Sanwal, D., & Teter, M. A. 2004, Young Neutron Stars and Their Environments, IAU Symposium, 218, 239, doi: 10.48550/arXiv.astro-ph/0311526 Pavlov, G. G., Zavlin, V. E., Aschenbach, B., Tr¨ umper, J., & Sanwal, D. 2000, ApJL, 531, L53, doi: 10.1086/312521 Raga, A. C., Noriega-Crespo, A., & Vel´ azquez, P. F. 2002, ApJL, 576, L149, doi: 10.1086/343760 Ren, J., & Dai, Z. G. 2022, MNRAS, 512, 5572, doi: 10.1093/mnras/stac797 Reynolds, S. P. 2008, ARA&A, 46, 89, doi: 10.1146/annurev.astro.46.060407.145237 Safi-Harb, S., Doerksen, N., Rogers, A., & Fryer, C. L. 2019, JRASC, 113, 7, doi: 10.48550/arXiv.1812.11320 Safi-Harb, S., et al. 2000, ApJ, 545, 922, doi: 10.1086/317823 Safi-Harb, S., et al. 2005, ApJ, 618, 321, doi: 10.1086/425960 Silk, J., & White, S. D. M. 1978, ApJL, 226, L103, doi: 10.1086/182841 Tananbaum, H. 1999, IAUC, 7246, 1 The MathWorks Inc. 2023, MATLAB version: 9.13.0 (R2023b), Natick, Massachusetts, United States: The MathWorks Inc. https://www.mathworks.com Troja, E., van Eerten, H., Zhang, B., et al. 2020, MNRAS, 498, 5643, doi: 10.1093/mnras/staa2626 Weinberg, D. H., Mortonson, M. J., Eisenstein, D. J., et al. 2013, PhR, 530, 87, doi: 10.1016/j.physrep.2013.05.001 Wilms, J., Allen, A., & McCray, R. 2000, ApJ, 542, 914, doi: 10.1086/317016 Yamaguchi, H., Badenes, C., Petre, R., et al. 2014, ApJL, 785, L27, doi: 10.1088/2041-8205/785/2/L27 Zhaoxu Liu / slandarer. 2025, 200 colormap, MATLAB Central File Exchange. https://www.mathworks.com/ matlabcentral/fileexchange/120088-200-colormap