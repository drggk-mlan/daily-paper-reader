# Automatic Stability and Recovery for Neural Network Training
# 神经网络训练的自动稳定性与恢复

**Authors**: Barak Or \
**Date**: 2026-01-24 \
**PDF**: https://arxiv.org/pdf/2601.17483v1 \
**Tags**: <span class="tag-label tag-green">EAA</span> \
**Score**: 6.0 \
**Evidence**: 训练中的自动稳定性与恢复 \
**TLDR**: 一种用于在神经网络训练过程中自动检测并恢复不稳定状态的框架。

---

## 速览
**TLDR**：提出一种自动检测并恢复神经网络训练不稳定性（如发散）的运行时监控框架。 \
**Motivation**：现代神经网络训练容易出现严重的更新不稳定，而现有优化器缺乏在不稳定发生后进行检测和恢复的能力。 \
**Method**：将优化视为受控随机过程，通过验证集探针等次级测量提取创新信号，实现无需修改优化器的自动检测与恢复。 \
**Result**：提供了有界的性能退化与恢复的理论安全保证，且在内存受限环境下具有极低的计算开销。 \
**Conclusion**：该框架为提高大规模模型训练的鲁棒性提供了一种高效且通用的外部监控方案。

---

## Abstract
Training modern neural networks is increasingly fragile, with rare but severe destabilizing updates often causing irreversible divergence or silent performance degradation. Existing optimization methods primarily rely on preventive mechanisms embedded within the optimizer, offering limited ability to detect and recover from instability once it occurs. We introduce a supervisory runtime stability framework that treats optimization as a controlled stochastic process. By isolating an innovation signal derived from secondary measurements, such as validation probes, the framework enables automatic detection and recovery from destabilizing updates without modifying the underlying optimizer. We provide theoretical runtime safety guarantees that formalize bounded degradation and recovery. Our implementation incurs minimal overhead and is compatible with memory-constrained training settings.

## 摘要
现代神经网络的训练日益脆弱，罕见但严重的失稳更新往往会导致不可逆的发散或隐蔽的性能下降。现有的优化方法主要依赖于嵌入在优化器内部的预防机制，在不稳定发生后检测和恢复的能力有限。我们引入了一种监督式运行时稳定性框架，将优化视为一个受控的随机过程。通过隔离源自二次测量（如验证探针）的创新信号，该框架能够在不修改底层优化器的情况下，实现对失稳更新的自动检测与恢复。我们提供了理论上的运行时安全保证，对有界退化和恢复进行了形式化说明。我们的实现产生的开销极小，并且兼容内存受限的训练环境。