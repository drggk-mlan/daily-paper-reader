Title: Evolving Interdependent Operators with Large Language Models for Multi-Objective Combinatorial Optimization

URL Source: https://arxiv.org/pdf/2601.17899v1

Published Time: Tue, 27 Jan 2026 02:04:12 GMT

Number of Pages: 28

Markdown Content:
# Evolving Interdependent Operators with Large Language Models for Multi-Objective Combinatorial Optimization 

## Junhao Qiu 1, Xin Chen 1, Liang Ge 2, Liyong Lin *2 , Zhichao Lu 1, Qingfu Zhang † 1  

> 1

Department of Computer Science, City University of Hong Kong  

> 2

Contemporary Amperex Technology Limited junhaoqiu2-c@my.cityu.edu.hk, llin5@e.ntu.edu.sg, qingfu.zhang@cityu.edu.hk 

Abstract 

Neighborhood search operators are critical to the performance of Multi-Objective Evolutionary Algorithms (MOEAs) and rely heavily on expert design. Although recent LLM-based Automated Heuristic Design (AHD) methods have made no-table progress, they primarily optimize individual heuristics or components independently, lacking explicit exploration and exploitation of dynamic coupling relationships between multiple operators. In this paper, multi-operator optimization in MOEAs is formulated as a Markov decision process, en-abling the improvement of interdependent operators through sequential decision-making. To address this, we propose the 

Evolution of Operator Combination ( E2OC ) framework for MOEAs, which achieves the co-evolution of design strate-gies and executable codes . E2OC employs Monte Carlo Tree Search to progressively search combinations of operator de-sign strategies and adopts an operator rotation mechanism to identify effective operator configurations while supporting the integration of mainstream AHD methods as the underlying designer. Experimental results across AHD tasks with varying objectives and problem scales show that E2OC consistently outperforms state-of-the-art AHD and other multi-heuristic co-design frameworks, demonstrating strong generalization and sustained optimization capability. 

## 1 Introduction 

Multiobjective combinatorial optimization problems (MCOPs) are widely encountered in fields such as production scheduling (Neufeld, Schulz, and Buscher 2023; Li et al. 2024a), engineering design (Peng et al. 2023), and hyper-parameter tuning in machine learning (Morales-Hern ´andez, Van Nieuwenhuyse, and Rojas Gonzalez 2023). For these NP-hard problems, obtaining the entire Pareto set/frontier using exact algorithms (e.g., dynamic programming) is more challenging (Wang et al. 2023). Heuristic-based approximation approaches include multi-objective evo-lutionary algorithms (e.g., NSGA-II (Deb et al. 2002), NSGA-III (Deb and Jain 2014), MOEA/D (Qingfu Zhang and Hui Li 2007)), Pareto local search methods (e.g., PLS (Paquete, Chiarandini, and St ¨utzle 2004a), 2PPLS (Lust and Teghem 2010a), PPLS/D-C (Shi et al. 2022)), and methods combining evolutionary algorithms and local 

> *

Corresponding author. 

> †

Corresponding author. 

search (Paquete, Chiarandini, and St ¨utzle 2004b; Kumar and Singh 2007; Jaszkiewicz and Zielniewicz 2009). However, the effectiveness of multiobjective metaheuristics hinges on the choice and interplay of domain-specific search operators. Different application domains often require different algorithms and/or configurations. Manually designing and tuning these operators is expensive and heavily reliant on expert knowledge. Automated heuristic design (AHD) is a promising research direction for addressing this problem (Burke et al. 2013; St ¨utzle and L ´opez-Ib ´a ˜nez 2019). Genetic Programming (GP), one of the earliest techniques for automatic heuristic discov-ery (Langdon and Poli 2013; Zhang et al. 2023), evolves al-gorithms via simulated natural selection. However, GP relies on a set of permissible primitives or mutation operations, con-structing a domain-agnostic set remains fundamentally diffi-cult across diverse multiobjective metaheuristics and problem settings (Pillay and Qu 2018; O’Neill et al. 2010). The AHD integrated with the code generation and lan-guage comprehension capability of the Large Language Mod-els (LLMs) has introduced a new search paradigm in recent years (Liu et al. 2026; Wu et al. 2024). LLMs are employed as a heuristic designer in certain iterative frameworks (Zhang et al. 2024a), such as evolutionary search (Liu et al. 2024; Ye et al. 2024; van Stein and B ¨ack 2024; Yao et al. 2025), neighborhood search (Xie et al. 2025), and Monte Carlo Tree Search (MCTS) (Zheng et al. 2025a; Kiet et al. 2025) These methods represent a shift from traditional approaches, lever-aging LLMs’ reasoning abilities to synthesize algorithmic ideas and adapt them to problem-specific tasks. While these methods have achieved significant progress in evolving sin-gle operators and strategies, they focus primarily on evolving isolated components rather than multi-operator systems. In complex MCOPs, effective optimization requires com-bining operators with complementary search biases. The over-all performance of MOEAs therefore depends on how well these operators complement and interact with one another to balance exploration and exploitation throughout the optimiza-tion process. However, both expert-designed and LLM-driven approaches, particularly traditional single-operator evolution methods, remain limited in systematically reasoning operator interactions and sequencing effects. Consequently, establish-ing a co-evolutionary mechanism for operators is essential to enhance the performance and adaptability of MOEAs in        

> arXiv:2601.17899v1 [cs.NE] 25 Jan 2026 (a) Manual Design (b) LLM -based Heuristic Design
> Designer
> Code Slover
> obj1
> obj2
> LLM
> Ideas/
> Thoughts
> Codes Slover
> obj1
> obj2
> ...
> ...
> obj1
> obj2
> obj1
> obj2
> Slover
> LLM
> Codes
> Integrate
> Operators C o-design
> (c) LLM -based Multi -Operator Co -desi gn
> Ideas/Thoughts
> Ideas/
> Thoughts
> coupling
> design strategy

Figure 1: The design of single operators in MOEAs has evolved from reliance on (a) expert knowledge to (b) LLM-based iterative refinement of algorithmic ideas and code (e.g., EoH, MCTS AHD). In contrast, (c) E2OC accounts for cou-pling among multiple operators and enables the co-evolution of design strategies and codes .complex multi-objective optimization. To bridge the gap in the co-evolution of different operators and thoughts in MOEAs, we propose a new algorithm de-sign paradigm, dubbed Evolution of Operator Combination (E2OC ). This approach models operator interdependencies and synergies at the design strategy level to guide the evo-lution of operator combinations. A design strategy com-prises high-level design thoughts, which are actionable and algorithm-aware suggestions aimed at improving existing operators, rather than merely representing the semantic ideas of the operators (Liu et al. 2024). By systematically explor-ing combinations of these thoughts, the search for effec-tive operator combinations is guided toward promising di-rections. We demonstrate that LLM-assisted co-evolution of design thoughts and operator code, guided by carefully crafted prompts, achieves state-of-the-art multi-operator de-sign. We expect E2OC to provide a significant advancement in the automated design of complex algorithms. In summary, our contributions are as follows: • We propose E2OC, a new algorithm design paradigm that supports the LLM-based co-evolution of design strategies 

and codes , achieving automated design of multi-operators in MOEAs with significantly minimum hand-craft. • We develop a progressive design strategy search mech-anism that explores combinations of decoupled design thoughts and the couplings between operators to guide evolutionary directions. • We implement operator rotation evolution to systemati-cally explore design strategies and identify optimal oper-ator combinations, while supporting flexible evaluation with diverse state-of-the-art AHD methods. • We comprehensively evaluate E2OC on benchmarks of two widely studied MCOPs. The results demonstrate that E2OC outperforms many existing AHD methods, such as EOH and MCTS AHD. In two- or three-objective prob-lems, E2OC brings significant enhancements in manually designed MOEAs. In particular, E2OC leverages the evo-lution of design strategies to achieve sustained enhance-ments under continued resource investment. 

## 2 Problem Formulation 

2.1 Multi-Operator Optimization in MOEAs 

Multi-Objective Optimization. The objective of multi-objective optimization is to identify a set of solutions that balance multiple, often conflicting, objectives. A general formulation is given by: 

min  

> x∈X

f (x) = ( f1(x), f 2(x), . . . , f M (x)) , (1) where X denotes the feasible solution space, x is a decision vector, and f : X → RM represents an objective function vector with M objectives. 

Pareto Dominance. Given two solutions xa, xb ∈ X ,

xa is said to dominate xb (denoted xa ≺ xb) if and only if 

fi(xa) ≤ fi(xb), ∀i ∈ { 1, 2, . . . , M }, and fj (xa) < f j (xb)

for at least one j.

Pareto Optimality: A solution x∗ ∈ X is Pareto-optimal if there is no x′ ∈ X such that x′ ≺ x∗. In other words, no feasible solution exists that can improve one objective without degrading another. 

Pareto Set and Pareto Front: The collection of all Pareto-optimal solutions in the decision space forms the Pareto set, and its corresponding projection in the objective space con-stitutes the Pareto Front (PF). The effectiveness of a multi-objective optimization algo-rithm is typically evaluated based on two aspects: the conver-gence of solutions toward the PF and the diversity of their distribution along it. 

Multi-Operator Solver. The performance of MOEAs de-pends on the operators or search strategies employed, in-cluding their actions and parameter settings. We define a solver S(d | O) parameterized by a set of K operators 

O = ( O1, O 2, . . . , O K ), which generates candidate solu-tions x ∈ X for a problem instance d:

f (x) = f (S(d | O)) ≈ f (x∗). (2) Each operator Oi, i ∈ 1, ..., K is instantiated through an algorithm generator G(· | pi) guided by a prompt pi. Prompts are generated by a prompt generator P(· | Oi), and all opera-tor prompts form the vector p = ( p1, p 2, . . . , p K ). Operators act on specific decision subspaces and perform search opera-tions (e.g., crossover, mutation) to optimize solutions. To reduce stochastic variance, multiple independent evalu-ations are conducted. Given N evaluations on instance d, the objective vectors for operator combination O are: 

f n(d | O) = ( f1(Sn(d | O)) , . . . , f M (Sn(d | O))) , (3) and the averaged performance is: 

F N (d | O) = 1

N

> N

X

> n=1

f n(d | O), (4) where F N (d | O) can represent a vector of averaged multi-objective outcomes. 

Operator Combination Optimization. In the multi-operator optimization framework, each operator Oi within the combination can be iteratively refined through evolution-ary updates to enhance the solver’s overall performance. To obtain a scalar performance value from a multi-objective eval-uation, a scalarization function Φ : RM → R is introduced. This function maps the multi-objective performance vector into a single-valued score, where Φ( ·) can represent metrics such as the Hypervolume (HV) (Zitzler and Thiele 1999), the Inverted Generational Distance (IGD) (Coello and Cort ´es 2005)), or other monotonic scalarizing indicators. The scalar-ized performance of an operator combination O is defined as: 

FN (d | O) = Φ  F N (S(d | O))  , (5) where F N (S(d | O)) ∈ RM denotes the averaged multi-objective performance obtained from N evaluations under the solver S parameterized by O, and Φ( ·) transforms it into a scalar performance score. Assuming multiple optimization instances d ∈ D , the overall optimization objective is formu-lated as: 

O∗ ∈ arg max  

> O∈G (·|P (·))

Ed∼D 

FN (d | O) , (6) subject to a total computational budget T (e.g., total solver runs or evaluation time). This formulation treats the evolution of operator combinations as a higher-level optimization over search strategies in MOEAs, where operators collaboratively contribute to a shared objective and exhibit strong coupling effects in guiding the global search process. 

2.2 Markov Decision Process 

The LLM-based multi-operator evolution process is inher-ently dynamic rather than a static multi-variable optimization problem, as it involves evolving interdependent operators with changing algorithmic distributions. This process can be formulated as a Markov Decision Process (MDP), rep-resented by the tuple (S, A, P, R ), where the optimization proceeds iteratively over time steps t ∈ T .

State Space. At iteration t, the state st ∈ S represents the current operator combination and its associated prompt information, defined as: 

st = ( O1,t , O 2,t , . . . , O K,t | Pt) , (7) where Oi,t denotes the i-th operator at step t, and Pt =(p1,t , p 2,t , . . . , p K,t ) represents the corresponding prompt set, with pi,t being the prompt template used for the generation of Oi,t .

Action Space. During the operator combination evolution, each action determines which operator i should be evolved and whether its corresponding prompt should be regenerated. Let wi ∈ { 0, 1} denote the binary decision to rewrite the prompt pi. Thus, each action at = ( i, w i) specifies both the target operator and its prompt update. Changing a prompt directly affects the generation distribution of the LLM-based algorithm constructor Gi(· | pi,t ).

Reward Function. The reward function guides the evo-lution of the operator combination toward the optimization objective. Based on scalarized evaluation, the reward im-provement at step t + 1 is defined as: 

R(st, a t, s t+1 ) = FN (d | O′) − F N (d | O), (8) where O and O′ represent the operator combinations before and after applying action at, respectively. A positive reward indicates an improvement in the scalarized performance met-ric, guiding the evolutionary search toward more effective operator configurations. Given a total computational budget T , the overall opti-mization objective is to maximize the expected cumulative reward: 

max  

> O∈G (·|P (·))

Ed∼D 

"T −1X

> t=0

R(st, a t, s t+1 )

#

, a t ∼ π(· | st),

(9) where π(at | st) denotes the decision policy over actions (e.g., operator selection and prompt rewriting), and O de-notes the operator set and their corresponding prompts to be evolved by the prompt generator G(· | P (·)) . The expectation is taken over problem instances d ∈ D and the stochasticity introduced by the solver S, the generator G, and the evalua-tion process. This formulation captures the adaptive evolu-tion of operator and prompt configurations within the given computational budget T , aiming to maximize the cumulative improvement in scalarized multi-objective performance. 

Transition Probability. Given a state st and an action at

at decision step t, the generator Gi(· | pi,t ) samples q oper-ator codes {ci, 1, c i, 2, . . . , c i,q }. Fixing all other operators, q

new combinations {s′

> 1

, s ′

> 2

, . . . , s ′ 

> q

} are evaluated. The next state st+1 is selected according to the transition probability 

P (st+1 | st, a t), which depends on the performance of the sampled combinations. 

## 3 Methodology 

3.1 Overall Framework of E2OC 

E2OC designs multi-operators in MOEAs automatically us-ing LLM to co-evolve operators combinations and design strategies. The overall framework is shown in Figure 2, in-cluding four core components: 1) warm-start: the algorithm generator G(· | P0) is employed to generate candidate oper-ator code set OS with a prompt containing code templates. Then the operators are analyzed and summarized with the prompt generator P(·) to design multi-level design strategies 

P S . 2) Language space of design strategies: The multi-level design thoughts extracted from elite operators constitute a language space of operator design strategies with complex Problem Solver Template     

> Independent Operator Search
> Defining Design Tasks
> Prompt AI-S AI-S AI-S
> Algorithm
> Generator
> Sequential
> design Operator
> Set
> ...
> Analysis and Thought Design
> Prompt
> Generator
> Rewrite
> templates
> ... ...
> ...
> ...
> ...
> ...
> Selection &
> Analysis
> Language Space of Multi -Operator
> design strategies

Multi -Operator Design Strategies Progressive Search    

> Selection Expansion Simulation Backpropagation
> Update value
> Selected node
> Expanded node

Multi -Operator Design and Evaluation           

> Set Thought Thought
> A) Determine
> operator to be
> designed AI-S AI-S AI-S
> Thoughts
> ... ...
> ...
> B) Search individual
> operator
> Codes
> Optimization
> Multi -Operator
> Rotation Design
> and Evolution
> Operator Combination
> Optimal
> C) Update Operator
> Combination
> Others remain
> unchanged
> scores Thoughts set :∈:∈:∈:∈∙
> P1
> P2
> P3
> P4
> i
> Coupling AI-A AI-A AI-A

Figure 2: The framework of E2OC. Left: In the warm-start process, independently design operator sets and analyze improvement suggestions for different operators. Center: The language space of multi-operator strategies is complex. Prompts generated by differing design strategies among operators exhibit intricate coupling relationships. Right: Leverage branch selection and expansion in MCTS to explore advantageous combinations of operator design thoughts and strengthen dominant paths by operator rotation evolution. coupling associations between levels and different levels. 3) Progressive search for design strategies: Different combi-nations of design thoughts in the language space are explored and evaluated by MCTS to locate the best potential strategies. 

4) Multi-Operator Design and Evaluator: The design of different operators based on operator rotation, solving the problem instance set D with a replacement-by-replacement multi-operator solver of MOEAs with varying operators, cal-culating multi-objective performance and returning scale-quantized scores. Given the MOP description, the initial code and prompt of operators, E2OC first carries out independent warm-start evo-lution for each operator to form the set of candidate operators and elite profiles (see Section 3.2). Subsequently, knowledge extraction is performed on the elites to construct multi-level design knowledge. On this basis, E2OC treats the selection of design thoughts combination as a strategy search problem in a language-based design space (see Section 3.3 ), and employs MCTS-based progressive strategy search to iteratively select, evaluate, and update within the space of codes and strategies, oriented to maximize the desired improvement for a given computational budget T (see Section 3.4). To reduce the vari-ance from coupling and expensive multi-objective computa-tion, the framework supports operator rotational evaluation with fast feedback (see Section 3.5). 

3.2 Warm-Start Initialization of Multi-Operator Sets 

Different operators (e.g., crossover, mutation, selection, local search, etc.) in MOEAs have their own independent coding domains and neighborhood structures, and their effective de-signs are often characterized as multi-source, diverse and weakly separable. For this reason, E2OC performs indepen-dent evolution and knowledge extraction for each operator 

i ∈ { 1, ..., L max } during the warm-start stage (see Algo-rithm 1): • Step1: For different operator i, the candidate code sets are generated by the algorithm generator Gi(· | pi) based on initial templates Oi and prompts pi. And the operators are checked for validity to remove illegal and invalid operators. • Step2: A fast evaluation is performed on the instance set D using the multi-operator solver S(·) to compute the performance of the candidate operators OS by multi-objective evaluator Eva (·). After obtaining FN , sort the scores f it and maintain the corresponding elite profiles. • Step3: The elite operators are analyzed for dominance by the prompt generator P(·) and are used as code tem-plates for new prompts in initialize prompt storage P S ,with suggestions and limitations for subsequent operator improvements indicated. Through the above independent evolution, E2OC estab-lishes an interpretable a prior knowledge surface and a robust code family for each operator, providing reusable components and knowledge support for subsequent combinatorial-level strategy search and coupled modeling. 

3.3 Language Space of Multi-level Thoughts 

The complex coupling relationships between design thoughts of different operators constitute a high-dimensional and non-linear language space. Each design thought represents a spe-Algorithm 1: warm-start for design knowledge extraction.  

> 1:

Input: Initial operator combination O1 and prompt set 

P1 at iteration step t = 1 ; Instance set D; Number of initial added prompt AP ; Candidate operator storage 

OS ; Number of operators to be evolved Lmax . 

> 2:

Output: Initial operator design prompt set P S . 

> 3:

Initialize evaluator of multi-objective optimization Eva ; 

> 4:

for i = 1 , . . . , L max do  

> 5:

pi ← Pi, 1; 

> 6:

Initialize operator generator Gi(· | pi) of Oi; 

> 7:

for j = 1 , . . . , ON max do  

> 8:

Oi,j ← G i(· | pi); 

> 9:

O′ 

> 1

←Update the operator i in O1 with Oi,j ; 

> 10:

f it i,j ← Eva (D|O′

> 1

); 

> 11:

OS i,j ← (Oi,j , f it i,j ); 

> 12:

end for  

> 13:

end for  

> 14:

dOS ← Sort by f it i,j and filter invalid operators in OS ; 

> 15:

Initialize prompt storage P S ; 

> 16:

for i = 1 , . . . , L max do  

> 17:

ON i ←select the smaller of AP and the size of dOS i; 

> 18:

P S i, 1 ← Pi, 1; 

> 19:

for g = 1 , . . . , ON i − 1 do  

> 20:

Oi,g +1 ← dOS i,g ; 

> 21:

Initialize the prompt generator P(· | Oi,g +1 ) of Oi; 

> 22:

P S i,g +1 ← P (· | Oi,g +1 ); 

> 23:

end for  

> 24:

end for 

cific class of operation logic or decision paradigm of an operator, and the interactions among operators determine the overall optimization performance. The interactions between different thoughts may lead to complementary, conflicting, or dependent effects, which affect the performance of the final combination of operators. To model and mine the coupling relationships, E2OC intro-duces a progressive search mechanism for systematic selec-tion and evaluation in the language space of design strategies via MCTS. By continuously updating and adjusting the de-sign combination, E2OC is capable for finding the optimal design strategy in the complex space to maximize the perfor-mance of multi-objective optimization. 

3.4 Progressive Design Strategy Search 

The progressive design strategy search mechanism based on MCTS is to gradually mine the synergistic paths among operators in the multi-level design thought space. During the search process, the design strategies of the operators are regarded as nodes in a tree structure, where each node rep-resents a specific design state and the edges of the tree indi-cate potential relationships between different design thoughts. Specifically, the state of node j contains the score, visit count. Its parent node is p, then the score is computed based on Upper Confidence Bound (UCB) as follows: Algorithm 2: Progressive Search for Design strategies. 

Input: Max number of outer iterations Nouter ; Number of operators to be evolved Lmax ; Operator design prompt set P S ; Storage of operator combination SO .

Output: Top scoring operator combination Obest and prompt combination Pbest .

N0 ← root node (empty state); 

for j = 1 , . . . , N outer do 

# Selection 

Nj ← N 0;

while Nj has child node do 

N S ← get the child node set of Nj ;

Nj ← select the node of highest UCB score in N S ;

end while 

# Expansion 

i ← the size of state in Nj ;

sta j ← get the state of Nj ;

if i<L max then for pg ∈ P S i do 

sta g ← sta j + [ pg ];Add a new child node N ′ of Nj with state sta g ;

end for end if 

# Simulation 

while i<L max do 

pi ← random sampling a prompt in P S i;

sta j ← sta j + [ pi];update the new state sta j of Nj ;

end while 

Pj ← get the prompt set of sta j ;

(SO j , f it j ) ← get the operator combination and score of Nj by OperatorRotationEvaluation (Pj );

# Backpropagation 

Np ← N j ;

while If the node Np exists do 

sco j ← sco j + f it j ; # Default node score is 0. 

vs j ← vs j + 1 ; # Default visit count is 0. 

Np ← get the parent node of Nj ;

end while end for 

Obest ← get the highest score combination in SO ;

Pbest ← get the state of the highest scoring node; 

U CB j = sco j

vs j

+ c

s

ln (vs p + 1) 

vs j

(10) where c is an adjustable parameter with a default value of √2.Through an iterative process of selection, expansion, simu-lation, and backpropagation, it progressively explores differ-ent combinations of designs in a tree structure and updates the search strategy based on its performance feedback. The pro-cedure is described in Algorithm 2. In each round of external iterations, it performs the following steps: 

Selection. Starting from the root node, the child node with the highest UCB score in the current state is recursively selected, and the potential combinations of design thoughts are progressively explored in depth along the search path. 

Expansion. When the current node has not yet reached the maximum number of operators Lmax , new child nodes are generated and expanded from all feasible prompts P S in the current design state. This process generates new design paths by adding new operator design thoughts. 

Simulation. Multi-objective evaluation is performed on nodes whose state reaches the length Lmax . If not reached , new design prompts are randomly sampled and the current design state is updated. Through this phase, the algorithm is able to explore unrevealed design combinations and evaluate their potential optimization. 

Backpropagation. After completing the simulation, the information of the parent node is updated by calculating the design strategy score f it j for the current node. The score accumulation reflects the superiority of each design path in the search process, thus guiding the search towards a better evolution. After each external iteration, MCTS selects the highest-scoring operator combination Obest and hint set Pbest as the current optimal solution based on the feedback score infor-mation. Through the evolution of multiple iterations, E2OC finds operator combinations with high efficiency and diversity in the design language space through progressive search to support the final multi-objective optimization. This progres-sive refinement of the design strategy not only accelerates the optimization process of operator combinations, but also effectively avoids missing potentially superior solutions due to premature convergence. 

3.5 Operator Rotation Evolution 

To evaluate for operator design strategies, a co-design and evolution strategy based on operator rotation is proposed, which utilizes LLM for deep mutation and reconstruction of design thoughts and operators. A multi-objective evolution-ary solver with rolling updates of multiple operators is used to quickly evaluate the design potential of different combi-nations of thoughts, thus achieving continuous optimization and co-evolution of operators. Operator rotation is used to gradually replace the operators in the operator combination and evaluate their performance so as to continuously improve the optimization of the whole design strategy. In each round of iteration, new operators are generated using LLM by updating the design prompt for each operator and evaluated in combination with multi-objective optimization (see Algorithm 3 for details). First, the multi-objective evaluator Eva is initialized to evaluate the performance of the initial operator combination 

O1 on the set of instances D to obtain the initial fitness value 

f it .Operator rotation and updating: in each inner iteration, for operator Oi, obtain its design hint pi from the hint set P, and generate a set of candidate operators OS i based on it. Then, the operator O′ 

> i

with the highest fitness is selected to replace the original operator and update the whole operator combination O′.Performance evaluation: the updated operator combination 

O′ is evaluated by multi-objective optimization to get the Algorithm 3: Operator rotation evaluation mechanism. 

Input: Max number of middle iterations Nmiddle ; Num-ber of operators to be evolved Lmax ; Operator design prompt set P ; Instance set D; Initial operator combina-tion O1.

Output: The (BO , f it ) of the highest fitness. Initialize evaluator of multi-objective optimization Eva ;

f it ← Eva (D|O1);

BO ← O1;

for k = 1 , . . . , N middle do for i = 1 , . . . , L max do 

pi ← get the prompt of operator i in P ;

OS i ← generate operators set by Gi(· | pi);

O′ 

> i

← get the highest fitness operator in OS i;

O′ ← update i-operator with O′

> i

;

f it ′ ← Eva (D|O′);

if f it ′ ≥ f it then 

f it ← f it ′;

BO ← O′;

end if end for end for 

new fitness value f it ′. If the fitness of the new combination 

f it ′ is higher than the original fit, then update the optimal operator combination BO and fitness value. Iterative design: through multiple rounds of inner iteration and operator rotation, operator combinations are progres-sively optimized to finally obtain the operator combination 

BO with the highest fitness and its corresponding design prompts. The advantage of this mechanism is the flexibility to ex-plore and optimize the design strategies of different operators through operator rotation without completely changing the whole operator combination, which in turn continuously im-proves the performance of multi-objective optimization. By combining with MCTS search, E2OC maintains an efficient exploration capability during operator design and evolution, and achieves the convergence of optimal solutions by dynamically adjusting the operator combination. This co-design and evolution method based on operator rotation not only accelerates the multi-operator optimization process, but also effectively improves the adaptability and robustness of the algorithm. 

## 4 Experiments 

4.1 Experimental Setting 

Problems. We evaluate the proposed E2OC on two clas-sical problems, which are studied in automated algorithm design and multi-objective optimization, namely multi-objective flexible job shop scheduling problem (FJSP) (Dauz `ere-P ´er `es et al. 2024) and traveling salesman problem (TSP) (Lust and Teghem 2010b). Specifically, we solve the bi-objective FJSP, the tri-objective FJSP, the bi-objective TSP, and the tri-objective TSP. In FJSP, the well-known Brandi-marte benchmarks are selected (Brandimarte 1993), in which we consider the minimization of three conflicting objectives of wide interest: makespan, total machine load, and max ma-chine load. It includes 15 instances of different sizes and characteristics, with mk15 being one of the most complex instances, containing more processing qualification require-ments. In addition, the M -objective TSP consists of M two-dimensional sets of k node coordinates, where the m-th ob-jective value is computed from the m-th two-dimensional coordinate corresponding to the solution (Chen et al. 2023). Three different problem sizes are considered, with k tak-ing values of 20/50/100, respectively, minimizing multiple objective representations. 

Hyperparameters. E2OC is designed offline (similar to offline training) to obtain high-quality multi-operator combi-nations before online evaluation. In the offline design phase, the deepseek-chat model is selected based on quality-cost performance, and all model temperature values default to 1. The proposed E2OC can be divided into four components: the outer MCTS, the middle operator rotation and the inner algorithm generator and evaluator, with hyperparameter set-tings specifically shown in Table 7. The offline evaluators are used to rapidly assess newly designed operators and are configured with half of the computational budget used in on-line evaluations. Specifically, for the FJSP, the offline setting uses 15 iterations and a population size of 100, while for the TSP it uses 100 iterations and a population size of 100. Both problems are evaluated three times in the offline stage. The online evaluation settings follow established practices in prior studies. For the FJSP, 30 iterations and a population size of 200 are used. For the TSP, 200 iterations and a population size of 200 are adopted, with five independent runs conducted for each configuration. The mean performance over all runs is reported as the final performance of each multi-objective algorithm. 

Baselines. We select two types of state-of-the-art meth-ods for comparison with E2OC. (1) MOEAs include: a) the dominance-relation-based NSGA-II (Deb et al. 2002) and NSGA-III (Deb and Jain 2014) which represent one of the mainstream solution strategies for MOFJSP, b) the decomposition-based MOEA/D (Qingfu Zhang and Hui Li 2007), and c) the Pareto-neighborhood-search-based PPLS/D-C . These methods employ commonly used crossover, mutation, and neighborhood search operators, as described in Appendix C.2 and D.2. (2) The baseline for single-algorithm design includes recently popular methods such as Random (Zhang et al. 2024b), FunSearch (Romera-Paredes et al. 2024), EoH (Liu et al. 2024), ReEvo (Ye et al. 2024) and MCTS-AHD (Zheng et al. 2025b). These methods complete the design tasks of multiple operators in MOEAs in the same order. (3) Different multi-algorithm collaborative de-sign frameworks, such as those based on coordinate-descent (CD ), upper-confidence-bound( UCB ), LLM , MCTS and their variants, are described in detail in Appendix G.1. All methods such as independent design and co-design are configured to use the same LLM sampling budget. All experiments are conducted on an Intel Core i7-12700F CPU and the code is implemented in Python 3.8 or above with Numpy 1.24.3. 

Experience design. The primary capability of E2OC is the collaborative design of multiple operators within multi-objective algorithms, which reduces manual design effort and enhances algorithmic performance. The key research questions are as follows: (1) Can automatically designed operator combinations outperform expert-designed counter-parts? (2) Can high efficiency be maintained across addi-tional objectives and diverse problem instances? (3) Does E2OC exhibit superior performance compared to advanced methods that evolve operators independently? (4) Is E2OC more efficient than alternative multi-operator design strate-gies? (5) Does the approach possess potential for continuous optimization? (6) Are all constituent modules of E2OC ef-fective? To rigorously address these questions, the following experiments are designed: (1) comparison with state-of-the-art multi-objective evolutionary algorithms on bi-objective and tri-objective FJSP and TSP; (2) comparison with recent single-heuristic automatic design methods; (3) evaluation against different multi-operator design strategies; (4) assess-ment of the optimization continuity of E2OC over multiple iterations; (5) analysis of performance and computational cost under varying LLMs and key parameter AP; (6) ablation studies. Furthermore, to examine the influence of operator combinations on MOEAs, the effects of different combina-tions and sequences of classical operators on MOEA perfor-mance are analyzed on TSP. Additional experimental details are provided in the Appendix. 

Metrics. To evaluate the performance of MOEAs incorpo-rating different operators, hypervolume (HV) and inverted generational distance (IGD) are selected as the primary met-rics. Higher HV and lower IGD values indicate superior over-all convergence and diversity performance. Experimental results report the mean values obtained over multiple evalua-tions as the performance measure. Additionally, when assess-ing the performance of automatic design methods, metrics such as code accuracy, computational cost, and quality-cost are considered. The best values for each metric are high-lighted in bold for emphasis. 

4.2 Main results 

Comparison with expert design In several representa-tive MOEAs, including NSGA-II, NSGA-III, MOEA/D, and PPLS/D, the E2OC-generated operator combinations are compared with expert-designed combinations on bi-objective and tri-objective FJSP and TSP instances. The detailed oper-ator combination settings for each problem are provided in Appendix C.2 and D.2, and their effectiveness has been vali-dated in prior studies. The benchmark instances are divided into training, testing, and complete sets. All algorithms are independently executed five times, and the average HV, IGD, and RI of HV over the baseline are reported in Table 1. 

Bi-objective FJSP & TSP. In bi-objective optimization, the operator combinations generated by E2OC consistently outperform the benchmark operators designed by experts. The NSGA-II with expert-designed operators achieves the best initial performance on both problems, and after E2OC improvements, the performance increases by 32.43% and 14%, respectively. In all other algorithms, E2OC also brings at least a 10% performance improvement, indicating that the improved operator combinations effectively enhance the performance of the original MOEAs, covering a larger region of high-quality solutions in the objective space. 

Tri-objective FJSP & TSP. In the more challenging tri-objective problems, the performance improvement brought by E2OC is slightly smaller, but it remains significant. It is worth noting that in the tri-objective scenario, all methods have the same evaluation budget of operator combinations. In the Tri-FJSP NSGA-II operator combination design task, the performance improves by 18.84%. This fully validates the effectiveness of E2OC in surpassing traditional human-designed paradigms. More importantly, E2OC achieves the highest average performance improvement across all test in-stances, strongly demonstrating that the learned strategies have powerful generalization and robustness, rather than over-fitting to the training instance.                                                                                                                                                                                                                                                                         

> Bi-FJSP All instaces Train instace Test instaces RI ↑
> Method HV ↑IGD ↓HV ↑IGD ↓HV ↑IGD ↓
> Expert  NSGA-II 0.1996 2.8126 0.1515 2.3746 0.2030 2.8439 -NSGA-III 0.1927 3.0851 0.1470 2.4620 0.1959 3.1296 -MOEA/D 0.1853 3.3879 0.1853 3.3879 0.1879 3.4620 -PPLS/D 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 -E2OC  NSGA-II 0.2435 1.3129 0.2435 1.3129 0.2467 1.3400 32.43% NSGA-III 0.2182 2.1470 0.2182 2.1470 0.2217 2.1554 22.89% MOEA/D 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 10.00% PPLS/D 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.00%
> Bi-TSP Bi-TSP20 Bi-TSP50 Bi-TSP100 RI ↑
> Method HV ↑IGD ↓HV ↑IGD ↓HV ↑IGD ↓
> Expert  NSGA-II 0.5597 0.1200 0.3484 0.1526 0.2561 0.2487 -NSGA-III 0.5444 0.1427 0.3244 0.1889 0.2281 0.3300 -MOEA/D 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 -PPLS/D 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 -E2OC  NSGA-II 0.6100 0.0679 0.4281 0.2471 0.2890 0.3863 14.00% NSGA-III 0.5993 0.0922 0.3854 0.3168 0.2526 0.4996 12.81% MOEA/D 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 10.89% PPLS/D 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.00%
> Tri-FJSP All instaces Train instace Test instaces RI ↑
> Method HV ↑IGD ↓HV ↑IGD ↓HV ↑IGD ↓
> Expert  NSGA-II 0.1266 1.8398 0.0960 0.9831 0.1287 1.9010 -NSGA-III 0.1200 2.1074 0.0928 1.0744 0.1220 2.1812 -MOEA/D 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 -PPLS/D 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 -E2OC  NSGA-II 0.1485 1.1619 0.1183 0.6368 0.1507 1.1994 18.84% NSGA-III 0.1407 1.4379 0.1111 0.7956 0.1428 1.4838 17.87% MOEA/D 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 10.89% PPLS/D 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.00%
> Tri-TSP Bi-TSP20 Bi-TSP50 Bi-TSP100 RI ↑
> Method HV ↑IGD ↓HV ↑IGD ↓HV ↑IGD ↓
> Expert  NSGA-II 0.3561 0.1480 0.1215 0.1594 0.0542 0.2158 -NSGA-III 0.3561 0.2336 0.1215 0.2028 0.0542 0.2390 -MOEA/D 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 -PPLS/D 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 -E2OC  NSGA-II 0.3934 0.1481 0.1333 0.1809 0.0551 0.2298 9.39% NSGA-III 0.3820 0.1783 0.1292 0.1983 0.0507 0.2564 5.63% MOEA/D 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 10.89% PPLS/D 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.00%

Table 1: Comparison with Expert-based MOEAs. The train-ing instance in FJSP is mk15, and the rest are test in-stances.The number of nodes 100 in TSP is the training instance, and the rest are test instances. All methods are run 5 times and the mean values of HV and IGD are recorded. and RI is the relative improvement of HV compared to the baseline. 

Comparison with LLM-based AHD Methods The com-parison results between existing advanced LLM-based AHD methods and various multi-heuristic design frameworks on the bi-objective FJSP problem are shown in Table 6. All methods design multi-operators in NSGA-II using the same initial combinations. The same number of evaluations are per-formed for all methods to ensure a fair comparison with same evaluation budget. All details of the methods are described in Appendix G.1.                                                                      

> Type Method All instaces Train instace Test instaces
> HV ↑IGD ↓HV ↑IGD ↓HV ↑IGD ↓
> Single
> Random 0.2263 1.4193 0.1702 0.8546 0.2303 1.4597 FunSearch 0.2265 1.4070 0.1712 0.8386 0.2210 1.4193 EoH 0.2258 1.4352 0.1694 0.8409 0.2298 1.4777 ReEvo 0.2185 1.6551 0.1669 0.8712 0.2222 1.7110 MCTS-AHD 0.2269 1.3950 0.1709 0.8371 0.2309 1.4348 Multi  CD 0.2170 1.6536 0.1630 0.9572 0.2209 1.7033 UCB 0.2182 1.6300 0.1663 0.9296 0.2219 1.6800 LLM 0.2148 1.8772 0.1654 0.9424 0.2183 1.9440 Win-UCB 0.2256 1.4619 0.1763 0.7566 0.2292 1.5123 E2OC 0.2435 1.1423 0.1985 0.6830 0.2467 1.1751

Table 2: Comparison with different AHD methods on Bi-FJSP. The operator combinations designed by all methods are independently tested 5 times in NSGA-II, with the average performance recorded. The best performance is highlighted in bold. 

Single-heuristic design. In all single-heuristic design algo-rithms, the same budget are allocated to each operator and operators are designed in the same order. It is observed that in the training instance, the operator designed by FunSearch achieves the best mean performance in five independent runs of NSGA-II, with an HV of 0.1712. However, for the test instances and overall performance, MCTS-AHD shows the best results, demonstrating the outstanding performance of MCTS in such collaborative design scenarios. Notably, the operator combinations designed by E2OC consistently out-perform others in all instances , achieving an HV of 0.2435. Compared to sequentially optimizing multiple operators in-dependently, E2OC’s co-evolution of design strategies and executable codes clearly provides greater advantages in multi-operator design tasks. 

Multi-heuristic design. Among the various multi-operator collaborative design frameworks, methods based on CD, UCB, and LLM result in performance degradation. Notably, directly using LLM for operator optimization decisions per-forms the worst. This further confirms that relying solely on LLM or expert knowledge to directly control the operator combination design process in MOEAs is difficult to produce the expected results. Win-UCB achieves the second-best per-formance after E2OC, with an HV of 0.1763 in the training instances, significantly outperforming all single-heuristic de-signs, but underperforms in other instances. E2OC achieves the best average performance across all instances, strongly demonstrating that its generated strategies are not locally optimized for the training instances, but rather a robust op-timization strategy that generalizes to different instances of similar problems. 0 4 8 12 16 20 24 28 

> Generation
> 0.12
> 0.14
> 0.16
> 0.18
> 0.20
> 0.22
> 0.24
> HV
> HV (mean ± CI)

(a) HV on training instance 500 600 700 800 900 1000  

> obj1
> 4500
> 4600
> 4700
> 4800
> obj2
> Pareto Front (best run per method)

(b) PF on training instance 0 4 8 12 16 20 24 28  

> Generation
> 0.25
> 0.50
> 0.75
> 1.00
> 1.25
> 1.50
> 1.75
> 2.00
> IGD
> IGD (mean ± CI)

(c) IGD on training instance 0 4 8 12 16 20 24 28 

> Generation
> 0.11
> 0.12
> 0.13
> 0.14
> 0.15
> 0.16
> 0.17
> 0.18
> HV
> HV (mean ± CI)

(d) HV on testing instance 800 1000 1200 1400 1600  

> obj1
> 5050
> 5100
> 5150
> 5200
> 5250
> 5300
> 5350
> 5400
> obj2
> Pareto Front (best run per method)

(e) IGD on testing instance 0 4 8 12 16 20 24 28  

> Generation
> 0.0
> 0.5
> 1.0
> 1.5
> 2.0
> 2.5
> 3.0
> 3.5
> IGD
> IGD (mean ± CI)

(f) PF on testing instance Random 

> FunSearch
> EoH
> ReEvo
> MCTS-AHD
> CD
> UCB
> LLM
> Win-UCB
> E2OC

Figure 3: Performance of different AHD methods on BIFJSP training (mk15) and test (mk14) instances. 

## 5 Discussion and Future Works 

5.1 Discussion 

Different parameters The number of initial added prompts 

AP controls the number of operator design thoughts gener-ated during the warm-start phase. Larger AP values increase the diversity of initial design thoughts and cover a broader range of improvement directions, but they also expand the de-sign strategy search space, making it more difficult to identify optimal strategy paths. With four operators, each associated with AP design thoughts, the number of possible design strategies scales as AP 4. All experiments use the same manually designed initial operator code templates, design thoughts, and warm-start operator sets, and AP is varied solely to control the number of LLM-generated design thoughts. We evaluate 

AP ∈ [1 , 3, 5, 7] , corresponding to strategy spaces of sizes [42, 44, 46, 48], respectively. To assess the impact of different AP settings, instances are split into training and testing sets, and the search behavior and performance of generated operators are analyzed. The results, summarized in Table 3, show that larger AP values increase the difficulty of invalid branches caused by the pruning con-flict design strategy in MCTS, leading to a higher proportion of illegal operator code. Although AP = 5 achieves the best HV on the training set, AP = 3 delivers the most stable and best overall performance across all instances and the test set. To avoid overfitting, AP = 3 is adopted in all subsequent experiments. 

Parameter AP 1 3 5 7Search ValidR ↑ 0.9969 0.9965 0.9946 0.9930 

performance Mean ↑ 0.1508 0.1574 0.1498 0.1511 Range ↑ 0.1638 0.1749 0.1639 0.1654 Std ↑ 0.0087 0.0120 0.0098 0.0127 All instances HV ↑ 0.2199 0.2260 0.2198 0.2185 IGD ↓ 1.5762 1.3966 1.5782 1.5891 

Train instance HV ↑ 0.1732 0.1709 0.1746 0.1726 IGD ↓ 0.7796 0.8532 0.7734 0.7735 

Test instances HV ↑ 0.2232 0.2300 0.2230 0.2218 IGD ↓ 1.6331 1.4355 1.6357 1.6474 Table 3: Comparison of different number of initial added prompt AP (see Algorithm 1). The performance metrics of the search process include: ValidRate (correctness of gen-erated code), Mean, Range, and standard values Std of the scores. 

Different LLMs The effectiveness of E2OC and other LLM-based AHD methods is closely related to the character-istics of the underlying LLM, which can result in differences in the quality of generated design thoughts and operator code. We evaluate six representative LLMs from the DeepSeek, GPT, Qwen, and Gemini families on the NSGA-II operator design task for Bi-FJSP under identical experimental settings. Search performance, evaluation performance, and computa-tional expenditure are summarized in Table 4.                                                           

> Search performance Evaluation Expenditure LLM ValidR ↑Mean ↑Range ↑HV ↑IGD ↓Token Cost ↓Ratio ↓
> deepseek-chat 99.76% 0.1485 0.1684 0.2271 1.5437 3.34M $1.14 41.53
> gpt-4.1-mini 99.97% 0.1502 0.0432 0.2266 1.4234 3.41M $1.22 45.23 gpt-4o-mini 100.00% 0.1458 0.1612 0.2211 1.5840 2.44M $2.23 103.29 qwen3-8B ∗99.93% 0.1475 0.1629 0.2258 1.4556 2.83M $3.19 121.99 qwen3-30B-A3B ∗99.93% 0.1473 0.1652 0.2244 1.4997 5.39M $13.56 222.87 gemini-2.5-pro 99.90% 0.1482 0.1629 0.2223 1.5745 14.35M $117.84 5196.28

Table 4: Comparison of different LLMs. The ∗ denotes open-source models, which are cheaper to deploy locally. The Ratio represents the quality-cost ratio, calculated as performance improvement over the baseline divided by cost. Shading high-lights the most cost-effective LLM. The results show that stronger general LLMs do not nec-essarily yield superior performance in improvement sum-marization or operator design within E2OC. While gpt-4.1-mini achieves the best search performance in some instances, deepseek-chat consistently provides a more favorable trade-off, with competitive performance, lower evaluation cost, and higher quality-cost ratio. Therefore, deepseek-chat is adopted as the default backbone model in subsequent experiments. 

Different MCTS variants MCTS enables effective reuse of branching information and provides a principled frame-work for modeling dependencies among multiple operators. According to differences in state representation and expan-sion mechanisms, we consider four MCTS variants for multi-operator collaborative design: 1) MCTS OC , which pro-gressively searches operator combinations; 2) MCTS Tuple ,which progressively searches design strategy, with node states composed of design thought tuples. 3) MCTS Sample ,which progressively samples and searches design thoughts during expansion; and 4) E2OC , which searches over a pre-defined design thought space constructed via warm-start. De-tailed descriptions are provided in Appendix E.                                             

> Method All instancess Train instances Test instancess
> HV ↑IGD ↓HV ↑IGD ↓HV ↑IGD ↓
> MCTS OC 0.2085 2.3828 0.1583 2.0977 0.2121 2.4031 MCTS Tuple 0.2186 2.0888 0.1655 1.9628 0.2224 2.0978 MCTS Sample 0.2181 2.1088 0.1633 1.9905 0.2220 2.1172 E2OC 0.2435 1.7749 0.1985 1.1188 0.2467 1.8217 E2OC ′0.2454 1.6617 0.1986 1.1095 0.2487 1.7012 E2OC ′′ 0.2475 1.5453 0.1999 1.0238 0.2509 1.5826

Table 5: Comparison of different MCTS variants and valida-tion of continuous optimization. For fairness, MCTS OC and MCTS Tuple do not restrict the number of LLM samplings, whereas MCTS Sample and E2OC limit the number of sampled design thoughts per op-erator to AP , with E2OC constructing the design strategy space in advance. All experimental results are summarized in Table 5. Under a fixed evaluation budget, E2OC achieves the best performance across different instances, with HV values of 0.1985, 0.2467, and 0.2435 on the training, test, and all instance sets, respectively, significantly outperforming the other variants. These results indicate that searching within a fixed yet structured design thought space enables more ef-ficient identification of high-quality design strategies than dynamically sampling thoughts during tree search. 

Continuous Optimization Analysis The design thought space of E2OC is initialized from an elite operator set ob-tained during the warm-start phase, allowing progressive dis-covery of strategies and operator combinations that surpass expert-designed baselines. To examine its potential for sus-tained optimization, we conduct three consecutive E2OC runs on the NSGA-II operators design task for Bi-FJSP, where the output strategies and operators of each run are reused as inputs for the next. The results show consistent performance improvements in both the second E2OC ′ and third E2OC ′′ runs compared with the previous ones in Table 5, demonstrating that initial-izing E2OC with increasingly stronger design strategies and operator sets further enhances performance. This iterative reconstruction of the design thought space endows E2OC with clear continuous optimization capability. 

5.2 Future Works 

Although LLM-based AHD has recently gained attention, it remains at an early stage of development. Existing studies indicate substantial potential in automatic algorithm design, warranting deeper and more systematic investigation. 

Semantic-level optimization LLMs introduce an optimiza-tion paradigm that operates in semantic spaces rather than purely numerical or combinatorial domains. Future research should focus on developing principled formulations and tools for semantic-level optimization, where language and knowl-edge representations define the search space and optimization dynamics. 

Human–AI collaborative design The design strategies in E2OC provide continuous guidance for heuristic evolution and improve interpretability. However, practical deployment under complex domain constraints requires effective inte-gration of expert knowledge. Future work could explore in-teractive optimization frameworks that incorporate human preferences or expert evaluations to guide and accelerate algorithm design. 

Autonomous algorithmic system evolution Current LLM-based AHD frameworks have demonstrated promise but of-ten rely on limited supervision and relatively simple algo-rithm structures. A key direction is to exploit LLMs’ self-reflection and multi-agent coordination capabilities to sup-port autonomous, iterative evolution of algorithmic systems, which calls for systematic modeling of algorithm representa-tions and their dynamic evolution mechanisms. 

## 6 Conclusion 

This paper investigates the automated design of interde-pendent operator combinations in multi-objective evolution-ary algorithms(MOEAs). We propose an evolutionary op-erator combination (E2OC) framework that co-evolves de-sign strategies with executable operator code. Progressive 0 4 8 12 16 20 24 28 

> Generation
> 0.12
> 0.14
> 0.16
> 0.18
> 0.20
> 0.22
> 0.24
> HV
> HV (mean ± CI)

(a) HV on training instance 500 600 700 800  

> obj1
> 4600
> 4700
> 4800
> 4900
> obj2
> Pareto Front (best run per method)

(b) PF on training instance 0 4 8 12 16 20 24 28  

> Generation
> 0.0
> 0.5
> 1.0
> 1.5
> 2.0
> 2.5
> 3.0
> 3.5
> IGD
> IGD (mean ± CI)

(c) IGD on training instance 0 4 8 12 16 20 24 28 

> Generation
> 0.12
> 0.14
> 0.16
> 0.18
> 0.20
> 0.22
> 0.24
> 0.26
> HV
> HV (mean ± CI)

(d) HV on testing instance 500 550 600 650 700 750 800 850  

> obj1
> 3800
> 3900
> 4000
> 4100
> 4200
> 4300
> obj2
> Pareto Front (best run per method)

(e) IGD on testing instance 0 4 8 12 16 20 24 28  

> Generation
> 0
> 1
> 2
> 3
> 4
> 5
> IGD
> IGD (mean ± CI)

(f) PF on testing instance MCTS_OC MCTS_Tuple MCTS_Sample E2OC 

Figure 4: Performance of different MCTS variants on BIFJSP training (mk15) and test (mk13) instances. search based on Monte Carlo trees is performed for com-binations between different operator design ideas. The op-timal operator combination is systematically searched and determined through operator rotation evolution, and is com-patible with mainstream AHD methods. We evaluate E2OC on bi-objective and tri-objective flexible job shop schedul-ing problem and traveling salesman problem. Experimen-tal results demonstrate that E2OC consistently outperforms well-established human-designed operators across multiple MOEAs. By explicitly modeling and exploring inter-operator coupling, E2OC achieves superior performance compared to state-of-the-art AHD methods. 

## Acknowledgements 

The work described in this paper was supported by the Re-search Grants Council of the Hong Kong Special Adminis-trative Region, China (GRF Project No. CityU11217325), and the Natural Science Foundation of China (Project No: 62276223). 

## Impact Statement 

This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal con-sequences of our work, none of which we feel must be specif-ically highlighted here. 

## References 

Akiba, T.; Sano, S.; Yanase, T.; Ohta, T.; and Koyama, M. 2019. Optuna: A next-generation hyperparameter optimiza-tion framework. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining , 2623–2631. Ardeh, M. A.; Mei, Y.; and Zhang, M. 2021. Genetic pro-gramming with knowledge transfer and guided search for uncertain capacitated arc routing problem. IEEE Transac-tions on Evolutionary Computation , 26(4): 765–779. Brandimarte, P. 1993. Routing and scheduling in a flexible job shop by tabu search. Annals of Operations Research ,41(3): 157–183. Burke, E. K.; Gendreau, M.; Hyde, M.; Kendall, G.; Ochoa, G.; ¨Ozcan, E.; and Qu, R. 2013. Hyper-heuristics: A survey of the state of the art. Journal of the Operational Research Society , 64: 1695–1724. Burke, E. K.; Hyde, M. R.; Kendall, G.; Ochoa, G.; ¨Ozcan, E.; and Woodward, J. R. 2019. A classification of hyper-heuristic approaches: revisited. Handbook of metaheuristics ,453–477. Chen, J.; Zhang, Z.; Cao, Z.; Wu, Y.; Ma, Y.; Ye, T.; and Wang, J. 2023. Neural multi-objective combinatorial opti-mization with diversity enhancement. Advances in Neural Information Processing Systems , 36: 39176–39188. Chen, P.; Liang, J.; Qiao, K.-J.; Song, H.; Suganthan, P. N.; Dai, L.-L.; and Ban, X.-X. 2025. A Reinforced Neighbor-hood Search Method Combined With Genetic Algorithm for Multi-Objective Multi-Robot Transportation System. IEEE Transactions on Intelligent Transportation Systems .Coello, C. A. C.; and Cort ´es, N. C. 2005. Solving multiobjec-tive optimization problems using an artificial immune system. 

Genetic Programming and Evolvable Machines , 6: 163–190. Coulom, R. 2007. Computing “elo ratings” of move patterns in the game of go. ICGA journal , 30(4): 198–208. d O Costa, P. R.; Rhuggenaath, J.; Zhang, Y.; and Akcay, A. 2020. Learning 2-opt heuristics for the traveling salesman problem via deep reinforcement learning. In Asian confer-ence on machine learning , 465–480. PMLR. Dat, P. V. T.; Doan, L.; and Binh, H. T. T. 2025. HSEVO: Elevating automatic heuristic design with diversity-driven harmony search and genetic algorithm using llms. In Pro-ceedings of the AAAI Conference on Artificial Intelligence ,26931–26938. Dauz `ere-P ´er `es, S.; Ding, J.; Shen, L.; and Tamssaouet, K. 2024. The flexible job shop scheduling problem: A review. 

European Journal of Operational Research , 314(2): 409–432. Deb, K.; and Jain, H. 2014. An Evolutionary Many-Objective Optimization Algorithm Using Reference-Point-Based Non-dominated Sorting Approach, Part I: Solving Problems With Box Constraints. IEEE Transactions on Evolutionary Com-putation , 18(4): 577–601. Deb, K.; Pratap, A.; Agarwal, S.; and Meyarivan, T. 2002. A fast and elitist multiobjective genetic algorithm: NSGA-II. IEEE Transactions on Evolutionary Computation , 6(2): 182–197. Drake, J. H.; Kheiri, A.; ¨Ozcan, E.; and Burke, E. K. 2020. Recent advances in selection hyper-heuristics. European Journal of Operational Research , 285(2): 405–428. Fu, Z.-H.; Qiu, K.-B.; and Zha, H. 2021. Generalize a small pre-trained model to arbitrarily large tsp instances. In Pro-ceedings of the AAAI conference on artificial intelligence ,volume 35, 7474–7482. Helsgaun, K. 2000. An effective implementation of the Lin– Kernighan traveling salesman heuristic. European journal of operational research , 126(1): 106–130. Hong, L.; Drake, J. H.; Woodward, J. R.; and ¨Ozcan, E. 2018. A hyper-heuristic approach to automated generation of mutation operators for evolutionary programming. Applied Soft Computing , 62: 162–175. Huang, C.; Li, Y.; and Yao, X. 2019. A survey of automatic parameter tuning methods for metaheuristics. IEEE transac-tions on evolutionary computation , 24(2): 201–216. Jaszkiewicz, A.; and Zielniewicz, P. 2009. Pareto memetic algorithm with path relinking for bi-objective traveling sales-person problem. European Journal of Operational Research ,193(3): 885–890. Jia, Y.-H.; Mei, Y.; and Zhang, M. 2022. Learning heuristics with different representations for stochastic routing. IEEE Transactions on Cybernetics .Kiet, N. V. T.; Van Tung, D.; Dao, T. C.; and Binh, H. T. T. 2025. MOTIF: Multi-strategy Optimization via Turn-based Interactive Framework. arXiv preprint arXiv:2508.03929 .Kumar, R.; and Singh, P. 2007. Pareto evolutionary algorithm hybridized with local search for biobjective TSP. Hybrid Evolutionary Algorithms , 75(1): 361–398. Lan, W.; Ye, Z.; Ruan, P.; Liu, J.; Yang, P.; and Yao, X. 2021. Region-focused memetic algorithms with smart initialization for real-world large-scale waste collection problems. IEEE Transactions on Evolutionary Computation , 26(4): 704–718. Langdon, W. B.; and Poli, R. 2013. Foundations of genetic programming . Springer Science & Business Media. Li, F.; Gao, L.; and Shen, W. 2022. Surrogate-assisted multi-objective evolutionary optimization with Pareto front model-based local search method. IEEE Transactions on Cybernet-ics , 54(1): 173–186. Li, R.; Wang, L.; Gong, W.; and Ming, F. 2024a. An evolu-tionary multitasking memetic algorithm for multi-objective distributed heterogeneous welding flow shop scheduling. 

IEEE Transactions on Evolutionary Computation .Li, R.; Wang, L.; Gong, W.; and Ming, F. 2024b. An evolu-tionary multitasking memetic algorithm for multi-objective distributed heterogeneous welding flow shop scheduling. 

IEEE Transactions on Evolutionary Computation .Li, R.; Wang, L.; Sang, H.; Yao, L.; and Pan, L. 2025. LLM-assisted automatic memetic algorithm for lot-streaming hy-brid job shop scheduling with variable sublots. IEEE Trans-actions on Evolutionary Computation .Liao, R.; Qiu, J.; Chen, X.; and Li, X. 2025. LLM4EO: Large Language Model for Evolutionary Optimization in Flexible Job Shop Scheduling. arXiv preprint arXiv:2511.16485 .Liu, F.; Tong, X.; Yuan, M.; Lin, X.; Luo, F.; Wang, Z.; Lu, Z.; and Zhang, Q. 2024. Evolution of heuristics: Towards efficient automatic algorithm design using large language model. In Proceedings of the International Conference on Machine Learning , 32201–32223. Liu, F.; Yao, Y.; Guo, P.; Yang, Z.; Lin, X.; Zhao, Z.; Tong, X.; Mao, K.; Lu, Z.; Wang, Z.; et al. 2026. A systematic survey on large language models for algorithm design. ACM Computing Surveys .Lust, T.; and Teghem, J. 2010a. The multiobjective traveling salesman problem: A survey and a new approach. In Ad-vances in Multi-Objective Nature Inspired Computing , 119– 141. Springer. Lust, T.; and Teghem, J. 2010b. The multiobjective traveling salesman problem: A survey and a new approach. In Ad-vances in Multi-Objective Nature Inspired Computing , 119– 141. Springer. Ma, Z.; Guo, H.; Gong, Y.-J.; Zhang, J.; and Tan, K. C. 2025. Toward automated algorithm design: A survey and practical guide to meta-black-box-optimization. IEEE Transactions on Evolutionary Computation .Mara, S. T. W.; Norcahyo, R.; Jodiawan, P.; Lusiantoro, L.; and Rifai, A. P. 2022. A survey of adaptive large neigh-borhood search algorithms and applications. Computers & Operations Research , 146: 105903. Mei, Y.; Chen, Q.; Lensen, A.; Xue, B.; and Zhang, M. 2022. Explainable artificial intelligence by genetic programming: A survey. IEEE Transactions on Evolutionary Computation .Mo, S.; Wu, K.; Gao, Q.; Teng, X.; and Liu, J. 2025. Au-toSGNN: Automatic propagation mechanism discovery for spectral graph neural networks. In Proceedings of the AAAI Conference on Artificial Intelligence , 19493–19502. Morales-Hern ´andez, A.; Van Nieuwenhuyse, I.; and Ro-jas Gonzalez, S. 2023. A survey on multi-objective hyperpa-rameter optimization algorithms for machine learning. Artifi-cial Intelligence Review , 56(8): 8043–8093. Neufeld, J. S.; Schulz, S.; and Buscher, U. 2023. A system-atic review of multi-objective hybrid flow shop scheduling. 

European Journal of Operational Research , 309(1): 1–23. Nguyen, S.; Mei, Y.; and Zhang, M. 2017. Genetic pro-gramming for production scheduling: a survey with a unified framework. Complex & Intelligent Systems , 3(1): 41–66. Novikov, A.; Vu, N.; Eisenberger, M.; Dupont, E.; Huang, P.-S.; Wagner, A. Z.; Shirobokov, S.; Kozlovskii, B.; Ruiz, F. J.; Mehrabian, A.; et al. ???? AlphaEvolve: A coding agent for scientific and algorithmic discovery, 2025. URL: https://arxiv. org/abs/2506.13131 .O’Neill, M.; Vanneschi, L.; Gustafson, S.; and Banzhaf, W. 2010. Open issues in genetic programming. Genetic Pro-gramming and Evolvable Machines , 11(3): 339–363. Paquete, L.; Chiarandini, M.; and St ¨utzle, T. 2004a. Pareto local optimum sets in the biobjective traveling salesman prob-lem: An experimental study. In Metaheuristics for multiob-jective optimisation , 177–199. Springer. Paquete, L.; Chiarandini, M.; and St ¨utzle, T. 2004b. Pareto local optimum sets in the biobjective traveling salesman prob-lem: An experimental study. In Metaheuristics for multiob-jective optimisation , 177–199. Springer. Pei, J.; Mei, Y.; Liu, J.; Zhang, M.; and Yao, X. 2025. Adap-tive operator selection for meta-heuristics: A survey. IEEE Transactions on Artificial Intelligence .Peng, B.; Wei, Y.; Qin, Y.; Dai, J.; Li, Y.; Liu, A.; Tian, Y.; Han, L.; Zheng, Y.; and Wen, P. 2023. Machine learning-enabled constrained multi-objective design of architected materials. Nature Communications , 14(1): 6630. Pillay, N.; and Qu, R. 2018. Hyper-heuristics: theory and applications . Springer. Qingfu Zhang; and Hui Li. 2007. MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition. IEEE Transactions on Evolutionary Computation , 11(6): 712–731. Qiu, J.; Zhuang, H.; Liu, F.; Liu, J.; and Zhang, Q. 2026. LLM-Assisted Automatic Dispatching Rule Design for Dy-namic Flexible Assembly Flow Shop Scheduling. arXiv preprint arXiv:2601.15738 .Romera-Paredes, B.; Barekatain, M.; Novikov, A.; Balog, M.; Kumar, M. P.; Dupont, E.; Ruiz, F. J.; Ellenberg, J. S.; Wang, P.; Fawzi, O.; et al. 2024. Mathematical discoveries from program search with large language models. Nature ,625(7995): 468–475. Shi, J.; Sun, J.; Zhang, Q.; Zhang, H.; and Fan, Y. 2022. Im-proving pareto local search using cooperative parallelism strategies for multiobjective combinatorial optimization. 

IEEE Transactions on Cybernetics , 54(4): 2369–2382. Shinn, N.; Cassano, F.; Gopinath, A.; Narasimhan, K.; and Yao, S. 2023. Reflexion: Language agents with verbal rein-forcement learning. Advances in Neural Information Pro-cessing Systems , 36: 8634–8652. Silver, D.; Huang, A.; Maddison, C. J.; Guez, A.; Sifre, L.; Van Den Driessche, G.; Schrittwieser, J.; Antonoglou, I.; Panneershelvam, V.; Lanctot, M.; et al. 2016. Mastering the game of Go with deep neural networks and tree search. 

nature , 529(7587): 484–489. St ¨utzle, T.; and L ´opez-Ib ´a ˜nez, M. 2019. Automated design of metaheuristic algorithms. Handbook of metaheuristics ,541–579. ´Swiechowski, M.; Godlewski, K.; Sawicki, B.; and Ma ´ndziuk, J. 2023. Monte Carlo tree search: A review of recent modifi-cations and applications. Artificial Intelligence Review , 56(3): 2497–2562. Tang, K.; Mei, Y.; and Yao, X. 2009. Memetic algorithm with extended neighborhood search for capacitated arc routing problems. IEEE Transactions on Evolutionary Computation ,13(5): 1151–1166. van Stein, N.; and B ¨ack, T. 2024. Llamea: A large language model evolutionary algorithm for automatically generating metaheuristics. IEEE Transactions on Evolutionary Compu-tation .Wang, Z.; Yao, S.; Li, G.; and Zhang, Q. 2023. Multiobjective combinatorial optimization using a single deep reinforcement learning model. IEEE transactions on cybernetics , 54(3): 1984–1996. Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Xia, F.; Chi, E.; Le, Q. V.; Zhou, D.; et al. 2022. Chain-of-thought prompt-ing elicits reasoning in large language models. Advances in neural information processing systems , 35: 24824–24837. Wu, X.; Wu, S.-h.; Wu, J.; Feng, L.; and Tan, K. C. 2024. Evolutionary computation in the era of large language model: Survey and roadmap. IEEE Transactions on Evolutionary Computation .Xie, Z.; Liu, F.; Wang, Z.; and Zhang, Q. 2025. LLM-Driven Neighborhood Search for Efficient Heuristic Design. In 2025 IEEE Congress on Evolutionary Computation (CEC) , 1–8. IEEE. Xu, Z.; Zhang, Y.; Bao, W.; Wang, H.; Chen, M.; Ye, H.; Jiang, W.; Yan, H.; and Wang, J. 2025. AutoEP: LLMs-Driven Automation of Hyperparameter Evolution for Meta-heuristic Algorithms. arXiv preprint arXiv:2509.23189 .Yao, S.; Liu, F.; Lin, X.; Lu, Z.; Wang, Z.; and Zhang, Q. 2025. Multi-objective evolution of heuristic using large lan-guage model. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 39, 27144–27152. Yao, S.; Yu, D.; Zhao, J.; Shafran, I.; Griffiths, T.; Cao, Y.; and Narasimhan, K. 2023. Tree of thoughts: Deliberate problem solving with large language models. Advances in neural information processing systems , 36: 11809–11822. Ye, H.; Wang, J.; Cao, Z.; Berto, F.; Hua, C.; Kim, H.; Park, J.; and Song, G. 2024. Reevo: Large language models as hyper-heuristics with reflective evolution. Advances in neural information processing systems , 37: 43571–43608. Ye, H.; Xu, H.; Yan, A.; and Cheng, Y. 2025. Large lan-guage model-driven large neighborhood search for Large-scale MILP problems. In Proceedings of the International Conference on Machine Learning .Zhang, F.; Mei, Y.; Nguyen, S.; and Zhang, M. 2023. Survey on Genetic Programming and Machine Learning Techniques for Heuristic Design in Job Shop Scheduling. IEEE Transac-tions on Evolutionary Computation .Zhang, R.; Liu, F.; Lin, X.; Wang, Z.; Lu, Z.; and Zhang, Q. 2024a. Understanding the importance of evolutionary search in automated heuristic design with large language models. In 

International Conference on Parallel Problem Solving from Nature , 185–202. Springer. Zhang, R.; Liu, F.; Lin, X.; Wang, Z.; Lu, Z.; and Zhang, Q. 2024b. Understanding the importance of evolutionary search in automated heuristic design with large language models. In 

International Conference on Parallel Problem Solving from Nature , 185–202. Springer. Zhao, F.; Zhou, G.; and Wang, L. 2023. A cooperative scat-ter search with reinforcement learning mechanism for the distributed permutation flowshop scheduling problem with sequence-dependent setup times. IEEE Transactions on Sys-tems, Man, and Cybernetics: Systems .Zheng, Z.; Xie, Z.; Wang, Z.; and Hooi, B. 2025a. Monte carlo tree search for comprehensive exploration in llm-based automatic heuristic design. arXiv preprint arXiv:2501.08603 .Zheng, Z.; Xie, Z.; Wang, Z.; and Hooi, B. 2025b. Monte Carlo tree search for comprehensive exploration in LLM-based automatic heuristic design. In Proceedings of the International Conference on Machine Learning .Zitzler, E.; and Thiele, L. 1999. Multiobjective evolutionary algorithms: A comparative case study and the strength Pareto approach. IEEE Transactions on Evolutionary Computation ,3(4): 257–271. A Related Works 

A.1 Automatic Heuristic Design (AHD) 

General AHD method. Automatic heuristic design, also known as hyper-heuristics (Burke et al. 2013; St ¨utzle and L ´opez-Ib ´a ˜nez 2019), aims to automatically generate, select, or adapt heuristics for complex optimization problems, reducing reliance on expert knowledge and enhancing cross-domain applicability (Burke et al. 2019; Akiba et al. 2019). Genetic Programming (GP)-based methods form a major paradigm within AHD (Langdon and Poli 2013). They encode heuristics as tree-structured programs or executable code and evolve high-performing rules through genetic operators such as crossover, mutation, and selection within a defined search space (Jia, Mei, and Zhang 2022; Mei et al. 2022). Genetic Programming (GP)-based AHD has been applied to domains such as production scheduling (Nguyen, Mei, and Zhang 2017; Zhang et al. 2023) and path planning (Jia, Mei, and Zhang 2022; Ardeh, Mei, and Zhang 2021), demonstrating its ability to discover complex heuristic strategies, including priority rules in scheduling and composite heuristics for combinatorial problems. Despite their effectiveness, these methods rely on manually designed genetic operators and fixed terminal and function sets (Pillay and Qu 2018; O’Neill et al. 2010). The resulting heuristics often have complex, hard-to-interpret structures, which limits scalability and practical applicability. 

LLM-driven AHD. LLMs have enabled a new paradigm for AHD, in which heuristic construction is guided by language-based generative models (Liu et al. 2026; Zhang et al. 2024a). In this setting, AHD is often formulated as an evolutionary program search, where LLMs generate and modify algorithmic code within an evolutionary optimization framework. These approaches have shown strong empirical performance in optimization (Liu et al. 2024; Ye et al. 2024; van Stein and B ¨ack 2024; Ye et al. 2025; Dat, Doan, and Binh 2025; Yao et al. 2025; Li et al. 2025; Qiu et al. 2026), mathematical discovery (Romera-Paredes et al. 2024; Novikov et al.), black-box optimization (Ma et al. 2025; Xu et al. 2025) and machine learning (Mo et al. 2025). FunSearch provides a baseline by using an island-based evolutionary framework with a single prompting strategy for LLM-driven code optimization (Romera-Paredes et al. 2024). Building on this, the EoH jointly evolves heuristic ideas and executable code (Liu et al. 2024), introducing multiple prompting strategies to enhance diversity and exploration. MEOH further incorporates dominance-based selection on objective vectors (Yao et al. 2025), enabling efficient multi-objective heuristic design within the same LLM-driven evolutionary setting. Beyond evolutionary approaches, alternative search paradigms have been explored. Monte Carlo Tree Search (MCTS) guides LLM-based heuristic synthesis through structured exploration (Zheng et al. 2025b; Kiet et al. 2025), while neighborhood search improves sample efficiency and local refinement (Xie et al. 2025). Collectively, these LLM-driven methods reduce dependence on manually predefined symbol sets and operate in semantically richer spaces, enabling more flexible and expressive heuristic synthesis. 

A.2 Operator Selection and Design in Evolutionary Algorithms 

The effectiveness of evolutionary algorithms largely depends on the employed variation operators. Existing research on operator selection and design can be broadly categorized into two directions: adaptive operator selection based on search feedback, and the design of problem-informed operators that exploit domain-specific structures (Pei et al. 2025). 

Operator Selection. Operator selection is commonly studied as an online decision-making problem, where operator usage is adapted according to the current search state and historical performance. In many studies, this process is further formulated within the frameworks of adaptive parameter control (Huang, Li, and Yao 2019) or selection hyper-heuristics (Drake et al. 2020), in which each candidate operator is treated as an alternative parameter configuration or heuristic strategy to be selected during the evolutionary search. Methods such as adaptive large neighborhood search(Mara et al. 2022; Tang, Mei, and Yao 2009) and reinforcement learning model(d O Costa et al. 2020; Zhao, Zhou, and Wang 2023) selection as a policy mapping states to operator choices, with feedback derived from fitness gain or diversity preservation. This allows operator distributions to adapt dynamically, reducing reliance on fixed schedules or expert heuristics. 

Operator Design. Operator design is undergoing a transition from expert-crafted operators (Helsgaun 2000; Lan et al. 2021) tailored to specific problems and objectives toward automated design approaches. Early methods based on GP evolve operator components and compositions within predefined structural spaces (Hong et al. 2018). More recently, LLM–based approaches have demonstrated the ability to automatically generate and explore operator structures via natural language specifications or code synthesis (Liao et al. 2025), providing a more expressive and flexible design space. 

Operator Combination in Multi-Objective EAs. In multi-objective EAs (MOEAs), operators must balance convergence toward the Pareto front with preservation of solution diversity(Li, Gao, and Shen 2022). Single operators often bias the search toward specific regions. To mitigate this, methods combine multiple mutation or recombination operators with complementary behaviors and manage their usage through cooperative or competitive strategies (Chen et al. 2025; Li et al. 2024b). The challenge lies in designing operator sets and selection mechanisms that adapt to dynamic Pareto fronts while accounting for inter-operator interactions rather than evaluating operators in isolation. A.3 MCTS with LLM for Structured Reasoning and Decision-Making 

Monte Carlo Tree Search (MCTS) is a simulation-based heuristic search for large, structured decision spaces, providing approximate solutions when exhaustive search is infeasible (Coulom 2007). It operates through a cycle of selection, expansion, simulation, and backpropagation, balancing exploration of uncertain paths with exploitation of promising ones ( ´Swiechowski et al. 2023). Beyond passive evaluation, MCTS can actively guide decision-making by coordinating with deep neural networks (Silver et al. 2016; Fu, Qiu, and Zha 2021), demonstrating effectiveness in complex spaces. 

MCTS with LLM. Recent work integrates MCTS with LLMs for structured reasoning and algorithm design (Zheng et al. 2025b; Kiet et al. 2025). In one approach, LLMs generate reasoning steps while MCTS evaluates and selects promising paths, as in the Tree of Thoughts framework, enabling self-correcting multi-step reasoning (Wei et al. 2022; Yao et al. 2023). In another, MCTS-AHD (Zheng et al. 2025b), LLMs produce candidate heuristic configurations and MCTS manages search via progressive expansion in large program spaces. MOTIF extends this to multi-strategy collaborative design, facilitating turn-based optimization between two LLM agents(Kiet et al. 2025). These methods combine LLMs’ generative flexibility with MCTS’s selective control. LLMs provide diverse candidate solutions, while MCTS guides efficient search through hierarchical selection and backpropagation. This integration enhances structured reasoning and offers a scalable framework for complex decision problems, transforming MCTS into a dynamic controller of LLM outputs. 

A.4 Reflective Prompting 

Reflective prompting enables LLMs to iteratively generate, evaluate, and revise outputs, forming a generate-reflect-revise loop to improve quality (Shinn et al. 2023). In automated algorithm design, ReEvo embeds reflection into evolutionary search (Ye et al. 2024), allowing LLMs to compare algorithm variants and extract insights to guide subsequent search. LLM4EO applies reflective prompting in operator design to identify patterns from successful instances and enable knowledge reuse (Liao et al. 2025). By integrating reflection with optimization, these methods support multi-round self-assessment and learning from past errors, improving efficiency and generalization in complex design tasks. 

## B Prompt Engineering 

The prompts used in E2OC are for algorithm and prompt generation. During algorithm generation, E2OC adopts heuristic prompting strategies consistent with those used in existing single-heuristic design methods. For example, EOH employs evolution prompts including Exploration prompts (E1, E2) and Modification prompts (M1, M2, M3) (Liu et al. 2024), while MCTS-AHD uses prompts such as i1, e1, e2, m1, m2, and s1 for MCTS initialization and tree expansion (Zheng et al. 2025b). Other baseline methods similarly follow the prompt strategies specified in their original studies(Romera-Paredes et al. 2024; Yao et al. 2025; Ye et al. 2024). When constructing the language space of design strategies, dedicated prompts are used to analyze existing design ideas and reformulate them, as illustrated in Figure 5. To ensure compatibility across different algorithm design frameworks, design strategies are embedded into structured algorithm-parameter description blocks, corresponding to the improvement suggestions shown in the figure. These prompts typically include three components. First, Elite Candidate Operator (new alg) obtained from the warm-start phase are provided as reference targets. Second, an Expert-designed Operator (ini template) designed by domain experts is supplied to ground the design process. Third, an Output Femplate (output template) is specified to standardize the format of the LLM responses. As highlighted in the improvement suggestion task description in Figure 5, the LLM is guided to analyze the strengths and weaknesses of the reference algorithm. The model then produces a revised algorithm template augmented with explicit improvement suggestions. Each such template represents a distinct design strategy and is subsequently incorporated into the prompt strategies of different algorithm design frameworks for downstream use. 

## C Multi-Objective Flexible Job Shop Scheduling Problem 

C.1 Problem Description 

The FJSP extends the classical job shop scheduling problem by allowing each operation to be processed on multiple eligible machines with varying processing times. In multi-objective FJSPs, the objectives typically include minimizing the makespan, the maximum machine load, and the total machine load, which reflect distinct and often conflicting performance criteria. While makespan measures the completion time of the last job, maximum machine load emphasizes the balance of heavily loaded machines, and total load captures overall resource utilization. In the Bi-FJSP, we focus on makespan and maximum machine load, whereas the Tri-FJSP additionally considers total machine load. The conflicting nature of these objectives complicates scheduling, as improvements in one criterion may degrade others. To tackle these challenges, MOEAs are commonly employed, leveraging sophisticated operator designs for both operation sequencing and machine assignment. Designing effective operators is particularly demanding due to the combinatorial complexity, the interdependence between operations and machines, and the need to balance exploration and exploitation across objectives. Benchmark instances proposed by (Brandimarte 1993) provide standard testbeds for evaluating algorithm performance. The import <required_libraries>    

> def <function_name>(<parameter>: <type>) -> <return_type>:
> """
> <Function description>
> Args:
> <param_name> (<type>): <parameter_description>
> Improvement Suggestions:
> -<Suggestion 1 based on reference algorithm>
> -<Suggestion 2 for HV optimization>
> Returns:
> <return_type>: <return_description>
> """
> # <Implemented function body>
> return <result>

You are an AI Python expert specializing in multi -objective optimization algorithms. 

Your task is to refine the provided prompt template to generate more advanced and 

robust Python implementations. 

Reference Algorithm (Analyze its strengths for inspiration): 

<new_alg> 

Original Template to Improve: 

<Ini_ template> 

Refinement Requirements: 

1. Return a complete, runnable Python function including: 

- All necessary import statements .

- Preserved function name, input parameters (with type hints), and return type .

- Full function body implementation .

2. Strictly adhere to PEP 8 guidelines: 

- Correct any syntax errors in the original template 

3. Enhance the docstring by adding an "Improvement Suggestions" . Add 2 -3

specific recommendations from the following perspectives :

- Leverage strengths of the reference algorithm .

- Focus on Hypervolume (HV) optimization strategies .

Output Format: 

Return ONLY the final refined template as a single string, structured as follows: 

<Output _template> AI-A AI-A AI-A 

Design 

thought 

Prompt for thought extraction and prompt rewriting 

Code templates with design thought ∙

Elite 

Candidate 

Operator 

Expert -

designed 

operator 

Analysis and 

rewriting Figure 5: Prompt for design thought analysis and prompt rewriting. combination of multiple objectives, practical constraints, and operator design complexity makes two- and three-objective FJSP a highly challenging setting for advanced multi-objective optimization methods. 

C.2 Operator Implementation Details 

The MOEAs used to solve the multi-objective FJSP employ four operators to explore the solution space within the two-part encoding, as shown in Figure 6. Two operators target operation sequencing, performing crossover and mutation on the first part of the encoding to optimize the order of operations across jobs. The other two operators focus on machine assignment, applying crossover and mutation to the second part to refine machine selection for each operation. Each operator addresses specific optimization tasks within its respective encoding segment and is designed according to its functional requirements. 0.1 0.4 0.6 0.2 0.3 0.4 0.8 0.2 1 3 1 4 2 5 2 1

operation crossover operator 

operation mutation operator 

machine crossover operator 

machine mutation operator 

Operation 

sequencing 

Machine 

assignment Priority of operation Machine index 

Figure 6: Encoding representation and operators in FJSP. These operators exhibit interdependencies, as modifications in operation sequencing affect the performance of machine assignment, and vice versa. Designing these operators independently often leads to suboptimal performance, since improvements achieved by one operator may be offset or invalidated by another. The complex couplings among operators make it difficult to achieve balanced exploration and exploitation across multiple objectives while maintaining feasibility. Consequently, effective multi-operator evolutionary algorithm design requires mechanisms that consider operator interactions and enable their coordinated evolution to ensure consistent and robust performance in both two- and three-objective FJSP scenarios. D Multi-Objective Traveling Salesman Problem 

D.1 Problem Description 

The Traveling Salesman Problem (TSP) is a classical combinatorial optimization problem, where a salesman must visit a set of cities exactly once and return to the starting point, minimizing the total travel distance. In multi-objective TSPs, the objectives are typically derived by applying different weights to the distance, allowing the formulation of two- or three-objective problems that reflect trade-offs among alternative optimization criteria. While the specific objectives may vary, they are inherently conflicting, as improvements along one weighted distance can lead to deteriorations in others. Benchmark instances from publicly available datasets, such as TSPLIB, are commonly used to evaluate the performance of MOEAs in this context. 5 3 6 4 7 1 2 8

Path 

Representation City index 

Neighborhood search operator combination 

Figure 7: Encoding representation and operators in TSP. 

D.2 Operator Implementation Details 

To explore the solution space of multi-objective TSPs, MOEAs employ multiple domain-specific search operators that act on the same path representation, as shown in Figure 7. These operators, including crossover and mutation variants, have overlapping functionalities but differ in the manner and scope of exploration. Each operator is designed to improve certain aspects of the tour, such as segment reordering, edge exchange, or route inversion. Despite acting on the same encoding region, the operators are interdependent: the effect of one operator may enhance or interfere with the effect of another. This overlapping and mutually influencing behavior makes independent design of operators insufficient and may result in suboptimal performance if interactions are ignored. Effectively coordinating these operators to balance exploration and exploitation across multiple objectives remains a significant challenge in multi-operator evolutionary algorithm design. 

## E Different MCTS variants 

From the perspective of multi-variable optimization, the application of MCTS to multi-operator collaborative design can be categorized into four types based on state representation and expansion mechanisms, as illustrated in Figure 8. • Progressive multi-operator search , where each node represents a single operator. The final operator set is obtained by selecting the highest-scoring path whose depth equals the total number of operators. During expansion, an algorithm generator is invoked to generate new operators as child nodes. • Progressive design strategy search with tuple states , where each node represents a tuple of design rationales across operators. Expansion is performed by randomly modifying one element of the tuple, yielding a new candidate strategy. The highest-scoring tuple is then used for multi-operator design. • Progressive sampling and search of design thoughts , where each node corresponds to a design thought for a single operator. During expansion, the LLM is queried to generate new thoughts for the target operator, and the highest-scoring root-to-leaf path defines the final design strategy. • Progressive design strategy search with warm-start , corresponding to E2OC, where nodes represent individual design thoughts but the thought space at each depth is predefined during the warm-start phase and does not grow dynamically during expansion. All four variants are capable of supporting collaborative multi-operator design. However, for thought-based search strategies (b–d in Figure 8), an additional operator design stage is required once a complete design strategy has been identified. A comparison and analysis of these variants can be found in Seciton 5.1. 

## F Metric Definition 

To evaluate the effectiveness of the proposed MOEAs, this study primarily employs two widely accepted performance metrics, hypervolume (HV) and inverted generational distance (IGD). These metrics jointly assess the convergence and diversity of the obtained Pareto fronts, providing a comprehensive measure of algorithm performance in multi-objective optimization tasks. The following sections provide detailed definitions and formulations of HV and IGD. AI-S AI-S AI-S Progressive multi -

operator search 

O1

O2

O3

O4

> Design
> operator

O1-1

O2-2

O3-1 O3-2

O4-1

Evaluation Design & Evaluation          

> (p1-0, p2-0, p3-0, p4-0)
> (p1-0, p2-0,p3-0, p4-0)
> (p1-0, p2-0, p3-0, p4-0)

…Randomly select 

> Generate
> thoughts
> highest score highest score

P1

P2

P3

P4

P1-1

P2-2

P3-1

P4-1

Design & Evaluation 

> highest score

P2-1

> Generate
> thoughts

P1

P2

P3

P4

P1-1

P2-2

P3-1

P4-1

Design & Evaluation 

> highest score

P2-1

Progressive design strategy 

search with tuple states Progressive sampling and 

search of design thoughts Progressive design strategy 

search with warm up AI-A AI-A AI-A AI-A AI-A AI-A 

(a) (b) (c) (d) Figure 8: Different MCTS variants for multi-operator design. 

F.1 HV 

Hypervolume is a widely used performance metric in multi-objective optimization that measures the volume of the objective space dominated by the obtained Pareto front relative to a reference point. A larger hypervolume indicates better convergence and diversity of solutions. In this study, the reference point r is manually set to ensure it dominates all obtained solutions. Formally, given a set of Pareto-optimal solutions P = {p1, p 2, . . . , p n}, the hypervolume is defined as HV (P ) = vol 

 [ 

> p∈P

[p, r ]



, (11) where [p, r ] denotes the hyper-rectangle spanned by solution p and the reference point r, and vol (·) represents the Lebesgue measure in the corresponding objective space. 

F.2 IGD 

Inverted generational distance evaluates both convergence and diversity of an obtained Pareto front by measuring its average distance to a reference Pareto front. In this study, the reference Pareto front P ∗ = {p∗

> 1

, p ∗

> 2

, . . . , p ∗

> m

} is constructed from the union of non-dominated solutions obtained by all compared algorithms to approximate the true Pareto front. Given an obtained solution set P = {p1, p 2, . . . , p n}, the IGD is computed as IGD (P, P ∗) = 1

|P ∗|

X 

> p∗∈P∗

min  

> p∈P

d(p, p ∗), (12) where d(p, p ∗) is the Euclidean distance between solution p and reference solution p∗ in the objective space. Lower IGD values indicate that the obtained solutions are closer to and more uniformly distributed along the reference Pareto front. 

F.3 RI 

The Relative Improvement (RI) metric quantifies the percentage improvement of a new method’s performance relative to a baseline method. It is calculated using the formula: 

RI = A − BB × 100% (13) where Arepresents the performance value of the new method and Brepresents the performance value of the baseline method. 

## G Experiment Implement Detail 

G.1 Comparison Method Detail 

In addition to recent SOTA single-heuristic design methods, this study compares E2OC with a range of multi-heuristic design frameworks. These methods can be categorized along three dimensions, namely whether algorithmic ideas are explicitly incorporated, whether prompt rewriting is employed, and whether a warm-start phase is required, as summarized in Table 6. Single-heuristic methods focus on designing a single algorithm and therefore do not rely on warm-start mechanisms to balance exploration and exploitation across multiple design tasks. Type Methods Ideas Prompts Warm-start                                           

> Single-heuristic  Random ✗✗✗
> FunSearch ✗✗✗
> EoH ✓✗✗
> MEoH ✓✗✗
> ReEvo ✗✓✗
> MCTS AHD ✓✗✗
> Multi-heuristic  CD ✓✗✗
> UCB ✓✗✓
> Win-UCB ✓✓✓
> LLM ✓✓✗
> MCTS OC ✓✗✗
> MCTS Tuple ✓✓✓
> MCTS Sampling ✓✓✓
> E2OC ✓✓✓

Table 6: Comparison of different methods on ideas inclusion, prompt rewriting, and warm-start In this context, an idea is defined as a linguistic description that represents the high-level logic of a heuristic (Liu et al. 2024). Methods such as EOH (Liu et al. 2024), MEOH (Yao et al. 2025), and MCTS AHD (Zheng et al. 2025b) manage ideas together with executable code as part of the population archive. Among the compared approaches, only ReEvo explicitly incorporates prompt rewriting. Empirical evidence suggests that dynamic prompt adjustment is effective in reducing code generation errors and improving the quality of generated algorithms. Existing LLM-based collaborative algorithm design frameworks can be categorized according to how they formulate the multi-algorithm design task and organize decision-making over interacting algorithms. From this perspective, prior studies can be broadly divided into four classes: coordinate-descent (CD)-based, upper-confidence-bound(UCB)-based, MCTS-based, and LLM-driven approaches. Coordinate-descent-based methods formulate multi-algorithm collaboration as a deterministic continuous optimization problem over the algorithm space. Multiple algorithms are optimized in a rotational manner, where one algorithm is updated while others are fixed, and the process iterates to identify high-performing combinations, corresponding to CD in Table 6. These methods emphasize structured and controllable search dynamics and are most effective when inter-algorithm interactions are relatively stable. UCB-based methods model collaborative algorithm design as a stochastic decision-making problem, typically using a multi-armed bandit formulation. Each algorithm or operator is treated as an arm with an unknown reward distribution, and the search explicitly balances exploration and exploitation, corresponding to UCB in Table 6. When LLM-generated prompts are introduced, reward distributions may shift over time, complicating estimation. Moreover, dependencies among algorithms often motivate extensions to combinatorial bandit settings, where window-constrained UCB strategies are used to adapt to non-stationary environments, corresponding to Win-UCB in Table 6. MCTS-based methods cast multi-algorithm design as a sequential decision-making process, in which each design action influences subsequent states. A search tree is incrementally constructed to encode historical design trajectories, enabling a principled trade-off between exploration and exploitation. To control search complexity and handle non-stationary feedback, practical implementations commonly restrict search horizons or limit tree depth. This paradigm has been applied to both single-heuristic design and collaborative search over algorithm combinations or design strategies, corresponding to MCTS-OC, MCTS-Tuple and MCTS-Sampling in Table 6. Finally, fully LLM-driven approaches dispense with explicit search heuristics and rely on structured prompts to enable LLMs to autonomously perform operator selection, algorithm composition, and resource allocation. These methods exploit high-level semantic reasoning to dynamically adjust collaborative optimization strategies, offering greater flexibility at the cost of reduced explicit control, corresponding to LLM in Table 6. Notably, most multi-heuristic design frameworks treat single-heuristic design methods as modular building blocks. In this study, EOH is adopted as the foundational single-algorithm design module across all compared frameworks, with explicit management of algorithm ideas. Among these frameworks, UCB-based methods and those constructing explicit design spaces typically require a warm-start phase for initialization. 

G.2 Resource Consumption 

The authors of ReEvo (Ye et al. 2024) argued that efficiency benchmarking for LLM-EPS methods should focus on the number of fitness evaluations rather than the number of LLM calls. Similarly, MCTS AHD, as the most recent LLM-based AHD method at the time of its submission, also follows this benchmarking protocol (Zheng et al. 2025b). Accordingly, in this study, the performance of different methods is compared by controlling for a similar number of fitness evaluations, ensuring consistency in assessment. The key algorithmic parameters of E2OC for solving FJSP are summarized in Table 7, including the outer-layer MCTS configuration, the number of operator-rotation iterations, as well as parameters related to the algorithm generator and the evaluator. Each newly designed operator combination is repeatedly embedded into MOEAs for optimization, and its performance is assessed by averaging the resulting HV or IGD values. The overall multi-algorithm design process of E2OC is realized through iterative interactions between the operator generator and the prompt generator.                         

> Type Component Hyperparameters Value Offline
> LLM Model deepseek-chat Temperature 1.0 MCTS Outer iteration 30 Number of initial operator 4Number of initial added prompt 3* Operator Rotation Middle iteration 5Generator Inner iteration 5Operator population size 5Max sampling number 25 Evaluator Iteration 15* Solution population size 100* Number of validations 3*
> Online  Evaluation Iteration 30* Solution population size 200* Number of validations 5*

Table 7: Overview of hyperparameters used in E2OC. The values of the parameters with * are defined by the problem, the gray highlighting is defined by the experiment, all others are default values. The number of evaluations required for algorithm design equals the number of generated algorithms and is given by 

(iter out + 1) × iter mid × Lmax × sam max . (14) Here, iter out + 1 denotes the sum of the warm-up stage and the outer MCTS iterations, iter mid represents the number of operator-rotation steps, and sam max is the maximum number of newly generated algorithms accumulated by the internal algorithm generator. The algorithm generator supports different design modules, such as EOH and ReEvo. To eliminate the influence of heterogeneous population selection mechanisms across different generators, sam max is used as a unified upper bound on the number of algorithms generated per design task, while the remaining parameters follow the settings reported in the corresponding literature. Compared with other methods, E2OC additionally relies on the prompt generator to construct the design strategy space for operator combinations, which incurs Lmax × AP calls to the LLM interface. 

G.3 MOEAs parameter settings 

Directly applying newly designed operator combinations in MOEAs to optimize MCOPs does not yield reliable quantitative performance. Instead, as shown in Table 7 regarding the number of verifications, multiple validations are required, and performance must be assessed based on the aggregated results of these repeated evaluations, which incurs higher computational costs. In this study, three classical multi-objective evolutionary algorithms (MOEAs) are employed as baseline methods: NSGA-II (Deb et al. 2002), NSGA-III (Deb and Jain 2014), and MOEA/D (Qingfu Zhang and Hui Li 2007). The key parameter settings are summarized below, serving as default values for all benchmark experiments. These settings can be adjusted according to problem scale and complexity. • NSGA-II and NSGA-III: For Bi-FJSP and Tri-FJSP, the population size is set to 100 with a maximum of 250 generations. For Bi-TSP and Tri-TSP, the population size and maximum generations are set to 100 and 250, respectively. • MOEA/D: The population size is set to 150, with a maximum of 200 generations. The neighborhood size is 20, and the probability of selecting individuals from the neighborhood is 0.9. All algorithms employ the same initial neighborhood operators. For FJSP, Simulated Binary Crossover (SBX) and polynomial mutation are used with consistent crossover and mutation probabilities. For TSP, the local search operators OR-Opt, 2-Opt, and 3-Opt are applied. Reference points are set identically across all benchmark instances. These parameter settings ensure a reasonable balance between exploration and exploitation across all MOEAs while maintaining consistency for fair comparisons in benchmark evaluations. 

G.4 Automated design methods parameter settings 

To ensure a fair and consistent comparison with existing LLM-based automated algorithm design methods, we normalize the computational budget across all competing approaches using a unified algorithm evaluation resources. Comparison with single-heuristic design methods. When comparing against single-heuristic design methods, the multi-algorithm design problem is decomposed into a sequence of independent single-algorithm design tasks. The total evaluation budget is fixed and evenly distributed across these sub-tasks. For EOH, the population size is set to 20, consistent with the original implementation, while the algorithm terminates upon reaching a predefined maximum number of sampled candidates rather than a fixed number of generations. ReEvo explicitly constrains the number of newly constructed prompts. To ensure comparability, this limit is set to Lmax × AP , matching the prompt budget used in E2OC. All remaining baseline methods adopt the parameter settings recommended in their respective studies and are likewise terminated based on the maximum number of sampled designs. 

Comparison with multi-heuristic design methods. For the comparison with multi-heuristic design frameworks, we still use the same total evaluation budget. To accurately compare the performance of different multi-algorithm search frameworks, we ensure that the unit design and evaluation resources for each individual algorithm are consistent and that all evaluations are performed on EOH. Specifically, the maximum number of evaluations allocated to a single algorithm design task within one decision round is fixed and defined as a standard singgle algorithm design resource . This definition enables a principled comparison across frameworks with fundamentally different control structures. In CD framework, the number of rotation iterations determines how many times algorithms are optimized in an alternating manner. Within each rotation, operators are designed sequentially, and the design of one operator consumes exactly one standard resource unit. Accordingly, the total number of rotation steps is set to (iter out + 1) × iter mid , which aligns the overall resource usage with that of E2OC. UCB-based framework do not follow a predetermined design order but instead dynamically select algorithms based on estimated utility. Under the unified resource definition, the total number of available standard resource units is set to (iter out +1) × iter mid × Lmax , reflecting the additional flexibility introduced by operator-level selection. Among the MCTS-based variants, MCTS OC does not perform explicit search over design strategy spaces. As a result, its effective outer-loop iteration count is set to (iter out + 1) × iter mid × Lmax , where each tree node corresponds to one standard algorithm-design resource unit. In contrast, MCTS-Tuple and MCTS-Fixing explicitly explore strategy-level decision spaces and therefore adopt the same parameter settings as E2OC. It is worth noting that the parameter settings of the LLM-based decision framework are consistent with those of UCB-related methods. Under these unified resource allocation rules, all methods are evaluated with an equivalent number of standard algorithm-design resource units, ensuring that observed performance differences can be attributed to the quality of the multi-algorithm search mechanisms rather than disparities in evaluation budgets. 

## H Additional Experiment Results 

H.1 Comparison with Expert-Designed Operators 

To systematically assess the performance gap between E2OC and expert-designed operators, we conduct comparative experiments against classical operators and their manually constructed combinations on the TSP. NSGA-II is adopted as the multi-objective baseline algorithm. The evaluated operator set includes classical local search heuristics for TSP, named 2opt , 3opt , and oropt ,as well as commonly used genetic operators such as ox and swap. These operators are organized into three categories. The first category consists of individual operators (2opt, 3opt, and oropt). The second category includes hybrid combinations of crossover, mutation, and local search, namely ox swap , ox swap 2opt , ox swap 3opt , and ox swap oropt . The third category contains sequential compositions of classical local search operators with different execution orders, including 2opt 3opt oropt ,

3opt 2opt oropt , and oropt 2opt 3opt . Among these, the combination oropt 2opt 3opt exhibits the worst average performance and is therefore selected as the initial operator configuration for E2OC. The RI is measured with respect to this baseline, following the definition in Section F.3. The experimental results are summarized in Table 8. The results indicate that the standalone 2opt operator achieves the best HV performance, surpassing multiple manually designed operator combinations. The convergence trends of HV and IGD, and the Pareto front for all operators in Bi-TSP20, 50, and 100 are shown in Figure 9. Although the combination of ox and swap yields a relative improvement of 2.76% on the bi-objective TSP20 instance, further incorporating local search operators such as 2opt leads to performance degradation. To analyze the influence of operator ordering, different permutations of 2opt, 3opt, and oropt are evaluated within the third category. All reordered combinations exhibit inferior performance, with varying degrees of degradation, suggesting the presence of implicit operator incompatibilities that are difficult to resolve through manual composition. Using the consistently worst-performing oropt 2opt 3opt as the starting configuration, E2OC achieves the best performance on TSP50 and TSP100. Through a progressive search over operator design principles and composition strategies, E2OC not only substantially improves upon the initial configuration but also outperforms the best expert-designed operator, 2opt. 

H.2 Generalization Comparison on TSPs with Different Scales 

This section further examines the generalization capability of operators designed by E2OC by comparing them with the best expert-designed operator (2opt) and the initial operator configuration (oropt 2opt 3opt) on larger-scale Bi-TSP150 and Bi-TSP200 instances, as summarized in Table 9. In Bi-TSP150 and Bi-TSP200, E2OC achieves relative improvements of approximately 0 25 50 75 100 125 150 175 200 

Generation 

0.35 

0.40 

0.45 

0.50 

0.55 

0.60 

0.65 

> HV

HV (mean ± CI) (a) HV of Bi-TSP20 0 25 50 75 100 125 150 175 200 

Generation 

0.15 

0.20 

0.25 

0.30 

0.35 

0.40 

0.45 

0.50 

0.55 

> HV

HV (mean ± CI) (b) HV of Bi-TSP50 0 25 50 75 100 125 150 175 200 

Generation 

0.10 

0.15 

0.20 

0.25 

0.30 

0.35 

0.40 

> HV

HV (mean ± CI) (c) HV of Bi-TSP100 4 6 8 10 12 

obj1 

3

4

5

6

7

8

9

10 

> obj2

Pareto Front (best run per method) 

(d) PF of Bi-TSP20 10 15 20 25 

obj1 

7.5 

10.0 

12.5 

15.0 

17.5 

20.0 

22.5 

25.0 

> obj2

Pareto Front (best run per method) (e) PF of Bi-TSP50 25 30 35 40 45 

obj1 

20 

25 

30 

35 

40 

45 

> obj2

Pareto Front (best run per method) (f) PF of Bi-TSP100 0 25 50 75 100 125 150 175 200 

Generation 

0.0 

0.1 

0.2 

0.3 

0.4 

0.5 

0.6 

0.7 

> IGD

IGD (mean ± CI) 

(g) IGD of Bi-TSP20 0 25 50 75 100 125 150 175 200 

Generation 

0.0 

0.2 

0.4 

0.6 

0.8 

> IGD

IGD (mean ± CI) (h) IDG of Bi-TSP50 0 25 50 75 100 125 150 175 200 

Generation 

0.0 

0.2 

0.4 

0.6 

0.8 

1.0 

> IGD

IGD (mean ± CI) (i) IDG of Bi-TSP100 2opt 

3opt 

oropt 

ox_swap 

ox_swap_2opt 

ox_swap_3opt 

ox_swap_oropt 

2opt_3opt_oropt 

3opt_2opt_oropt 

oropt_2opt_3opt 

E2OC 

Figure 9: HV, IDG and PF performance of different operators in solving Bi-TSPs. Bi-TSP20 Bi-TSP50 Bi-TSP100 Method HV ↑ IGD ↓ RI ↑ HV ↑ IGD ↓ RI ↑ HV ↑ IGD ↓ RI ↑                                                                                                   

> 2opt 0.6117±0.0523 0.0684±0.1124 9.29% 0.4255±0.1016 0.2122±0.2124 22.11% 0.2882±0.0907 0.3322±0.2708 12.54% 3opt 0.6003±0.0497 0.0821±0.1082 7.26% 0.4143±0.0971 0.2310±0.2074 18.90% 0.2797±0.0868 0.3555±0.2643 9.22% oropt 0.5932±0.0489 0.1041±0.1026 5.99% 0.4001±0.0839 0.2587±0.1850 14.82% 0.2842±0.0792 0.3436±0.2418 10.98% ox swap 0.5751±0.0473 0.1348±0.0994 2.76% 0.3604±0.0641 0.3081±0.1487 3.43% 0.2513±0.0554 0.3970±0.1823 -1.89% ox swap 2opt 0.5472±0.0365 0.1971±0.0851 -2.22% 0.3312±0.0510 0.3746±0.1219 -4.94% 0.2342±0.0466 0.4459±0.1562 -8.55% ox swap 3opt 0.5540±0.0420 0.1859±0.0870 -1.02% 0.3332±0.0533 0.3677±0.1300 -4.36% 0.2339±0.0481 0.4548±0.1638 -8.67% ox swap oropt 0.5350±0.0349 0.2127±0.0786 -4.41% 0.3279±0.0496 0.3790±0.1217 -5.90% 0.2282±0.0422 0.4646±0.1462 -10.89% 2opt 3opt oropt 0.5576±0.0399 0.1710±0.0897 -0.37% 0.3505±0.0575 0.3618±0.1373 0.60% 0.2517±0.0579 0.4292±0.1844 -1.70% 3opt 2opt oropt 0.5637±0.0428 0.1637±0.0894 0.71% 0.3517±0.0586 0.3459±0.1354 0.94% 0.2546±0.0581 0.4174±0.1847 -0.58% oropt 2opt 3opt 0.5597±0.0430 0.1698±0.0929 0.00% 0.3484±0.0610 0.3596±0.1434 0.00% 0.2561±0.0584 0.4165±0.1871 0.00% E2OC 0.6104±0.0522 0.0710±0.1132 9.06% 0.4312±0.1023 0.1023±0.0105 23.75% 0.2929±0.0930 0.3628±0.2928 14.38%

Table 8: Comparison of NSGA-II solving TSP with different classical operators. The ox is the sequential crossover operator and swap is the random swap mutation operator. The results are divided into three groups: group 1 is a single operator solved independently, group 2 is a cross-variable operator plus other neighborhood operators, and group 3 is a different order in the combinations. Bold text indicates optimal performance, and gray highlighting represents the baseline operator combination, which is the initial operator for E2OC. 30.93% and 22.06%, respectively, over oropt 2opt 3opt. In contrast, the performance of the 2opt operator deteriorates as the problem scale increases. The convergence trends of HV and IGD, and the Pareto front of different method in Bi-TSP150 and 200 are shown in Figure 10. In terms of average HV, E2OC consistently achieves the best results across small-scale instances (Bi-TSP20-200), large-scale instances (Bi-TSP150-200), and the complete benchmark set, thereby demonstrating strong generalization performance across different problem scales.                                       

> Bi-TSP150 Bi-TSP200 Mean HV ↑
> Method HV ↑IGD ↓RI ↑HV ↑IGD ↓RI ↑TSP20-100 TSP150-200 TSP20-200 2opt 0.1205±0.0550 0.5239±0.2611 -10.48% 0.1026±0.0442 0.5905±0.2845 -18.27% 0.4418 0.1116 0.3097 oropt 2opt 3opt 0.1346±0.0485 0.4477±0.2232 0.00% 0.1256±0.0454 0.4591±0.2672 0.00% 0.3881 0.1301 0.2849 E2OC 0.1762±0.0647 0.7430±0.5519 30.93% 0.1533±0.0554 0.5150±0.4603 22.06% 0.4448 0.1648 0.3328

Table 9: Comparison of NSGA-II for solving TSP of different sizes with different operators. TSP20-100 refers to the instance set containing TSP20, 50, and 100, and the same applies to others. 

H.3 Interpretability analysis 

During the warm-start phase, E2OC constructs a language space of design thoughts for each operator, composed of multiple improvement suggestions. Similar to multi-operator combinations, these design thoughts exhibit complex and hard-to-quantify coupling relationships. In E2OC, the number of initial added prompts is controlled by the parameter AP . A larger AP yields a richer set of operator design thoughts, but also enlarges the combinatorial design space, thereby requiring more computational resources to identify effective design strategies, i.e., optimal combinations of thoughts. This results in an inherent trade-off between search cost and design space expressiveness. To investigate this effect, we conduct a sensitivity analysis on AP , as reported in Table 3. Moreover, different operator design thoughts often possess implicit coupling relations, such as mutual reinforcement, competi-tion, or redundancy. The progressive search of design thought combinations via MCTS in E2OC can be interpreted as an attempt to quantify and exploit these latent interactions through performance-driven evaluation. Taking the Bi-FJSP as an example, we analyze the multi-level operator design thought space generated by E2OC with AP = 3 and NSGA-II as the warm-start baseline. For the FJSP setting, this space includes design thoughts associated with operators acting on different coding regions of the chromosome, namely operation crossover and operation mutation operators, as well as machine crossover and machine mutation operators, and it has been distinguished by different colors in Figure 11. In E2OC, initial design thoughts, code templates, and semantic descriptions are required for each operator prior to the warm-start phase. For multi-objective optimization operators, we adopt a minimal and generic initialization principle: ensuring legality and robustness while pursuing performance improvement. The design thoughts of other operators are automatically derived by the LLM through advantage analysis of high-performing operators observed during warm-start, resulting in structured improvement suggestions. As summarized in Table 10, these suggestions emphasize different design focuses across operators. The combinations of such heterogeneous focuses constitute the diversity of design strategies and form the basis of interpretability in E2OC. 0 25 50 75 100 125 150 175 200 

> Generation
> 0.05
> 0.10
> 0.15
> 0.20
> 0.25
> HV
> HV (mean ± CI)

(a) HV of Bi-TSP150 35 40 45 50 55 60 65 70 

> obj1
> 40
> 45
> 50
> 55
> 60
> 65
> 70
> obj2

Pareto Front (best run per method) (b) PF of Bi-TSP150 0 25 50 75 100 125 150 175 200  

> Generation
> 0.0
> 0.2
> 0.4
> 0.6
> 0.8
> 1.0
> 1.2
> IGD
> IGD (mean ± CI)

(c) IDG of Bi-TSP150 0 25 50 75 100 125 150 175 200 

> Generation
> 0.025
> 0.050
> 0.075
> 0.100
> 0.125
> 0.150
> 0.175
> 0.200
> 0.225
> HV
> HV (mean ± CI)

(d) HV of Bi-TSP200 60 70 80 90  

> obj1
> 60
> 65
> 70
> 75
> 80
> 85
> 90
> 95
> 100
> obj2
> Pareto Front (best run per method)

(e) PF of Bi-TSP200 0 25 50 75 100 125 150 175 200  

> Generation
> 0.0
> 0.2
> 0.4
> 0.6
> 0.8
> 1.0
> 1.2
> IGD
> IGD (mean ± CI)

(f) IDG of Bi-TSP200 oropt_2opt_3opt E2OC 2opt 

Figure 10: HV, IDG and PF performance of different operators in solving Bi-TSPs with different scales. 

Operator Notation Focus 

Operation Crossover p1-0 Predefined: Constraint- and robustness-first performance optimization 

p1-1 Pareto preservation and generation-aware exploration 

p1-2 Hypervolume-driven offspring selection 

p1-3 Parent-proximity control and convergence Operation Mutation p2-0 Predefined: Constraint- and robustness-first performance optimization 

p2-1 HV-aware adaptivity and diversity preservation 

p2-2 Exploration control via mutation rate adaptation 

p2-3 Structural diversification driven by HV contribution Machine Crossover p3-0 Predefined: Constraint- and robustness-first performance optimization 

p3-1 Performance-aware crossover and diversity maintenance 

p3-2 Fitness-weighted recombination and feasibility handling 

p3-3 Fitness-landscape-guided exploration Machine Mutation p4-0 Predefined: Constraint- and robustness-first performance optimization 

p4-1 Multi-point exploration with experience guidance 

p4-2 Structural diversity through value replacement 

p4-3 Adaptivity and exploration intensity control Table 10: The focus of different operator design suggestions in the language space constructed by E2OC in Bi-FJSP. 

H.4 Designed Operators 

This section compares the FJSP crossover operators generated by E2OC with those obtained from manual design and EOH, focusing on their design motivations and implementation characteristics. Although EOH and E2OC both employ LLMs to assist operator construction, they differ in how design knowledge is represented and incorporated into the final operators. The specific Design suggestions:                          

> Improve performance while
> meeting legality and robustness
> requirements.
> -Recommends non -uniform,
> generation dependent mutation for
> exploration.
> -Emphasizes maintaining the
> Pareto front during crossover.
> -Advocates specialized mutation to
> expand objective -space coverage.
> -Highlights selecting offspring that
> directly improve HV.
> -Introduces non -uniform crossover
> to preserve parent similarity.
> -Suggests post -crossover mutation
> to accelerate HV convergence.
> Design suggestions:
> Improve performance while
> meeting legality and robustness
> requirements.
> -Suggests adaptive crossover points
> driven by performance metrics.
> -Proposes blending strategies to
> preserve diversity and improve HV.
> -Recommends fitness -weighted
> gene blending.
> -Advocates non -uniform crossover
> for broader exploration.
> -Emphasizes repair mechanisms to
> ensure feasibility under machine
> constraints.
> -Introduces adaptive crossover
> points based on the fitness
> landscape.
> -Utilizes non -uniform crossover to
> maintain diversity and enhance HV.
> Design suggestions:
> Improve performance while
> meeting legality and robustness
> requirements.
> -Proposes multi -point mutation to
> explore multiple regions
> simultaneously.
> -Suggests heuristic, performance -
> informed selection of mutation
> indices.
> -Recommends swap -based
> mutation for stronger diversity.
> -Advocates Gaussian or smooth
> mutations for controlled exploration.
> -Suggests increasing perturbation
> range for broader exploration.
> -Emphasizes adaptive mutation rates
> based on population performance.
> Design suggestions:
> Improve performance while
> meeting legality and robustness
> requirements.
> Suggests adaptive mutation guided
> by hypervolume improvement.
> Proposes blending -based mutations
> to maintain solution diversity.
> -Recommends non -uniform
> mutation to strengthen exploration.
> -Emphasizes adaptive mutation
> rates based on solution
> performance and HV.
> -Advocates adaptive mutation rates
> using hypervolume contribution.
> -Introduces two -point exchange or
> inversion for stronger search -space
> diversification.
> OP_Crossover
> OP_Mutation
> MA_Crossover
> MA_Mutation

Initial 

Initial 

Initial 

Initial 

p1 -0

p1 -3

p2 -0

p2 -3

p3 -0

p3 -3

p4 -0

p4 -3

p1 -2

p1 -4

p2 -2

p2 -4

p3 -2

p3 -4

p4 -4

p4 -2Figure 11: Example of a language space constructed by E2OC in Bi-FJSP implementations of these operators are shown in Figure 13 and Figure 12. The performance differences are shown in Table 3. For the machine-selection crossover, shown in Figure 13, the manually designed operator applies a single-point positional recombination, which is simple and problem-agnostic but ignores solution-level feedback. The EOH-designed operator empha-sizes structural preservation by explicitly retaining identical decision components and introducing random exchanges only on divergent positions, reflecting a design bias toward stable inheritance within a single-operator evolution setting. In contrast, the E2OC-designed operator incorporates objective-space distance into the crossover decision, adaptively adjusting recombination strength according to parent similarity. This behavior emerges from E2OC’s progressive design strategy search, where different recombination principles are explored and selected through operator rotation under performance feedback, rather than being fixed a priori. For the operation-sequence crossover, shown in Figure 12, manually designed and EOH-designed operators remain within positional segment exchange, differing mainly in recombination granularity. The E2OC-designed operator instead reformulates crossover in a continuous geometric space, where offspring are generated via fitness-aware interpolation between parent representations. This design reflects E2OC’s ability to explore couplings between operators and evaluation feedback, as the operator form is shaped not only by structural validity but also by how effectively it cooperates with other operators under repeated evaluation. Such non-positional recombination strategies are difficult to obtain through isolated heuristic evolution but naturally arise under E2OC’s multi-operator co-evolution framework. Overall, the observed performance advantages of E2OC-designed operators stem not from increased operator complexity, but from the systematic exploration of design strategies and their interactions enabled by operator rotation evolution. By allowing def Operation _Crossover (parent1: np.ndarray , parent2: np.ndarray , n_vars: 

int ) -> Tuple[np.ndarray, np.ndarray]: 

# Implement operation priority crossover 

if n_vars < 2: 

# Direct copy for extremely small length to avoid randint(1,1) error 

return parent1.copy(), parent2.copy() 

cp = np.random.randint(1, n_vars) 

child1 = np.concatenate([parent1[:cp], parent2[cp:]]) 

child2 = np.concatenate([parent2[:cp], parent1[cp:]]) 

return child1, child2 

def Operation _Crossover (parent1: np.ndarray , parent2: np.ndarray , n_vars: int ) ->

Tuple[np.ndarray, np.ndarray]: 

# Placeholder for fitness -based alpha calculation 

def calculate_alpha (fitness1, fitness2): 

return 0.5 + 0.2 * (fitness1 - fitness2) / (abs(fitness1) + abs(fitness2) + 1e -10) 

# Assume fitness is the negative of the objective function value for HV maximization 

# Replace with actual fitness evaluation logic 

fitness1 = -np.sum(parent1) 

fitness2 = -np.sum(parent2) 

alpha = calculate_alpha(fitness1, fitness2) 

r1 = np.linalg.norm(parent1) 

r2 = np.linalg.norm(parent2) 

theta1 = np.arctan2(parent1[1:], parent1[: -1]) if n_vars > 1 else np.array([]) 

theta2 = np.arctan2(parent2[1:], parent2[: -1]) if n_vars > 1 else np.array([]) 

# Cyclic rotation of angles 

theta_child1 = np.roll(theta1, 1) * (1 - alpha) + theta2 * alpha 

theta_child2 = np.roll(theta2, 1) * (1 - alpha) + theta1 * alpha 

# Blend radii 

r_child1 = alpha * r1 + (1 - alpha) * r2 

r_child2 = (1 - alpha) * r1 + alpha * r2 

# Convert back to Cartesian coordinates 

def polar_to_cartesian (r, angles): 

if n_vars == 1: 

return np.array([r]) 

elif n_vars == 2: 

return np.array([r * np.cos(angles[0]), r * np.sin(angles[0])]) 

else: 

coords = np.zeros(n_vars) 

coords[0] = r 

for i in range(1, n_vars - 1): 

coords[i] = r * np.prod(np.cos(angles[:i])) * np.sin(angles[i - 1]) 

coords[ -1] = r * np.prod(np.cos(angles[: n_vars - 2])) 

return coords 

child1 = polar_to_cartesian(r_child1, theta_child1) 

child2 = polar_to_cartesian(r_child2, theta_child2) 

return child1, child2 

## Initial 

## E2OC 

def Operation _Crossover (parent1: np.ndarray , parent2: np.ndarray , n_vars: 

int ) -> Tuple[np.ndarray, np.ndarray]: 

if parent1.shape != (n_vars,) or parent2.shape != (n_vars,): 

return parent1.copy(), parent2.copy() 

try: 

point1, point2 = np.sort(np.random.choice(range(1, n_vars), size=2, 

replace=False)) 

child1 = np.concatenate([parent1[:point1], parent2[point1:point2], 

parent1[point2:]]) 

child2 = np.concatenate([parent2[:point1], parent1[point1:point2], 

parent2[point2:]]) 

child1 = np.clip(child1, 0, 1) 

child2 = np.clip(child2, 0, 1) 

return child1, child2 

except: 

return parent1.copy(), parent2.copy() 

## EOH Figure 12: Operation crossover operators designed by EOH and E2OC on FJSP. multiple design thoughts to be decoupled, recombined, and empirically validated across operators, E2OC produces operators that exhibit more adaptive and context-aware recombination behaviors, leading to more robust performance on FJSP instances. def Machine _Crossover (parent1: np.ndarray , parent2: np.ndarray , n_vars: int ) -

> Tuple[np.ndarray, np.ndarray]: 

# Randomly select crossover point 

cross_point = np.random.randint(1, n_vars) 

# Create offspring 

child1 = np.concatenate([parent1[:cross_point], parent2[cross_point:]]) 

child2 = np.concatenate([parent2[:cross_point], parent1[cross_point:]]) 

return child1, child2 

def Machine _Crossover (parent1: np.ndarray , parent2: np.ndarray , n_vars: int ) -

> Tuple[np.ndarray, np.ndarray]: 

obj_distance = np.linalg.norm(parent1 - parent2) 

# Adjust crossover probability based on objective space distance 

crossover_prob = 0.5 + 0.3 * (1 - obj_distance / np.max([obj_distance, 1e -6])) 

mask = np.random.rand(n_vars) < crossover_prob 

child1 = np.where(mask, parent1, parent2) 

child2 = np.where(~mask, parent1, parent2) 

return child1, child2 

## Initial 

## E2OC 

def Machine _Crossover (parent1: np.ndarray , parent2: np.ndarray , n_vars: int ) -

> Tuple[np.ndarray, np.ndarray]: 

common_mask = parent1 == parent2 

divergent_mask = ~common_mask 

child1 = np.empty(n_vars, dtype=parent1.dtype) 

child2 = np.empty(n_vars, dtype=parent1.dtype) 

child1[common_mask] = parent1[common_mask] 

child2[common_mask] = parent1[common_mask] 

swap_mask = np.random.random(n_vars) < 0.5 

swap_mask &= divergent_mask 

child1[swap_mask] = parent2[swap_mask] 

child2[swap_mask] = parent1[swap_mask] 

keep_mask = divergent_mask & ~swap_mask 

child1[keep_mask] = parent1[keep_mask] 

child2[keep_mask] = parent2[keep_mask] 

return child1, child2 

## EOH Figure 13: Machine crossover operators designed by EOH and E2OC on FJSP.