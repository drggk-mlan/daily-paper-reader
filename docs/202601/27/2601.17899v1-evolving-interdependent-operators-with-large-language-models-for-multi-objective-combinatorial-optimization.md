# Evolving Interdependent Operators with Large Language Models for Multi-Objective Combinatorial Optimization
# 利用大语言模型演化多目标组合优化的互依算子

**Authors**: Junhao Qiu, Xin Chen, Liang Ge, Liyong Lin, Zhichao Lu, Qingfu Zhang \
**Date**: 2026-01-25 \
**PDF**: https://arxiv.org/pdf/2601.17899v1 \
**Tags**: <span class="tag-label tag-green">LNS</span> <span class="tag-label tag-green">EOH</span> <span class="tag-label tag-green">EAA</span> \
**Score**: 10.0 \
**Evidence**: 基于大语言模型的自动化启发式设计与算子演化 \
**TLDR**: 提出E2OC框架，利用大模型演化多目标优化中的相互依赖邻域搜索算子。

---

## 速览
**TLDR**：提出 E2OC 框架，利用大模型和蒙特卡洛树搜索协同进化多目标优化中的相互依赖算子。 \
**Motivation**：现有的自动化启发式设计方法通常独立优化单个算子，忽视了多个算子之间复杂的动态耦合关系。 \
**Method**：将多算子优化建模为马尔可夫决策过程，结合蒙特卡洛树搜索和算子轮换机制，实现设计策略与代码的协同进化。 \
**Result**：在不同目标和规模的任务中，E2OC 的性能均优于现有的最先进方法，并展现出强大的泛化能力。 \
**Conclusion**：该研究证明了通过显式探索算子间的相互依赖性，可以显著提升多目标组合优化算法的性能。

---

## Abstract
Neighborhood search operators are critical to the performance of Multi-Objective Evolutionary Algorithms (MOEAs) and rely heavily on expert design. Although recent LLM-based Automated Heuristic Design (AHD) methods have made notable progress, they primarily optimize individual heuristics or components independently, lacking explicit exploration and exploitation of dynamic coupling relationships between multiple operators. In this paper, multi-operator optimization in MOEAs is formulated as a Markov decision process, enabling the improvement of interdependent operators through sequential decision-making. To address this, we propose the Evolution of Operator Combination (E2OC) framework for MOEAs, which achieves the co-evolution of design strategies and executable codes. E2OC employs Monte Carlo Tree Search to progressively search combinations of operator design strategies and adopts an operator rotation mechanism to identify effective operator configurations while supporting the integration of mainstream AHD methods as the underlying designer. Experimental results across AHD tasks with varying objectives and problem scales show that E2OC consistently outperforms state-of-the-art AHD and other multi-heuristic co-design frameworks, demonstrating strong generalization and sustained optimization capability.

## 摘要
邻域搜索算子对多目标演化算法（MOEAs）的性能至关重要，且高度依赖专家设计。尽管近期基于大语言模型（LLM）的自动启发式设计（AHD）方法取得了显著进展，但它们主要独立地优化单个启发式算法或组件，缺乏对多个算子之间动态耦合关系的显式探索和利用。本文将 MOEAs 中的多算子优化建模为马尔可夫决策过程，从而能够通过序列决策来改进互依算子。为此，我们为 MOEAs 提出了算子组合演化（E2OC）框架，实现了设计策略与可执行代码的协同演化。E2OC 采用蒙特卡洛树搜索来逐步搜索算子设计策略的组合，并采用算子轮换机制来识别有效的算子配置，同时支持将主流 AHD 方法集成为底层设计器。在具有不同目标和问题规模的 AHD 任务上的实验结果表明，E2OC 始终优于最先进的 AHD 和其他多启发式协同设计框架，展示了强大的泛化能力和持续的优化能力。

---

## 论文详细总结（自动生成）

这是一份关于论文《Evolving Interdependent Operators with Large Language Models for Multi-Objective Combinatorial Optimization》的结构化深度分析报告：

### 1. 核心问题与研究动机
*   **核心问题**：如何在多目标组合优化（MCOP）中，利用大语言模型（LLM）自动设计并优化多个**相互依赖（Interdependent）**的搜索算子。
*   **研究动机**：
    *   **专家依赖性**：多目标演化算法（MOEA）的性能高度依赖于交叉、变异和局部搜索算子的设计，传统上这需要深厚的专家知识。
    *   **现有方法局限**：目前的自动化启发式设计（AHD）方法（如 EoH, FunSearch）大多独立优化单个算子，忽视了算子之间在搜索过程中的动态耦合和协同效应。
    *   **复杂性挑战**：在多目标场景下，算子不仅要推动收敛，还要维持多样性，算子间的组合爆炸使得搜索最优配置变得极具挑战。

### 2. 方法论：E2OC 框架
E2OC（Evolution of Operator Combination）将多算子优化建模为**马尔可夫决策过程（MDP）**，核心思想是实现“设计策略（思想）”与“执行代码”的协同演化。

*   **关键技术细节**：
    1.  **热启动初始化（Warm-start）**：首先对各个算子进行独立的初步演化，利用 LLM 提取出高性能算子的“设计思想”（Design Thoughts），构建初始的语言策略空间。
    2.  **多层思想语言空间**：将算子的改进建议转化为可组合的语义模块，形成高维的策略搜索空间。
    3.  **渐进式设计策略搜索（MCTS）**：引入蒙特卡洛树搜索（MCTS）来探索不同算子设计思想的组合。树的每一层代表一个算子的设计决策，通过选择、扩展、模拟和反向传播来定位最有潜力的策略路径。
    4.  **算子轮换演化（Operator Rotation）**：在评估阶段，采用轮换机制——每次只更新一个算子的代码，而保持其他算子固定。这种方式能有效捕捉算子间的耦合关系，并降低多目标评估的高昂计算成本。
    5.  **标量化评估**：使用超体积（HV）或反转生成距离（IGD）等指标将多目标表现转化为标量分数，指导 MCTS 的奖励反馈。

### 3. 实验设计
*   **实验场景**：
    *   **柔性车间调度问题（FJSP）**：双目标与三目标（最小化完工时间、总机器负载、最大机器负载）。
    *   **旅行商问题（TSP）**：双目标与三目标，涉及 20/50/100/150/200 个节点的规模。
*   **Benchmark 与对比方法**：
    *   **专家设计算法**：NSGA-II, NSGA-III, MOEA/D, PPLS/D-C。
    *   **单启发式 AHD 方法**：Random, FunSearch, EoH, ReEvo, MCTS-AHD。
    *   **多启发式协同设计框架**：基于坐标下降（CD）、UCB 算法、纯 LLM 决策等变体。
*   **评估指标**：Hypervolume (HV) 和 Inverted Generational Distance (IGD)。

### 4. 资源与算力
*   **LLM 模型**：主要使用 **DeepSeek-chat**（基于其高性价比），同时也对比了 GPT-4o-mini, Qwen, Gemini 2.5 Pro 等模型。
*   **算力成本**：
    *   文中明确记录了 Token 成本（如 DeepSeek-chat 完成一次完整设计约需 1.14 美元，消耗 3.34M Tokens）。
    *   硬件环境：Intel Core i7-12700F CPU。
    *   **未明确说明**：未提及具体的 GPU 训练时长，因为该方法主要依赖 API 调用进行推理和本地 CPU 进行启发式算法的评估。

### 5. 实验数量与充分性
*   **实验规模**：涵盖了从基础的 20 节点到复杂的 200 节点 TSP，以及 15 个不同规模的 FJSP 实例。
*   **消融与对比**：
    *   对比了 6 种不同的 LLM 背景模型。
    *   测试了 4 种不同的 MCTS 变体。
    *   进行了**持续优化分析**（连续运行三次 E2OC，验证性能是否持续提升）。
*   **客观性**：所有对比方法均在相同的 LLM 采样预算和评估次数下进行，确保了公平性。实验通过多次独立运行取均值，并提供了置信区间。

### 6. 主要结论与发现
*   **超越专家**：E2OC 设计的算子组合在所有任务中均显著优于专家手工设计的算子，在双目标 FJSP 上 HV 提升高达 **32.43%**。
*   **协同效应**：实验证明，显式考虑算子耦合（E2OC）比独立优化各个算子（如 EoH）能获得更好的全局性能。
*   **泛化能力**：在小规模实例上设计的算子策略，可以直接推广到大规模实例（如从 TSP100 推广到 TSP200），且依然保持领先。
*   **持续进化**：E2OC 具有“自我改进”能力，通过迭代重构设计思想空间，算法性能随资源投入持续增长。

### 7. 优点与亮点
*   **解耦策略与代码**：通过 MCTS 在语义空间搜索“思想组合”，再由 LLM 生成代码，这种两层架构提高了搜索效率。
*   **算子轮换机制**：巧妙地解决了多算子同时变动导致的评估噪声问题，使得信用分配（Credit Assignment）更准确。
*   **高性价比**：证明了使用国产模型（DeepSeek）配合合理的搜索框架，可以达到甚至超过昂贵模型（GPT-4）的效果。

### 8. 不足与局限
*   **评估开销**：尽管引入了轮换机制，但多目标优化的评估（尤其是计算 HV）在大规模实例上依然非常耗时，限制了迭代次数。
*   **初始模板依赖**：虽然减少了手工设计，但仍需要初始的算子代码模板和基本的问题描述，完全“零代码”启动仍有难度。
*   **语义空间限制**：设计思想的提取依赖于 LLM 的总结能力，如果 LLM 无法准确捕捉高性能代码的本质，搜索空间质量会受限。

（完）
