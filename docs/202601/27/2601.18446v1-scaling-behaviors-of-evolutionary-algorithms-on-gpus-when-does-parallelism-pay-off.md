# Scaling Behaviors of Evolutionary Algorithms on GPUs: When Does Parallelism Pay Off?
# 演化算法在 GPU 上的扩展行为：并行化何时奏效？

**Authors**: Xinmeng Yu, Tao Jiang, Ran Cheng, Yaochu Jin, Kay Chen Tan \
**Date**: 2026-01-26 \
**PDF**: https://arxiv.org/pdf/2601.18446v1 \
**Tags**: <span class="tag-label tag-green">EOH</span> \
**Score**: 8.0 \
**Evidence**: GPU上进化算法的系统性研究 \
**TLDR**: 研究GPU并行化如何从根本上改变进化算法的行为与效率。

---

## 速览
**TLDR**：本研究探讨了 GPU 并行化对进化算法（EAs）性能和行为的深层影响，揭示了其在不同维度和种群规模下的扩展规律。 \
**Motivation**：现有研究多关注 GPU 带来的原始加速比，缺乏对并行化何时以及为何能从根本上提升进化算法性能的深入理解。 \
**Method**：对 16 种代表性进化算法在 30 个基准问题上进行了系统性实证研究，对比了不同问题维度和种群规模下 CPU 与 GPU 的执行表现。 \
**Result**：发现 GPU 加速效果受算法结构影响显著，且在大种群规模下能揭示出 CPU 环境下难以观察到的收敛与多样性动态。 \
**Conclusion**：GPU 并行化不仅是实现细节，更是影响进化算法评估、比较和设计的关键因素，建议采用固定时间而非固定评价次数的评估方式。

---

## Abstract
Evolutionary algorithms (EAs) are increasingly implemented on graphics processing units (GPUs) to leverage parallel processing capabilities for enhanced efficiency. However, existing studies largely emphasize the raw speedup obtained by porting individual algorithms from CPUs to GPUs. Consequently, these studies offer limited insight into when and why GPU parallelism fundamentally benefits EAs. To address this gap, we investigate how GPU parallelism alters the behavior of EAs beyond simple acceleration metrics. We conduct a systematic empirical study of 16 representative EAs on 30 benchmark problems. Specifically, we compare CPU and GPU executions across a wide range of problem dimensionalities and population sizes. Our results reveal that the impact of GPU acceleration is highly heterogeneous and depends strongly on algorithmic structure. We further demonstrate that conventional fixed-budget evaluation based on the number of function evaluations (FEs) is inadequate for GPU execution. In contrast, fixed-time evaluation uncovers performance characteristics that are unobservable under small or practically constrained FE budgets, particularly for adaptive and exploration-oriented algorithms. Moreover, we identify distinct scaling regimes in which GPU parallelism is beneficial, saturates, or degrades as problem dimensionality and population size increase. Crucially, we show that large populations enabled by GPUs not only improve hardware utilization but also reveal algorithm-specific convergence and diversity dynamics that are difficult to observe under CPU-constrained settings. Consequently, our findings indicate that GPU parallelism is not strictly an implementation detail, but a pivotal factor that influences how EAs should be evaluated, compared, and designed for modern computing platforms.

## 摘要
演化算法（EAs）越来越多地在图形处理器（GPU）上实现，以利用并行处理能力来提高效率。然而，现有研究主要强调将单个算法从 CPU 移植到 GPU 所获得的原始加速比。因此，这些研究对于 GPU 并行化何时以及为何从根本上使演化算法受益提供的见解有限。为了填补这一空白，我们研究了 GPU 并行化如何改变演化算法的行为，而不仅仅是简单的加速指标。我们对 30 个基准问题上的 16 种代表性演化算法进行了系统的实证研究。具体而言，我们在广泛的问题维度和种群规模范围内比较了 CPU 和 GPU 的执行情况。我们的结果表明，GPU 加速的影响具有高度异质性，并强烈依赖于算法结构。我们进一步证明，基于函数评估次数（FEs）的传统固定预算评估对于 GPU 执行是不够的。相比之下，固定时间评估揭示了在较小或实际受限的 FE 预算下无法观察到的性能特征，特别是对于自适应和面向探索的算法。此外，我们确定了不同的扩展机制，在这些机制中，随着问题维度和种群规模的增加，GPU 并行化是有益的、饱和的或退化的。至关重要的是，我们展示了由 GPU 实现的大规模种群不仅提高了硬件利用率，还揭示了在 CPU 受限环境下难以观察到的特定于算法的收敛和多样性动态。因此，我们的研究结果表明，GPU 并行化不仅仅是一个实现细节，而是一个影响现代计算平台上演化算法应如何评估、比较和设计的关键因素。

---

## 论文详细总结（自动生成）

这篇论文对演化算法（EAs）在 GPU 上的扩展行为进行了系统且深入的实证研究，探讨了并行化在何种条件下能真正发挥作用。以下是该论文的结构化总结：

### 1. 核心问题与研究动机
*   **核心问题**：GPU 并行化除了带来原始的计算加速外，如何从根本上改变演化算法的搜索行为、扩展性以及评估结果？
*   **研究背景**：
    *   传统研究多关注“加速比”（Speedup），即 CPU 与 GPU 的运行时间对比，忽视了算法结构的内在影响。
    *   传统的评估标准（如固定函数评价次数 FEs）在 GPU 环境下可能不再适用，因为 GPU 可以在极短时间内完成海量评价。
    *   GPU 使得大规模种群（Large Population）成为可能，但这种规模的改变对算法收敛和多样性动态的影响尚不明确。

### 2. 方法论
*   **核心思想**：通过在统一的硬件加速框架（EvoX）下，系统对比 16 种算法在不同维度（D）和种群规模（N）下的表现，识别 GPU 并行化的收益边界。
*   **关键技术细节**：
    *   **算法异质性分析**：将算法按计算密度、数据依赖性和同步需求分类。例如，矩阵运算密集的算法（如 CMA-ES）与同步需求高的算法（如 NSGA-III）在 GPU 上的表现截然不同。
    *   **评估范式转换**：提出从“固定评价次数（Fixed-FE）”转向“固定时间（Fixed-Time）”评估，以更真实地反映现代硬件下的搜索效率。
    *   **扩展机制识别**：通过指数级增加 D 和 N（从 16 到 8192），观察运行时间、吞吐量（NFEs）和解质量的变化曲线。
    *   **大种群动态研究**：分析大种群如何通过改变采样密度来影响协方差矩阵估计（CMA-ES）或遗传漂变（GA）。

### 3. 实验设计
*   **算法基准**：共 16 种算法。
    *   **单目标（SOEAs）**：PSO, CSO, DE, SaDE, GA (两种变体), CMA-ES, IPOP-CMA-ES。
    *   **多目标（MOEAs）**：NSGA-II, NSGA-III, SPEA2, IBEA, HypE, MOEA/D, RVEA, LMOCSO。
*   **测试问题**：共 30 个。
    *   **数值优化**：CEC2022 (F1-F5), Ackley, Griewank, Rosenbrock, Schwefel, Sphere, DTLZ (1-7), ZDT (1-3)。
    *   **神经演化（Neuroevolution）**：基于 Brax 物理引擎的 10 个任务（包括单目标和多目标机器人控制）。
*   **对比基准**：以 Intel Xeon CPU 上的执行表现作为 Baseline，对比两款不同架构的 GPU。

### 4. 资源与算力
*   **GPU 型号**：NVIDIA GeForce RTX 3090 (24GB GDDR6X) 和 NVIDIA GeForce RTX 2080 Ti (11GB GDDR6)。
*   **CPU 型号**：Intel Xeon Gold 6226R (16核, 2.90GHz)。
*   **软件框架**：所有实验均基于 **EvoX** 框架实现，确保了算法逻辑在不同硬件上的一致性和可重复性。
*   **实验时长**：包括固定 30 秒和 600 秒的运行测试。

### 5. 实验数量与充分性
*   **实验规模**：数值优化实验重复 15 次，神经演化实验重复 10 次。
*   **覆盖范围**：涵盖了从低维到高维（最高 8192 维）、从小种群到超大种群（最高 8192 个个体）的广泛区间。
*   **充分性评价**：实验设计非常充分且客观。通过控制变量法（固定 D 变 N，或固定 N 变 D）清晰地展示了性能拐点，且涵盖了数值函数与复杂的物理模拟任务，具有很强的说服力。

### 6. 主要结论与发现
*   **加速效果的异质性**：计算密集且数据独立的算法（如 CMA-ES, HypE）在 GPU 上收益巨大；而轻量级或同步频繁的算法（如 PSO, NSGA-III）在 GPU 上可能出现性能饱和甚至退化。
*   **评估标准的局限性**：在 GPU 上，固定 FE 预算往往过小，导致算法在未充分探索前就停止。固定时间评估能更好地揭示自适应算法（如 SaDE）的潜力。
*   **扩展行为规律**：GPU 在处理高维和大种群时，运行时间几乎保持常数（直到显存溢出），而 CPU 呈线性增长。
*   **大种群的科学价值**：大种群不仅是提高硬件利用率的手段，它还能显著改善某些算法的收敛稳定性（如 CMA-ES 的曲率估计更准）和多样性维持能力。

### 7. 优点
*   **视角独特**：跳出了单纯“比快”的圈子，深入探讨了并行化对算法设计论（Methodology）的影响。
*   **框架统一**：使用 EvoX 框架消除了底层实现差异对实验结果的干扰。
*   **实用性强**：为研究人员在现代计算平台上选择和设计演化算法提供了明确的指导原则。

### 8. 不足与局限
*   **硬件局限**：实验主要基于 NVIDIA GPU，未涉及 AMD GPU 或 TPU 等其他加速器，架构差异可能影响结论的普适性。
*   **算法实现依赖**：结论高度依赖于算法是否能被有效向量化（Vectorized）。对于某些本质上难以向量化的算法，GPU 的劣势可能被放大。
*   **问题类型限制**：主要集中在连续空间优化，未深入探讨离散或组合优化问题在 GPU 上的扩展行为。

（完）
