# RouteMoA: Dynamic Routing without Pre-Inference Boosts Efficient Mixture-of-Agents
# RouteMoA：无需预推理的动态路由提升高效多智能体混合

**Authors**: Jize Wang, Han Wu, Zhiyuan You, Yiming Song, Yijun Wang, Zifei Shan, Yining Li, Songyang Zhang, Xinyi Le, Cailian Chen, Xinping Guan, Dacheng Tao \
**Date**: 2026-01-26 \
**PDF**: https://arxiv.org/pdf/2601.18130v1 \
**Tags**: <span class="tag-label tag-green">EAA</span> \
**Score**: 6.0 \
**Evidence**: 高效代理混合与动态路由 \
**TLDR**: 提出一种高效的代理混合框架，通过动态路由降低推理成本。

---

## 速览
**TLDR**：RouteMoA 通过推理前的动态路由机制，在保持高性能的同时大幅降低了多模型协作（MoA）的计算成本和延迟。 \
**Motivation**：现有的 MoA 方法通常需要所有模型先完成推理再由 LLM 评判，导致在大型模型池中成本极高且效率低下。 \
**Method**：提出一种包含轻量级评分器预筛选、多评判者后验修正以及综合性能与成本的模型排序机制的动态路由框架。 \
**Result**：在大型模型池中，RouteMoA 在性能优于传统 MoA 的前提下，成功降低了 89.8% 的成本和 63.6% 的延迟。 \
**Conclusion**：该研究证明了通过推理前的智能路由可以实现高效、可扩展且低成本的多模型协作系统。

---

## Abstract
Mixture-of-Agents (MoA) improves LLM performance through layered collaboration, but its dense topology raises costs and latency. Existing methods employ LLM judges to filter responses, yet still require all models to perform inference before judging, failing to cut costs effectively. They also lack model selection criteria and struggle with large model pools, where full inference is costly and can exceed context limits. To address this, we propose RouteMoA, an efficient mixture-of-agents framework with dynamic routing. It employs a lightweight scorer to perform initial screening by predicting coarse-grained performance from the query, narrowing candidates to a high-potential subset without inference. A mixture of judges then refines these scores through lightweight self- and cross-assessment based on existing model outputs, providing posterior correction without additional inference. Finally, a model ranking mechanism selects models by balancing performance, cost, and latency. RouteMoA outperforms MoA across varying tasks and model pool sizes, reducing cost by 89.8% and latency by 63.6% in the large-scale model pool.

## 摘要
多智能体混合（Mixture-of-Agents, MoA）通过分层协作提升了大语言模型（LLM）的性能，但其密集的拓扑结构增加了成本和延迟。现有方法采用 LLM 评判器来过滤响应，但仍要求所有模型在评判前进行推理，因此无法有效降低成本。此外，这些方法缺乏模型选择标准，且在处理大规模模型池时面临挑战，因为全量推理成本高昂且可能超出上下文限制。为了解决这些问题，我们提出了 RouteMoA，这是一个具有动态路由的高效多智能体混合框架。它采用轻量级评分器，通过根据查询预测粗粒度性能来进行初步筛选，在无需推理的情况下将候选模型缩小到高潜力子集。随后，混合评判器基于现有模型输出，通过轻量级的自我评估和交叉评估来细化这些分数，在不增加额外推理的情况下提供后验修正。最后，模型排序机制通过平衡性能、成本和延迟来选择模型。RouteMoA 在各种任务和模型池规模上均优于 MoA，在大规模模型池中将成本降低了 89.8%，延迟降低了 63.6%。