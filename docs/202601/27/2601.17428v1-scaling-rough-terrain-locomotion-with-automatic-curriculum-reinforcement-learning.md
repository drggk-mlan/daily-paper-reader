# Scaling Rough Terrain Locomotion with Automatic Curriculum Reinforcement Learning
# 利用自动课程强化学习扩展崎岖地形运动能力

**Authors**: Ziming Li, Chenhao Li, Marco Hutter \
**Date**: 2026-01-24 \
**PDF**: https://arxiv.org/pdf/2601.17428v1 \
**Tags**: <span class="tag-label tag-green">EAA</span> \
**Score**: 6.0 \
**Evidence**: 强化学习的自动课程生成 \
**TLDR**: 提出LP-ACRL框架，在复杂的机器人运动任务中实现自动课程生成。

---

## 速览
**TLDR**：提出一种基于学习进度的自动课程强化学习框架，使四足机器人在复杂地形上实现高速稳定运动。 \
**Motivation**：传统的课程学习在复杂任务空间中难以预定义任务难度结构，限制了其在大规模场景下的扩展性。 \
**Method**：提出 LP-ACRL 框架，通过在线评估学习进度并自适应调整任务采样分布，实现无需先验知识的自动课程生成。 \
**Result**：ANYmal D 机器人在楼梯、斜坡和碎石等多种地形上实现了 2.5 m/s 的高速运动，突破了以往方法在复杂地形下的速度限制。 \
**Conclusion**：该方法具有强大的扩展性和实际应用价值，为复杂机器人任务空间的课程生成提供了稳健的基准。

---

## Abstract
Curriculum learning has demonstrated substantial effectiveness in robot learning. However, it still faces limitations when scaling to complex, wide-ranging task spaces. Such task spaces often lack a well-defined difficulty structure, making the difficulty ordering required by previous methods challenging to define. We propose a Learning Progress-based Automatic Curriculum Reinforcement Learning (LP-ACRL) framework, which estimates the agent's learning progress online and adaptively adjusts the task-sampling distribution, thereby enabling automatic curriculum generation without prior knowledge of the difficulty distribution over the task space. Policies trained with LP-ACRL enable the ANYmal D quadruped to achieve and maintain stable, high-speed locomotion at 2.5 m/s linear velocity and 3.0 rad/s angular velocity across diverse terrains, including stairs, slopes, gravel, and low-friction flat surfaces--whereas previous methods have generally been limited to high speeds on flat terrain or low speeds on complex terrain. Experimental results demonstrate that LP-ACRL exhibits strong scalability and real-world applicability, providing a robust baseline for future research on curriculum generation in complex, wide-ranging robotic learning task spaces.

## 摘要
课程学习在机器人学习中已展现出显著的有效性。然而，在扩展到复杂且广泛的任务空间时，它仍面临局限性。这类任务空间通常缺乏明确定义的难度结构，使得以往方法所需的难度排序难以定义。我们提出了一种基于学习进度的自动课程强化学习（LP-ACRL）框架，该框架在线估计智能体的学习进度并自适应地调整任务采样分布，从而在无需任务空间难度分布先验知识的情况下实现自动课程生成。使用 LP-ACRL 训练的策略使 ANYmal D 四足机器人能够在包括楼梯、坡道、碎石路和低摩擦平面在内的多种地形上，实现并保持 2.5 m/s 的线速度和 3.0 rad/s 的角速度稳定高速运动——而以往的方法通常局限于平坦地形上的高速或复杂地形上的低速。实验结果表明，LP-ACRL 展现出强大的可扩展性和现实世界适用性，为未来在复杂、广泛的机器人学习任务空间中进行课程生成研究提供了稳健的基准。