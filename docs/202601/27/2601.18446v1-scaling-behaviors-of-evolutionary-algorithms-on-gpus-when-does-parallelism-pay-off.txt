Title: Scaling Behaviors of Evolutionary Algorithms on GPUs: When Does Parallelism Pay Off?

URL Source: https://arxiv.org/pdf/2601.18446v1

Published Time: Tue, 27 Jan 2026 03:13:48 GMT

Number of Pages: 28

Markdown Content:
> BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 1

# Scaling Behaviors of Evolutionary Algorithms on GPUs: When Does Parallelism Pay Off? 

Xinmeng Yu, Tao Jiang, Ran Cheng, Yaochu Jin, and Kay Chen Tan 

Abstract â€”Evolutionary algorithms (EAs) are increasingly im-plemented on graphics processing units (GPUs) to leverage parallel processing capabilities for enhanced efficiency. However, existing studies largely emphasize the raw speedup obtained by porting individual algorithms from CPUs to GPUs. Consequently, these studies offer limited insight into when and why GPU parallelism fundamentally benefits EAs. To address this gap, we investigate how GPU parallelism alters the behavior of EAs beyond simple acceleration metrics. We conduct a systematic empirical study of 16 representative EAs on 30 benchmark problems. Specifically, we compare CPU and GPU executions across a wide range of problem dimensionalities and population sizes. Our results reveal that the impact of GPU acceleration is highly heterogeneous and depends strongly on algorithmic structure. We further demonstrate that conventional fixed-budget evaluation based on the number of function evaluations (FEs) is inadequate for GPU execution. In contrast, fixed-time evalua-tion uncovers performance characteristics that are unobservable under small or practically constrained FE budgets, particularly for adaptive and exploration-oriented algorithms. Moreover, we identify distinct scaling regimes in which GPU parallelism is beneficial, saturates, or degrades as problem dimensionality and population size increase. Crucially, we show that large popula-tions enabled by GPUs not only improve hardware utilization but also reveal algorithm-specific convergence and diversity dynamics that are difficult to observe under CPU-constrained settings. Consequently, our findings indicate that GPU parallelism is not strictly an implementation detail, but a pivotal factor that influences how EAs should be evaluated, compared, and designed for modern computing platforms. 

Index Terms â€”Evolutionary Algorithm, GPU Acceleration, Per-formance Benchmark 

I. I NTRODUCTION 

# EVOLUTIONARY algorithms are a class of population-based, derivative-free optimization methods inspired by natural selection. Due to their robustness and flexibility, EAs are particularly effective for nonconvex, discontinuous, and black-box optimization problems where gradient-based methods are inapplicable or unreliable [1], [2]. Canonical paradigms, such as Genetic Algorithms (GA) [3], Particle Swarm Optimization (PSO) [4], and Differential Evolution (DE) [5], form the methodological foundation for a wide range of real-world applications. These applications include medical diagnosis [6], [7], industrial process optimization [8], [9], and neural architecture search [10], [11]. Despite their broad applicability, the practical deployment of EAs has long been constrained by substantial computational cost. Large popula-tion sizes, extended evolutionary horizons, and expensive fit-ness evaluations frequently render comprehensive exploration infeasible under conventional CPU-based execution. Recent advances in parallel hardware, particularly GPUs, have significantly altered this computational landscape. GPUs offer massive data-level parallelism, which enables the simul-taneous evaluation of thousands of candidate solutions. Con-sequently, GPUs constitute a natural platform for population-based optimization. Motivated by this capability, a growing body of work has migrated EAs from CPUs to GPUs. These studies consistently report substantial speedups and reduced wall-clock time cost. Early studies demonstrated the feasibility of GPU-accelerated EAs [12], followed by GPU implemen-tations of PSO, DE, and related methods [13], [14]. More recently, general-purpose frameworks, such as EvoJAX [15], evosax [16], and EvoX [17], have further lowered imple-mentation barriers by supporting batched fitness evaluations and modular evolutionary operators. Collectively, these efforts establish that EAs can achieve significant computational ac-celeration when executed on GPUs. However, a more fundamental question remains largely un-explored: what does GPU parallelism change for EAs beyond raw speed? Most existing studies evaluate GPU-accelerated EAs primarily through acceleration ratios obtained on specific algorithms, benchmarks, and hardware platforms. While such analyses effectively quantify computational gains, they offer limited insight into how GPU execution reshapes algorithm behavior, scalability, and evaluation outcomes across different evolutionary mechanisms. In particular, three critical gaps persist in the current literature. First, the benefits of GPU parallelism are highly heteroge-neous across EAs. Acceleration depends not only on compu-tational intensity but also on algorithmic structure, including data dependencies, synchronization requirements, and memory access patterns. As problem dimensionality and population size increase, GPU parallelism may yield substantial bene-fits, gradually saturate, or even degrade performance due to overheads and resource contention. Despite this complexity, the literature lacks a systematic understanding of when GPU parallelism is effective for EAs and under what conditions its advantages diminish. Second, EA performance is still predominantly evaluated using fixed numbers of FEs as a proxy for computational cost. This assumption is reasonable in CPU-based environments, where evaluations are processed sequentially at a relatively stable rate. Under GPU execution, however, population-level parallelism enables substantially different numbers of eval-uations to be completed within the same wall-clock time. Consequently, FE budgets that are standard in CPU-based studies may become disproportionately small from a GPU perspective, which prevents GPU-enabled algorithmic behav- 

> arXiv:2601.18446v1 [cs.NE] 26 Jan 2026 BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 2

iors from fully emerging and causes some search processes to terminate prematurely. Moreover, such limited FE budgets are often misaligned with practical deployment scenarios, in which performance is typically judged by time-to-solution rather than evaluation count. Thus, fixed-FE comparisons may no longer reflect practical efficiency or the true optimization potential of different EAs under GPU execution. Third, GPU execution fundamentally relaxes long-standing constraints on population size. Classical EAs typically employ small to moderate populations due to computational limita-tions, whereas GPUs make large-scale populations compu-tationally feasible. However, whether such large populations merely improve hardware utilization or instead induce quali-tatively different convergence and diversity dynamics remains an open question, with important implications for algorithm design, parameterization, and theoretical analysis. In this work, we address these gaps through a comprehen-sive empirical study of EAs under GPU parallelism. Rather than treating GPU acceleration as a purely implementation-level improvement, we explicitly examine how GPU execution reshapes the relationship among computational cost, evaluation budget, data scales, and evolutionary dynamics. We bench-mark sixteen representative single- and multi-objective EAs on both numerical optimization and neuroevolution tasks, and we systematically compare CPU and GPU execution across a wide range of problem dimensions and population sizes. Our analysis focuses on practical evaluation and scalability characteristics, rather than isolated speedup metrics. The main contributions of this paper are summarized as follows:  

> â€¢

We provide a systematic analysis of GPU acceleration across a diverse set of EAs. Specifically, we identify key algorithmic characteristics, such as computational density, data independence, and synchronization requirements, that govern heterogeneous speedups and scalability limits.  

> â€¢

We demonstrate that GPU parallelism fundamentally challenges fixed-FE evaluation as a fair comparison crite-rion for EAs. Through fixed-time evaluations, we reveal performance characteristics that remain hidden under the limited FE budgets commonly used in conventional benchmarks.  

> â€¢

We characterize the scaling behavior of EAs with respect to problem dimensionality and population size. In doing so, we identify distinct regimes in which GPU parallelism is beneficial, saturates, or loses its advantage.  

> â€¢

We show that the large populations enabled by GPU parallelism expose algorithm-specific convergence and diversity behaviors that are inaccessible under CPU-constrained settings. This finding elevates population size to an emerging research dimension for EA analysis and design. The remainder of this paper is organized as follows. Section II reviews background on GPU-accelerated EAs. Section III describes the experimental methodology. Section IV presents and analyzes the experimental results. Section V discusses the implications for evolutionary algorithm research, and Section VI concludes the paper. II. B ACKGROUND AND MOTIVATION 

This section presents the conceptual and historical back-ground that motivates the increasing importance of GPU parallelism in EA research. We review the inherent parallelism of classical EA paradigms and their mapping to parallel hard-ware. Furthermore, we argue that modern GPUs fundamentally alter the computational landscape for EAs. 

A. Classic EA Paradigms and their Parallel Potential 

EAs are population-based stochastic search methods in-spired by natural evolution. Their population structure, in-dependent evaluation and variation steps make them well-suited for parallel architectures like GPUs. Depending on the optimization objectives, EAs can be broadly classified into single-objective and multi-objective variants. 

1) Single-Objective EAs (SOEAs): SOEAs target the opti-mization of a single fitness function. Four principal families are outlined below.  

> â€¢

Particle Swarm Optimizer : PSO models the social behavior of swarms, where each particle updates its position based on both its personal best and the global best. Although global communication is needed for in-teractions, particle updates and fitness evaluations can be done independently. Variants like Competitive Swarm Optimizer (CSO) [18] and Comprehensive Learning PSO (CLPSO) [19] retain the basic framework while intro-ducing social interactions and learning mechanisms to enhance performance.  

> â€¢

Differential Evolution : Canonical DE generates can-didate solutions by applying differential mutation and crossover to a target population. Specifically, the algo-rithm constructs a mutant vector using scaled differences between selected individuals, a process that effectively explores the search space. While mutation and recombi-nation are typically parallelizable, random sampling may introduce minor dependencies. Adaptive variants, such as Self-adaptive DE (SaDE) [20] and adaptive DE with optional external archive (JADE) [21], dynamically adjust the control parameters. This mechanism substantially enhances the flexibility and robustness of the algorithm.  

> â€¢

Genetic Algorithm : The GA [3] represents solutions as chromosomes and evolves them through selection, crossover, and mutation. The independence of these op-erations allows them to be vectorized across the popu-lation. Standard implementations utilize crossover opera-tors such as simulated binary crossover (SBX) [22] and uniform recombination (UR) [23]. Additionally, mutation strategies often employ polynomial mutation (PM) and Gaussian mutation (GM) [24].  

> â€¢

Evolution Strategy : The Covariance Matrix Adaptation Evolution Strategy (CMA-ES) [25] samples candidate solutions from a multivariate Gaussian distribution. The algorithm iteratively updates the mean and covariance matrix based on successful individuals, which captures variable dependencies and enables efficient local search. This reliance on matrix operations renders the method BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 3

highly parallelizable. Furthermore, variants such as In-creasing Population Size CMA-ES (IPOP-CMA-ES) [26] and Separable CMA-ES (sep-CMA-ES) [27] modify pop-ulation management and covariance modeling, thereby improving scalability. 

2) Multi-Objective EAs (MOEAs): MOEAs optimize mul-tiple conflicting objectives by generating trade-off solutions. Several classic MOEAs are introduced based on selection principles:  

> â€¢

Pareto-based MOEAs : These methods use Pareto dom-inance for fitness evaluation and selection. The classical Non-dominated Sorting Genetic Algorithm-II (NSGA-II) [28] combines non-dominated sorting and crowding distance to balance diversity and convergence. Exten-sions such as NSGA-III [29] introduce reference points to handle many-objective scenarios effectively. While some operations, such as diversity calculations, can be parallelized, global sorting steps remain a parallelism bottleneck.  

> â€¢

Indicator-based MOEAs : These approaches optimize performance indicators, such as hypervolume. A repre-sentative algorithm is the Indicator-Based Evolutionary Algorithm (IBEA) [30], which selects solutions by maxi-mizing hypervolume contributions. To improve efficiency, the Hypervolume Estimation algorithm (HypE) [31] em-ploys approximate hypervolume calculations. However, calculating these indicators often involves pairwise or setwise comparisons. Consequently, this process entails substantial computational overhead.  

> â€¢

Decomposition-based MOEAs : The Multi-objective Evolutionary Algorithm Based on Decomposition (MOEA/D) [32] decomposes multi-objective problems into scalarized subproblems that are optimized concurrently. These subproblems can often leverage parallel computational architectures. However, inter-problem dependencies often present challenges. Variants such as MOEA/D-DE [32] integrate adaptive evolutionary operators. This integration enhances convergence and improves adaptability to diverse problem characteristics. 

B. Mapping EAs onto GPU Architectures 

The parallelization of EAs predates modern GPU com-puting and has long been an active topic in evolutionary computation. Early work primarily focused on exploiting coarse-grained parallelism in distributed or multi-core CPU environments [33], [34], [35]. In these settings, populations were partitioned across processors, and fitness evaluations were executed concurrently. Representative paradigms include island models [36], masterâ€“slave models [37], and cellular EAs [38], which differ in their communication and synchro-nization structures. Historically, parallelism was largely treated as an engineering strategy to reduce wall-clock time, while algorithmic structures and evaluation protocols remained fun-damentally aligned with CPU-oriented execution assumptions. The emergence of programmable GPUs marked a qualitative shift in this research trajectory [39]. Unlike CPUs, which emphasize latency-optimized and control-flowâ€“rich execution, GPUs are designed for throughput-oriented workloads with massive fine-grained data-level parallelism. These architec-tures favor regular computation patterns, predictable memory access, limited control-flow divergence, and minimal syn-chronization [40]. This architectural divergence fundamentally altered how parallelism could be exploited, thereby prompting renewed interest in how EAs might be mapped onto GPU execution models. Early GPU-based implementations typically targeted the most computationally intensive component of EAs, i.e., fit-ness evaluation. These approaches offloaded population-wide evaluations to the GPU while retaining evolutionary operators and control logic on the CPU [41], [42]. Although such hybrid designs demonstrated substantial speedups, they also revealed that naive offloading often failed to fully exploit GPU capabilities. Specifically, frequent data transfers and synchro-nization between the CPU and GPU introduced non-negligible overheads. At a structural level, EAs exhibit several properties that make them naturally amenable to GPU acceleration. First, fitness evaluations across individuals are usually independent, which enables straightforward data-parallel execution. Second, variation operators such as mutation and crossover can often be applied element-wise across populations. This characteristic lends itself to vectorized and batched computation. Moreover, many EAs operate on continuous representations and rely on arithmetic or linear-algebraâ€“based operations, which are well supported by GPU hardware. However, practical challenges arise from algorithmic de-pendencies and synchronization requirements. Operations such as global-best updates, dominance sorting in multi-objective optimization, archive maintenance, and neighborhood-based interactions introduce communication, reduction, and coordi-nation steps. These mechanisms often involve irregular mem-ory access patterns or frequent global synchronization, both of which are known performance bottlenecks on GPU archi-tectures. Consequently, the performance of GPU-based EAs is governed not only by computational complexity but also by structural properties, including data independence, memory access regularity, and synchronization frequency. Thus, not all EAs benefit equally from GPU execution, and certain algorithmic designs inherently constrain achievable parallel efficiency. Recent years have witnessed the rise of high-level numerical and machine learning frameworks that abstract away low-level GPU programming details. Frameworks such as JAX [43] and PyTorch [44] promote batch-oriented and tensorized computa-tion as first-class abstractions. Consequently, these platforms encourage algorithm designs that align naturally with GPU execution models. Building on these ecosystems, several evo-lutionary computation libraries, including EvoJAX, evosax, and EvoX, have emerged. These libraries express EAs in fully vectorized and batched forms, thereby enabling end-to-end GPU execution without algorithm-specific kernel engineering. This shift reflects a broader transition from hand-optimized GPU implementations toward structurally GPU-native formu-lations of EAs. Ultimately, this progression provides a unified foundation for systematically studying the interaction between algorithm design and parallel hardware. BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 4

C. The Role of GPU Parallelism in EAs 

EAs are inherently population-based and stochastic, relying on repeated evaluations of candidate solutions to explore complex and often rugged search spaces. This design endows EAs with strong robustness and flexibility for nonconvex, discontinuous, and gradient-inaccessible optimization prob-lems, but it also makes their performance tightly coupled to available computational resources [45]. Historically, the practical deployment and empirical evaluation of EAs have therefore been shaped by a fundamental constraint: fitness evaluations are computationally expensive, forcing population sizes and evolutionary horizons to remain limited. Over the past decade, rapid advances in parallel hardware have increasingly challenged traditional computational con-straints. Graphics Processing Units (GPUs) and specialized accelerators, such as TPUs, have become the dominant compu-tational substrate for large-scale workloads [46], [47]. In fields such as deep learning and reinforcement learning, algorithmic research has co-evolved with hardware capabilities. This co-evolution explicitly treats parallelism, scalability, and time-to-solution as key design considerations. A similar transition is now emerging in EAs. Specifically, GPU parallelism is no longer peripheral but is increasingly central to both method-ology and practice. Research trends further demonstrate the growing relevance of GPUs to evolutionary computation. As illustrated in Fig. 1, the number of studies connecting EAs with GPU acceler-ation has steadily increased over the past three decades. Although GPU-related work still constitutes a minority within the broader EA literature, its sustained growth reflects the maturation and accessibility of GPU hardware. Moreover, this growth signals a broader shift toward scalability-aware algorithmic research. Consequently, computational efficiency and hardware alignment are becoming integral to the evolu-tion of optimization algorithms, rather than remaining mere implementation concerns. 

> Fig. 1: Number of publications retrieved over the past 30 years from the Web of Science using different requests. TS queries the topic field (title, abstract, and keywords), whereas TI restricts the keyword to the article title only.

The integration of massive parallelism into EAs fundamen-tally alters the relationship between computational time and FEs. By substantially lowering the computational cost per evaluation, GPUs allow EAs to process orders of magnitude more FEs within a fixed time budget. This capability chal-lenges the long-standing assumption that FEs are a scarce resource, a premise that underlies many classical evaluation protocols. Consequently, comparisons based on fixed evalua-tion counts may prematurely truncate evolutionary processes, which obscures the true search potential of certain algo-rithms. Therefore, under massively parallel execution, time-based evaluation emerges as a more robust and practically meaningful performance criterion. Simultaneously, GPU parallelism fundamentally relaxes his-torical constraints on population size. Classical EAs typically employ small or moderate populations, primarily because larger sizes are computationally infeasible under CPU-based execution. In contrast, GPUs make large-scale populations practically accessible, which enables new regimes of explo-ration, diversity maintenance, and convergence behavior. As a result, this structural shift broadens the applicability of EAs to problem domains that were previously considered prohibitively expensive, including large-scale neuroevolution and simulation-driven control. Finally, the availability of abundant parallel computation facilitates emerging research directions in EAs. Advanced methodologies, such as learn to optimize (L2O) [48], [49] and meta-optimization [50], [51], often require the repeated execution of EAs across extensive task or parameter spaces. While these approaches are impractical under traditional CPU-based constraints, GPU execution transforms them from con-ceptual possibilities into viable research practices. Thus, GPU parallelism functions not merely as an implementation-level acceleration technique, but as a pivotal structural change that reshapes how EAs are designed, applied, and evaluated. III. E XPERIMENTAL METHODOLOGY 

In this paper, we investigate the impact of GPU parallelism on EAs from a systematic empirical perspective. Our goal is not only to measure acceleration, but also to understand how GPU execution influences algorithmic behavior, evalu-ation efficiency, and scalability under practical constraints. To this end, we design a comprehensive experimental study that examines EA performance across a diverse set of algo-rithms, problem types, data scales, and hardware platforms. This section details the algorithms, benchmark problems, and computing platforms used in our experiments, followed by an explanation of our performance evaluation framework, including the metrics and methods for comparative assessment. 

A. Selected Algorithms and Benchmark Problems 

The overview of our experimental configurations is illus-trated in Fig. 2. Specifically, this research leveraged eight SOEAs, which are: PSO [4], CSO [18], DE [5], SaDE [20], GA-SBX/PM [22] which employs simulated binary crossover (SBX) with polynomial mutation (PM), GA-UR/GM which uses uniform random crossover (UR) [23] alongside Gaussian mutation (GM) [24], CMA-ES [25], IPOP-CMA-ES [52]. We also employed eight MOEAs: NSGA-II [28], NSGA-III [29], Strength Pareto Evolutionary Algorithm 2 (SPEA2) [53], BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 5Single -                                               

> Objective
> Benchmarks Algorithms
> Multi -
> Objective
> Numerical
> Problems
> Neuroevolution
> Tasks
> Single -
> Objective
> Multi -
> Objective
> Single -
> Objective
> Multi -
> Objective
> Pareto -based
> Indicator -based
> PSO variants
> DE variants
> ES variants
> GA variants
> PSO
> CSO
> NSGA -II
> NSGA -III
> SPEA2
> IBEA
> HypE
> MOEA/D
> RVEA
> LMOCSO
> Decomposition
> -based
> Other
> ð’‡ ð’‚ ðŸ -ð’‡ ð’‚ ðŸ“ :20 -dimensional
> CEC2022 F1 -F5
> ð’‡ ð’‚ ðŸ” -ð’‡ ð’‚ ðŸðŸŽ :50 -dimensional
> Ackley, Griewank,
> Rosenbrock, Schwefel,
> Sphere
> ð’‡ ð’‚ ðŸðŸ -ð’‡ ð’‚ ðŸðŸ• :50 -dimensional DTLZ1 -7
> with 3 -objectives
> ð’‡ ð’‚ ðŸðŸ– -ð’‡ ð’‚ ðŸðŸŽ :50 -dimensional ZDT1 -3
> with 2 -objectives
> ð’‡ ð’ƒ ðŸ :Halfcheetah
> ð’‡ ð’ƒ ðŸ :Hopper
> ð’‡ ð’ƒ ðŸ‘ :Reacher
> ð’‡ ð’ƒ ðŸ’ :Swimmer
> ð’‡ ð’ƒ ðŸ“ :Walker2d
> ð’‡ ð’ƒ ðŸ” :MoHopper -m2
> ð’‡ ð’ƒ ðŸ• :MoHopper -m3
> ð’‡ ð’ƒ ðŸ– :MoReacher
> ð’‡ ð’ƒ ðŸ— :MoSwimmer
> ð’‡ ð’ƒ ðŸðŸŽ :MoWalker2d
> CPU :
> Intel Xeon Gold 6226R
> GPUs :
> NVIDIA RTX 2080 Ti ,
> NVIDIA RTX 3090
> GA -UR/GM
> GA -SBX/PM
> DE
> SaDE
> CMA -ES
> IPOP -CMA -ES
> GPUs :
> NVIDIA RTX 2080 Ti ï¼Œ
> NVIDIA RTX 3090

Fig. 2: Overview of the experimental setup, including evaluated algorithms, benchmark problems, and hardware specifications. 

HypE [31], IBEA [30], Reference Vector Guided Evolution-ary Algorithm (RVEA) [54], MOEA/D [32] and Efficient Large-Scale Multiobjective Optimization Based on Compet-itive Swarm Optimizer (LMOCSO) [55]. The benchmark problems in this study are divided into two primary categories: numerical optimization problems ( fa)and neuroevolution tasks ( fb). The fa category encompasses single-objective problems, including the Ackley, Griewank, Rosenbrock, Schwefel, and Sphere functions, as well as CEC2022 F1-F5 [56]. It also includes multi-objective prob-lems selected from the DTLZ (DTLZ1-DTLZ7) [57] and ZDT (ZDT1-ZDT3) [58] suites. In contrast, the fb category utilizes the Brax physics simulation engine to evaluate five single-objective neuroevolution tasks [59]. To accommodate multi-objective optimization, we extended the Brax framework following the methodology in [54], thereby introducing five new multi-objective neuroevolution tasks. A consistent policy architecture is applied across all tasks, which consists of a multilayer perceptron (MLP) with three fully connected layers. Fig. 2 presents the corresponding labels for these benchmark problems, and Supplementary Document X and XI provides detailed descriptions. 

B. Computing Platform 

Our experiments were conducted on both GPU and CPU architectures. The key specifications are summarized below:  

> â€¢

GPU Platforms :

â€“ NVIDIA GeForce RTX 3090: 24GB GDDR6X mem-ory, 10496 CUDA cores 

â€“ NVIDIA GeForce RTX 2080 Ti: 11GB GDDR6 mem-ory, 4352 CUDA cores  

> â€¢

CPU Platform :

â€“ Intel Xeon Gold 6226R: 16-core processor, 2.90GHz base frequency, 64GB DDR4 RAM All tests were implemented using the EvoX framework [17], which provides uniform execution pipelines, deterministic modes, and fine-grained metric logging. This design ensures identical algorithmic configurations across devices, thereby eliminating implementation differences and guaranteeing the reproducibility and direct comparability of GPU/CPU results. 

C. Evaluation Framework 

This paper evaluates the performance of EAs across two key dimensions: solution quality and computational efficiency. 

1) Solution Quality Metrics: For SOEAs, we report the best-found fitness value, distinguishing between minimiza-tion ( fa1 -fa10 ) and maximization ( fb1 -fb5 ) problems. Multi-objective optimization is evaluated with specialized quality in-dicators based on the problem type: for numerical optimization tasks ( fa11 -fa20 ), we use the IGD metric, comparing solutions to known Pareto fronts, with lower value indicating better performance, while for neuroevolution tasks ( fb6 -fb10 ), we apply the HV metric, with higher value indicating superior solutions. 

2) Computational Efficiency Metric: Computational effi-ciency is characterized by three complementary indicators. First, we record the execution time ( T ), defined as the wall-clock duration required to reach a common stopping criterion. Second, we quantify parallelization efficiency by computing the speed-up ratio between GPU and CPU implementations, which is defined as: Speed-up = TCPU 

TGPU 

,

where TCPU and TGPU denote the execution time of CPU and GPU variants, respectively. Finally, we assess computational throughput by recording the NFEs completed within a fixed time window, which reflects how effectively each platform converts wall-clock time into search effort. 

3) Comparison Approach: We treat solution quality and computational efficiency as joint objectives, mapping each EA onto this two-dimensional space, as illustrated in Fig. 3. BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 6

This visualization approach provides several analytical in-sights: (i) direct comparison of algorithm performance trade-offs between accuracy and efficiency, (ii) quantification of performance improvements from changes in experimental con-figurations, such as hardware platform or population size, and (iii) identification of dominant implementations. Computational Efficiency 

Solution Quality 

> Algo. y
> Algo. x
> (setting j)
> Algo. x
> (setting i)
> No
> ð— âˆ—
> ð— ð‘”
> Update Rule
> ð— ð‘” +1
> Terminate ï¼Ÿ
> Yes
> Function
> Evaluation

Workflow Pareto Front of Performance 

> Accuracy
> gains
> Efficiency
> declines

Fig. 3: Evaluation methodology used in this study: the left panel depicts the classic EA workflow, while the right panel visualizes the resulting Pareto front of performance that contrasts computational efficiency (vertical axis) with solution quality (horizontal axis) for different algorithm settings. 

IV. W HAT GPU P ARALLELISM CHANGES IN PRACTICE 

While GPU acceleration is often discussed in terms of raw speedup, its practical impact on EAs extends far beyond re-duced runtime. By fundamentally altering the relationship be-tween computational cost, function evaluations, and population scale, GPU parallelism reshapes how algorithms behave, how they should be evaluated, and which mechanisms ultimately benefit from increased computational resources. In this section, we systematically investigate how GPU parallelism changes EA performance in practice, moving from computational ef-ficiency to evaluation paradigms, scalability limits, and the algorithmic consequences of large populations. 

A. Computational Cost under CPU and GPU Execution 

We begin by examining the most immediate and observable effect of GPU parallelism: the reduction of computational cost. Although GPU acceleration is commonly reported as a single speedup ratio, such aggregate metrics often obscure substantial variations across algorithms. Here, we analyze how different EAs translate GPU parallelism into wall-clock efficiency and FE throughput, and identify the algorithmic characteristics that govern these heterogeneous gains. Experiments utilized a fixed population size of 128 and an evaluation budget of 1,000,000 FEs. This population size aligns with standard practices in EAs, while the extended evaluation budget ensures sufficient GPU runtime for accurate performance comparison. To isolate algorithmic mechanisms, the EvoX platform provided consistent data structures and evaluation pipelines across devices, thereby minimizing exter-nal influences. Tables I and II summarize the averaged runtime and corresponding speed-ups over 15 independent runs. The results reveal substantial heterogeneity in GPU accel-eration across algorithms. Computationally intensive methods, such as CMA-ES and HypE, exhibit pronounced speedups. This performance gain stems from dense linear algebra oper-ations and massively parallel dominance or sampling proce-dures, which align well with GPU architectures. In contrast, lightweight algorithms, such as PSO and CSO, show compara-tively modest gains. Although their update rules are inherently parallel, their low arithmetic intensity allows CPUs to execute these operations efficiently. Consequently, limited headroom remains for GPU acceleration once kernel launch and memory overheads are accounted for. Notably, high computational complexity alone does not guarantee superior GPU performance. Algorithms such as NSGA-III experience limited or even negative speedup, despite their heavy computational load. This behavior arises from synchronization-intensive components, such as layered non-dominated sorting and reference-point niche selection. These components introduce frequent global reductions and irregular memory access patterns. In such cases, algorithmic structures that favor sequential execution or fine-grained control flow undermine the architectural strengths of GPUs. The findings highlight that effective GPU acceleration occurs when algorithmic properties match the architectural strengths of GPUs. In general, algorithms characterized by minimal data dependencies, continuous data structures, and high computational intensity benefit substantially from GPU parallelism. CMA-ES variants exemplify this category. In contrast, methods that require frequent synchronization or complex data dependencies tend to perform better on the CPU. NSGA-III represents this class of algorithms. Table III summarizes these main effects and influencing factors. 

TABLE I AVERAGED RUNTIME AND SPEED -UPS BETWEEN GPU AND CPU TESTED UNDER 1,000,000 FE S ACROSS EIGHT SOEA S.                                                                                                                                                                                                                                                      

> Func. Metric PSO CSO DE SaDE CMA-ES IPOP-CMA-ES GA-SBX/PM GA-UR/GM
> fa1
> TCPU 14.34 14.51 55.68 83.92 153.49 128.99 23.83 19.86
> TGPU 8.36 8.20 9.21 24.73 30.76 15.35 9.71 9.06 Speed-up 1.71 1.77 6.04 3.39 4.99 8.41 2.45 2.19
> fa2
> TCPU 14.85 14.82 55.74 84.26 155.66 131.09 23.97 20.82
> TGPU 8.55 8.59 9.12 24.80 15.73 15.07 10.48 8.95 Speed-up 1.74 1.73 6.11 3.40 9.90 8.70 2.29 2.33
> fa3
> TCPU 15.62 15.43 56.56 84.57 167.40 174.10 25.21 22.67
> TGPU 10.32 10.08 10.98 26.43 36.91 14.73 11.58 10.72 Speed-up 1.51 1.53 5.15 3.20 4.54 11.82 2.18 2.12
> fa4
> TCPU 14.92 15.01 56.45 84.20 123.40 129.61 23.87 21.03
> TGPU 8.70 8.27 9.11 24.22 18.51 14.85 9.40 9.01 Speed-up 1.71 1.82 6.20 3.48 6.67 8.73 2.54 2.33
> fa5
> TCPU 16.63 14.88 57.07 83.48 162.05 133.42 25.47 21.45
> TGPU 9.31 8.64 9.18 25.11 13.97 14.58 10.42 8.91 Speed-up 1.79 1.72 6.22 3.32 11.60 9.15 2.44 2.41
> fa6
> TCPU 36.11 15.27 59.27 90.71 741.90 750.62 55.18 41.12
> TGPU 8.07 8.32 9.09 24.02 13.30 16.56 9.40 8.66 Speed-up 4.47 1.84 6.52 3.78 55.77 45.33 5.87 4.75
> fa7
> TCPU 36.74 15.51 66.01 98.44 712.59 717.00 55.43 40.46
> TGPU 8.17 8.61 9.12 24.65 13.13 16.45 8.99 8.91 Speed-up 4.49 1.80 7.46 3.99 54.27 43.59 6.16 4.54
> fa8
> TCPU 30.47 16.49 63.39 95.25 759.80 750.42 52.60 35.06
> TGPU 8.51 9.98 8.85 24.79 14.73 17.79 11.25 8.97 Speed-up 3.58 1.65 6.95 3.84 51.58 42.18 4.68 3.91
> fa9
> TCPU 33.58 14.83 64.01 95.49 738.20 770.70 55.91 40.67
> TGPU 8.50 8.46 8.93 23.88 12.16 12.33 2.54 2.30 Speed-up 3.95 1.75 7.17 4.00 60.70 62.51 22.03 17.65
> fa10
> TCPU 34.66 14.43 64.99 96.65 726.80 735.40 54.91 38.70
> TGPU 7.95 8.42 8.98 24.97 13.34 16.72 9.86 8.60 Speed-up 4.36 1.71 7.23 3.87 54.47 43.98 5.57 4.50

BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 7

TABLE II AVERAGED RUNTIME AND SPEED -UPS BETWEEN GPU AND CPU TESTED UNDER 1,000,000 FE S ACROSS EIGHT MOEA S.                                                                                                                                                                                                                                                         

> Func. Metric NSGA-II NSGA-III SPEA2 IBEA HypE MOEA/D RVEA LMOCSO
> fa11
> TCPU 32.49 41.56 223.63 46.47 575.32 26.88 40.88 50.73
> TGPU 7.10 56.95 12.48 10.96 7.91 13.02 5.34 7.13 Speed-up 4.58 0.73 17.91 4.24 72.76 2.07 7.65 7.11
> fa12
> TCPU 71.24 79.23 324.48 85.57 608.32 70.08 86.76 88.57
> TGPU 6.05 56.96 18.05 10.74 7.14 13.31 6.15 6.97 Speed-up 11.77 1.39 17.98 7.97 85.16 5.26 14.11 12.71
> fa13
> TCPU 72.12 80.43 263.79 85.71 673.91 66.40 44.55 91.37
> TGPU 7.21 55.73 12.72 10.59 8.43 12.74 5.25 7.06 Speed-up 10.00 1.44 20.73 8.09 79.95 5.21 8.48 12.94
> fa14
> TCPU 72.65 81.38 327.35 86.22 675.47 67.44 88.33 89.55
> TGPU 6.19 57.88 17.42 10.71 7.00 12.73 6.03 7.03 Speed-up 11.74 1.41 18.79 8.05 96.54 5.30 14.64 12.75
> fa15
> TCPU 71.78 103.10 286.72 86.28 617.48 66.86 39.27 40.56
> TGPU 6.59 73.59 14.30 10.70 7.81 12.90 5.19 6.10 Speed-up 10.89 1.40 20.06 8.06 79.04 5.18 7.56 6.64
> fa16
> TCPU 72.91 102.76 303.79 85.80 560.12 20.35 41.01 90.63
> TGPU 6.91 71.79 15.48 10.82 6.24 12.36 5.22 6.82 Speed-up 10.56 1.43 19.62 7.93 89.81 1.65 7.86 13.29
> fa17
> TCPU 71.74 96.16 347.76 85.35 610.66 65.98 37.82 38.66
> TGPU 6.21 69.09 19.51 10.95 7.05 13.08 5.51 5.74 Speed-up 11.54 1.39 17.83 7.80 86.64 5.04 6.87 6.73
> fa18
> TCPU 26.62 33.55 245.91 38.37 816.41 23.69 45.12 46.04
> TGPU 5.80 55.59 14.14 10.62 6.98 12.73 6.18 6.59 Speed-up 4.59 0.60 17.39 3.61 117.01 1.86 7.30 6.98
> fa19
> TCPU 26.66 33.94 242.65 38.29 755.25 23.48 44.32 45.52
> TGPU 6.19 55.53 13.73 10.78 7.30 12.65 5.83 6.60 Speed-up 4.30 0.61 17.68 3.55 103.50 1.86 7.60 6.89
> fa20
> TCPU 26.72 40.04 233.17 38.57 756.19 23.47 44.59 45.84
> TGPU 3.02 53.91 10.28 8.19 4.73 9.95 3.37 3.62 Speed-up 8.84 0.74 22.68 4.71 159.71 2.36 13.25 12.65

TABLE III GPU A CCELERATION EFFECTS AND INFLUENCING ALGORITHMIC 

CHARACTERISTICS 

Effect E.g. Key Mechanisms Algorithmic Characteristics 

> Beneficial  CMA-ES, IPOP-CMA-ES

Dominated by matrix oper-ations, dense linear algebra computations. Algorithms that have operations with low data dependencies and independent tasks; high computational complexity with regular memory access. 

> SPEA2, HypE

Hypervolume sampling/ den-sity estimation can be well-parallelized. Detrimental  PSO, CSO 

Lightweight computation, global best updates or random pairing in updates requires global synchronization and non-contiguous memory access. Algorithms that involve low computational density and high data transfer, global synchronization, random memory access, complex data dependencies, dynamic structures, and high communication overhead. 

> NSGA-III

Layered non-dominated sort-ing: dominance relationship checks increase data depen-dencies, dynamic reference point updates raise synchro-nization overheads. 

B. Evaluation Paradigm: Fixed-FE vs. Fixed-Time 

Reductions in wall-clock time naturally raise a more fun-damental question: how should EAs be fairly evaluated under GPU parallelism? Conventional EA benchmarking protocols fix the NFEs to control computational cost, an assumption that is largely valid in CPU-based settings, where evaluations are executed serially at a relatively stable rate. Under such conditions, NFEs serve as a reasonable proxy for wall-clock time. GPU execution fundamentally breaks this equivalence. By evaluating large populations in parallel, GPUs can com-plete orders of magnitude more FEs within the same time bud-get. Consequently, FE budgets that are appropriate for CPUs become extremely small from a GPU perspective, potentially truncating the optimization process prematurely and rendering the evaluation unrealistic. Fixed-FE comparisons therefore fail to reflect actual computational efficiency or the effective search effort enabled by modern hardware. To illustrate this mismatch, we conducted fixed-time exper-iments using a 30-second time budget and a fixed popula-tion size of 128. For each run, we recorded the number of completed evaluations and the resulting solution quality. As shown in Fig. 4, each point represents a trade-off between efficiency (NFEs) and effectiveness (fitness or IGD), where the lower-left region indicates the ideal balance. Notably, the GPU results consistently achieve approximately an order-of-magnitude higher FE throughput than their CPU counterparts under identical time constraints. This increased evaluation capacity directly translates into additional generations. Con-sequently, algorithms that benefit from extensive sampling achieve substantial performance gains. For example, SPEA2 leverages a more accurate external archive to enhance the di-versity and coverage of the search space. Similarly, LMOCSO benefits from denser sampling, which improves solution accu-racy and exploration. However, higher FE counts do not uniformly guarantee bet-ter optimization performance. For instance, CMA-ES achieves superior results on single-objective benchmarks despite com-paratively fewer evaluations, owing to its effective covari-ance matrix adaptation. In contrast, PSO and GA variants fail to improve accuracy even with substantially increased FE budgets on GPUs. This limitation arises because their relatively coarse search dynamics tend to converge prema-turely to local optima. SaDE exhibits the opposite behavior. Although it is less competitive under FE-limited CPU settings, it surpasses swarm-based methods when permitted to exploit millions of evaluations on GPUs. This improvement stems from its adaptive mutation mechanisms and embedded local search strategies, which enable the effective utilization of the expanded evaluation budget. The full experimental results are provided in Supplementary Document XII-A. 

C. Scaling Behavior under GPU Parallelism 

While GPUs substantially enhance computational through-put, their advantages do not emerge uniformly across all problem dimensionalities and population sizes. Instead, per-formance gains vary across different scaling regimes. In this subsection, we systematically investigate how increasing prob-lem dimensionality and population size affects computational efficiency on both CPUs and GPUs, with the aim of identifying when parallelism becomes effective, reaches saturation, or begins to degrade performance. To this end, we conducted benchmark experiments on two GPU architectures (NVIDIA GeForce RTX 3090 and RTX 2080 Ti) and an Intel Xeon Gold 6226R CPU. Either the problem dimensionality or the population size was increased exponentially from 16 to 8,192 while keeping the other factor fixed. For each configuration, we recorded (i) the wall-clock time required to complete 100 generations and (ii) the NFEs achieved within a fixed 30-second time budget. All results were averaged over 15 independent runs. Detailed experimental results are reported in Supplementary Document XII-B. 

1) Scaling with Problem Dimensionality ( D): Keeping the population size fixed at 128, Fig. 5 presents two representa-tive cases of scaling the problem dimension. CPU runtime BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 8PSO GPU      

> PSO CPU
> CSO GPU
> CSO CPU
> DE GPU
> DE CPU
> SaDE GPU
> SaDE CPU
> GA-SBX/PM GPU
> GA-SBX/PM CPU
> GA-UR/GM GPU
> GA-UR/GM CPU
> CMA-ES GPU
> CMA-ES CPU
> IPOP-CMA-ES GPU
> IPOP-CMA-ES CPU 0.00 1.00 2.00 3.00 4.00 5.00
> Ã—10 1
> 0.00 1.00 2.00 3.00 4.00
> Number of FEs
> Ã—10 6
> CMA-ES GPU
> GA-SBX/PM GPU
> IPOP-CMA-ES GPU
> CSO GPU
> GA-UR/GM GPU
> PSO GPU
> SaDE GPU
> DE GPU
> Fitness Value

(a) fa20.00 0.30 0.60 0.90 1.20 1.50  

> Ã—10 2
> 0.00 1.00 2.00 3.00 4.00
> Number of FEs
> Ã—10 6
> CMA-ES GPU
> GA-SBX/PM GPU
> GA-UR/GM GPU
> DE GPU
> IPOP-CMA-ES GPU
> CSO GPU
> PSO GPU
> SaDE GPU
> Fitness Value

(b) fa10 HypE GPU      

> HypE CPU
> IBEA GPU
> IBEA CPU
> RVEA GPU
> RVEA CPU
> MOEA/D GPU
> MOEA/D CPU
> NSGA-II GPU
> NSGA-II CPU
> NSGA-III GPU
> NSGA-III CPU
> SPEA2 GPU
> SPEA2 CPU
> LMOCSO GPU
> LMOCSO CPU 0.00 0.40 0.80 1.20 1.60
> IGD Value Ã—10 2
> 0.00 2.00 4.00 6.00
> Number of FEs
> Ã—10 6
> HypE GPU
> RVEA GPU
> LMOCSO GPU
> MOEA/D GPU
> IBEA GPU
> NSGA-II GPU
> NSGA-III GPU
> SPEA2 GPU

(c) fa11 1.15 1.17 1.18 1.20 1.21  

> IGD Value
> 0.00 1.50 3.00 4.50 6.00
> Number of FEs
> Ã—10 6
> HypE GPU
> IBEA GPU
> MOEA/D GPU
> NSGA-II GPU
> NSGA-III GPU
> SPEA2 GPU
> LMOCSO GPU
> RVEA GPU

(d) fa18 

Fig. 4: Performance of EAs tested on CPU and GPU, evaluated in terms of solution quality and number of FEs completed within 30 seconds. Lower fitness/IGD value denotes better performance. Results represent averaged performance values across 15 independent runs. Solid markers denote GPU-based implementations; hollow markers indicate CPU-based counterparts. 

increases nearly linearly with dimensionality due to rising computational load and memory limitations, while both GPUs maintain nearly constant costs through parallelization and efficient memory bandwidth utilization. The RTX 3090 GPU outperforms the 2080 Ti, thanks to its superior architecture, including more CUDA cores and higher memory bandwidth. For small-dimensional problems (empirically D < 512 in our tests), the CPU and 2080 Ti GPU show comparable performance, as the CPU handles small tasks more efficiently without the overhead of parallelization. When operating under a fixed time constraint, the FE count completed on the CPU decreases significantly with increasing dimensionality, while both GPUs maintain a 2-3 order-of-magnitude advantage. The RTX 3090 even completes about 2 million FEs at D = 8192 

due to massive CUDA cores and superior memory bandwidth. For MOEA/D on the small-scale DTLZ1 problem, the CPU outperforms the 2080 Ti due to more efficient handling of synchronization and communication. However, for the PSO on the low-dimensional Ackley function, the situation is reversed. Performance differences arise because PSO thrives due to its parallelism-friendly nature, while MOEA/D on DTLZ1 requires frequent synchronization and communication, limiting the GPUâ€™s advantages and making it more suited to CPU processing for small-scale tasks. 

2) Scaling with Population Size ( N ): When the problem di-mensionality is fixed at D = 50 , Fig. 6 illustrates the effect of population size on computational efficiency. As the population size increases, the CPU runtime grows almost linearly, which reflects the limited ability of the CPU to parallelize tasks. 0 5000 10000 15000 

Dimension Scale 

0

2

4

6

8

10 

12 

> t

GPU: RTX 2080 Ti GPU: RTX 3090 CPU: Xeon Gold 6226R 0 2000 4000 6000 8000     

> Dimension Scale
> 0
> 5
> 10
> 15
> 20
> 25
> 30
> Time (s) 02000 4000 6000 8000
> Dimension Scale
> 0
> 1
> 2
> 3
> 4
> Number of FEs
> 1e6

(a) PSO ( N = 128) on Ackley 0 2000 4000 6000 8000     

> Dimension Scale
> 0
> 10
> 20
> 30
> 40
> Time (s) 02000 4000 6000 8000
> Dimension Scale
> 0.0
> 0.5
> 1.0
> 1.5
> 2.0
> 2.5
> Number of FEs
> 1e6

(b) MOEA/D ( N = 128) on DTLZ1 

Fig. 5: Computational performance tested across varying problem dimensions on three hardware platforms. Left : Total runtime over 100 generations. Right :Number of FEs completed within a 30-second time budget. Results are averaged over 15 independent runs; solid lines indicate mean values, and shaded regions represent standard deviations. 

Conversely, the runtime on GPUs remains nearly constant. This performance stability results from the large-scale CUDA cores, which allow for concurrent evaluations and updates. However, for smaller populations (approximately N < 256 ), the RTX 2080 Ti underperforms relative to the CPU. In this regime, the overhead of GPU resource management becomes more pronounced than the computational gain. At N = 8192 ,the RTX 2080 Ti requires approximately twice the runtime of the RTX 3090. The RTX 3090 leverages its higher core count and superior bandwidth to parallelize processing more effectively. The right panel of Fig. 6 presents the NFEs completed within a fixed 30-second window. Larger populations result in more evaluations per generation, a workload that GPUs handle efficiently. Conversely, smaller populations require more iterations to achieve the same evaluation count, which favors the serial processing capabilities of the CPU. For PSO on the Ackley function, the GPU throughput increases monotonically with population size. The simplicity of the PSO algorithm prevents resource bottlenecks on the GPU. However, for MOEA/D on the DTLZ1 problem, the NFE completion rate initially rises with population size but subsequently plateaus or declines. As the population size grows, the synchronization and communication overheads for subproblem cooperation become significant. These factors reduce the parallelization benefit, thereby leading to diminishing returns. Consequently, the simpler mechanism of PSO facilitates more efficient par-allelization compared to the complex interaction patterns of MOEA/D. BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 9000 10000 15000 

Dimension Scale                   

> GPU: RTX 2080 Ti GPU: RTX 3090 CPU: Xeon Gold 6226R 02000 4000 6000 8000
> Population Size
> 1
> 2
> 3
> 4
> 5
> 6
> Time (s) 02000 4000 6000 8000
> Population Size
> 0.0
> 0.5
> 1.0
> 1.5
> Number of FEs
> 1e8
> (a) PSO on Ackley (D = 50) 02000 4000 6000 8000
> Population Size
> 0
> 100
> 200
> 300
> Time (s) 02000 4000 6000 8000
> Population Size
> 0.0
> 0.5
> 1.0
> 1.5
> 2.0
> 2.5
> 3.0
> Number of FEs
> 1e6
> (b) MOEA/D on DTLZ1 (D = 50)

Fig. 6: Computational performance of two EAs configured with varying population sizes across three hardware platforms. Left : Total runtime over 100 generations. Right : Number of FEs completed within a 30-second time budget. Each curve represents the average of 15 independent runs; solid lines denote mean values, and shaded areas indicate standard deviations. 0 5 10 15 20 0510 15 20                     

> Time (s)
> PSO CSO DE SaDE GA-SBX/PM GA-UR/GM CMA-ES IPOP-CMA-ES
> Fitness Value
> (a) fa60200 400 600 800 0510 15 20
> Time (s)
> PSO CSO DE SaDE GA-SBX/PM GA-UR/GM CMA-ES IPOP-CMA-ES
> Fitness Value (b) fa10 200 400 800 1000 600
> IGD Value
> 0246810 12 14
> Time (s)
> HypE IBEA RVEA MOEA/D NSGA-II NSGA-III SPEA2 LMOCSO
> (c) fa11 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0
> IGD Value
> 010 20 30 40
> Time (s)
> HypE IBEA RVEA MOEA/D NSGA-II NSGA-III SPEA2 LMOCSO (d) fa19

Fig. 7: Performance comparison of EAs under varying population sizes, evaluated in terms of solution quality and time consumed over 100 itera-tions. Lower fitness/IGD value denotes better performance. Results represent averaged performance values across 15 independent runs. Markers represent individual algorithms, color-coded from light to dark to indicate increasing population sizes (from 16 to 8192). 

D. Large-Population Dynamics beyond Hardware Utilization 

The scalability of GPUs enables population sizes far beyond those traditionally used in EAs. While larger populations are often viewed merely as a means to improve hardware utiliza-tion, their algorithmic implications remain less understood. Do large populations enabled by GPU parallelism merely consume additional computational resources, or do they fundamentally change optimization behavior? In this subsection, we move beyond efficiency analysis and examine how expanded popula-tion sizes affect convergence dynamics, diversity maintenance, and solution quality across different classes of EAs. 

1) Numerical Optimization Problems: We benchmarked sixteen EAs across ten population sizes, ranging exponen-tially from 16 to 8192, and conducted 15 independent repeti-tions across six numerical functions on an NVIDIA GeForce RTX 3090 GPU. To isolate the effect of population size on performance, we fixed the iteration count at 100 for each algorithm. Fig. 7 demonstrates that computational efficiency on GPU architectures remains manageable despite substantial increases in population size. Complete results appear in the Supplementary Document XII-C1. Specifically, despite an over 500-fold increase in the number of individuals, runtime scaling remained efficient. Larger populations enhanced performance in most cases, notably for CMA-ES and NSGA-II, which suggests improved search space coverage. However, these positive effects are not universal. Algorithms such as DE and MOEA/D tended to show stagnation or slight regression with additional individuals. To analyze this divergence, we tracked fitness progression and population diversity over 100 generations. Fig. 8 illustrates the convergence behavior of four EAs on fa6 . CMA-ES and PSO follow comparable dynamics. Larger populations enable these algorithms to adjust covariance matrices or locate elite individuals sooner. Subsequently, their internal update rules drive rapid convergence. In contrast, GA-SBX/PM sustains higher diversity in large populations while achieving steady improvement in outcomes. This behavior aligns with its reliance on abundant genetic recombination. Although DE exhibits even greater diversity with large populations, this advantage is undermined by significantly slower convergence. This indicates that excessively large populations may impair optimization efficiency within a limited iteration budget. To explore this trade-off under computational constraints, we extended the evaluation window to a fixed 30-second duration. This adjustment allowed for a substantial increase in function evaluation throughput, which revealed distinct patterns. Fig. 9 (d) shows that DE with populations of 128 and 1024 achieves significant quality improvements under this constraint. Modest populations converge quickly but stall early. Conversely, larger populations sustain exploration and ultimately dominate in solution quality. These observa-tions highlight that large populations often require extended convergence periods to fully realize their benefits. Parallel hardware alleviates computational overhead by enabling the concurrent operation of more individuals, which allows for more iterations within a fixed time budget. Consequently, this capability mitigates the classical trade-off between exploration BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 10 0 20 40 60 80 100 

Generation      

> 0.00
> 0.50
> 1.00
> 1.50
> 2.00
> Fitness Value
> Ã—10 1
> CMA-ES
> Population=8192
> Population=1024
> Population=128
> Population=16 020 40 60 80 100

Generation 

> 0.00
> 0.50
> 1.00
> 1.50
> 2.00
> Population Diversity
> Ã—10 2
> CMA-ES
> Population=8192
> Population=1024
> Population=128
> Population=16

(a) CMA-ES 0 20 40 60 80 100 

Generation      

> 0.50
> 1.00
> 1.50
> 2.00
> Fitness Value
> Ã—10 1
> PSO
> Population=8192
> Population=1024
> Population=128
> Population=16 020 40 60 80 100

Generation  

> 0.00
> 0.25
> 0.50
> 0.75
> 1.00
> 1.25
> 1.50
> 1.75
> Population Diversity
> Ã—10 2
> PSO
> Population=8192
> Population=1024
> Population=128
> Population=16

(b) PSO 0 20 40 60 80 100 

Generation      

> 0.50
> 1.00
> 1.50
> 2.00
> Fitness Value
> GA-SBX/PM
> Population=8192
> Population=1024
> Population=128
> Population=16 020 40 60 80 100

Generation 

> 0.00
> 0.20
> 0.40
> 0.60
> 0.80
> 1.00
> 1.20
> Population Diversity
> Ã—10 1
> GA-SBX/PM
> Population=8192
> Population=1024
> Population=128
> Population=16

(c) GA-SBX/PM 0 20 40 60 80 100 

Generation      

> 1.60
> 1.70
> 1.80
> 1.90
> 2.00
> 2.10
> Fitness Value
> Ã—10 1
> DE
> Population=8192
> Population=1024
> Population=128
> Population=16 020 40 60 80 100

Generation  

> 0.50
> 1.00
> 1.50
> 2.00
> Population Diversity
> Ã—10 2
> DE
> Population=8192
> Population=1024
> Population=128
> Population=16

(d) DE 

Fig. 8: Evolutionary dynamics of EAs configured with four population sizes (16, 128, 1024, and 8192) on fa6 over 100 generations. Left : Fitness convergence (red curves), which illustrates the mean and interquartile range across 15 independent runs. Right : Population diversity (blue curves), as quantified by the mean pairwise Euclidean distance between individuals. 0 5 10 15 20 25 30 

Time (s) 

> 0.00
> 0.50
> 1.00
> 1.50
> 2.00
> Fitness Value
> Ã—10 1
> CMA-ES
> Population=8192
> Population=1024
> Population=128
> Population=16

(a) CMA-ES 0 5 10 15 20 25 30 

Time (s)  

> 0.00
> 0.50
> 1.00
> 1.50
> 2.00
> Fitness Value
> Ã—10 1
> PSO
> Population=8192
> Population=1024
> Population=128
> Population=16

(b) PSO 0 5 10 15 20 25 30 

Time (s)  

> 0.00
> 0.50
> 1.00
> 1.50
> 2.00
> Fitness Value
> GA-SBX/PM
> Population=8192
> Population=1024
> Population=128
> Population=16

(c) GA-SBX/PM 0 5 10 15 20 25 30 

Time (s)  

> 0.00
> 0.50
> 1.00
> 1.50
> 2.00
> Fitness Value
> Ã—10 1
> DE
> Population=8192
> Population=1024
> Population=128
> Population=16

(d) DE 

Fig. 9: Convergence curves of the mean fitness value across 15 independent runs on fa6 , where each trial is executed within a 30-second time budget. 

and exploitation inherent in large-population EAs. Table IV summarizes these behaviors and correlates the observed trends in Fig. 7 with the underlying evolutionary mechanisms. Fig. 10 complements Fig. 7 by analyzing the NFEs com-pleted within a 30-second interval relative to the optimization results. Facilitated by GPU acceleration, most EAs executed millions to tens of millions of NFEs within this timeframe, even at population sizes of up to 8192. This substantial increase in evaluation throughput facilitates enhanced search depth. Consequently, the results demonstrate pronounced con-vergence patterns, in which most data points cluster near the theoretical optima. 

2) Neuroevolution Tasks: We further extended our inves-tigation to neuroevolution optimization tasks, executing all algorithms on an RTX 3090 GPU with three different pop-ulation sizes (128, 1024, and 8192). Each configuration ran for 600 seconds, with 10 independent trials. Using fixed-time evaluation, rather than fixed-FE, allowed us to better highlight the impact of GPU parallelism: larger populations raise per-generation latency owing to memory-bandwidth and synchro-nisation overheads, yet the mass of concurrent evaluations still lifts the cumulative NFEs. Fig. 11 reports achieved reward on single-objective tasks and HV value for multi-objective optimization conditions, together with the NFEs achieved on four neuroevolution tasks. The NFE trace (y-axis) does not scale proportionally with population size, confirming that kernel throughput eventually plateaus under the constraints of the cardâ€™s memory subsystem. Complete experimental data is available in Supplementary Document XII-C2. For both single-objective tasks, the data points shift from the bottom-left to the top-right as the population grows. This trajectory indicates a dual gain in reward and NFE. CMA-ES benefits the most from this scaling due to its reliance on sample size for covariance matrix estimation. With alarge population, the algorithm efficiently collects sufficient statistics in parallel on the GPU, which leads to the most significant improvement in reward. Similarly, larger popula-tions allow PSO and CSO to maintain a more diverse set of candidate solutions, thereby improving convergence to the global optimum. In contrast, classical GAs with SBX/PM or UR/GM operators exhibit only marginal progress. Their static crossover and mutation repertoire cannot maintain diversity in very high-dimensional weight spaces. Consequently, additional samples merely reiterate local patterns. Furthermore, these methods experience diminishing returns due to the overhead of global communication in large populations, which limits BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 11 

TABLE IV OBSERVED EFFECTS OF SCALING POPULATION IN TESTED EA S AND UNDERLYING MECHANISMS . (16â€“8192 INDIVIDUALS , 100 

GENERATIONS )

Algorithm Key mechanism Effect of larger population 

Swarm-based 

(PSO, CSO) 

Positions updated toward personal/global elites; CSO adds winnerâ€“loser competition mechanism. 

+ More particles cover a wider search radius and sustain diversity; CSOâ€™s competitive sampling amplifies this benefit and accelerates escape from local optima. Diff. Evo. 

(DE, SaDE) 

Trial vectors are built from scaled parent differences and crossover; SaDE self-adapts scaling factor ( F )and crossover rate ( CR ) during the iterative process. 

- Larger parent spacing inflates step sizes, causing frequent overshoot and stagnation; SaDE regains stability via self-adaptation. GA (GA-UR/GM, GA-SBX/PM) 

Stochastic recombination (uniform / simulated binary crossover) plus mutation pool gene statistics. 

+ A bigger gene pool yields more reliable allele-frequency estimates, curbing genetic drift and delaying premature convergence while still broadening exploration. ES (CMA-ES, IPOP-CMA-ES) 

CMA updates full covariance and global step size Ïƒ;IPOP restarts with doubled Î».

+ Extra offspring sharpen covariance estimates, revealing clearer curvature directions; IPOP leverages large Î» restarts for aggressive global search. Indicator-based 

(HypE, IBEA) 

Fitness assigned via hypervolume or Îµ-indicator. + Denser Pareto set improves trade-off resolution; however, indicator evaluation scales and quickly dominates runtime without GPU kernels or pruning. Pareto-based 

(SPEA2, NSGA-II/III) 

Non-dominated sorting and crowding-distance den-sity estimation. 

+ More individuals fill gaps and extremes, producing a smoother front; sorting overhead grows significantly. Decomposition 

(RVEA, MOEA/D) 

Problem split into weight-vector subproblems opti-mized cooperatively. 

â€“ An overly dense weight grid yields redundant neighborhoods, dilutes search pressure, and leads to stalled improvement despite higher cost. Swarm-based 

(LMOCSO) 

Pairwise winnerâ€“loser moves guided by an external archive. 

+ A massive candidate set intensifies selection pressure, accelerating convergence while maintaining diversity across objectives. The symbols â€œ+â€ and â€œâ€“â€ denote beneficial and detrimental effects, respectively. PSO CSO DE SaDE GA-SBX/PM GA-UR/GM CMA-ES IPOP-CMA-ES 0.00 0.50 1.00 1.50 2.00  

> Ã—10 1
> 0.00 0.40 0.80 1.20
> Number of FEs
> Ã—10 8
> Population Size = 8192 Population Size = 1024 Population Size = 128
> PSO 8192
> CSO 8192
> DE 8192
> SaDE 8192
> IPOP-CMA-ES 8192
> CMA-ES 8192
> GA-UR/GM 8192
> GA-SBX/PM 819 2

Fitness Value 

(a) fa60.00 0.80 1.60 2.40 3.20  

> Ã—10 1
> 0.00 2.00 4.00 6.00
> Number of FEs
> Ã—10 7
> Population Size = 8192 Population Size = 1024 Population Size = 128
> PSO 8192
> CSO 8192
> DE 8192
> GA-UR/GM 8192
> CMA-ES 8192
> IPOP-CMA-ES 8192
> GA-SBX/PM 819 2
> SaDE 8192

Fitness Value (b) fa10 HypE IBEA RVEA MOEA/D NSGA-II NSGA-III SPEA2 LMOCSO 0 200 400 600 800 

IGD Value   

> 3.00 3.00 3.00 3.01
> Number of FEs
> Ã—10 1
> Population Size = 8192 Population Size = 1024 Population Size = 128
> SPEA2 8192
> IBEA 8192
> RVEA 8192
> NSGA-III 8192
> MOEA/D 8192 HypE 8192
> LMOCSO 8192
> NSGA-II 8192

(c) fa11 1.6 2.4 3.2 4.0 4.8 

IGD Value     

> 3.00 3.02 3.04 3.06
> Number of FEs
> Ã—10 1
> Population Size = 8192 Population Size = 1024 Population Size = 128
> SPEA2 8192
> RVEA 8192
> NSGA-III 8192
> HypE 819 2MOEA/D 8192 
> IBEA 8192
> LMOCSO 8192
> NSGA-II 8192

(d) fa19 

Fig. 10: Performance of EAs tested on numerical problems under varying population sizes, evaluated in terms of solution quality and number of FEs completed within 30 seconds. Lower fitness/IGD value denote better performance. Results represent averaged performance values across 15 in-dependent runs. Marker styles indicate population scales: hollow symbols for small populations (128), forward-slash-filled symbols for medium populations (1024), and solid symbols for large populations (8192). Different marker shapes distinguish between algorithms. PSO CSO DE SaDE GA-SBX/PM GA-UR/GM CMA-ES IPOP-CMA-ES 0.90 0.60 0.30 0.00 0.30  

> Ã—10 3
> 0.00 1.00 2.00 3.00
> Number of FEs
> Ã—10 5
> Population Size = 8192 Population Size = 1024 Population Size = 128
> CSO 8192
> PSO 8192
> CMA-ES 8192
> IPOP-CMA-ES 8192
> SaDE 8192
> DE 8192
> GA-UR/GM 1024
> GA-SBX/PM 128

Reward 

(a) fb42.50 2.75 3.00 3.25 3.50 3.75 

> Ã—10 2
> 0.00 1.00 2.00 3.00 4.00
> Number of FEs
> Ã—10 5
> Population Size = 8192 Population Size = 1024 Population Size = 128
> DE 8192
> SaDE 8192
> CSO 8192
> IPOP-CMA-ES 8192
> PSO 8192
> GA-UR/GM 128
> CMA-ES 8192
> GA-SBX/PM 128

Reward (b) fb5HypE IBEA RVEA MOEA/D NSGA-II NSGA-III SPEA2 LMOCSO 3.25 3.50 3.75 4.00 4.25 

HV Value Ã—10 5   

> 0.00 1.50 3.00 4.50
> Number of FEs
> Ã—10 5
> Population Size = 8192 Population Size = 1024 Population Size = 128
> SPEA2 8192 HypE 8192 IBEA 8192
> MOEA/D 8192
> RVEA 8192
> LMOCSO 8192 NSGA-II 8192
> NSGA-III 8192

(c) fb61.36 1.44 1.52 1.60 1.68 1.76 

HV Value Ã—10 10    

> 0.00 1.50 3.00 4.50
> Number of FEs
> Ã—10 5
> Population Size = 8192 Population Size = 1024 Population Size = 128
> RVEA 8192 SPEA2 8192
> MOEA/D 8192
> IBEA 8192
> LMOCSO 1024
> HypE 1024
> NSGA-III 1024
> NSGA-II 8192

(d) fb7

Fig. 11: Performance of EAs tested on neuroevolution tasks under varying population sizes, evaluated in terms of solution quality and number of FEs completed within 600 seconds. Higher reward/HV value denotes better performance. Results represent averaged performance values across 10 inde-pendent runs. Marker styles indicate population scales: hollow symbols for small populations (128), forward-slash-filled symbols for medium populations (1024), and solid symbols for large populations (8192). Different marker shapes distinguish between algorithms. BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 12 

their scalability. SaDE employs on-line strategy adaptation to overcome this limitation and thus decisively outperforms standard DE. For the bi-objective (fb6 ) and tri-objective (fb7 ) cases, HV rises monotonically with population size. However, the magnitude of this rise depends on the algorithm. HypE shows significant HV gain in the tri-objective setting because its hypersphere-based extreme-value sampling naturally exploits large batches to probe the high-dimensional tails of the Pareto front. Since the bi-objective surface offers fewer such ex-tremes, the extra samples are less valuable in that context. RVEA also gains markedly, which confirms that its angular-regulation mechanism preserves exploration at scale. Con-versely, NSGA-II/III and SPEA2 suffer from excessive selec-tion pressure. Non-dominated sorting and density estimators promote early convergence around incumbent elitists. As a result, additional individuals are quickly culled rather than used to diversify the front, which leads to HV saturation at a population size of 8192. Collectively, these results indicate that enlarging the parallel evaluation budget is more cost-effective than pursuing additional generations under a fixed wall-time. GPU parallelism amplifies the strengths of algorithms that are sample-hungry or sampling-efficient, such as CMA-ES and HypE. V. I MPLICATIONS FOR EA R ESEARCH 

The results of this study demonstrate that GPU parallelism introduces substantive changes to the practical behavior of EAs, with implications that extend beyond implementation efficiency to evaluation methodology, algorithm design and future research directions. First, evaluation protocols for EAs require reconsideration. Since FEs can be executed in large batches with highly vari-able throughput, a fixed and uniform number of evaluations no longer provides a reliable proxy for computational cost. Under GPU execution, such fixed-FE budgets may prematurely trun-cate evolutionary processes and systematically underestimate algorithms that benefit from prolonged exploration or late-stage refinement. Consequently, time-constrained evaluation offers a more direct and hardware-aligned measure of effi-ciency. In addition to reflecting practical computational cost, time-based evaluation allows algorithms to more fully exploit available parallel resources, thereby aligning benchmarking practices with real-world deployment scenarios. Second, the heterogeneous effectiveness of GPU accel-eration underscores the growing importance of algorithmic structure. Our results indicate that scalability is governed not only by nominal computational complexity but also by syn-chronization patterns, data dependencies, and memory access regularity. Specifically, algorithms with largely independent operations and regular data flow exhibit substantially better scalability than those that require frequent global coordina-tion or irregular memory access. These findings suggest that future EA development should explicitly account for parallel execution characteristics. In particular, structural parallelism must be treated as a key design consideration alongside search operators, selection mechanisms, and adaptation strategies. Third, the ability to deploy substantially larger populations at manageable computational cost elevates population size from an implementation constraint to an analytical dimension. Different evolutionary mechanisms respond to population scal-ing in distinct ways, which shapes convergence behavior, di-versity maintenance, and overall search dynamics. Such effects reveal intrinsic algorithmic properties that remain obscured un-der CPU-constrained regimes. Consequently, population size should not be viewed merely as a tunable hyperparameter, but rather as a factor that enables deeper analysis of algorithm behavior under relaxed computational constraints. Finally, these observations have implications for emerging research directions, including meta-optimization and learning-based evolutionary methods. GPU-enabled scalability supports richer feedback signals, broader sampling regimes, and longer training horizons. This scalability facilitates the study of adaptive operators and learned optimizers under conditions that more closely resemble their intended deployment environ-ments. This capability is particularly relevant for approaches that rely on large-scale data or extended training horizons, where computational limitations have previously restricted experimental scope. VI. C ONCLUSION 

This work examined the impact of GPU parallelism on EAs from the perspectives of computational efficiency, scal-ability, and algorithmic behavior. Through a comprehensive empirical analysis, we showed that GPU acceleration yields highly heterogeneous effects across algorithms and problem settings. While GPU execution can substantially reduce run-time, the magnitude of these gains depends critically on algorithmic structure, revealing a close coupling between evolutionary mechanisms and hardware characteristics. At the same time, GPU parallelism exhibits practical limits, with per-formance saturation arising from synchronization overheads and hardware resource constraints. Furthermore, GPU paral-lelism fundamentally alters the relationship between function evaluations, population size, and optimization progress, chal-lenging long-standing assumptions in evolutionary algorithm benchmarking. By enabling time-based evaluation and large-population regimes, parallel hardware exposes performance characteristics and algorithmic behaviors that remain hidden under traditional CPU-constrained settings. Collectively, these findings suggest that GPU parallelism acts as a pivotal factor that reshapes the evaluation, design, and understanding of EAs, rather than serving as a peripheral implementation detail. Consequently, accounting for these im-plications is essential for developing evolutionary methods on modern computing platforms that are scalable, interpretable, and practically relevant. REFERENCES [1] T. BÂ¨ ack and H.-P. Schwefel, â€œAn overview of evolutionary algorithms for parameter optimization,â€ Evolutionary Computation , vol. 1, no. 1, pp. 1â€“23, 1993. [2] D. A. Van Veldhuizen and G. B. Lamont, â€œMultiobjective evolutionary algorithm research: A history and analysis,â€ Tech. Rep., 1998. [3] J. H. Holland, Adaptation in natural and artificial systems: an intro-ductory analysis with applications to biology, control, and artificial intelligence . MIT press, 1975. BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 13 

[4] J. Kennedy and R. Eberhart, â€œParticle swarm optimization,â€ in Proceed-ings of International Conference on Neural Networks (ICNNâ€™95) . IEEE, 1995, pp. 1942â€“1948. [5] R. Storn and K. V. Price, â€œDifferential evolution-A simple and efficient heuristic for global optimization over continuous spaces,â€ J. Glob. Optim. , vol. 11, no. 4, pp. 341â€“359, 1997. [6] J. Liang, Z. Hu, Z.-W. Li, K. Qiao, and W.-F. Guo, â€œMultiobjective optimization-based network control principles for identifying person-alized drug targets with cancer,â€ IEEE Transactions on Evolutionary Computation , vol. 28, no. 5, pp. 1322â€“1335, 2024. [7] F. Neri, J. Toivanen, and R. A. E. MÂ¨ akinen, â€œAn adaptive evolution-ary algorithm with intelligent mutation local searchers for designing multidrug therapies for HIV,â€ Applied Intelligence , vol. 27, no. 3, pp. 219â€“235, 2007. [8] K. Grantham, M. Mukaidaisi, H. K. Ooi, M. S. Ghaemi, A. Tchagang, and Y. Li, â€œDeep evolutionary learning for molecular design,â€ IEEE Computational Intelligence Magazine , vol. 17, no. 2, pp. 14â€“28, 2022. [9] J. Zhao, W. Peng, H. Wang, W. Yao, and W. Zhou, â€œA morphological transfer-based multi-fidelity evolutionary algorithm for soft robot de-sign,â€ IEEE Computational Intelligence Magazine , vol. 19, no. 4, pp. 16â€“30, 2024. [10] Z. Wang, T. Luo, M. Li, J. T. Zhou, R. S. M. Goh, and L. Zhen, â€œEvo-lutionary multi-objective model compression for deep neural networks,â€ 

IEEE Computational Intelligence Magazine , vol. 16, no. 3, pp. 10â€“21, 2021. [11] S. Xue, H. Chen, C. Xie, B. Zhang, X. Gong, and D. Doermann, â€œFast and unsupervised neural architecture evolution for visual representation learning,â€ IEEE Computational Intelligence Magazine , vol. 16, no. 3, pp. 22â€“32, 2021. [12] M.-L. Wong and T.-T. Wong, â€œParallel hybrid genetic algorithms on consumer-level graphics hardware,â€ in 2006 IEEE International Confer-ence on Evolutionary Computation , 2006, pp. 2973â€“2980. [13] D. L. Souza, G. D. Monteiro, T. C. Martins, V. A. Dmitriev, and O. N. Teixeira, â€œPSO-GPU: accelerating particle swarm optimization in CUDA-based graphics processing units,â€ in Proceedings of the 13th Annual Conference Companion on Genetic and Evolutionary Computa-tion , ser. GECCO â€™11, Dublin, Ireland, 2011, p. 837â€“838. [14] A. K. Qin, F. Raimondo, F. Forbes, and Y. S. Ong, â€œAn improved CUDA-based implementation of differential evolution on GPU,â€ in 

Proceedings of the 14th Annual Conference on Genetic and Evolutionary Computation , ser. GECCO â€™12, Philadelphia, Pennsylvania, USA, 2012, p. 991â€“998. [15] Y. Tang, Y. Tian, and D. Ha, â€œEvoJAX: hardware-accelerated neuroevo-lution,â€ in Proceedings of the Genetic and Evolutionary Computation Conference Companion , ser. GECCO â€™22, Boston, Massachusetts, 2022, p. 308â€“311. [16] R. T. Lange, â€œevosax: JAX-based evolution strategies,â€ in Proceedings of the Companion Conference on Genetic and Evolutionary Computation ,ser. GECCO â€™23 Companion, Lisbon, Portugal, 2023, p. 659â€“662. [17] B. Huang, R. Cheng, Z. Li, Y. Jin, and K. C. Tan, â€œEvoX: A distributed GPU-accelerated framework for scalable evolutionary computation,â€ 

IEEE Transactions on Evolutionary Computation , pp. 1â€“1, 2024. [18] R. Cheng and Y. Jin, â€œA competitive swarm optimizer for large scale optimization,â€ IEEE Transactions on Cybernetics , vol. 45, no. 2, pp. 191â€“204, 2015. [19] J. J. Liang, A. K. Qin, P. N. Suganthan, and S. Baskar, â€œComprehensive learning particle swarm optimizer for global optimization of multimodal functions,â€ IEEE Transactions on Evolutionary Computation , vol. 10, no. 3, pp. 281â€“295, 2006. [20] A. K. Qin, V. L. Huang, and P. N. Suganthan, â€œDifferential evolution algorithm with strategy adaptation for global numerical optimization,â€ 

IEEE Transactions on Evolutionary Computation , vol. 13, no. 2, pp. 398â€“417, 2009. [21] J. Zhang and A. C. Sanderson, â€œJADE: Adaptive differential evolution with optional external archive,â€ IEEE Transactions on Evolutionary Computation , vol. 13, no. 5, pp. 945â€“958, 2009. [22] R. B. Agrawal, K. Deb, and R. B. Agrawal, â€œSimulated binary crossover for continuous search space,â€ Complex Systems , vol. 9, no. 3, pp. 115â€“ 148, 1994. [23] G. Syswerda, â€œUniform crossover in genetic algorithms,â€ in Proceedings of the 3rd International Conference on Genetic Algorithms , 1989. [24] D. E. Goldberg and J. Richardson, â€œGenetic algorithms with sharing for multimodal function optimization,â€ Proc Icga , 1987. [25] N. Hansen, S. D. MÂ¨ uller, and P. Koumoutsakos, â€œReducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation (CMA-ES),â€ Evolutionary Computation , vol. 11, no. 1, pp. 1â€“18, 2003. [26] A. Auger and N. Hansen, â€œPerformance evaluation of an advanced local search evolutionary algorithm,â€ in 2005 IEEE congress on evolutionary computation , vol. 2. IEEE, 2005, pp. 1777â€“1784. [27] R. Ros and N. Hansen, â€œA simple modification in CMA-ES achieving linear time and space complexity,â€ in International conference on parallel problem solving from nature . Springer, 2008, pp. 296â€“305. [28] K. Deb, S. Agrawal, A. Pratap, and T. Meyarivan, â€œA fast and elitist multiobjective genetic algorithm: NSGA-II,â€ IEEE Transactions on Evolutionary Computation , vol. 6, no. 2, pp. 182â€“197, 2002. [29] K. Deb and H. Jain, â€œAn evolutionary many-objective optimization algorithm using reference-point-based nondominated sorting approach, part I: solving problems with box constraints,â€ IEEE Transactions on Evolutionary Computation , vol. 18, no. 4, pp. 577â€“601, 2014. [30] E. Zitzler and S. KÂ¨ unzli, â€œIndicator-based selection in multiobjective search,â€ in Parallel Problem Solving from Nature-PPSN VIII, 8th Inter-national Conference , ser. Lecture Notes in Computer Science, vol. 3242. Springer, 2004, pp. 832â€“842. [31] J. Bader and E. Zitzler, â€œHypE: An algorithm for fast hypervolume-based many-objective optimization,â€ Evolutionary Computation , vol. 19, no. 1, pp. 45â€“76, 2011. [32] Q. Zhang and H. Li, â€œMOEA/D: A multiobjective evolutionary algorithm based on decomposition,â€ IEEE Transactions on Evolutionary Compu-tation , vol. 11, no. 6, pp. 712â€“731, 2007. [33] E. CantÂ´ u-Paz, Efficient and Accurate Parallel Genetic Algorithms .Springer Science & Business Media, 2000. [34] R. Tanese, â€œDistributed genetic algorithms for function optimization,â€ Ph.D. dissertation, University of Michigan, 1989. [35] E. Alba and M. Tomassini, â€œParallelism and evolutionary algorithms,â€ 

IEEE Transactions on Evolutionary Computation , vol. 6, no. 5, pp. 443â€“ 462, 2002. [36] D. Whitley, S. Rana, and R. B. Heckendorn, â€œThe island model genetic algorithm: On separability, population size and convergence,â€ Journal of Computing and Information Technology , vol. 7, no. 1, pp. 33â€“47, 1999. [37] E. CantÂ´ u-Paz, â€œA survey of parallel genetic algorithms,â€ Calculateurs parall` eles, rÂ´ eseaux et syst` emes rÂ´ epartis , vol. 10, no. 2, pp. 141â€“171, 1998. [38] S. E. Eklund, â€œA massively parallel architecture for distributed genetic algorithms,â€ Parallel Computing , vol. 30, no. 5â€“6, pp. 647â€“676, 2004. [39] J. D. Owens, M. Houston, D. Luebke, S. Green, J. E. Stone, and J. C. Phillips, â€œGPU computing,â€ Proceedings of the IEEE , vol. 96, no. 5, pp. 879â€“899, 2008. [40] J. R. Cheng and M. Gen, â€œAccelerating genetic algorithms with gpu computing: A selective overview,â€ Computers & Industrial Engineering , vol. 128, pp. 514â€“525, 2019. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S036083521830665X [41] S. Harding and W. Banzhaf, â€œFast genetic programming on gpus,â€ in Genetic Programming: 10th European Conference, EuroGP 2007, Valencia, Spain, April 11-13, 2007. Proceedings 10 . Springer, 2007, pp. 90â€“101. [42] O. Maitre, L. A. Baumes, N. Lachiche, A. Corma, and P. Collet, â€œCoarse grain parallelization of evolutionary algorithms on gpgpu cards with easea,â€ in Proceedings of the 11th Annual Conference on Genetic and Evolutionary Computation , ser. GECCO â€™09. New York, NY, USA: Association for Computing Machinery, 2009, p. 1403â€“1410. [43] J. Bradbury, R. Frostig, P. Hawkins, M. J. Johnson, C. Leary, D. Maclaurin, G. Necula, A. Paszke, J. VanderPlas, S. Wanderman-Milne, and Q. Zhang, â€œJAX: composable transformations of Python+NumPy programs,â€ 2018. [Online]. Available: http://github.com/jax-ml/jax [44] J. Ansel, E. Yang, H. He, N. Gimelshein, A. Jain, M. Voznesensky, B. Bao, P. Bell, D. Berard, E. Burovski, G. Chauhan, A. Chourdia, W. Constable, A. Desmaison, Z. DeVito, E. Ellison, W. Feng, J. Gong, M. Gschwind, B. Hirsh, S. Huang, K. Kalambarkar, L. Kirsch, M. Lazos, M. Lezcano, Y. Liang, J. Liang, Y. Lu, C. Luk, B. Maher, Y. Pan, C. Puhrsch, M. Reso, M. Saroufim, M. Y. Siraichi, H. Suk, M. Suo, P. Tillet, E. Wang, X. Wang, W. Wen, S. Zhang, X. Zhao, K. Zhou, R. Zou, A. Mathews, G. Chanan, P. Wu, and S. Chintala, â€œPyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation,â€ in 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS â€™24) . ACM, Apr. 2024. [Online]. Available: https://docs.pytorch.org/assets/pytorch2-2.pdf [45] T. Back, U. Hammel, and H.-P. Schwefel, â€œEvolutionary computation: comments on the history and current state,â€ IEEE Transactions on Evolutionary Computation , vol. 1, no. 1, pp. 3â€“17, 1997. BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 14 

[46] S. Chetlur, C. Woolley, P. Vandermersch, J. Cohen, J. Tran, B. Catanzaro, and E. Shelhamer, â€œcudnn: Efficient primitives for deep learning.â€ CoRR ,vol. abs/1410.0759, 2014. [47] A. Krizhevsky, I. Sutskever, and G. E. Hinton, â€œImagenet classification with deep convolutional neural networks,â€ Commun. ACM , vol. 60, no. 6, p. 84â€“90, May 2017. [Online]. Available: https://doi.org/10.1145/ 3065386 [48] L.-N. Xing, Y.-W. Chen, P. Wang, Q.-S. Zhao, and J. Xiong, â€œA knowledge-based ant colony optimization for flexible job shop scheduling problems,â€ Applied Soft Computing , vol. 10, no. 3, pp. 888â€“896, 2010. [Online]. Available: https://www.sciencedirect.com/ science/article/pii/S156849460900194X [49] Z.-H. Zhan, J.-Y. Li, S. Kwong, and J. Zhang, â€œLearning-aided evolution for optimization,â€ IEEE Transactions on Evolutionary Computation ,vol. 27, no. 6, pp. 1794â€“1808, 2023. [50] S. Hochreiter, A. S. Younger, and P. R. Conwell, â€œLearning to learn using gradient descent,â€ in Artificial Neural Networks â€” ICANN 2001 ,G. Dorffner, H. Bischof, and K. Hornik, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2001, pp. 87â€“94. [51] A. Abraham, â€œMeta learning evolutionary artificial neural networks,â€ 

Neurocomputing , vol. 56, pp. 1â€“38, 2004. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0925231203003692 [52] A. Auger and N. Hansen, â€œA restart CMA-EA with increasing population size,â€ in 2005 IEEE Congress on Evolutionary Computation , vol. 2, 2005, pp. 1769â€“1776 Vol. 2. [53] M. Kim, T. Hiroyasu, M. Miki, and S. Watanabe, â€œSPEA2+: Improving the performance of the strength pareto evolutionary algorithm 2,â€ in 

Parallel Problem Solving from Nature-PPSN VIII, 8th International Conference . Springer, 2004, pp. 742â€“751. [54] Z. Liang, T. Jiang, K. Sun, and R. Cheng, â€œGPU-accelerated evolutionary multiobjective optimization using tensorized RVEA,â€ in Proceedings of the Genetic and Evolutionary Computation Conference , ser. GECCO â€™24, Melbourne, VIC, Australia, 2024, p. 566â€“575. [55] Y. Tian, X. Zheng, X. Zhang, and Y. Jin, â€œEfficient large-scale multi-objective optimization based on a competitive swarm optimizer,â€ IEEE Transactions on Cybernetics , vol. 50, no. 8, pp. 3696â€“3708, 2020. [56] A. Kumar, K. V. Price, A. W. Mohamed, A. A. Hadi, and P. N. Suganthan, â€œProblem definitions and evaluation criteria for the 2022 special session and competition on single objective bound constrained numerical optimization,â€ in Technical Report , 2021. [57] K. Deb, L. Thiele, M. Laumanns, and E. Zitzler, â€œScalable multi-objective optimization test problems,â€ in Congress on Evolutionary Computation , 2002. [58] E. Zitzler, K. Deb, and L. Thiele, â€œComparison of multiobjective evolutionary algorithms: Empirical results,â€ Evolutionary computation ,vol. 8, no. 2, pp. 173â€“195, 2000. [59] C. D. Freeman, E. Frey, A. Raichuk, S. Girgin, I. Mordatch, and O. Bachem, â€œBrax - a differentiable physics engine for large scale rigid body simulation,â€ 2021. [Online]. Available: http://github.com/google/brax [60] M. Abdelatti, A. Hendawi, and M. Sodhi, â€œOptimizing a GPU-accelerated genetic algorithm for the vehicle routing problem,â€ in 

Proceedings of the Genetic and Evolutionary Computation Conference Companion , ser. GECCO â€™21, Lille, France, 2021, p. 117â€“118. [61] E. Zitzler, K. Deb, and L. Thiele, â€œComparison of multiobjective evolutionary algorithms: Empirical results,â€ MIT Press , no. 2, 2000. [62] R. Cheng, Y. Jin, M. Olhofer, and B. Sendhoff, â€œA reference vector guided evolutionary algorithm for many-objective optimization,â€ IEEE Transactions on Evolutionary Computation , vol. 20, no. 5, pp. 773â€“791, 2016. BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 15 

# Scaling Behaviors of Evolutionary Algorithms on GPUs: When Does Parallelism Pay Off? (Supplementary Document) 

VII. I NTRODUCTION 

This document is organized as follows: Section II provides the downloadable resources, including the testing platforms, software libraries, and benchmark functions utilized in the experiments. Section III lists the abbreviations used throughout the paper. Section IV introduces the neuroevolution tasks employed in the study. Section V details the experimental setup. Specifically, it outlines the device configurations and the parameter settings for each evaluated evolutionary algorithm. Finally, Section VI analyzes the experimental results. It presents visualizations and statistical summaries to illustrate the algorithmic performance across various hardware platforms based on the proposed metrics. VIII. D OWNLOADABLE MATERIAL 

All experiments in this paper are performed on the EvoX platform [17], a comprehensive framework tailored for evolutionary computation research. EvoX streamlines the execution and management of algorithms across a range of hardware configurations. The experiments include both single-objective and multi-objective optimization tasks, which are categorized into two primary categories: numerical optimization and neuroevolution. The numerical optimization problems are primarily sourced from the CEC 2022 [60], DTLZ [57], and ZDT [61] benchmark suites, while the neuroevolution tasks make use of environments from the Brax engine. These benchmark functions are extensively employed in evolutionary computation to evaluate the performance of algorithms across a range of optimization problems. Detailed descriptions and datasets are available through the links provided below. 

â€¢ EvoX : https://github.com/EMI-Group/evox 

â€¢ CEC2022 Benchmark : https://github.com/P-N-Suganthan/2022-SO-BO 

â€¢ DTLZ Test Suite : https://github.com/EMI-Group/evox/blob/main/src/evox/problems/numerical/dtlz.py 

â€¢ ZDT Test Suite : https://github.com/EMI-Group/evox/blob/main/src/evox/problems/numerical/zdt.py 

â€¢ Brax-Based Robotic Control Tasks : https://github.com/google/brax IX. A BBREVIATIONS 

Table V provides a list of the abbreviations employed throughout this paper, serving as a reference to maintain clarity and consistency in the presentation of terms and concepts. 

TABLE V LIST OF ABBREVIATIONS USED IN THIS ARTICLE 

Abbreviations Descriptions 

EA Evolutionary algorithm. Popsize Population size of an EA. FE Fitness evaluation of evolutionary algorithm. 

Pe The proposed evaluation metric that comprehensively considers power consumption and fitness evaluations. 

Pt A simplified version of Pe that replaces power consumption with the algorithmâ€™s runtime. 

Onorm The normalized optimization performance achieved by algorithms. 

S State space of robot control tasks, encapsulates all possible configurations and statuses that the robotic system can attain. 

A Action space of robot control tasks, comprises the set of all actionable controls or decisions that the robot can execute to transition from one state to another within the environment. ANOVA Analysis of variance. PSO [4] Particle swarm optimization CSO [18] Competitive Swarm Optimizer DE [5] Differential Evolution SaDE [20] Differential Evolution with Strategy adaptation CMA-ES [25] Evolution Strategy with Covariance Matrix Adaptation IPOP-CMA-ES [52] A Restart CMA Evolution Strategy With Increasing Population Size GA-UR/GM [23] Genetic algorithm with uniform random crossover and gaussian mutation GA-SBX/PM [24] Genetic algorithm with simulated binary crossover and polynomial mutation NSGA-II [28] Non-dominated Sorting Genetic Algorithm II NSGA-III [29] Non-dominated Sorting Genetic Algorithm III RVEA [62] Reference Vector Guided Evolutionary Algorithm MOEA/D [32] Multi-objective Evolutionary Algorithm Based on Decomposition HypE [31] Hypervolume Estimation Algorithm for Multi-objective Optimization LMOCSO [55] Efficient Large-Scale Multiobjective Optimization Based on Competitive Swarm Optimizer SPEA2 [53] Strength Pareto Evolutionary Algorithm II IBEA [30] Indicator-Based Evolutionary Algorithm BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 16 

X. N EUROEVOLUTION BENCHMARKS 

1) Robot Control Task based on Brax Engine: Brax provides a collection of robotic control environments that are widely used in reinforcement learning (RL) and evolutionary algorithm research. These environments simulate physically realistic dynamics and serve as benchmarks for evaluating various control strategies. Each task involves controlling an articulated agent with continuous actions in a simulated 3D environment. Fig. 12 illustrates several robot control environments based on the Brax engine. These environments leverage a differentiable physics engine built on JAX, which allows for highly efficient parallel simulation across hardware accelerators such as GPUs and TPUs. This architecture enables fast gradient-based learning and facilitates large-scale experimentation. Furthermore, Brax is compatible with various Reinforcement Learning (RL) algorithms, including Proximal Policy Optimization (PPO), Augmented Random Search (ARS), and Evolutionary Strategies (ES). Consequently, these environments serve as versatile benchmarks for both policy gradient methods and evolutionary strategies.   

> (a) Halfcheetah (b) Hopper
> (c) Pusher (d) Swimmer
> Fig. 12: Robotic control tasks based on Brax engine.

2) Multi-objective Neuroevolution: In the Brax environment, robot control tasks are conventionally defined as single-objective optimization problems. To align with the objectives of our experimental analysis, we reformulate five selected environments into multi-objective optimization tasks, thereby enhancing their suitability for comprehensive performance evaluation. The specific descriptions of the reformulated multi-objective tasks are as follows:  

> â€¢

MoHopper-m2: The observation and action spaces are defined as S âˆˆ R11 and A âˆˆ R3, respectively. Each episode comprises 1000 steps. The first objective is to maximize the forward reward, given by: 

f1 = w1 Â· vx âˆ’ X

> i

a2 

> i

+ C, (1) where vx denotes the velocity along the x-axis, w1 represents the corresponding weight, ai denotes the action of each actuator, and C = 1 is a constant survival reward that ensures the agent remains active. The second objective is to maintain or increase the height of the hopper, which is formulated as: 

f2 = 10 Â· (hcurr âˆ’ hinit ) âˆ’ X

> i

a2 

> i

+ C, (2) where hcurr denotes the current height of the hopper, and hinit represents the initial height. The term P 

> i

a2 

> i

penalizes excessive actuator actions, while C corresponds to the survival reward.  

> â€¢

MoHopper-m3: The observation and action spaces are S âˆˆ R11 and A âˆˆ R3, respectively. Each episode spans 1000 steps. The first objective is the forward reward, defined as: 

f1 = w1 Â· vx + C, (3) where vx denotes the velocity in the x-direction, w1 represents the corresponding weight, and C = 1 serves as a survival reward, thereby indicating the agentâ€™s continued activity. The second objective, i.e., height, is given by: 

f2 = 10 Â· (hcurr âˆ’ hinit ) + C, (4) BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 17 

where hcurr and hinit denote the current and initial heights of the hopper, respectively. The third objective is the control cost, which is expressed as: 

f3 = âˆ’ X

> i

a2 

> i

+ C, (5) where ai denotes the action of the corresponding actuator.  

> â€¢

MoReacher: The observation and action spaces are defined as S âˆˆ R11 and A âˆˆ R2, respectively. Each episode consists of 1000 steps. The first objective is the distance reward: 

f1 = âˆ’d, (6) where d denotes the Euclidean distance between the fingertip of the Reacher and the target. The second objective represents the control cost: 

f2 = âˆ’ X

> i

a2 

> i

, (7) where ai denotes the action of each actuator.  

> â€¢

MoSwimmer: The observation and action spaces are defined as S âˆˆ R8 and A âˆˆ R2, respectively. Each episode consists of 1000 steps. The first objective is the forward reward: 

f1 = w1 Â· vx, (8) where vx denotes the velocity in the x-direction and w1 represents the weight assigned to the velocity. The second objective is the control cost: 

f2 = âˆ’w2 Â· X

> i

a2 

> i

, (9) where ai denotes the action of the i-th actuator and w2 represents the weight of the control cost.  

> â€¢

MoWalker2d: The observation space and action space are defined as S âˆˆ R17 and A âˆˆ R6, respectively. Each episode consists of 1000 steps. The first objective is the forward reward: 

f1 = w1 Â· vx, (10) where vx denotes the velocity along the x-axis and w1 represents the velocity weight. The second objective is the control cost: 

f2 = âˆ’w2 Â· X

> i

a2 

> i

, (11) where ai denotes the action of each actuator, and w2 represents the weight for the control cost. XI. E XPERIMENTS SETUPS 

A. Algorithm Parameters Settings 

Table VI details the parameter settings for the sixteen EAs evaluated in the experiments. 

TABLE VI PARAMETER SETTINGS OF THE TESTED ALGORITHMS .

Algorithm Key Parameter Settings 

PSO inertia weight = 0.6, cognitive coefficient = 2.5, social coefficient = 0.8 CSO phi = 0 DE random selection, differential weight = 0.5, cross probability = 0.9, batch size = population size SaDE number of differential vectors = 9, learning period = 50 CMA-ES cm = 1, recombination weights = None IPOP-CMA-ES cm = 1, stagnation threshold = 50, recombination weights = None GA-UR/GM gaussian mutation, uniform random crossover GA-SBX/PM polynomial mutation, simulated binary crossover NSGA-II uniform random selection, polynomial mutation, simulated binary crossover NSGA-III uniform random selection, polynomial mutation, simulated binary crossover RVEA alpha = 2, fr = 0.1, reference vector guided selection, polynomial mutation, simulated binary crossover MOEA/D penalty-based boundary intersection, polynomial mutation, simulated binary crossover HypE number of samples = 10000, polynomial mutation, simulated binary crossover LMOCSO alpha = 2, reference vector guided selection, polynomial mutation SPEA2 polynomial mutation, simulated binary crossover IBEA kappa = 0.05, polynomial mutation, simulated binary crossover BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 18 

B. Benchmarking Function Settings 

Table VII summarizes the configuration of the benchmark functions used in our numerical optimization tasks, including their dimensionality, search space, and minimum. These functions are widely adopted in evolutionary computation research and span a range of landscapes from unimodal to highly multimodal.                                              

> TABLE VII NUMERICAL BENCHMARK FUNCTIONS USED IN THE EXPERIMENT
> Functions Name Dimension Search space Minimum
> fa1âˆ’5CEC2022 F1-F5 20 [âˆ’100 ,100] 0
> fa6Ackley 50 [âˆ’32 ,32] 0
> fa7Griewank 50 [âˆ’600 ,600] 0
> fa8Rosenbrock 50 [âˆ’5,10] 0
> fa9Schwefel 50 [âˆ’500 ,500] 0
> fa10 Sphere 50 [âˆ’5.12 ,5.12] 0
> fa11 âˆ’17 DTLZ 1-7 50 [0 ,1] 0
> fa18 âˆ’20 ZDT 1-3 50 [0 ,1] 0

All tasks employed a standardized policy architecture and evaluation protocol. Specifically, the policy was implemented as a multilayer perceptron (MLP) using Flax, which comprised a single hidden layer with 16 tanh-activated neurons. While this internal structure remained fixed, the input and output dimensions were adjusted to align with the observation and action spaces of each environment. Regarding optimization, the model parameters were constrained within a fixed range of [âˆ’8, 8] 

per dimension. Furthermore, each task was evaluated in a Brax environment, subject to a maximum of 1000 simulation steps per episode. Table VIII summarizes these settings for all neuroevolution tasks.                             

> TABLE VIII NEUROEVOLUTION OF ROBOTIC CONTROL TASKS
> Single-objective Multi-objective
> fb1-fb5dfb6-fb10 mdHalfcheetah 390 MoHopper-m2 2243 Hopper 243 MoHopper-m3 3243 Pusher 503 MoReacher 2226 Reacher 226 MoSwimmer 2178 Swimmer 178 MoWalker2d 2390

XII. E XPERIMENTAL RESULTS 

A. Time-capped Performance 

We evaluate the performance of various EAs under a fixed 30-second time constraint by comparing the number of FEs completed and the quality of the final solutions. All experiments were conducted using an NVIDIA RTX 3090 GPU, with GPU-based results depicted by solid markers and CPU-based results by hollow markers. In these plots, a horizontal shift from a hollow to a solid marker indicates improved optimization performance (lower objective or IGD value), while a vertical shift reflects increased computational efficiency (more NFEs completed). Consistent with previous findings, most EAs exhibit notable efficiency improvements when executed on the GPU. In some cases, GPU-based implementations even benefit from both dimensions, achieving superior solution quality as a result of significantly more evaluations within the same time window. BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 19 GPU PSO GPU CSO GPU DE GPU SaDE GPU GA-SBX/PM GPU GA-UR/GM GPU CMA-ES GPU IPOP-CMA-ES 0.00 0.40 0.80 1.20 1.60 0.00 1.50 3.00 4.50 

> Number of FEs

Ã—10 6

GA-SBX/PM GPU 

GA-UR/GM GPU 

IPOP-CMA-ES GPU 

CSO GPU 

SaDE GPU 

DE GPU 

CMA-ES GPU 

PSO GPU 

Fitness Value 

(a) fa1 : CEC2022 F1 0.00 1.50 3.00 4.50 6.00 

Ã—10 1

0.00 1.00 2.00 3.00 4.00 

> Number of FEs

Ã—10 6

CMA-ES GPU 

IPOP-CMA-ES GPU 

SaDE GPU 

CSO GPU GA-UR/GM GPU 

PSO GPU 

GA-SBX/PM GPU 

DE GPU 

Fitness Value (b) fa3 : CEC2022 F3 0.00 0.20 0.40 0.60 0.80 

Ã—10 2

0.00 1.00 2.00 3.00 4.00 

> Number of FEs

Ã—10 6

DE GPU PSO GPU 

CMA-ES GPU 

GA-SBX/PM GPU 

CSO GPU 

GA-UR/GM GPU 

IPOP-CMA-ES GPU 

SaDE GPU 

Fitness Value (c) fa4 : CEC2022 F4 0.00 0.40 0.80 1.20 1.60 

Ã—10 3

0.00 1.00 2.00 3.00 4.00 

> Number of FEs

Ã—10 6

CSO GPU 

DE GPU 

IPOP-CMA-ES GPU 

SaDE GPU 

GA-SBX/PM GPU 

GA-UR/GM GPU 

CMA-ES GPU 

PSO GPU 

Fitness Value (d) fa5 : CEC2022 F5 0.00 0.50 1.00 1.50 2.00 

Ã—10 1

0.00 1.00 2.00 3.00 4.00 

> Number of FEs

Ã—10 6

CMA-ES GPU IPOP-CMA-ES GPU 

PSO GPU 

DE GPU 

SaDE GPU 

CSO GPU 

GA-SBX/PM GPU 

GA-UR/GM GPU 

Fitness Value 

(e) fa6 : Ackley 0.00 1.00 2.00 3.00 4.00 5.00 

Ã—10 2

0.00 1.00 2.00 3.00 4.00 

> Number of FEs

Ã—10 6

CMA-ES GPU 

GA-UR/GM GPU 

IPOP-CMA-ES GPU 

GA-SBX/PM GPU 

DE GPU 

SaDE GPU 

CSO GPU 

PSO GPU 

Fitness Value (f) fa7 : Griewank 0.00 1.00 2.00 3.00 4.00 5.00 

Ã—10 5

0.00 1.00 2.00 3.00 4.00 

> Number of FEs

Ã—10 6

CMA-ES GPU 

GA-SBX/PM GPU 

GA-UR/GM GPU 

IPOP-CMA-ES GPU 

CSO GPU 

DE GPU 

SaDE GPU 

PSO GPU 

Fitness Value (g) fa8 : Rosenbrock 0.00 0.50 1.00 1.50 2.00 

Ã—10 4

0.00 3.00 6.00 9.00 

> Number of FEs

Ã—10 5

GA-SBX/PM GPU 

GA-UR/GM GPU 

CMA-ES GPU 

PSO GPU 

SaDE GPU CSO GPU DE GPU 

IPOP-CMA-ES GPU 

Fitness Value (h) fa9 : Schwefel GPU HypE GPU IBEA GPU RVEA GPU MOEA/D GPU NSGA-II GPU NSGA-III GPU SPEA2 GPU LMOCSO 1.52 1.56 1.60 1.64 1.68 

IGD Value 

0.00 1.50 3.00 4.50 6.00 

> Number of FEs

Ã—10 6

HypE GPU 

IBEA GPU 

LMOCSO GPU 

RVEA GPU 

MOEA/D GPU 

NSGA-II GPU 

NSGA-III GPU 

SPEA2 GPU 

(i) fa12 : DTLZ2 0.00 0.80 1.60 2.40 3.20 

IGD Value Ã—10 2

0.00 2.00 4.00 6.00 

> Number of FEs

Ã—10 6

HypE GPU 

LMOCSO GPU 

MOEA/D GPU 

NSGA-II GPU 

NSGA-III GPU 

SPEA2 GPU 

RVEA GPU 

IBEA GPU (j) fa13 : DTLZ3 1.53 1.56 1.59 1.62 1.65 1.68 

IGD Value 

0.00 1.50 3.00 4.50 6.00 

> Number of FEs

Ã—10 6

HypE GPU 

RVEA GPU 

IBEA GPU 

MOEA/D GPU 

NSGA-III GPU 

NSGA-II GPU 

LMOCSO GPU 

SPEA2 GPU (k) fa14 : DTLZ4 1.80 2.40 3.00 3.60 4.20 

IGD Value 

0.00 2.00 4.00 6.00 

> Number of FEs

Ã—10 6

HypE GPU 

IBEA GPU 

LMOCSO GPU 

MOEA/D GPU 

NSGA-II GPU 

NSGA-III GPU 

SPEA2 GPU 

RVEA GPU (l) fa15 : DTLZ5 0.00 0.60 1.20 1.80 2.40 3.00 

IGD Value Ã—10 1

0.00 2.00 4.00 6.00 

> Number of FEs

Ã—10 6

RVEA GPU 

HypE GPU 

IBEA GPU 

LMOCSO GPU 

MOEA/D GPU 

NSGA-II GPU 

NSGA-III GPU 

SPEA2 GPU 

(m) fa16 : DTLZ6 0.75 1.00 1.25 1.50 1.75 2.00 

IGD Value Ã—10 1

0.00 2.00 4.00 6.00 

> Number of FEs

Ã—10 6

HypE GPU 

IBEA GPU LMOCSO GPU 

MOEA/D GPU 

NSGA-II GPU 

NSGA-III GPU 

SPEA2 GPU 

RVEA GPU (n) fa17 : DTLZ7 1.56 1.60 1.64 1.68 1.72 1.76 

IGD Value 

0.00 1.50 3.00 4.50 6.00 

> Number of FEs

Ã—10 6

HypE GPU 

IBEA GPU 

LMOCSO GPU 

MOEA/D GPU 

NSGA-III GPU 

NSGA-II GPU 

SPEA2 GPU 

RVEA GPU (o) fa19 : ZDT2 7.80 8.00 8.20 8.40 8.60 

IGD Value Ã—10 1

0.00 0.40 0.80 1.20 1.60 

> Number of FEs

Ã—10 7

LMOCSO GPU 

RVEA GPU 

HypE GPU 

IBEA GPU 

MOEA/D GPU 

NSGA-II GPU 

NSGA-III GPU 

SPEA2 GPU (p) fa20 : ZDT3 

Fig. 13: Performance comparison of EAs tested on CPU and GPU (NVIDIA GeForce RTX-3090), evaluated in terms of solution quality and number of FEs completed within 30 seconds. Lower fitness/IGD value denote better performance. Results represent averaged performance value across 15 independent runs. Solid markers denote GPU-based (NVIDIA GeForce RTX-3090) implementations; hollow markers indicate CPU-based counterparts. Algorithms achieving notable improvements in both efficiency and accuracy on the GPU compared to the CPU are highlighted with connecting lines. 

B. Scaling Behavior of EAs on GPUs vs. CPU 

This section analyzes the computational efficiency of evolutionary algorithms across three hardware platforms, focusing on their scaling behavior under varying experimental parameters. Specifically, we investigate the sensitivity of performance to changes in population size and problem dimensionality, both scaled exponentially from 16 to 8192. This analysis aims to reveal how different architectures respond to increasing computational demands and to identify conditions under which GPU acceleration offers the most significant advantages. 

1) Scaling Problem Dimension: Fig. 14 illustrates the computational efficiency of EAs on different hardware platforms under increasing problem dimensionalities. The left panel shows the runtime over 100 generations, while the right panel reports the number of FEs completed within a fixed 30-second time window. Problem dimensions were scaled exponentially, taking values from 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192. Algorithms were evaluated with a fixed population size of 128 across all configurations. Each setting was repeated 15 times, with the plotted curves representing the mean performance BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 20 

and the shaded bands indicating standard deviations. Different colors denote different hardware platforms. Lower runtime and higher NFE counts are indicative of greater computational efficiency. 5000 10000 15000 

Dimension Scale 

GPU: RTX 2080 Ti GPU: RTX 3090 CPU: Xeon Gold 6226R 0 5000 10000 15000 

Dimension Scale 

0

2

4

6

8

10 

12 

> t

GPU: RTX 2080 Ti GPU: RTX 3090 CPU: Xeon Gold 6226R 0 2000 4000 6000 8000 

Dimension Scale     

> 0
> 5
> 10
> 15
> 20
> 25
> 30
> Time (s) 0.00 0.20 0.40 0.60 0.80

Dimension Scale Ã—10 4

> 0.00
> 1.00
> 2.00
> 3.00
> 4.00
> Number of FEs
> Ã—10 6

(a) PSO on Ackley (Popsize = 128) 0.00 2.00 4.00 6.00 8.00 

Dimension Scale Ã—10 3    

> 0.00
> 1.00
> 2.00
> 3.00
> 4.00
> Time (s)
> Ã—10 10.00 0.20 0.40 0.60 0.80

Dimension Scale Ã—10 4 

> 0.00
> 0.50
> 1.00
> 1.50
> 2.00
> 2.50
> Number of FEs
> Ã—10 6

(b) MOEA/D on DTLZ1 (Popsize = 128) 0.00 2.00 4.00 6.00 8.00 

Dimension Scale Ã—10 3    

> 0.00
> 0.50
> 1.00
> 1.50
> 2.00
> 2.50
> Time (s)
> Ã—10 10.00 0.20 0.40 0.60 0.80

Dimension Scale Ã—10 4

> 0.00
> 0.50
> 1.00
> 1.50
> 2.00
> Number of FEs
> Ã—10 6

(c) PSO on Schwefel (Popsize = 128) 0.00 2.00 4.00 6.00 8.00 

Dimension Scale Ã—10 3    

> 0.00
> 2.00
> 4.00
> 6.00
> 8.00
> Time (s)
> Ã—10 10.00 0.20 0.40 0.60 0.80

Dimension Scale Ã—10 4 

> 0.00
> 0.50
> 1.00
> 1.50
> 2.00
> Number of FEs
> Ã—10 6

(d) MOEA/D on ZDT1 (Popsize = 128) 0.00 2.00 4.00 6.00 8.00 

Dimension Scale Ã—10 3    

> 0.00
> 2.00
> 4.00
> 6.00
> Time (s)
> Ã—10 10.00 0.20 0.40 0.60 0.80

Dimension Scale Ã—10 4

> 0.00
> 0.25
> 0.50
> 0.75
> 1.00
> 1.25
> Number of FEs
> Ã—10 6

(e) SaDE on Ackley (Popsize = 128) 0.00 2.00 4.00 6.00 8.00 

Dimension Scale Ã—10 3    

> 0.00
> 2.00
> 4.00
> 6.00
> 8.00
> Time (s)
> Ã—10 10.00 0.20 0.40 0.60 0.80

Dimension Scale Ã—10 4 

> 0.00
> 1.00
> 2.00
> 3.00
> 4.00
> Number of FEs
> Ã—10 5

(f) NSGA-III on DTLZ1 (Popsize = 128) 0.00 2.00 4.00 6.00 8.00 

Dimension Scale Ã—10 3    

> 0.00
> 2.00
> 4.00
> 6.00
> Time (s)
> Ã—10 10.00 0.20 0.40 0.60 0.80

Dimension Scale Ã—10 4

> 0.00
> 1.00
> 2.00
> 3.00
> 4.00
> 5.00
> Number of FEs
> Ã—10 5

(g) SaDE on Schwefel (Popsize = 128) 0.00 2.00 4.00 6.00 8.00 

Dimension Scale Ã—10 3    

> 0.00
> 2.00
> 4.00
> 6.00
> Time (s)
> Ã—10 10.00 0.20 0.40 0.60 0.80

Dimension Scale Ã—10 4 

> 0.00
> 1.00
> 2.00
> 3.00
> 4.00
> 5.00
> Number of FEs
> Ã—10 5

(h) NSGA-III on ZDT1 (Popsize = 128) 

Fig. 14: Computational performance tested across varying problem dimensions on three hardware platforms. Left : Total runtime over 100 generations. Right :Number of FEs completed within a 30-second time budget. Results are averaged over 15 independent runs; solid lines indicate mean values, and shaded regions represent standard deviations. 

2) Scaling Population Size: Fig. 15 presents the impact of different population sizes on computational efficiency of EAs, with values set to 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192. The problem dimensionality is fixed at 50 across all tests. The left panel shows the runtime over 100 generations, while the right panel reports the number of FEs completed within a fixed 30-second time window. Problem dimensions were fixed at 50 across all configurations. Each setting was repeated 15 times, with the plotted curves representing the mean performance and the shaded bands indicating standard deviations. Different colors denote different hardware platforms. Lower runtime and higher NFE counts are indicative of greater computational efficiency. BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 21 5000 10000 15000 

Dimension Scale 

GPU: RTX 2080 Ti GPU: RTX 3090 CPU: Xeon Gold 6226R 0 5000 10000 15000 

Dimension Scale 

0

2

4

6

8

10 

12 

> t

GPU: RTX 2080 Ti GPU: RTX 3090 CPU: Xeon Gold 6226R 0.00 2000.00 4000.00 6000.00 8000.00 

Population Size     

> 1.00
> 2.00
> 3.00
> 4.00
> 5.00
> 6.00
> Time (s) 02000 4000 6000 8000

Population Size 

> 0.0
> 0.5
> 1.0
> 1.5
> Number of FEs
> 1e8

(a) PSO on Ackley (D = 50) 0.00 2.00 4.00 6.00 8.00 

Population Size Ã—10 3    

> 0.00
> 1.00
> 2.00
> 3.00
> Time (s)
> Ã—10 20.00 2.00 4.00 6.00 8.00

Population Size Ã—10 3 

> 0.00
> 0.50
> 1.00
> 1.50
> 2.00
> 2.50
> 3.00
> Number of FEs
> Ã—10 6

(b) MOEA/D on DTLZ1 (D = 50) 0.00 2000.00 4000.00 6000.00 8000.00 

Population Size     

> 0.00
> 0.20
> 0.40
> 0.60
> 0.80
> 1.00
> 1.20
> Time (s)
> Ã—10 10.00 2.00 4.00 6.00 8.00

Population Size Ã—10 3

> 0.00
> 0.50
> 1.00
> 1.50
> Number of FEs
> Ã—10 8

(c) PSO on Schwefel (D = 50) 0.00 2.00 4.00 6.00 8.00 

Population Size Ã—10 3    

> 0.00
> 0.20
> 0.40
> 0.60
> 0.80
> 1.00
> 1.20
> Time (s)
> Ã—10 30.00 2.00 4.00 6.00 8.00

Population Size Ã—10 3 

> 0.00
> 1.00
> 2.00
> 3.00
> Number of FEs
> Ã—10 6

(d) MOEA/D on ZDT1 (D = 50) 0.00 2.00 4.00 6.00 8.00 

Population Size Ã—10 3    

> 0.00
> 2.00
> 4.00
> 6.00
> Time (s)
> Ã—10 30.00 2.00 4.00 6.00 8.00

Population Size Ã—10 3

> 0.00
> 0.50
> 1.00
> 1.50
> 2.00
> Number of FEs
> Ã—10 6

(e) SaDE on Ackley (D = 50) 0.00 2.00 4.00 6.00 8.00 

Population Size Ã—10 3    

> 0.00
> 0.50
> 1.00
> 1.50
> Time (s)
> Ã—10 30.00 2.00 4.00 6.00 8.00

Population Size Ã—10 3 

> 0.00
> 0.50
> 1.00
> 1.50
> 2.00
> Number of FEs
> Ã—10 6

(f) NSGA-III on DTLZ1 (D = 50) 0.00 2.00 4.00 6.00 8.00 

Population Size Ã—10 3    

> 0.00
> 2.00
> 4.00
> 6.00
> 8.00
> Time (s)
> Ã—10 30.00 2.00 4.00 6.00 8.00

Population Size Ã—10 3

> 0.00
> 0.50
> 1.00
> 1.50
> 2.00
> Number of FEs
> Ã—10 6

(g) SaDE on Schwefel (D = 50) 0.00 2.00 4.00 6.00 8.00 

Population Size Ã—10 3    

> 0.00
> 0.50
> 1.00
> 1.50
> 2.00
> 2.50
> 3.00
> Time (s)
> Ã—10 30.00 2.00 4.00 6.00 8.00

Population Size Ã—10 3 

> 0.00
> 0.20
> 0.40
> 0.60
> 0.80
> 1.00
> 1.20
> Number of FEs
> Ã—10 6

(h) NSGA-III on ZDT1 (D = 50) 

Fig. 15: Computational performance of two EAs configured with varying population sizes across three hardware platforms. Left : Total runtime over 100 generations. Right : Number of FEs completed within a 30-second time budget. Each curve represents the average of 15 independent runs; solid lines denote mean values, and shaded areas indicate standard deviations. 

C. Exploiting Large Population Size on GPU-based EAs 1) Results on Numerical Problems: We evaluate EA performance under two distinct computational constraints: (i) fixed-generation (100 iterations) and (ii) fixed-time (30-second) conditions, Each algorithm was tested across ten population sizes (range from 16 to 8192) over 100 iterations, conducting 15 independent repetitions on an NVIDIA GeForce RTX-3090 GPU, with solution quality, runtime, and NFEs completed serving as key performance metrics. Table IX presents the mean of best fitness/IGD value obtained over 100 iterations with varying population size on NVIDIA GeForce RTX-3090. Fig. 16 complements Table IX with Pareto front visualizations. BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 22           

> TABLE IX MEAN OF BEST FITNESS / IGD VALUE OBTAINED UNDER 100 I TERATIONS WITH 10 P OPULATION SIZE ON NVIDIA G EFORCE RTX-3090.

Func. Population Size PSO CSO DE SaDE CMA-ES IPOP-CMA-ES GA-SBX/PM GA-UR/GM 

fa2

16 174.97 200.27 192.59 195.33 470.65 453.65 19.48 3892.91 32 118.67 71.97 84.99 124.98 177.67 372.37 18.21 1386.11 64 119.68 56.98 93.49 78.19 221.95 316.64 17.34 308.84 128 49.14 59.27 99.33 66.35 112.93 289.93 16.36 40.26 256 49.10 55.38 113.14 56.54 93.57 273.92 15.75 16.71 512 73.81 54.50 112.86 52.44 105.47 255.14 13.60 13.33 1024 49.10 54.17 107.47 54.10 79.43 244.68 9.91 12.38 2048 49.08 53.71 114.48 50.09 75.97 243.47 5.23 13.12 4096 49.08 53.54 102.78 49.85 75.71 234.48 5.39 12.36 8192 49.08 52.81 97.04 49.99 73.51 233.31 5.28 12.00 

fa6

16 17.60 14.71 15.45 10.84 2.20 0.78 21.31 21.30 32 12.46 10.63 12.68 6.62 2.19 0.00 4.75 21.27 64 10.54 9.34 14.81 4.50 1.93 0.00 2.54 21.28 128 7.59 9.66 18.53 3.23 1.54 0.00 1.31 21.22 256 5.94 9.31 19.88 2.42 1.45 0.00 1.56 21.02 512 3.93 9.32 20.09 1.73 1.32 0.00 3.04 18.98 1024 3.22 8.82 20.37 0.63 0.95 0.00 3.21 11.72 2048 2.41 8.94 20.31 0.42 0.24 0.00 0.76 3.37 4096 2.05 8.79 20.19 0.31 0.15 0.00 0.03 0.09 8192 1.51 8.62 20.29 0.24 0.10 0.00 0.00 0.00 

fa10 

16 51.31 28.19 44.67 16.08 12.77 2.00 2.25 843.69 32 32.00 13.02 19.08 3.13 8.53 0.00 1.08 655.66 64 13.90 8.36 27.43 0.90 4.04 0.00 0.03 449.58 128 4.58 7.08 41.04 0.20 1.46 0.00 0.01 351.15 256 1.21 7.28 79.10 0.08 0.99 0.00 0.01 179.21 512 0.45 6.82 116.50 0.02 0.64 0.00 0.10 56.78 1024 0.18 6.97 117.63 0.01 0.55 0.00 0.05 6.54 2048 0.03 5.99 117.95 0.01 0.51 0.00 0.00 0.11 4096 0.00 6.34 137.86 0.00 0.52 0.00 0.00 0.00 8192 0.00 5.93 133.91 0.00 0.38 0.00 0.00 0.00 Func. Population Size HypE IBEA RVEA MOEA/D NSGA-II NSGA-III SPEA2 LMOCSO 

fa11 

16 314.18 235.91 586.23 1116.02 365.79 299.74 497.86 871.80 32 188.39 172.11 740.06 794.18 281.19 228.85 318.81 851.12 64 148.97 122.81 305.75 824.91 217.35 287.93 202.87 817.60 128 147.71 110.14 298.39 918.94 261.36 237.25 186.41 753.89 256 123.85 100.59 323.10 1011.99 232.98 242.56 142.39 716.83 512 133.94 110.15 334.38 1036.51 227.82 224.67 119.91 672.64 1024 140.91 92.78 332.80 1051.77 220.06 196.49 140.50 687.58 2048 144.61 110.62 362.61 1046.40 212.60 197.79 111.06 616.33 4096 139.63 110.71 1038.03 1029.58 193.53 192.94 111.44 635.26 8192 137.87 105.74 1068.18 1014.46 180.24 177.24 111.22 618.74 

fa15 

16 2.2677 1.9680 4.6477 4.2245 2.0371 1.9434 2.7285 4.8017 32 1.7963 1.6865 4.7141 2.6062 1.7921 1.7401 2.0449 4.7233 64 1.6712 1.6412 4.6089 2.4241 1.6825 1.6658 1.7853 4.5242 128 1.6537 1.6310 4.5304 2.4438 1.6496 1.6419 1.6769 4.2075 256 1.6364 1.6281 4.4557 2.6082 1.6390 1.6373 1.6361 4.3052 512 1.6302 1.6269 4.3382 2.8632 1.6333 1.6327 1.6307 4.3086 1024 1.6282 1.6266 4.2081 3.0332 1.6313 1.6304 1.6283 4.1439 2048 1.6273 1.6264 3.9551 3.2942 1.6298 1.6294 1.6272 3.9793 4096 1.6266 1.6264 3.9300 3.4027 1.6288 1.6284 1.6267 3.9960 8192 1.6264 1.6263 3.9288 3.3610 1.6283 1.6279 1.6265 3.8841 

fa19 

16 3.1467 3.4636 3.6157 5.1363 2.7801 3.0238 4.5059 3.4256 32 2.3067 2.7873 2.9867 3.7253 2.0274 2.2809 3.0948 3.0772 64 1.805 1.9318 2.4781 3.2443 1.7804 1.7887 2.5331 2.4471 128 1.6302 1.6861 5.1294 3.2506 1.6315 1.6316 1.8225 5.1412 256 1.591 1.5907 5.1482 3.0809 1.6003 1.6034 1.665 5.1944 512 1.5825 1.5801 5.0399 3.1803 1.5901 1.5897 1.5906 5.191 1024 1.5791 1.5785 5.0725 3.4082 1.5862 1.585 1.5793 5.0912 2048 1.5784 1.5779 4.9281 3.5546 1.5841 1.5833 1.5784 4.974 4096 1.5781 1.5777 4.9346 3.8128 1.5835 1.5822 1.5779 4.9351 8192 1.578 1.5776 4.7815 4.0614 1.583 1.5819 1.5777 4.8466 BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 23 0 1000 2000 3000 4000 0510 15 20 25 

> Time (s)

PSO CSO DE SaDE GA-SBX/PM GA-UR/GM CMA-ES IPOP-CMA-ES 

Fitness Value 

(a) fa20 5 10 15 20 0510 15 20 

> Time (s)

PSO CSO DE SaDE GA-SBX/PM GA-UR/GM CMA-ES IPOP-CMA-ES 

Fitness Value (b) fa60 200 400 600 800 0510 15 20 

> Time (s)

PSO CSO DE SaDE GA-SBX/PM GA-UR/GM CMA-ES IPOP-CMA-ES 

Fitness Value (c) fa10 200 400 800 1000 600 

IGD Value 

0246810 12 14 

> Time (s)

HypE IBEA RVEA MOEA/D NSGA-II NSGA-III SPEA2 LMOCSO 

(d) fa11 1.5 2.0 2.5 3.0 3.5 4.0 4.5 

IGD Value 

0510 15 20 25 

> Time (s)

HypE IBEA RVEA MOEA/D NSGA-II NSGA-III SPEA2 LMOCSO (e) fa15 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 

IGD Value 

010 20 30 40 

> Time (s)

HypE IBEA RVEA MOEA/D NSGA-II NSGA-III SPEA2 LMOCSO (f) fa19 

Fig. 16: Performance comparison of EAs under varying population sizes, evaluated in terms of solution quality and time consumed over 100 iterations. Lower fitness/IGD value denote better performance. Results represent averaged performance values across 15 independent runs. Markers represent individual algorithms, color-coded from light to dark to indicate increasing population sizes (from 16 to 8192). 

To investigate the performance gains associated with larger populations, we conducted a detailed convergence analysis by tracking both fitness values and population diversity metrics throughout the optimization process. Fig. 17 and Fig. 19 presents these evolutionary trajectories across two benchmark problems. These trajectories reveal distinct behavioral patterns, which explain the observed performance improvements. 0 20 40 60 80 100 

Generation 

0.00 

0.50 

1.00 

1.50 

2.00 

> Fitness Value

Ã—10 1

> CMA-ES
> Population=8192
> Population=1024
> Population=128
> Population=16

0 20 40 60 80 100 

Generation 

0.00 

0.50 

1.00 

1.50 

2.00 

> Population Diversity

Ã—10 2

> CMA-ES
> Population=8192
> Population=1024
> Population=128
> Population=16

(a) CMA-ES 0 20 40 60 80 100 

Generation 

0.50 

1.00 

1.50 

2.00 

> Fitness Value

Ã—10 1

> PSO
> Population=8192
> Population=1024
> Population=128
> Population=16

0 20 40 60 80 100 

Generation 

0.00 

0.25 

0.50 

0.75 

1.00 

1.25 

1.50 

1.75 

> Population Diversity

Ã—10 2 

> PSO
> Population=8192
> Population=1024
> Population=128
> Population=16

(b) PSO 0 20 40 60 80 100 

Generation 

0.50 

1.00 

1.50 

2.00 

> Fitness Value
> GA-SBX/PM
> Population=8192
> Population=1024
> Population=128
> Population=16

0 20 40 60 80 100 

Generation 

0.00 

0.20 

0.40 

0.60 

0.80 

1.00 

1.20 

> Population Diversity

Ã—10 1

> GA-SBX/PM
> Population=8192
> Population=1024
> Population=128
> Population=16

(c) GA-SBX/PM 0 20 40 60 80 100 

Generation 

1.60 

1.70 

1.80 

1.90 

2.00 

2.10 

> Fitness Value

Ã—10 1

> DE
> Population=8192
> Population=1024
> Population=128
> Population=16

0 20 40 60 80 100 

Generation 

0.50 

1.00 

1.50 

2.00 

> Population Diversity

Ã—10 2 

> DE
> Population=8192
> Population=1024
> Population=128
> Population=16

(d) DE 

Fig. 17: Evolutionary dynamics of EAs with four population sizes (16, 128, 1024, 8192) on fa6 over 100 generations. Left : Fitness convergence (red curves) showing median and interquartile range across 15 independent runs. Right : Population diversity (blue curves) quantified by mean pairwise Euclidean distance between individuals. BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 24 0 5 10 15 20 25 30 

Time (s) 

0.00 

0.50 

1.00 

1.50 

2.00 

> Fitness Value

Ã—10 1

CMA-ES 

Population=8192 

Population=1024 

Population=128 

Population=16 

(a) CMA-ES 0 5 10 15 20 25 30 

Time (s) 

0.00 

0.50 

1.00 

1.50 

2.00 

> Fitness Value

Ã—10 1

PSO 

Population=8192 

Population=1024 

Population=128 

Population=16 (b) PSO 0 5 10 15 20 25 30 

Time (s) 

0.00 

0.50 

1.00 

1.50 

2.00 

> Fitness Value

GA-SBX/PM 

Population=8192 

Population=1024 

Population=128 

Population=16 (c) GA-SBX/PM 0 5 10 15 20 25 30 

Time (s) 

0.00 

0.50 

1.00 

1.50 

2.00 

> Fitness Value

Ã—10 1

DE 

Population=8192 

Population=1024 

Population=128 

Population=16 (d) DE 

Fig. 18: Convergence of mean fitness on fa6 over 15 independent runs. Each trial is limited to 30 seconds. 0 20 40 60 80 100 

Generation 

0.00 

1.00 

2.00 

3.00 

4.00 

5.00 

> Fitness Value

Ã—10 2

CMA-ES 

Population=8192 

Population=1024 

Population=128 

Population=16 0 20 40 60 80 100 

Generation 

0.00 

1.00 

2.00 

3.00 

> Population Diversity

Ã—10 1

CMA-ES 

Population=8192 

Population=1024 

Population=128 

Population=16 

(a) CMA-ES 0 20 40 60 80 100 

Generation 

0.00 

0.50 

1.00 

1.50 

2.00 

2.50 

3.00 

3.50 

> Fitness Value

Ã—10 2

PSO 

Population=8192 

Population=1024 

Population=128 

Population=16 0 20 40 60 80 100 

Generation 

0.00 

0.50 

1.00 

1.50 

2.00 

2.50 

3.00 

> Population Diversity

Ã—10 1

PSO 

Population=8192 

Population=1024 

Population=128 

Population=16 (b) PSO 0 20 40 60 80 100 

Generation 

0.00 

0.50 

1.00 

1.50 

2.00 

> Fitness Value

Ã—10 1

GA-SBX/PM 

Population=8192 

Population=1024 

Population=128 

Population=16 0 20 40 60 80 100 

Generation 

0.00 

2.00 

4.00 

6.00 

8.00 

> Population Diversity

GA-SBX/PM 

Population=8192 

Population=1024 

Population=128 

Population=16 

(c) GA-SBX/PM 0 20 40 60 80 100 

Generation 

0.50 

1.00 

1.50 

2.00 

2.50 

3.00 

3.50 

4.00 

> Fitness Value

Ã—10 2

DE 

Population=8192 

Population=1024 

Population=128 

Population=16 0 20 40 60 80 100 

Generation 

0.00 

0.50 

1.00 

1.50 

2.00 

2.50 

3.00 

> Population Diversity

Ã—10 1

DE 

Population=8192 

Population=1024 

Population=128 

Population=16 (d) DE 

Fig. 19: Evolutionary dynamics of EAs with four population sizes (16, 128, 1024, 8192) on fa10 over 100 generations. Left : Fitness convergence (red curves) showing median and interquartile range across 15 independent runs. Right : Population diversity (blue curves) quantified by mean pairwise Euclidean distance between individuals. 0 5 10 15 20 25 30 

Time (s) 

0.00 

1.00 

2.00 

3.00 

4.00 

5.00 

> Fitness Value

Ã—10 2

CMA-ES 

Population=8192 

Population=1024 

Population=128 

Population=16 

(a) CMA-ES 0 5 10 15 20 25 30 

Time (s) 

0.00 

0.50 

1.00 

1.50 

2.00 

2.50 

3.00 

3.50 

> Fitness Value

Ã—10 2

PSO 

Population=8192 

Population=1024 

Population=128 

Population=16 (b) PSO 0 5 10 15 20 25 30 

Time (s) 

0.00 

0.50 

1.00 

1.50 

2.00 

> Fitness Value

Ã—10 1

GA-SBX/PM 

Population=8192 

Population=1024 

Population=128 

Population=16 (c) GA-SBX/PM 0 5 10 15 20 25 30 

Time (s) 

0.00 

1.00 

2.00 

3.00 

> Fitness Value

Ã—10 2

DE 

Population=8192 

Population=1024 

Population=128 

Population=16 (d) DE 

Fig. 20: Convergence curves of mean fitness values across 15 independent runs on fa10 . Each trial is limited to a 30-second duration. BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 25 PSO CSO DE SaDE GA-SBX/PM GA-UR/GM CMA-ES IPOP-CMA-ES 0 10000 20000 30000 40000 0.00 0.80 1.60 2.40 

> Time (s)

Ã—10 1

Population Size = 8192 Population Size = 1024 Population Size = 128 

Fitness Value 

PSO 8192 

DE 8192 

SaDE 8192 

IPOP-CMA-ES 8192 

CSO 8192 

GA-UR/GM 8192 

GA-SBX/PM 128 

CMA-ES 8192 0 2000 4000 6000 8000 0.00 2.00 4.00 6.00 8.00 

> Number of FEs

Ã—10 7

Population Size = 8192 Population Size = 1024 Population Size = 128 

Fitness Value 

PSO 8192 

DE 8192 

SaDE 8192 

IPOP-CMA-ES 8192 

CSO 8192 

GA-UR/GM 8192 

GA-SBX/PM 819 2

CMA-ES 8192 

(a) CEC2022 F1 0 60 120 180 240 300 0.00 0.80 1.60 2.40 

> Time (s)

Ã—10 1

Population Size = 8192 Population Size = 1024 Population Size = 128 

Fitness Value 

PSO 128 

DE 8192 

SaDE 8192 

IPOP-CMA-ES 8192 

CMA-ES 8192 

GA-UR/GM 8192 

GA-SBX/PM 819 2

CSO 8192 0 15 30 45 60 75 0.00 2.00 4.00 6.00 8.00 

> Number of FEs

Ã—10 7

Population Size = 8192 Population Size = 1024 Population Size = 128 

Fitness Value 

PSO 8192 

DE 8192 

SaDE 8192 

IPOP-CMA-ES 8192 

CSO 8192 

GA-UR/GM 8192 

GA-SBX/PM 819 2

CMA-ES 8192 (b) CEC2022 F2 0 15 30 45 60 0.00 0.80 1.60 2.40 

> Time (s)

Ã—10 1

Population Size = 8192 Population Size = 1024 Population Size = 128 

Fitness Value 

PSO 8192 

DE 8192 

SaDE 8192 

IPOP-CMA-ES 128 

CMA-ES 8192 

GA-UR/GM 8192 

GA-SBX/PM 819 2

CSO 8192 0 15 30 45 60 0.00 2.00 4.00 6.00 

> Number of FEs

Ã—10 7

Population Size = 8192 Population Size = 1024 Population Size = 128 

Fitness Value 

PSO 8192 

DE 8192 

SaDE 8192 

IPOP-CMA-ES 8192 

CSO 8192 

GA-UR/GM 8192 

GA-SBX/PM 819 2

CMA-ES 8192 

(c) CEC2022 F3 0 30 60 90 120 0.00 0.80 1.60 2.40 

> Time (s)

Ã—10 1

Population Size = 8192 Population Size = 1024 Population Size = 128 

Fitness Value 

PSO 8192 

DE 8192 

SaDE 8192 

IPOP-CMA-ES 8192 

CSO 8192 

GA-UR/GM 8192 

GA-SBX/PM 819 2

CMA-ES 8192 0 20 40 60 80 0.00 2.00 4.00 6.00 8.00 

> Number of FEs

Ã—10 7

Population Size = 8192 Population Size = 1024 Population Size = 128 

Fitness Value 

PSO 8192 

DE 8192 

SaDE 8192 

IPOP-CMA-ES 8192 

CMA-ES 8192 

GA-UR/GM 8192 

GA-SBX/PM 819 2

CSO 8192 (d) CEC2022 F4 0 400 800 1200 1600 2000 0.00 0.80 1.60 2.40 

> Time (s)

Ã—10 1

Population Size = 8192 Population Size = 1024 Population Size = 128 

Fitness Value 

PSO 8192 

DE 8192 

SaDE 8192 

IPOP-CMA-ES 128 

CMA-ES 8192 

GA-UR/GM 8192 

GA-SBX/PM 819 2

CSO 8192 0 400 800 1200 1600 0.00 2.00 4.00 6.00 8.00 

> Number of FEs

Ã—10 7

Population Size = 8192 Population Size = 1024 Population Size = 128 

Fitness Value 

PSO 8192 

DE 8192 

SaDE 8192 

IPOP-CMA-ES 8192 

CSO 8192 

GA-UR/GM 8192 

GA-SBX/PM 819 2

CMA-ES 8192 

(e) CEC2022 F5 0 250 500 750 1000 1250 0.00 0.80 1.60 2.40 

> Time (s)

Ã—10 1

Population Size = 8192 Population Size = 1024 Population Size = 128 

Fitness Value 

PSO 8192 

DE 8192 

SaDE 8192 

IPOP-CMA-ES 128 

CMA-ES 8192 

GA-UR/GM 8192 

GA-SBX/PM 819 2

CSO 8192 0 25 50 75 100 125 0.00 2.00 4.00 6.00 

> Number of FEs

Ã—10 7

Population Size = 8192 Population Size = 1024 Population Size = 128 

Fitness Value 

PSO 8192 

DE 8192 

SaDE 8192 

IPOP-CMA-ES 8192 

CSO 8192 

GA-UR/GM 8192 

GA-SBX/PM 819 2

CMA-ES 8192 (f) Griewank 0.0 0.2 0.4 0.6 0.8 1.0 1e7 0.00 0.80 1.60 2.40 

> Time (s)

Ã—10 1

Population Size = 8192 Population Size = 1024 Population Size = 128 

Fitness Value 

DE 8192 

SaDE 8192 

IPOP-CMA-ES 128 

CSO 8192 

GA-UR/GM 8192 

GA-SBX/PM 819 2

PSO 8192 

CMA-ES 8192 0 6000 12000 18000 24000 0.00 2.00 4.00 6.00 

> Number of FEs

Ã—10 7

Population Size = 8192 Population Size = 1024 Population Size = 128 

Fitness Value 

PSO 8192 

DE 8192 

SaDE 8192 

IPOP-CMA-ES 8192 

CMA-ES 8192 

GA-UR/GM 8192 

GA-SBX/PM 819 2

CSO 8192 

(g) Rosenbrock 0 80 160 240 320 0.00 0.50 1.00 1.50 2.00 

> Time (s)

Ã—10 1

Population Size = 8192 Population Size = 1024 Population Size = 128 

Fitness Value 

PSO 8192 

DE 8192 

SaDE 8192 

IPOP-CMA-ES 128 

CMA-ES 8192 

GA-UR/GM 8192 

GA-SBX/PM 819 2

CSO 8192 0.00 0.80 1.60 2.40 3.20 

Ã—10 1

0.00 2.00 4.00 6.00 

> Number of FEs

Ã—10 7

Population Size = 8192 Population Size = 1024 Population Size = 128 

PSO 8192 

CSO 8192 

DE 8192 

GA-UR/GM 8192 

CMA-ES 8192 

IPOP-CMA-ES 8192 

GA-SBX/PM 819 2

SaDE 8192 

Fitness Value (h) Sphere 

Fig. 21: Performance comparison of SOEAs tested on numerical problems under varying population sizes, evaluated in terms of solution quality and computational efficiency under fixed-generation (100 iterations) versus fixed-time (30-second) constraints for EAs on an NVIDIA RTX-3090 GPU. Lower fitness/IGD values denote better performance. Results represent averaged performance values across 15 independent runs. Marker styles indicate population scales: hollow symbols for small populations (128), forward-slash-filled symbols for medium populations (1024), and solid symbols for large populations (8192). Different marker shapes distinguish between algorithms. BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 26 HypE IBEA RVEA MOEA/D NSGA-II NSGA-III SPEA2 LMOCSO 1.6 2.0 2.4 2.8 3.2 

IGD Value 

0.00 0.50 1.00 1.50 2.00 

> Time (s)

Ã—10 2

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 8192 

RVEA 8192 

NSGA-III 8192 

MOEA/D 8192 

HypE 8192 

LMOCSO 8192 

IBEA 8192 

NSGA-II 8192 1.6 2.0 2.4 2.8 3.2 

IGD Value 

0.00 0.80 1.60 2.40 3.20 

> Number of FEs

Ã—10 7

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 8192 

RVEA 8192 

NSGA-III 8192 

MOEA/D 8192 

HypE 8192 

LMOCSO 8192 

IBEA 8192 

NSGA-II 8192 

(a) DTLZ2 800 1600 2400 3200 

IGD Value 

0.00 0.40 0.80 1.20 1.60 

> Time (s)

Ã—10 1

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 8192 

RVEA 8192 

NSGA-III 8192 

MOEA/D 8192 

HypE 8192 

LMOCSO 8192 

NSGA-II 8192 

IBEA 8192 0 600 1200 1800 2400 

IGD Value 

0.00 0.80 1.60 2.40 3.20 

> Number of FEs

Ã—10 7

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 8192 

RVEA 8192 

NSGA-III 8192 

MOEA/D 8192 

HypE 8192 

LMOCSO 8192 

NSGA-II 1024 

IBEA 8192 (b) DTLZ3 1.6 2.0 2.4 2.8 3.2 

IGD Value 

0.00 0.50 1.00 1.50 2.00 

> Time (s)

Ã—10 2

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 8192 

RVEA 8192 

NSGA-III 8192 

MOEA/D 8192 

HypE 8192 

LMOCSO 8192 

NSGA-II 8192 

IBEA 8192 1.5 1.8 2.1 2.4 2.7 3.0 

IGD Value 

0.00 0.80 1.60 2.40 3.20 

> Number of FEs

Ã—10 7

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 8192 

RVEA 8192 

NSGA-III 8192 

MOEA/D 8192 

HypE 8192 

LMOCSO 8192 

NSGA-II 1024 

IBEA 8192 

(c) DTLZ4 1.8 2.4 3.0 3.6 4.2 

IGD Value 

0.00 0.80 1.60 2.40 

> Time (s)

Ã—10 1

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 8192 

RVEA 8192 

NSGA-III 8192 

MOEA/D 8192 

HypE 8192 LMOCSO 8192 

IBEA 8192 

NSGA-II 8192 1.8 2.4 3.0 3.6 4.2 4.8 

IGD Value 

0.00 0.80 1.60 2.40 3.20 

> Number of FEs

Ã—10 7

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 8192 

RVEA 8192 

NSGA-III 1024 

MOEA/D 8192 

HypE 1024 

LMOCSO 8192 

IBEA 8192 

NSGA-II 1024 (d) DTLZ5 0 10 20 30 40 

IGD Value 

0.40 0.80 1.20 1.60 

> Time (s)

Ã—10 1

Population Size = 8192 Population Size = 1024 Population Size = 128 SPEA2 8192 

RVEA 8192 

NSGA-III 8192 

MOEA/D 8192 

HypE 8192 

LMOCSO 8192 

IBEA 8192 

NSGA-II 8192 0 10 20 30 40 

IGD Value 

0.00 0.80 1.60 2.40 3.20 

> Number of FEs

Ã—10 7

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 8192 

RVEA 8192 

NSGA-III 8192 

MOEA/D 8192 

HypE 8192 

LMOCSO 8192 

IBEA 8192 

NSGA-II 1024 

(e) DTLZ6 7.5 10.0 12.5 15.0 17.5 20.0 

IGD Value 

0.00 0.50 1.00 1.50 

> Time (s)

Ã—10 2

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 8192 

RVEA 8192 

NSGA-III 8192 

MOEA/D 8192 

HypE 8192 LMOCSO 8192 

IBEA 8192 

NSGA-II 8192 7.5 10.0 12.5 15.0 17.5 20.0 

IGD Value 

0.00 0.80 1.60 2.40 3.20 

> Number of FEs

Ã—10 7

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 8192 

RVEA 8192 

NSGA-III 8192 MOEA/D 8192 

HypE 8192 

LMOCSO 8192 

IBEA 8192 

NSGA-II 8192 (f) DTLZ7 1.0 1.5 2.0 2.5 3.0 

IGD Value 

0.00 0.80 1.60 2.40 3.20 

> Time (s)

Ã—10 1

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 8192 

RVEA 8192 

NSGA-III 8192 

MOEA/D 8192 

HypE 8192 

LMOCSO 8192 

IBEA 8192 

NSGA-II 8192 1.2 1.6 2.0 2.4 2.8 3.2 

IGD Value 

0.00 0.80 1.60 2.40 3.20 

> Number of FEs

Ã—10 7

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 128

RVEA 8192 

NSGA-III 8192 MOEA/D 8192 

HypE 1024 

LMOCSO 8192 

NSGA-II 1024 

IBEA 8192 

(g) ZDT1 1.6 2.4 3.2 4.0 4.8 

IGD Value 

0.00 1.00 2.00 3.00 4.00 

> Time (s)

Ã—10 1

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 8192 

RVEA 8192 

NSGA-III 8192 

MOEA/D 8192 

HypE 8192 

LMOCSO 8192 IBEA 8192 

NSGA-II 8192 1.6 2.4 3.2 4.0 4.8 

IGD Value 

3.00 3.02 3.04 3.06 

> Number of FEs

Ã—10 1

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 8192 

RVEA 8192 

NSGA-III 8192 

HypE 819 2 MOEA/D 8192 

IBEA 8192 

LMOCSO 8192 

NSGA-II 8192 (h) ZDT2 

Fig. 22: Performance comparison of MOEAs tested on numerical problems under varying population sizes, evaluated in terms of solution quality and computational efficiency under fixed-generation (100 iterations) versus fixed-time (30-second) constraints for EAs on an NVIDIA RTX-3090 GPU. Lower fitness/IGD value denote better performance. Results represent averaged performance values across 15 independent runs. Marker styles indicate population scales: hollow symbols for small populations (128), forward-slash-filled symbols for medium populations (1024), and solid symbols for large populations (8192). Different marker shapes distinguish between algorithms. 

2) Results on Neuroevolution Tasks: We evaluated EA performance on ten neuroevolution tasks under 600 seconds, testing population sizes of 128, 1024 and 8192. Each configuration is tested for 10 times. All experiments were conducted on an NVIDIA RTX-3090 GPU and a RTX-2080-Ti, with solution quality and NFEs completed serving as key performance metrics. BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 27 PSO CSO DE SaDE GA-SBX/PM GA-UR/GM CMA-ES IPOP-CMA-ES HypE IBEA RVEA MOEA/D NSGA-II NSGA-III SPEA2 LMOCSO 0.50 1.00 1.50 2.00 2.50 

Ã—10 3

0.00 0.80 1.60 2.40 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

DE 8192 

CSO 8192 

PSO 8192 

SaDE 8192 

GA-UR/GM 819 2

GA-SBX/PM 819 2

CMA-ES 8192 

IPOP-CMA-ES 8192 

Reward 

(a) Halfcheetah 0.90 1.20 1.50 1.80 2.10 2.40 

Ã—10 3

0.00 1.50 3.00 4.50 

> Number of FEs

Ã—10 6

Population Size = 8192 Population Size = 1024 Population Size = 128 

CMA-ES 8192 

GA-SBX/PM 8192 

IPOP-CMA-ES 8192 

GA-UR/GM 8192 

CSO 8192 

SaDE 8192 

DE 8192 

PSO 8192 

Reward (b) Hopper 3.25 3.50 3.75 4.00 4.25 

HV Value Ã—10 5

0.00 1.50 3.00 4.50 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 8192 HypE 8192 IBEA 8192 

MOEA/D 8192 

RVEA 8192 

LMOCSO 8192 NSGA-II 8192 

NSGA-III 8192 (c) MoHopper-m2 1.36 1.44 1.52 1.60 1.68 1.76 

HV Value Ã—10 10 

0.00 1.50 3.00 4.50 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

RVEA 8192 SPEA2 8192 

MOEA/D 8192 

IBEA 8192 

LMOCSO 1024 

HypE 1024 

NSGA-III 1024 

NSGA-II 8192 (d) MoHopper-m3 2.80 2.60 2.40 2.20 2.00 

Ã—10 3

0.00 0.60 1.20 1.80 2.40 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

CMA-ES 8192 

DE 8192 

PSO 8192 

CSO 8192 

GA-UR/GM 8192 

GA-SBX/PM 8192 SaDE 8192 

IPOP-CMA-ES 8192 

Reward 

(e) Pusher 0.90 0.60 0.30 0.00 0.30 

Ã—10 3

0.00 1.00 2.00 3.00 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

CSO 8192 

PSO 8192 

CMA-ES 8192 

IPOP-CMA-ES 8192 

SaDE 8192 

DE 8192 

GA-UR/GM 1024 

GA-SBX/PM 128 

Reward (f) Reacher 0.00 1.00 2.00 3.00 4.00 

HV Value Ã—10 6

0.00 0.80 1.60 2.40 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

RVEA 8192 

IBEA 8192 

LMOCSO 8192 

SPEA2 128 

MOEA/D 128 

NSGA-III 1024 

HypE 8192 

NSGA-II 8192 (g) MoReacher 4.40 4.60 4.80 5.00 

HV Value Ã—10 4

0.00 1.00 2.00 3.00 4.00 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

RVEA 8192 

IBEA 1024 

NSGA-II 8192 

MOEA/D 8192 

SPEA2 8192 

LMOCSO 1024 

HypE 1024 

NSGA-III 8192 (h) MoSwimmer 2.50 2.75 3.00 3.25 3.50 3.75 

Ã—10 2

0.00 1.00 2.00 3.00 4.00 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

DE 8192 

SaDE 8192 

CSO 8192 

IPOP-CMA-ES 8192 

PSO 8192 

GA-UR/GM 128 

CMA-ES 8192 

GA-SBX/PM 128 

Reward 

(i) Swimmer 2.00 2.40 2.80 3.20 3.60 

HV Value Ã—10 5

0.00 1.50 3.00 4.50 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

RVEA 8192 

IBEA 8192 SPEA2 8192 

MOEA/D 8192 

NSGA-II 8192 

LMOCSO 1024 

NSGA-III 8192 

HypE 1024 (j) MoWalker2d 

Fig. 23: Performance comparison of EAs tested on neuroevolution tasks under varying population sizes with an NVIDIA RTX-3090 GPU, evaluated in terms of solution quality and number of FEs completed within 600 seconds. Higher reward/HV value denote better performance. Results represent averaged performance values across 10 independent runs. Marker styles indicate population scales: hollow symbols for small populations (128), forward-slash-filled symbols for medium populations (1024), and solid symbols for large populations (8192). Different marker shapes distinguish between algorithms. BARE DEMO OF IEEETRAN.CLS FOR IEEE JOURNALS 28 PSO CSO DE SaDE GA-SBX/PM GA-UR/GM CMA-ES IPOP-CMA-ES HypE IBEA RVEA MOEA/D NSGA-II NSGA-III SPEA2 LMOCSO 0.60 1.20 1.80 2.40 3.00 

Ã—10 3

0.00 0.60 1.20 1.80 2.40 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

Reward 

DE 8192 

CMA-ES 8192 

PSO 8192 

SaDE 8192 

GA-UR/GM 819 2

GA-SBX/PM 819 2IPOP-CMA-ES 8192 

CSO 8192 

(a) Halfcheetah 0.20 0.40 0.60 0.80 1.00 

Ã—10 3

0.00 2.00 4.00 6.00 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

Reward 

DE 8192 

CMA-ES 8192 

PSO 8192 

SaDE 8192 GA-UR/GM 1024 GA-SBX/PM 819 2

IPOP-CMA-ES 1024 CSO 8192 (b) Hopper 0.84 0.90 0.96 1.02 1.08 1.14 

HV Value Ã—10 6

0.00 0.40 0.80 1.20 1.60 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

HypE 8192 

IBEA 8192 

RVEA 8192 

LMOCSO 8192 

MOEA/D 8192 

NSGA-III 8192 

NSGA-II 8192 

SPEA2 8192 (c) MoHopper-m2 1.20 1.30 1.40 1.50 1.60 

HV Value Ã—10 10 

0.00 0.60 1.20 1.80 2.40 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 8192 

IBEA 8192 

RVEA 8192 

LMOCSO 8192 

NSGA-II 1024 

NSGA-III 1024 

MOEA/D 8192 HypE 8192 (d) MoHopper-m3 9.00 8.50 8.00 7.50 7.00 

Ã—10 2

0.00 0.60 1.20 1.80 2.40 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

Reward 

DE 8192 

CSO 8192 PSO 8192 

SaDE 8192 

GA-UR/GM 819 2

GA-SBX/PM 819 2IPOP-CMA-ES 8192 CMA-ES 8192 

(e) Pusher 1.00 0.75 0.50 0.25 0.00 

Ã—10 3

0.00 0.60 1.20 1.80 2.40 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

Reward 

DE 8192 

CSO 8192 PSO 8192 

SaDE 1024

GA-UR/GM 1024 

GA-SBX/PM 819 2

IPOP-CMA-ES 8192 

CMA-ES 1024 (f) Reacher 0.00 1.00 2.00 3.00 4.00 

HV Value Ã—10 6

0.00 0.60 1.20 1.80 2.40 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

IBEA 1024 

RVEA 8192 

LMOCSO 8192 

NSGA-II 8192 

NSGA-III 8192 

MOEA/D 8192 

HypE 1024 

SPEA2 1024 (g) MoReacher 4.75 5.00 5.25 5.50 5.75 

HV Value Ã—10 4

0.00 0.40 0.80 1.20 1.60 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 8192 IBEA 8192 RVEA 8192 

LMOCSO 8192 

MOEA/D 8192 

NSGA-III 8192 

NSGA-II 1024 

HypE 8192 (h) MoSwimmer 2.40 2.70 3.00 3.30 3.60 

Ã—10 2

0.00 1.00 2.00 3.00 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

Reward 

DE 8192 

CMA-ES 8192 

PSO 8192 

SaDE 8192 

GA-UR/GM 819 2

GA-SBX/PM 819 2

IPOP-CMA-ES 128 

CSO 8192 

(i) Swimmer 3.00 3.60 4.20 4.80 5.40 6.00 

HV Value Ã—10 5

0.00 1.50 3.00 4.50 

> Number of FEs

Ã—10 5

Population Size = 8192 Population Size = 1024 Population Size = 128 

SPEA2 8192 

IBEA 8192 

RVEA 8192 

LMOCSO 1024 

NSGA-II 8192 

NSGA-III 8192 

MOEA/D 8192 

HypE 8192 (j) MoWalker2d 

Fig. 24: Performance comparison of EAs tested on neuroevolution tasks under varying population sizes with an NVIDIA RTX-2080-Ti GPU, evaluated in terms of solution quality and number of FEs completed within 600 seconds. Higher reward/HV value denote better performance. Results represent averaged performance values across 10 independent runs. Marker styles indicate population scales: hollow symbols for small populations (128), forward-slash-filled symbols for medium populations (1024), and solid symbols for large populations (8192). Different marker shapes distinguish between algorithms.