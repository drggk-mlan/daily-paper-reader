# Martingale Foresight Sampling: A Principled Approach to Inference-Time LLM Decoding
# 鞅前瞻采样：一种基于原理的大语言模型推理时解码方法

**Authors**: Huayu Li, ZhengXiao He, Siyuan Tian, Jinghao Wen, Ao Li \\
**Date**: 2026-01-21 \\
**PDF**: https://arxiv.org/pdf/2601.15482v1 \\
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-pink">keyword:LNS</span> <span class="tag-label tag-pink">keyword:EAA</span> \\
**Score**: 6.0 \\
**Evidence**: principled approach to search space pruning and path valuation \\

---

## Abstract
Standard autoregressive decoding in large language models (LLMs) is inherently short-sighted, often failing to find globally optimal reasoning paths due to its token-by-token generation process. While inference-time strategies like foresight sampling attempt to mitigate this by simulating future steps, they typically rely on ad-hoc heuristics for valuing paths and pruning the search space. This paper introduces Martingale Foresight Sampling (MFS), a principled framework that reformulates LLM decoding as a problem of identifying an optimal stochastic process. By modeling the quality of a reasoning path as a stochastic process, we leverage Martingale theory to design a theoretically-grounded algorithm. Our approach replaces heuristic mechanisms with principles from probability theory: step valuation is derived from the Doob Decomposition Theorem to measure a path's predictable advantage, path selection uses Optional Stopping Theory for principled pruning of suboptimal candidates, and an adaptive stopping rule based on the Martingale Convergence Theorem terminates exploration once a path's quality has provably converged. Experiments on six reasoning benchmarks demonstrate that MFS surpasses state-of-the-art methods in accuracy while significantly improving computational efficiency. Code will be released at https://github.com/miraclehetech/EACL2026-Martingale-Foresight-Sampling.

## 摘要
大语言模型（LLMs）中标准的自回归解码本质上是短视的，由于其逐标记（token-by-token）的生成过程，往往无法找到全局最优的推理路径。虽然前瞻采样等推理时策略试图通过模拟未来步骤来

---

## 速览摘要（自动生成）

**问题**：LLM自回归解码存在短视性，且现有前瞻采样方法依赖启发式规则，缺乏理论支撑。

**方法**：提出MFS框架，利用鞅论将解码建模为随机过程，通过Doob分解评估路径价值，结合停时定理进行剪枝，并依据收敛定理实现自适应停止。

**结论**：在六项推理任务中显著提升了准确率与计算效率。