# Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial Optimization Problems
# 采用部分停用机制增强基于概率比特的模拟退火算法在处理大规模组合优化问题时的收敛性

**Authors**: Naoya Onizawa, Takahiro Hanyu \\
**Date**: 2026-01-22 \\
**PDF**: https://arxiv.org/pdf/2601.15561v1 \\
**Tags**: <span class="tag-label tag-blue">精读区</span> <span class="tag-label tag-pink">keyword:LNS</span> <span class="tag-label tag-pink">keyword:EOH</span> <span class="tag-label tag-pink">keyword:EAA</span> \\
**Score**: 8.0 \\
**Evidence**: improving simulated annealing for large-scale optimization relates to neighborhood search and heuristic evolution \\

---

## Abstract
This article critically investigates the limitations of the simulated annealing algorithm using probabilistic bits (pSA) in solving large-scale combinatorial optimization problems. The study begins with an in-depth analysis of the pSA process, focusing on the issues resulting from unexpected oscillations among p-bits. These oscillations hinder the energy reduction of the Ising model and thus obstruct the successful execution of pSA in complex tasks. Through detailed simulations, we unravel the root cause of this energy stagnation, identifying the feedback mechanism inherent to the pSA operation as the primary contributor to these disruptive oscillations. To address this challenge, we propose two novel algorithms, time average pSA (TApSA) and stalled pSA (SpSA). These algorithms are designed based on partial deactivation of p-bits and are thoroughly tested using Python simulations on maximum cut benchmarks that are typical combinatorial optimization problems. On the 16 benchmarks from 800 to 5,000 nodes, the proposed methods improve the normalized cut value from 0.8% to 98.4% on average in comparison with the conventional pSA.

## 摘要
本文深入研究了基于概率比特的模拟退火算法（pSA）在解决大规模组合优化问题时的局限性。研究首先对 pSA 过程进行了深入分析，重点关注概率比特

---

## 论文详细总结（自动生成）

这篇论文由日本东北大学的研究团队撰写，重点探讨了如何改进基于概率比特（p-bit）的模拟退火算法，以解决大规模组合优化问题。以下是对该论文的结构化总结：

### 1. 核心问题与整体含义
*   **研究动机**：组合优化问题（如 MAX-CUT）通常是 NP-hard 的。基于概率比特的模拟退火（pSA）因其能够并行更新节点，理论上比传统串行模拟退火（SA）更快。
*   **核心问题**：研究发现，当问题规模扩大时，传统的 pSA 效果极差。其根本原因在于并行更新机制引发了 p-bit 之间的**非预期振荡**（Oscillations），导致 Ising 模型的能量无法下降，陷入停滞状态。
*   **研究目标**：通过引入“部分停用”机制来抑制振荡，提升算法在大规模问题上的收敛性和求解质量。

### 2. 方法论
论文提出了两种改进算法，核心思想是通过非线性处理打破同步更新带来的反馈环路：
*   **时间平均 pSA (TApSA)**：
    *   **核心思想**：借鉴随机计算（Stochastic Computing）的概念。
    *   **技术细节**：不再直接使用瞬时输入，而是计算输入信号在特定时间窗口（$\alpha$）内的平均值。这相当于一个低通滤波器，能够平滑信号并滤除高频振荡。
*   **停滞 pSA (SpSA)**：
    *   **核心思想**：引入概率性的更新延迟。
    *   **技术细节**：每个 p-bit 在每一轮更新时，有概率 $p$ 保持上一时刻的状态而不进行更新（即“停滞”）。这种随机的局部停用破坏了全局同步振荡的条件。
*   **超参数确定**：使用统计方法（基于局部能量分布）来确定伪逆温度 $I_0$ 的初值、终值和变化率 $\beta$。

### 3. 实验设计
*   **实验场景**：最大剪切问题（MAX-CUT）和图同构问题（GI）。
*   **数据集（Benchmark）**：
    *   **G-set**：包含 800 到 5000 个节点的随机图、平面图和环形图（如 G1, G22, G58 等）。
    *   **K2000**：2000 个节点的全连接图。
*   **对比方法**：
    *   传统模拟退火（SA, Kirkpatrick 等提出）。
    *   传统概率比特模拟退火（pSA）。
    *   GPU 异步并行算法。
    *   相干 Ising 机（CIM/SimCIM）。

### 4. 资源与算力
*   **硬件环境**：Apple M1 Ultra 芯片，配有 128 GB 内存。
*   **软件环境**：Python 3.11。
*   **算力说明**：论文未提及多卡并行或超算集群，所有模拟均在单台工作站上完成。实验记录了不同参数（$\alpha, p$）下的模拟耗时，指出 TApSA 和 SpSA 虽然增加了少量计算开销，但在高循环次数下影响较小。

### 5. 实验数量与充分性
*   **实验规模**：针对 16 个不同的 Benchmark 进行了测试，涵盖了从 800 到 5000 节点的多种拓扑结构。
*   **重复性**：每组实验均独立运行 **100 次**，并统计最小、平均和最大剪切值，以排除随机性干扰。
*   **消融/参数研究