# Towards Automated Kernel Generation in the Era of LLMs
# 迈向大语言模型时代的自动化算子生成

**Authors**: Yang Yu, Peiyu Zang, Chi Hsu Tsai, Haiming Wu, Yixin Shen, Jialing Zhang, Haoyu Wang, Zhiyou Xiao, Jingze Shi, Yuyu Luo, Wentao Zhang, Chunlei Men, Guang Liu, Yonghua Lin \\
**Date**: 2026-01-22 \\
**PDF**: https://arxiv.org/pdf/2601.15727v1 \\
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-pink">keyword:EAA</span> \\
**Score**: 7.0 \\
**Evidence**: Automates kernel generation and optimization using iterative feedback-driven agentic loops \\

---

## Abstract
The performance of modern AI systems is fundamentally constrained by the quality of their underlying kernels, which translate high-level algorithmic semantics into low-level hardware operations. Achieving near-optimal kernels requires expert-level understanding of hardware architectures and programming models, making kernel engineering a critical but notoriously time-consuming and non-scalable process. Recent advances in large language models (LLMs) and LLM-based agents have opened new possibilities for automating kernel generation and optimization. LLMs are well-suited to compress expert-level kernel knowledge that is difficult to formalize, while agentic systems further enable scalable optimization by casting kernel development as an iterative, feedback-driven loop. Rapid progress has been made in this area. However, the field remains fragmented, lacking a systematic perspective for LLM-driven kernel generation. This survey addresses this gap by providing a structured overview of existing approaches, spanning LLM-based approaches and agentic optimization workflows, and systematically compiling the datasets and benchmarks that underpin learning and evaluation in this domain. Moreover, key open challenges and future research directions are further outlined, aiming to establish a comprehensive reference for the next generation of automated kernel optimization. To keep track of this field, we maintain an open-source GitHub repository at https://github.com/flagos-ai/awesome-LLM-driven-kernel-generation.

## 摘要
现代人工智能系统的性能从根本上受限于其底层算子的质量，

---

## 速览摘要（自动生成）

**问题**：算子内核开发高度依赖专家经验，耗时且难以扩展，且该领域缺乏系统性综述。

**方法**：本文对基于大模型（LLM）及智能体（Agent）的内核生成与优化方法进行系统综述，涵盖数据集、基准测试及反馈驱动的优化工作流。

**结论**：为自动化内核优化建立了全面参考框架，并指明了未来研究方向。